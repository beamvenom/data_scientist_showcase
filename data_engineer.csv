id,title,name,requirements,tasks,text,pageUrl
JOB21015061843,"Results for ""Data Engineer Jobs in New York, United States""","Results for ""Data Engineer Jobs in New York, United States""",,,,https://www.linkedin.com/jobs/data-engineer-jobs-new-york-ny
JOB21689607496,"Results for ""Data Engineer Jobs in Portland, Oregon Metropolitan Area""","Results for ""Data Engineer Jobs in Portland, Oregon Metropolitan Area""",,,,https://www.linkedin.com/jobs/data-engineer-jobs-portland-oregon-metropolitan-area
JOB32335439175,Staff Data Engineer,Staff Data Engineer,,,"About Us
Venmo was founded on the principles of breaking down the intimidating barriers around financial transactions to make them intuitive, friendly, and even fun. And it worked: people love sending money with Venmo, and we’re growing by leaps and bounds!
But we’re only just getting started. We want to take that magic of sending money with Venmo and cascade it into every place where people use money. That means connecting people to their money in the most intuitive and fun way possible, then connecting people with each other. Users already love Venmo, but we know there are lots of things we haven’t thought of to make the experience of using Venmo even more delightful and valuable. All that’s going to take a lot of figuring out. Let’s figure it out together!
At Venmo, we are creating a product that people love. We strive to create a delightful user experience while connecting the world and empowering people through payments. We are looking for intellectually curious people who want to be inspired and inspire others to change the world. Engineering is a craft, and at Venmo we want the internals of our software to be as elegant as the end user experience we are designing. We spend our days scaling our capacities and building new features to meet and exceed our user’s needs and wants. We teach and learn from one another and push each other to be at our creative and analytical bests.
Applied Science team
Imagine what you could do here. Venmo is the fastest growing peer-to-peer financial brand and keeps innovating in the tech industry. We as Venmo Applied Science team are looking for talented Staff Data Engineer to join us and build creative next generation of data products and high-velocity AI services. We derive valuable insights from our extensive, rich and rapidly growing datasets in order to improve customer daily experience. This role is critical to the engineering team and will be deeply embedded within multi-disciplinary teams across the company.
You will join the team that interacts with Data Scientists, Data Engineers and Machine Learning Engineers to embrace rich data into Machine Learning as a service. You will have the opportunity to take full stack ownership of design and implementation of highly reliable, scalable and high-performance products. You will drive appropriate technologies for the business, lead the way for continuous innovation and shape the future of e-commerce.
What We’re Looking For
Professional 5+ years of industry and academic experiences in a quantitative role with an advanced degree.
Advanced proficiency with SQL and highly skilled in at least one scripting language such as Python.
Expert in ETL, big data platforms and tooling (AWS, Snowflake, Kafka, Luigi, Hadoop, Hive, Spark, Cassandra, Airflow, etc).
Strong fundamentals of data structures, algorithms and design patterns.
Familiarity with statistics and mathematical analysis, prior experience in data visualization tools such as Tableau or Looker is plus.
Build, forecast, and report on metrics that drive strategy and facilitate decision making for key business initiatives.
Passion and intellectual curiosity for the FinTech domain.
Comfortable in working in ambiguous, fast-paced and high-growth dynamic environment.
Excellent written and verbal communication to take ownership of meeting with cross-functional team leads on a regular basis.
We know the confidence gap and imposter syndrome can get in the way of meeting spectacular candidates. Please don't hesitate to apply.
Industries
Computer SoftwareInternetFinancial Services
",https://www.linkedin.com/jobs/view/staff-data-engineer-at-venmo-2351006152?refId=d12bb5b9-dbc2-4d10-811c-235676b93818&trackingId=4Emq2YQ3pzkp9dqDl%2BNPbA%3D%3D&position=5&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click
JOB47455872374,Senior Data Engineer - Customer Operations Data,Senior Data Engineer - Customer Operations Data,"Experience with end-to-end ETL work using Python and SQL,Strong systems design knowledge; you know how to architect data pipelines and how storage and compute fits together,Prior experience making large datasets accessible; familiarity with Hive, Presto and parquet is a plus,Experience with compute frameworks and job orchestration systems,Experience with Google Cloud Platform a plus,4+ years of industry experience,Health insurance with 100% premium covered for you and your dependent children,Flexible vacation & paid time off,Up to 20 weeks of paid family leave,Equity plan for all employees,Retirement benefits with employer match,Fertility and adoption benefits,Free lunch and snacks at all offices,Education reimbursement,Dog-friendly workplace in New York office,Commuter benefit in the form of reduced tax (Ireland) and pretax (US)","Build end-to-end data pipelines, consuming from a variety of sources,Work with data consumers to identify self-service opportunities, and make sure they have access to the data they need to make decisions.,Help guide the team towards data best practices, and mentor teammates.,Contribute to a technical roadmap for the CustOps data program, and set priorities for work across the team,Build and refine processes to make pipeline implementations faster, simpler, and less error-prone for product engineers,Participate in architectural decisions across the organization, particularly with respect to the impact on data collection,Set timeliness and correctness goals for our data pipelines, maintain sufficient monitoring & coverage to ensure that incidents and outages are mitigated appropriately","Squarespace’s Customer Operations Data Engineering team is responsible for writing and maintaining pipelines that enhance customer service’s ability to effectively support Squarespace customers and better understand where users struggle with the product.
In this role, you’ll be part of a small team focused on implementation and working to improve data ingestion across tools that drive critical decisions by CustOps leadership, while working towards enabling more self-service data usage across the department.
Responsibilities
Build end-to-end data pipelines, consuming from a variety of sources
Work with data consumers to identify self-service opportunities, and make sure they have access to the data they need to make decisions.
Help guide the team towards data best practices, and mentor teammates.
Contribute to a technical roadmap for the CustOps data program, and set priorities for work across the team
Build and refine processes to make pipeline implementations faster, simpler, and less error-prone for product engineers
Participate in architectural decisions across the organization, particularly with respect to the impact on data collection
Set timeliness and correctness goals for our data pipelines, maintain sufficient monitoring & coverage to ensure that incidents and outages are mitigated appropriately
Qualifications
Experience with end-to-end ETL work using Python and SQL
Strong systems design knowledge; you know how to architect data pipelines and how storage and compute fits together
Prior experience making large datasets accessible; familiarity with Hive, Presto and parquet is a plus
Experience with compute frameworks and job orchestration systems
Experience with Google Cloud Platform a plus
4+ years of industry experience
About Squarespace
Squarespace empowers people with creative ideas to succeed. By blending elegant design and sophisticated engineering, we empower millions of people — from individuals and local artists to entrepreneurs shaping the world’s most iconic businesses — to share their stories with the world. Squarespace’s team of more than 1300 is headquartered in downtown New York City, with offices in Dublin and Portland. For more information, visit www.squarespace.com/about.
Benefits & Perks
Health insurance with 100% premium covered for you and your dependent children
Flexible vacation & paid time off
Up to 20 weeks of paid family leave
Equity plan for all employees
Retirement benefits with employer match
Fertility and adoption benefits
Free lunch and snacks at all offices
Education reimbursement
Dog-friendly workplace in New York office
Commuter benefit in the form of reduced tax (Ireland) and pretax (US)
Today, more than a million people around the globe use Squarespace to share different perspectives and experiences with the world. Not only do we embrace and celebrate the diversity of our customer base, but we also strive for the same in our employees. At Squarespace, we are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, national origin, gender, sex, gender identity or expression, sexual orientation, age, citizenship, marital or parental status, disability, veteran status, or other class protected by applicable law. We are proud to be an equal opportunity workplace.
",https://www.linkedin.com/jobs/view/senior-data-engineer-customer-operations-data-at-squarespace-2311875709?refId=d9a19134-d2cb-4899-b726-d0f08d6f2554&position=8&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click
JOB49900758389,"Results for ""Data Engineer Jobs in San Diego, California, United States""","Results for ""Data Engineer Jobs in San Diego, California, United States""",,,,https://www.linkedin.com/jobs/data-engineer-jobs-san-diego-ca
JOB55518504303,Senior Data Engineer,Senior Data Engineer,,"Passionate about building a product with a positive impact on the world,5+ years professional experience as a software engineer or data engineer,Strong working knowledge of Python, Docker, Airflow (or a similar data workflow tool), and cloud computing concepts,Willing to learn new tools, languages, and patterns as needed to build a great product,A solid communicator who enjoys collaborating with other engineers, designers, PMs, and scientists","The Company‍
Sofar is on a mission to connect humanity to our world’s oceans. We collect data from a global network of distributed sensors to create the best marine weather forecasts. With more ocean data we help maritime customers to save fuel and reduce emissions. Our hardware and software platform gives researchers vital tools to understand the impact of climate change on commercial fisheries and coral reefs. Our goal is to provide critical ocean data and insights to anyone who lives near, or makes a living on the two-thirds of our planet that is covered by water.
The Position
We are looking for an experienced data engineer to refine and scale our weather forecast data pipeline. This pipeline combines realtime sensor readings from our worldwide fleet of ocean buoys, publicly available weather data sources, and our own proprietary forecast model into a variety of data products suitable for visualization and scientific analysis. In this role, you would be responsible for building out extensions to our current pipeline to scale and bring on board new data sources, as well as improve the reliability or existing pipeline where it supports mission-critical applications in production.
In this role, you would work alongside our software engineering team building out APIs and frontend applications that use our data, as well as domain experts in ocean science and other data scientists performing analysis on weather data. You will quickly learn that “the forecast” is a lot more complicated than it seems at first glance; our team works with multiple forecast models that each produce gigabytes of data every hour, at every location on the globe. Most of the industry-standard tools and data formats are optimized for an era of supercomputers, not cloud computing. We are looking for the right person who is up for the challenge of turning this data into something that can be indexed, filtered and queried efficiently across space and time.
Currently our stack is built with Apache Airflow, Docker & Kubernetes, Postgres/PostGIS, and AWS S3.
About You
Passionate about building a product with a positive impact on the world
5+ years professional experience as a software engineer or data engineer
Strong working knowledge of Python, Docker, Airflow (or a similar data workflow tool), and cloud computing concepts
Willing to learn new tools, languages, and patterns as needed to build a great product
A solid communicator who enjoys collaborating with other engineers, designers, PMs, and scientists
Excited to be be a part of a small but growing startup team
How to Apply
If this job aligns with your passion and experience, we would love to hear from you!
Visit our website and apply today!
Employee Conduct
It is the responsibility of every employee to contribute to a positive work environment through cooperative and professional interactions with co-workers, customers, and vendors.
Equal Employment Opportunity
All qualified applicants will receive consideration for employment without discrimination on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other factors prohibited by law.
Industries
Information Technology and Services
",https://www.linkedin.com/jobs/view/senior-data-engineer-at-sofar-ocean-2282697698
JOB60882150773,Data Engineer - Data Platform,Data Engineer - Data Platform,"Bachelor’s degree in computer science/software engineering or related fields with 3+ years of experience in data engineering,3+ years of experience working with Python, NodeJS,2+ years of experience working with Kafka based pipeline development,Strong knowledge of SQL is required,1+ year of hands-on experience with Apache Airflow,Experience with distributed computing using Hadoop ecosystem, Spark, Presto.,Knowledge of Java, Scala,Knowledge of Kafka connect ecosystem","Build and manage Kafka based streaming data pipelines,Build and manage Airflow based ETLs,Monitor and improve performance of the pipelines,Develop storage layer (relational / non-relational) for hosting data for analytical queries","Tesla is looking for a talented data engineer with experience working with the highly transactional and scalable data platform. We are working on architecture to support analytics on Tesla’s complex business applications suite. With this architecture, our business users should be able to get “What”, “When” and “how” answered much faster and help them to take data driven decisions
Responsibilities
Build and manage Kafka based streaming data pipelines
Build and manage Airflow based ETLs
Monitor and improve performance of the pipelines
Develop storage layer (relational / non-relational) for hosting data for analytical queries
Work on fast pace projects to deliver innovative solutions for our business users
Requirements
Bachelor’s degree in computer science/software engineering or related fields with 3+ years of experience in data engineering
3+ years of experience working with Python, NodeJS
2+ years of experience working with Kafka based pipeline development
Strong knowledge of SQL is required
1+ year of hands-on experience with Apache Airflow
Ability to debug production issues using tools like Grafana, Splunk or server logs
Nice to have
Experience with distributed computing using Hadoop ecosystem, Spark, Presto.
Knowledge of Java, Scala
Knowledge of Kafka connect ecosystem
Experience with Docker, Kubernetes
",https://www.linkedin.com/jobs/view/data-engineer-data-platform-at-tesla-2314382738?refId=1177ff47-28db-4659-ae5c-48e0ca19e540&trackingId=CVdTAl9I7tEPL2Ej2NN%2BSg%3D%3D
JOB75074692436,"5,000+Results for ""Data Engineer Jobs in San Jose, California, United States""(351 new)","5,000+Results for ""Data Engineer Jobs in San Jose, California, United States""(351 new)",,,,https://www.linkedin.com/jobs/data-engineer-jobs-san-jose-ca
JOB76827990985,Scientific Data Engineer II - Image Processing and Registration - Neural Circuits and Behavior,Scientific Data Engineer II - Image Processing and Registration - Neural Circuits and Behavior,,"Collaborate with neuroscientists and engineers to develop methods and workflows for image processing, registration, and alignment,Build and support pipelines for analysis of imaging datasets across multiple modalities,Contribute to open-source codebases in a collaborative manner,Produce well-documented, modular code that is useable and interpretable by research scientists,Participate in code review, scientific discussions, and project planning,Bachelor’s in software engineering, computer science, bioengineering, computational neuroscience, bioinformatics or related field or equivalent combination of degree and experience,Minimum 1 year of relevant experience post bachelor’s degree,Demonstrated excellent Python programming skills,Experience building, documenting, and maintaining a modular system,Experience with microscopy, image processing or image registration,Excellent organizational and interpersonal skills,Ability to manage time and independently complete tasks to meet deadlines,Strong work ethic, reliable and enthusiastic team player,Bachelor’s degree and 2 – 4 years of professional experience in software development, optical engineering, microscopy, bioengineering or related discipline,Experience working in a scientific research environment,Experience with machine vision and/or machine learning,Experience contributing to open-source codebases,Experience producing data visualizations and data dashboards,Please note, this opportunity offers relocation assistance,Please note, this opportunity offers work visa sponsorship","Data Scientist II (Scientific Data Engineer) – Imaging Processing and Registration – Neural Circuits and Behavior
The mission of the Allen Institute is to unlock the complexities of bioscience and advance our knowledge to improve human health. Using an open science, multi-scale, team-oriented approach, the Allen Institute focuses on accelerating foundational research, developing standards and models, and cultivating new ideas to make a broad, transformational impact on science.
The MindScope program seeks to understand the transformations, sometimes called computations, in coding and decoding that lead from photons to behavior and conscious experience by observing, perturbing, and modeling the physical transformations of signals in the cortical-thalamic visual system within a few perception-action cycles.
We are seeking a Scientific Data Engineer to be an integral member of a team investigating the role of neural circuits in learning and behavior. The primary role of this Engineer will be to develop and maintain tools for processing, registration and analysis of image-based data acquired using 2-photon microscopy, epifluorescence microscopy, and light sheet fluorescence microscopy. This Engineer will collaborate with Scientists to develop robust, standardized workflows that will support large-scale data collection and analysis. This will involve building new tools as well as contributing to existing open source codebases for analysis of neural data (ex: https://github.com/AllenInstitute/AllenSDK) and spatial transcriptomics (ex: https://spacetx-starfish.readthedocs.io/en/latest/).
The ideal candidate will have strong software engineering skills, experience working with imaging data, and experience or interest in neuroscientific research. As part of a highly collaborative team environment, good communication and enthusiasm for working with, learning from, and teaching others is essential to this role.
The datasets and tools created as part of this project will be publicly released as an open resource for the community, in line with the Allen Institute’s core principles of big science, open science and team science.
The Allen Institute believes that team science significantly benefits from the participation of diverse voices, experiences, and backgrounds. High-quality science can only be produced when it includes different perspectives. We are committed to increasing diversity across every team and encourage people from all backgrounds to apply for this role.
Essential Functions
Collaborate with neuroscientists and engineers to develop methods and workflows for image processing, registration, and alignment
Build and support pipelines for analysis of imaging datasets across multiple modalities
Contribute to open-source codebases in a collaborative manner
Produce well-documented, modular code that is useable and interpretable by research scientists
Participate in code review, scientific discussions, and project planning
Required Education and Experience
Bachelor’s in software engineering, computer science, bioengineering, computational neuroscience, bioinformatics or related field or equivalent combination of degree and experience
Minimum 1 year of relevant experience post bachelor’s degree
Demonstrated excellent Python programming skills
Experience building, documenting, and maintaining a modular system
Experience with microscopy, image processing or image registration
Excellent organizational and interpersonal skills
Ability to manage time and independently complete tasks to meet deadlines
Strong work ethic, reliable and enthusiastic team player
Preferred Education and Experience
Bachelor’s degree and 2 – 4 years of professional experience in software development, optical engineering, microscopy, bioengineering or related discipline
Experience working in a scientific research environment
Experience with machine vision and/or machine learning
Experience contributing to open-source codebases
Experience producing data visualizations and data dashboards
Physical Demands
Fine motor movements in fingers/hands to operate computers and other office equipment
Position Type/Expected Hours of Work
This role is currently able to work remotely due to COVID-19 and our focus on employee safety. We are a Washington State employer, and remote work must be performed in Washington State. We continue to evaluate the safest options for our employees. As restrictions are lifted in relation to COVID-19, this role will return to work onsite.
Additional Comments
Please note, this opportunity offers relocation assistance
Please note, this opportunity offers work visa sponsorship
It is the policy of the Allen Institute to provide equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state, or local law. In addition, the Allen Institute will provide reasonable accommodations for qualified individuals with disabilities.
",https://www.nature.com/naturecareers/job/scientific-data-engineer-ii-image-processing-and-registration-neural-circuits-and-behavior-allen-institute-for-brain-science-744917
JOB86723011949,"20,000+Results for ""Senior Data Engineer Jobs in United States""(929 new)","20,000+Results for ""Senior Data Engineer Jobs in United States""(929 new)","Must have a minimum of 2 years of Cyber Security Engineering experience, to include application of cyber security methodologies in an Enterprise environment,Must have experience with the following Security Frameworks: NIST 800-171r2,Candidates must have the ability to obtain, an maintain, a DOD Secret level security clearance as a condition of continued employment Preferred Qualifications: Certifications/Degrees,The ideal candidate will have a Master's degree in an STEM related discipline, and 6 years of experience with Cyber Security Engineering,Professional/technical certifications: CISSP, CISM, CCSP, Security Plus, AWS Certified Security - Specialty, AWS Certified Solutions Architect, Azure Security Engineer, Azure Solutions Architect,DoD 8570 IAT/IAM Level II or III certificationSecurity Skills,Senior-level cyber security engineering and architecture experience,Experience with interpreting and implementing security compliance standards and guidance including Governance, Risk & Compliance (GRC) policies and procedures, NIST 800-171 security control framework,Experience in areas such as system security, network, and application security,Knowledge of current and emerging cyber security threats, vulnerabilities, and controls,Contributor for architectural/industry changes in the area of cyber securityTechnical Skills,Experience with evaluating, designing, configuring, implementing cloud services models such as SaaS, PaaS, and IaaS,Experience with Linux and Windows operating systems,Experience with operating in an Agile/DevOps environment,Experience with Scripting,Knowledge of application program interface (API) and ability to manipulate API's to integrate different toolsets,Advanced knowledge in cybersecurity principles, networking, architecture, servers, systems design, virtual hosts, configuration management, Identity and Access Management, encryption, intrusion detection systems (IDS) and intrusion prevention systems (IPS),Experience in supporting the deployment, configuring, managing, and maintaining any of the below technologies:,Directory Services and Centralized Authentication, such as Active Directory or Red Hat,Identity Manager Vulnerability scanning and management of databases, operating systems, and/or web applications,IDS/IPS and anti-malware tools/technologiesProcess Skills,Experience with Agile, Scrum and Application Lifecycle Management (ALM),Experience operating in an Agile/DevOps environmentSoft skills,Exceptional verbal and written communications.,Quickly learn and adapt to new and changing business/technical concepts, requirements, skills, tools,Goal-oriented team player committed to quality and detail,Proven track record of driving decisions collaboratively, resolving conflicts and ensuring follow-through,Innovative and strategic thinker who is positive, proactive and readily embraces change","Design and engineer solutions that meets business requirements, cyber security practices, and compliance regulations * Provide security guidance in compliance with NIST 800-171r2 and Cyber Maturity Model Certification (CMMC) * Asses technical designs and identify security design gaps in existing and proposed architectures,Identify and communicate current and emerging security threats,Identify risks and provide guidance regarding remediation of gaps to facilitate a hardened and sustainable solutions,Take ownership of solutions, assignments, actions items and issues, and remain accountable for their completion,Work effectively with other team members, customers and key stakeholders and foster team success,Communicate and collaborate with leadership and technical teams to include systems and network administrators, security engineers, and IT Support teams,Security and risk assessments for services, applications, hardware and systems","Responsibilities
Transforming the future of technology ... Northrop Grumman Enterprise Services is seeking senior level Cyber Security Engineer to join the Information Security team supporting its mission of defending and protecting the company's networks, systems, data, intellectual property and personal information wherever it resides. Experience with security engineering is key for this role.
Design and engineer solutions that meets business requirements, cyber security practices, and compliance regulations * Provide security guidance in compliance with NIST 800-171r2 and Cyber Maturity Model Certification (CMMC) * Asses technical designs and identify security design gaps in existing and proposed architectures
Identify and communicate current and emerging security threats
Identify risks and provide guidance regarding remediation of gaps to facilitate a hardened and sustainable solutions
Take ownership of solutions, assignments, actions items and issues, and remain accountable for their completion
Work effectively with other team members, customers and key stakeholders and foster team success
Communicate and collaborate with leadership and technical teams to include systems and network administrators, security engineers, and IT Support teams
Security and risk assessments for services, applications, hardware and systems
Work with the Sector Chief Information Security Officer on a regular basis to provide security recommendations for approval.This position will have the ability to work virtually (from a home office) for the foreseeable future. However, the person will eventually be required to work at our Linthicum, MD facility (local candidates are preferred). Additionally, there will be occasional travel to various Northrop Grumman facilities across the country. Come join us on the edge ... the cutting edge! ESCSO
NGFeaturedJobs Qualifications: Basic Qualifications: * PhD with 0 years of IT experience; OR a Master's Degree with 3 years of IT experience; OR a Bachelor's Degree with 5 years of IT experience; OR an Associates degree with 7 years of IT experience; OR a High School Diploma with 9 years of IT experience is required
Must have a minimum of 2 years of Cyber Security Engineering experience, to include application of cyber security methodologies in an Enterprise environment
Must have experience with the following Security Frameworks: NIST 800-171r2
Candidates must have the ability to obtain, an maintain, a DOD Secret level security clearance as a condition of continued employment Preferred Qualifications: Certifications/Degrees
The ideal candidate will have a Master's degree in an STEM related discipline, and 6 years of experience with Cyber Security Engineering
Professional/technical certifications: CISSP, CISM, CCSP, Security Plus, AWS Certified Security - Specialty, AWS Certified Solutions Architect, Azure Security Engineer, Azure Solutions Architect
DoD 8570 IAT/IAM Level II or III certificationSecurity Skills
Senior-level cyber security engineering and architecture experience
Experience with interpreting and implementing security compliance standards and guidance including Governance, Risk & Compliance (GRC) policies and procedures, NIST 800-171 security control framework
Experience in areas such as system security, network, and application security
Knowledge of current and emerging cyber security threats, vulnerabilities, and controls
Contributor for architectural/industry changes in the area of cyber securityTechnical Skills
Experience with evaluating, designing, configuring, implementing cloud services models such as SaaS, PaaS, and IaaS
Experience with Linux and Windows operating systems
Experience with operating in an Agile/DevOps environment
Experience with Scripting
Knowledge of application program interface (API) and ability to manipulate API's to integrate different toolsets
Advanced knowledge in cybersecurity principles, networking, architecture, servers, systems design, virtual hosts, configuration management, Identity and Access Management, encryption, intrusion detection systems (IDS) and intrusion prevention systems (IPS)
Experience in supporting the deployment, configuring, managing, and maintaining any of the below technologies:
Directory Services and Centralized Authentication, such as Active Directory or Red Hat
Identity Manager Vulnerability scanning and management of databases, operating systems, and/or web applications
IDS/IPS and anti-malware tools/technologiesProcess Skills
Experience with Agile, Scrum and Application Lifecycle Management (ALM)
Experience operating in an Agile/DevOps environmentSoft skills
Exceptional verbal and written communications.
Quickly learn and adapt to new and changing business/technical concepts, requirements, skills, tools
Goal-oriented team player committed to quality and detail
Proven track record of driving decisions collaboratively, resolving conflicts and ensuring follow-through
Innovative and strategic thinker who is positive, proactive and readily embraces change
Demonstrated ability to explain technical details to a non-technical audienceNorthrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.
",https://www.linkedin.com/jobs/senior-data-engineer-jobs
JOB93502989646,"1,000+Results for ""Senior Data Engineer Jobs in San Francisco, California, United States""(90 new)","1,000+Results for ""Senior Data Engineer Jobs in San Francisco, California, United States""(90 new)",,,,https://www.linkedin.com/jobs/senior-data-engineer-jobs-san-francisco-ca
JOB96768894321,"Results for ""Data Engineer Jobs in Redwood City, California, United States""","Results for ""Data Engineer Jobs in Redwood City, California, United States""",,,,https://www.linkedin.com/jobs/data-engineer-jobs-redwood-city-ca
JOB101309146488,"Results for ""Data Engineer Jobs in Menlo Park, California, United States""","Results for ""Data Engineer Jobs in Menlo Park, California, United States""",,,,https://www.linkedin.com/jobs/data-engineer-jobs-menlo-park-ca
JOB106187744636,"Results for ""Data Engineer Jobs in Chicago, Illinois, United States""","Results for ""Data Engineer Jobs in Chicago, Illinois, United States""",,,,https://www.linkedin.com/jobs/data-engineer-jobs-chicago-il
JOB117929649501,"4,000+Results for ""Data Engineer Jobs in Seattle, Washington, United States""(242 new)","4,000+Results for ""Data Engineer Jobs in Seattle, Washington, United States""(242 new)",,,,https://www.linkedin.com/jobs/data-engineer-jobs-seattle-wa
JOB136735843664,Apple Music - Software Data Engineer,Apple Music - Software Data Engineer,,,"Summary
This team is more than a group of engineers — it’s a group of music lovers. That passion has made Apple Music the world’s most complete music experience, with over 60 million songs, thousands of playlists, and daily selections from music experts for 115 countries.
The team’s data-driven engineers focus relentlessly on the customer experience by running worldwide experiments and analyzing usage and latency, while collaborating with Apple’s product groups. As a result, someone can use the Shazam app to identify an intriguing song in a café in the morning, add it to their playlist from Apple Watch, listen to it through their AirPods on their commute, and share it with their family on HomePod at dinnertime. And there’s more where that came from, because personalization powered by machine learning and music science helps listeners discover more of what they love. Apple Music is a big part of Apple’s business because it’s a big part of people’s lives. Areas of work: macOS/iOS Engineering, Full-Stack Engineering, Front-End Engineering, Back-End Engineering, Quality Engineering, Machine Learning Engineering, Data Science, Data Engineering, Site Reliability Engineering, Commerce Engineering, and Engineering Project Management.
Key Qualifications
Experience in designing, implementing and supporting highly scalable data systems and services in Java and/or Scala
Experience with Hadoop-ecosystem technologies in particular MapReduce, Spark / Spark-SQL / Spark Streaming, Hive, YARN/MR2
Experience building and running large-scale data pipelines, including distributed messaging such as Kafka, data ingest to/from multiple sources to feed batch and near-realtime/streaming compute components
Experience in data-modeling and data-architecture optimized for big data patterns, ie. warehousing concepts; efficient storage and query on HDFS; data security and privacy techniques)
Knowledgable about distributed storage and network resources, at the level of hosts, clusters and DCs, to troubleshoot and prevent performance issues
Experience with low-latency NoSQL datastores and traditional relational databases is desired
Description
Our Data Engineering team is seeking a hardworking, performance-savvy, engineer to build out the big data platform and services, which power many of these customer features — existing and new. You will be responsible for designing and implementing features that rely on processing and serving very large datasets with an awareness of scalability. This will include crafting systems to model, ingest, process and compute large-scale, mission-critical data across Apple Music. High-throughput and reliability are essential.
This is your opportunity to help engineer highly visible global-scale systems with petabytes of data, supporting hundreds of millions of users!
Education & Experience
Bachelors degree in Computer Science, or equivalent experience.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.
",https://www.linkedin.com/jobs/view/apple-music-software-data-engineer-at-apple-2349914514?refId=1a0fba25-5523-43f6-8d17-fbc1762b5d5f&trackingId=1Cu90vdsMHf1NHunShSgVg%3D%3D&position=4&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click
JOB180874569080,"Results for ""Data Engineer Jobs in Houston, Texas, United States""","Results for ""Data Engineer Jobs in Houston, Texas, United States""",,,,https://www.linkedin.com/jobs/data-engineer-jobs-houston-tx
JOB199018128731,Senior Data Engineer - Core Data,Senior Data Engineer - Core Data,,"Getting hands-on experience with Google Cloud Platform and technology/languages such as BigQuery, Scala, Scio, Luigi, Styx and Docker,Understand what fuels many of Spotify's product features such as Discover Weekly, Daily Mix, Podcast offerings, holiday campaigns and others,Work hand-in-hand with the data science community to understand various user or content trends that influence product changes and customer acquisition strategies,Collaboration on a global scale; our squad offers ongoing opportunities to work in Stockholm with other engineering colleagues,Innovate our data products to create a single coherent platform with sources of truth that serve a plethora of product and data stakeholders,Communicate insights and recommendations to key stakeholders, engineering, data science and product partners,Work in a supportive team that offers engineers the flexibility to be creative and chase interesting ideas,Work closely with the product manager, end-users and stakeholders to understand, document, troubleshoot and analyze requirements for complex data solutions,Lead and mentor engineers as we grow the bigger team,A BS/MS in CS or any other relevant fields of study,You have 5+ years of experience in the development of high-quality database and data solutions.,Strong analytical and problem solving ability,Have worked in a team with both Data Engineers and Data Scientists,You are capable of tackling very loosely defined problems and thrive when working on a team which has autonomy in their day to day decisions,You are a self-motivated individual contributor and great teammate with the ability to multitask, prioritize and communicate progress in a rapidly changing environment.,Would like to build skills to further enhance the t-shape within analytics and data engineering,Strong coding skills in preferably Scala, Java and Python,Strong communication and data presentation skills (such as Tableau, PowerPoint, Qlik, etc.),Experience performing analysis with large datasets in a cloud based-environment, preferably with an understanding of Google’s Cloud Platform,You are a communicative person that values building strong relationships with colleagues and multiple stakeholders, and have the ability to explain complex topics in simple terms","We are looking for a Senior Data Engineer to join a band within the organization responsible for company key metrics, insights and data. Our mission is to be the Center of Excellence for data and analytics engineering, and to turn billions of daily data points into insights and datasets that power key business decisions at Spotify.
As a Senior Data Engineer in D&M (Data & Metrics product area) you will join a team of data engineers responsible for maintaining and evolving some of the most critical datasets in the company, such as the ones that ultimately power our Discovery Weekly feature, our company key metrics, royalty calculations, financial forecasting & performance management and much more. You will design and implement data pipelines with requirements for scalability, availability and quality. This as well as be instrumental to setting the golden standards and engineering best practices for the rest of the data engineering community at Spotify. This role is based in NYC.
Description
Data and information has become an invaluable asset for technology companies that focus on innovation and are dedicated to providing a great user experience. Spotify is taking this concept to heart and driving a ""Data as a Product"" initiative for its own data consumers within the company. The volume and breadth of data at Spotify is staggering – trillions of records of streamed music, app interactions, artist information and user behavior trends flow through our platform on a daily basis. This squad and its product area are at the center of this initiative. You will partner with business and engineering teams to prioritize requests and consistently deliver value against time-sensitive priorities. If you have a desire to exhibit and grow your technical skills, and are motivated by working directly with stakeholders, product managers and engineers, then this is a great opportunity to join the band.
What You'll Do
Getting hands-on experience with Google Cloud Platform and technology/languages such as BigQuery, Scala, Scio, Luigi, Styx and Docker
Understand what fuels many of Spotify's product features such as Discover Weekly, Daily Mix, Podcast offerings, holiday campaigns and others
Work hand-in-hand with the data science community to understand various user or content trends that influence product changes and customer acquisition strategies
Collaboration on a global scale; our squad offers ongoing opportunities to work in Stockholm with other engineering colleagues
Innovate our data products to create a single coherent platform with sources of truth that serve a plethora of product and data stakeholders
Communicate insights and recommendations to key stakeholders, engineering, data science and product partners
Work in a supportive team that offers engineers the flexibility to be creative and chase interesting ideas
Work closely with the product manager, end-users and stakeholders to understand, document, troubleshoot and analyze requirements for complex data solutions
Lead and mentor engineers as we grow the bigger team
… and of course, having fun! Being passionate about what you do also means celebrating milestones within the team and the tribe!
Who You Are
A BS/MS in CS or any other relevant fields of study
You have 5+ years of experience in the development of high-quality database and data solutions.
Strong analytical and problem solving ability
Have worked in a team with both Data Engineers and Data Scientists
You are capable of tackling very loosely defined problems and thrive when working on a team which has autonomy in their day to day decisions
You are a self-motivated individual contributor and great teammate with the ability to multitask, prioritize and communicate progress in a rapidly changing environment.
Would like to build skills to further enhance the t-shape within analytics and data engineering
Strong coding skills in preferably Scala, Java and Python
Strong communication and data presentation skills (such as Tableau, PowerPoint, Qlik, etc.)
Experience performing analysis with large datasets in a cloud based-environment, preferably with an understanding of Google’s Cloud Platform
You are a communicative person that values building strong relationships with colleagues and multiple stakeholders, and have the ability to explain complex topics in simple terms
Ideally you have experience working in a large scale, global consumer product company, in an engineering or insights role
You are welcome at Spotify for who you are, no matter where you come from, what you look like, or what’s playing in your headphones. Our platform is for everyone, and so is our workplace. The more voices we have represented and amplified in our business, the more we will all thrive, contribute, and be forward-thinking! So bring us your personal experience, your perspectives, and your background. It’s in our differences that we will find the power to keep revolutionizing the way the world listens.
Spotify transformed music listening forever when we launched in 2008. Our mission is to unlock the potential of human creativity by giving a million creative artists the opportunity to live off their art and billions of fans the chance to enjoy and be passionate about these creators. Everything we do is driven by our love for music and podcasting. Today, we are the world’s most popular audio streaming subscription service with a community of more than 345 million users.
Industries
Marketing and AdvertisingComputer SoftwareInternet
",https://www.linkedin.com/jobs/view/senior-data-engineer-core-data-at-spotify-2010916113
JOB201684755813,Senior Data Engineer and/or Data Engineer - Nationwide/Remote,Senior Data Engineer and/or Data Engineer - Nationwide/Remote,,,,https://www.linkedin.com/jobs/senior-data-engineer-jobs-los-angeles-ca
JOB210874803546,Data Engineer/Analyst,Data Engineer/Analyst,,"You get people. You have a unique blend of skills in developing deep consumer insights and competitive intelligence through data that drives product innovation to create the right experiences for people’s daily lives that achieve our goals to acquire, engage, and retain them.,You get data. You have a thirst for knowledge and insight. You thrive and strive to present data in ways that product, design, engineering, marketing, and executive teams understand and act upon. Your data is 100% accurate and credible. Your reports are always clear and actionable.,You get growth. You are a consumer-focused, data-driven, and growth-enabling analyst who has supported Growth strategies, roadmaps, scrums, and final product rollouts, across the analytics/insights, acquisition/referrals, activation/onboarding, and adoption/retention loop.,You get mobile/digital. You have significant industry experience – and a strong understanding of the mobile/digital ecosystem – from apps to advertising and analytics. You have successfully applied the latest mobile/digital tools to help drive reach, retention, and revenue growth.,Understand the marketplace trends and help answer revenue trends,Analyze supply as well as demand patterns and find revenue opportunities, explain model behaviors, suggest improvements etc.,Gain insights on what drives performance in terms of reach and revenue growth,Create dashboards and reports that provide analysis and commentary, explaining product, sales, and business trends for Executive reporting,Work closely with product and inform and update stakeholders on product performance, plans, and progress towards metrics,Define data testing plans and create methodologies that help teams to iterate fast and release new features for testing and, if successful, rollout to all users globally,Generate and go deep on consumer insights and competitive intelligence to help teams drive product innovation and iteration,Build strong partnerships with product, sales, engineering, and marketing teams and enable them to launch new Growth initiatives for testing/iteration,Provide feedback to product, sales and engineering teams on impact of product launches: target launch metrics, A|B testing, post-launch metrics,Investigate data and monitor data quality – partner closely with and provide requirements to the Data Engineering teams that can be clearly acted upon,BS/MS in highly-quantitative field (Analytics, Computer Science, Mathematics) is preferred,Data analysis, generating insights for consumer-focused products,B2B or advertising experience is a must,Experience with big data technologies such as Hive, Hadoop, MapReduce, Spark, PIG etc.,Experience with scripting programming languages such as Perl/Python is good to have,Familiarity with Unix/Linux environment highly recommended,Significant experience, proficiency in, and passion for Mobile and/or Web products,Track record of proactively establishing and following through on commitments,Demonstrated use of analytics, metrics, and benchmarking to drive decisions,Excellent interpersonal, organizational, creative, and communications skills,Team player in driving growth results combined with a positive attitude,Strong work ethic and strong core values (honesty, integrity, creativity)","Job description
The Yahoo Gemini marketplace empowers advertisers with insightful data, brand-safe premium content and advanced technologies to deliver engaging search and native advertising campaigns that drive results.
A Lot About You
You get people. You have a unique blend of skills in developing deep consumer insights and competitive intelligence through data that drives product innovation to create the right experiences for people’s daily lives that achieve our goals to acquire, engage, and retain them.
You get data. You have a thirst for knowledge and insight. You thrive and strive to present data in ways that product, design, engineering, marketing, and executive teams understand and act upon. Your data is 100% accurate and credible. Your reports are always clear and actionable.
You get growth. You are a consumer-focused, data-driven, and growth-enabling analyst who has supported Growth strategies, roadmaps, scrums, and final product rollouts, across the analytics/insights, acquisition/referrals, activation/onboarding, and adoption/retention loop.
You get mobile/digital. You have significant industry experience – and a strong understanding of the mobile/digital ecosystem – from apps to advertising and analytics. You have successfully applied the latest mobile/digital tools to help drive reach, retention, and revenue growth.
You get it done. You have successfully worked with product, design, engineering, marketing, and executive teams to understand requirements, translate business needs into data requests, develop methodologies/plans, analyze data, and present findings that are embraced/enacted.
Your Day
Understand the marketplace trends and help answer revenue trends
Analyze supply as well as demand patterns and find revenue opportunities, explain model behaviors, suggest improvements etc.
Gain insights on what drives performance in terms of reach and revenue growth
Create dashboards and reports that provide analysis and commentary, explaining product, sales, and business trends for Executive reporting
Work closely with product and inform and update stakeholders on product performance, plans, and progress towards metrics
Define data testing plans and create methodologies that help teams to iterate fast and release new features for testing and, if successful, rollout to all users globally
Generate and go deep on consumer insights and competitive intelligence to help teams drive product innovation and iteration
Build strong partnerships with product, sales, engineering, and marketing teams and enable them to launch new Growth initiatives for testing/iteration
Provide feedback to product, sales and engineering teams on impact of product launches: target launch metrics, A|B testing, post-launch metrics
Investigate data and monitor data quality – partner closely with and provide requirements to the Data Engineering teams that can be clearly acted upon
Frame business problems into questions that can be answered through data analysis, and translate business needs into requirements
You Must Have
BS/MS in highly-quantitative field (Analytics, Computer Science, Mathematics) is preferred
Data analysis, generating insights for consumer-focused products
B2B or advertising experience is a must
Experience with big data technologies such as Hive, Hadoop, MapReduce, Spark, PIG etc.
Experience with scripting programming languages such as Perl/Python is good to have
Familiarity with Unix/Linux environment highly recommended
Significant experience, proficiency in, and passion for Mobile and/or Web products
Track record of proactively establishing and following through on commitments
Demonstrated use of analytics, metrics, and benchmarking to drive decisions
Excellent interpersonal, organizational, creative, and communications skills
Team player in driving growth results combined with a positive attitude
Strong work ethic and strong core values (honesty, integrity, creativity)
Problem solver who never stops thinking about ways to improve
Oath is proud to be an equal opportunity workplace. All qualified applicants will receive consideration for employment without regard to, and will not be discriminated against based on, age, race, gender, color, religion, national origin, sexual orientation, gender identity, veteran status, disability or any other protected category. Oath is dedicated to providing an accessible environment for all candidates during the application process and for employees during their employment. Please let us know if you need a reasonable accommodation to apply for a job or participate in the application process.
Currently work for Oath? Please apply on our internal career site.
",https://www.linkedin.com/jobs/view/688174273/?eBP=CwEAAAFjrQdTV6WeA1luZITuFfDUFB68yX42mT-7vpggrYWJXN4jMRY1rIgXoeobmzHmZWfaGaB_6JYpPU3t6qb34tbJ9HcY-FAHmSSHuWqFoTykdjwLmeQpIr5q0kzvYlOr4xmg1_K-qIw2tmaGuaxtSubIvEqNYZqCWcamNZbLmnww4wmZYQkREuUhQ34wdSL0UUxQyDexOhI8bG2tmUKL04N2IM1YddPNyOV-5x3DMm-i_nuRCCxMF-3uWd87PQLA9h3J6f0TiORd-DzLXbz6I6gUwXTFzrpr4Zu2z9fHIWw2NX5gckzESQCS1Vd9zx6InnhSaXGvyfcxbJ-k&refId=9d649546-26e2-47d1-b39c-3a3d796422b3&trk=d_flagship3_search_srp_jobs&lipi=urn%3Ali%3Apage%3Ad_flagship3_search_srp_jobs%3Bmz4bv4U3RbSS%2BZXjQD6N5g%3D%3D&licu=urn%3Ali%3Acontrol%3Ad_flagship3_search_srp_jobs-A_jobssearch_job_result_click&lici=TmGc%2Bd1BRD6X7Lrs0Ov7gA%3D%3D
JOB211287778667,"Results for ""Data Engineer Jobs in Dallas, Texas, United States""","Results for ""Data Engineer Jobs in Dallas, Texas, United States""",,,"2,000+Results for ""Data Engineer Jobs in Dallas, Texas, United States""(161 new)
",https://www.linkedin.com/jobs/data-engineer-jobs-dallas-tx
JOB223993832814,Data Engineer,Data Engineer,,"Design, construct, test, optimize, and deploy solutions.,Deliver transformative solutions to clients that are aligned to industry best practices and provide thought leadership in data architecture and engineering space.,Possess exceptional analytical, conceptual, and problem-solving abilities.,Have experience with both traditional (e.g., MSBI) and modern (e.g., cloud) data architecture.,Collaborate as a part of a team to develop Cloud Data and Analytics solutions.,Assist in designing multi-phased cloud data strategies, including designing multi-phased implementation roadmaps.,Analyze, architect, design and actively develop cloud data warehouse, data lakes and other cloud-based data solutions.,Participate in development of cloud data warehouses and business intelligence solutions.,Exemplify strong focus on back end data integration.,Demonstrate strong focus on the design and development of data warehouses.,Highly self-motivated to deliver both independently and with strong team collaboration.,Ability to creatively take on new challenges and work outside comfort zone.,Solid written and oral communications along with presentation and interpersonal skills.,Comfortable conducting and supporting white-boarding sessions, workshops, design sessions, and project meetings as needed, playing a key role in client relations.,Quantitative background with 3+ years of experience applying data architecture or engineering to solve real-world business problems.,4+ years of data engineering and/or data warehousing experience.,2+ years of building cloud data solutions (AWS, Azure, GCP, Snowflake).,Experience with:,Relational and dimensional database structures, theories, principles, and practices.,Manipulating / mining data from database tables (SQL Server, Redshift, Oracle).,SQL, ETL / ELT optimization, and analytics tools including R, HiveQL, and Python.,Big data application development and/or with cloud data warehousing (e.g. Hadoop, Spark, Redshift, Snowflake, Azure, SQL DW, BigQuery)..,Solution architecture on cloud platforms such as AWS, Azure, an GCP.,Cloud SDKs and programmatic access services.,Practical knowledge of data visualization tools (e.g., Tableau, Power BI) a plus.,Expert programming skills in Python and a software development background.,Experience writing ""infrastructure as code"" deployments e.g. ARM, CloudFormation, Terraform.,Job function
Information Technology","Who You’ll Work With
We help people improve the future with data. The D&A core team drives strategic direction and initiatives. We accelerate innovation and learning, aggregate offerings and customer stories, and amplify a One Slalom voice to the customer. As a Data Engineer, you will have the opportunity to design, create and manage extremely large data sets. You know and love working with analytics tools, can write excellent SQL, and ETL code (e.g. SSIS, Informatica, etc), and can leverage your technical skills and creative approaches to help clients solve their most critical business challenges. You are proficient in cloud platforms and are responsible for contributing to client delivery, complex solutioning and knowledge management. Engineers are an integral part of Portland’s Data and Analytics Practice and in addition to working with clients, will have the chance to collaborate closely with members of the Slalom team who are focused on data visualization, advanced analytics, data science, data strategy, and process. Slalom is proud to be a Premier AWS partner, Microsoft Gold partner and Google Premier partner.
What You’ll Do
Design, construct, test, optimize, and deploy solutions.
Deliver transformative solutions to clients that are aligned to industry best practices and provide thought leadership in data architecture and engineering space.
Possess exceptional analytical, conceptual, and problem-solving abilities.
Have experience with both traditional (e.g., MSBI) and modern (e.g., cloud) data architecture.
Collaborate as a part of a team to develop Cloud Data and Analytics solutions.
Assist in designing multi-phased cloud data strategies, including designing multi-phased implementation roadmaps.
Analyze, architect, design and actively develop cloud data warehouse, data lakes and other cloud-based data solutions.
Participate in development of cloud data warehouses and business intelligence solutions.
Exemplify strong focus on back end data integration.
Demonstrate strong focus on the design and development of data warehouses.
Highly self-motivated to deliver both independently and with strong team collaboration.
Ability to creatively take on new challenges and work outside comfort zone.
Solid written and oral communications along with presentation and interpersonal skills.
Comfortable conducting and supporting white-boarding sessions, workshops, design sessions, and project meetings as needed, playing a key role in client relations.
Strong aptitude for learning new technologies and analytics techniques.
What You’ll Bring
Quantitative background with 3+ years of experience applying data architecture or engineering to solve real-world business problems.
4+ years of data engineering and/or data warehousing experience.
2+ years of building cloud data solutions (AWS, Azure, GCP, Snowflake).
Experience with:
Relational and dimensional database structures, theories, principles, and practices.
Manipulating / mining data from database tables (SQL Server, Redshift, Oracle).
SQL, ETL / ELT optimization, and analytics tools including R, HiveQL, and Python.
Big data application development and/or with cloud data warehousing (e.g. Hadoop, Spark, Redshift, Snowflake, Azure, SQL DW, BigQuery)..
Solution architecture on cloud platforms such as AWS, Azure, an GCP.
Cloud SDKs and programmatic access services.
Practical knowledge of data visualization tools (e.g., Tableau, Power BI) a plus.
Expert programming skills in Python and a software development background.
Experience writing ""infrastructure as code"" deployments e.g. ARM, CloudFormation, Terraform.
Understanding of cloud strategies and best practices expanding into cloud networking, cloud security, encryption, private cloud configuration, and overall cloud governance approaches.
About Us
Slalom is a modern consulting firm focused on strategy, technology, and business transformation. In 39 markets around the world, Slalom's teams have autonomy to move fast and do what's right. They are backed by regional innovation hubs, a global culture of collaboration, and partnerships with the world's top technology providers. Founded in 2001 and headquartered in Seattle, Slalom has organically grown to over 8,000 employees. Slalom has been named one of Fortune's 100 Best Companies to Work For five years running and is regularly recognized by employees as a best place to work. Learn more at slalom.com.
Slalom prides itself on helping team members thrive in their work and life. As a result, Slalom is proud it invest in benefits that include: meaningful time off and paid holidays, parental leave, 401(k) with a match, a range of choices for highly subsidized health, dental, & vision coverage, adoption and fertility assistance, and short/long-term disability. We also offer additional benefits such as a yearly $350 reimbursement account for any well-being related expenses as well as discounted home, auto, and pet insurance.
Slalom is an equal opportunity employer that is committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veterans status, or any other characteristic protected by federal, state, or local laws.
Job function
Information Technology
Industries
Information Technology and ServicesComputer SoftwareManagement Consulting
",https://www.linkedin.com/jobs/view/data-engineer-at-slalom-2328319200?refId=0cac9efd-b628-4c1e-ba66-18ad97b50c49&trackingId=eH3R86TpYMjg6zpusF4xew%3D%3D
JOB259523503444,"Results for ""Data Engineer Jobs in United States""","Results for ""Data Engineer Jobs in United States""",,,,https://www.linkedin.com/jobs/data-engineer-jobs
JOB1339598949,Principal Big Data Engineer,Principal Big Data Engineer,,,"
Job description
FreeWheel, A Comcast Company, comprised of FreeWheel Publishers, FreeWheel Markets, and FreeWheel Advertisers empowers all segments of The New TV Ecosystem. We are structured to provide the full breadth of solutions the advertising industry needs to achieve their goals. We power the technology, data enablement, and convergent marketplaces required to ensure buyers and sellers can transact across all screens, across all data types, and all sales channels, in order to ensure the ultimate goal results for marketers. With offices in New York, San Francisco, Chicago, London, Paris, Beijing, and across the globe, FreeWheel, A Comcast Company, stands to advocate for the entire industry through the FreeWheel Council for Premium Video.
FreeWheel is hiring a New York based Principal Big Data Engineer reporting to the Senior Director, Engineering. FreeWheel helps the television industry generate revenue from their premium content through a robust technology platform, which enables consumers to watch entertainment on any devices from PC, mobile, set-top box to traditional TV. FreeWheel's New York Engineering Team is part of a global engineering group that is building advanced and high quality applications, servers and tools to manage million dollar orders, handle billions of daily requests, and process terabytes of raw daily data.
RESPONSIBILITIES:
Lead engineering team to design, develop, and test data-driven solutions
Can oversee multiple projects, have in-depth knowledge to make technical decisions and lead technical discussions
Partner with global engineering, product and operations teams to further incorporate collective innovations
o Work with different teams to design tech solution
o Follow updates in different FreeWheel backend components and contribute to the long-term roadmap for FreeWheel's data strategy
Drive the optimization, testing and tooling to improve data quality
Improve performance, availability and scalability of our backend systems
ABOUT YOU:
Bachelor's or Master's Degree in Computer Science or similar field of study
5+ years of experience building large scale big data applications
Deep understanding of computer systems and have good abilities of architecture design
Strong SQL and database expertise
Proficient with Linux commands and environments
Proficient with 3""4 programming languages among Golang/C++/Scala/Python/Ruby/Java. Fast to pick up new languages.
Hands-on experiences with data processing or analysis systems is strongly preferred.
Experiences with Spark/Hadoop/Kafka/Presto and other Big-Data technologies are strongly preferred.
Experiences with AWS or other Cloud technology are strongly preferred.
Known for being a smart, analytical thinker who approaches their work with logic and enthusiasm
Detail oriented, flexible and can work well in a global team-oriented environment
Comcast is an EOE/Veterans/Disabled/LGBT employer
",https://stackoverflow.com/jobs/201270/principal-big-data-engineer-comcast
JOB2304393164,Data Engineer,Data Engineer,"Experience with Data Warehouses/Lakes (Big Query, RedShift, Snowflake), NoSQL (Cassandra, Redis), Stream Processing Engines (Dataflow, Flink), Workflow Management Tools (Airflow, Pachyderm), or other Big Data solutions are highly appreciated.","You have good problem-solving skills, a tendency towards simple and effective solutions, and a “getting things done” mentality.,Analytical thinking, troubleshooting skills, attention to detail.,You are a reliable, trustworthy person that keeps their promises.,Interest in keeping yourself up to date and learning new technologies.,Product-oriented mindset and eagerness to take part in shaping the products we build.,Ability to work autonomously in a fully distributed team.,Good communication skills in verbal and written English.,BS degree in Computer Science or similar technical field.,2+ years of software engineering experience.,Solid understanding of modern back-end systems, microservice architecture, message-driven solutions, distributed processing, and replication.,1+ years of experience with relational databases (Postgres, MariaDB, Oracle).,Background in building data processing pipelines.,Understanding of data streaming concepts and technologies such as Pulsar, Kafka, RabbitMQ, or similar.,Familiarity with Agile methodology, test-driven development, containerization, continuous integration/deployment, cloud environments, and monitoring.,Ability to write clean, efficient, maintainable, and well-tested code; Golang/Python skills are a plus.","Tech
Data Engineer
Job description
At BlueLabs we started out last year with the vision of building a next-generation sports betting platform focused on performance, reliability, modularity and automation. After a period of experimentation, we are now excited to see our technology powering the launch of a new B2C operator in Ghana in early 2021.
To ensure the continuous enhancement of our platform while scaling up operations and entering additional African countries, we are now looking into growing our team. As a result, our Data Team is on the lookout for a versatile Data Engineer. With our Data Platform still in its early stages, you’ll have an opportunity to make a huge impact, work on a variety of interesting data-related challenges and help us shape the future of our platform.
The Team
The mission of Data Team is to provide an ecosystem where data is transmitted, stored, processed, served, and analyzed in a fast, stable, reliable, and secure way. As a team, we have the expertise to drive data-related initiatives and make an impact in various parts of the organization.
Our goal is to provide a cutting-edge Data Platform which can be leveraged to explore data, discover insights, build predictive models, and collaborate with other teams on enhancing services. We strive for innovation and promote data-driven solutions which, we believe, will make our products more compelling and give us a competitive advantage on the market. We’re currently building a strong foundation for our platform - well-modelled Data Lake/Warehouse, real-time data ingestion pipelines with scalability in mind, sophisticated observability, and more. This will power our Business Intelligence, Machine Learning and Data Science initiatives in the future.
As a Data Engineer in our team, you’ll take part in the whole development lifecycle of a product. This involves identifying problems, designing solutions, implementing them, performing code reviews and maintaining services in the production environment. Careful modeling of the data storage layer, ensuring reliable and swift message transfer, building high-performance data pipelines, supporting Analytics and Data Science flows, are just some of the things you’ll face at your day-to-day work. We’re looking for a data generalist who is not afraid of the diverse challenges we will face while building the platform and truly enjoys working with data.
A good candidate should have high standards for himself, a desire to build high-quality, well-tested, production-ready solutions and constantly improve his/her skills. We expect you to take ownership of some parts of the platform, be proactive over the entire development lifecycle and have the ability to work in a fast-paced environment. If this sounds scary, don’t worry - you won’t be alone in this. We value teamwork, trust, communication and a healthy working relationship, so you can always count on the team for support.
About You
You have good problem-solving skills, a tendency towards simple and effective solutions, and a “getting things done” mentality.
Analytical thinking, troubleshooting skills, attention to detail.
You are a reliable, trustworthy person that keeps their promises.
Interest in keeping yourself up to date and learning new technologies.
Product-oriented mindset and eagerness to take part in shaping the products we build.
Ability to work autonomously in a fully distributed team.
Good communication skills in verbal and written English.
Remote Work
We are hiring for talent, not for a specific location. You will find that members of our team are distributed all over Europe. Being a distributed team enables us to hire only the best, without being restricted to the talent pool available at a specific geographic location. However, to facilitate team communication and collaboration we currently require you to be located in a European time zone (between UTC-1 and UTC+3). You must also be able to travel to other European locations a few times a year for on-site meetings and workshops.
Compensation
The budgeted compensation range for this role is €58,000 to €64,000 annually, depending on your background and experience. As an independent contractor, you will be responsible for paying any taxes or applicable fees in your country of residence. In addition to that, we offer a number of perks to each of our team members as we truly believe in a healthy work-life balance and continuous learning.
Job requirements
BS degree in Computer Science or similar technical field.
2+ years of software engineering experience.
Solid understanding of modern back-end systems, microservice architecture, message-driven solutions, distributed processing, and replication.
1+ years of experience with relational databases (Postgres, MariaDB, Oracle).
Background in building data processing pipelines.
Understanding of data streaming concepts and technologies such as Pulsar, Kafka, RabbitMQ, or similar.
Familiarity with Agile methodology, test-driven development, containerization, continuous integration/deployment, cloud environments, and monitoring.
Ability to write clean, efficient, maintainable, and well-tested code; Golang/Python skills are a plus.
Experience with Data Warehouses/Lakes (Big Query, RedShift, Snowflake), NoSQL (Cassandra, Redis), Stream Processing Engines (Dataflow, Flink), Workflow Management Tools (Airflow, Pachyderm), or other Big Data solutions are highly appreciated.
",https://www.sitepoint.com/jobs/bluelabs/data-engineer
JOB2550416447,"Data Engineer Jobs in Houston, TX","Data Engineer Jobs in Houston, TX",,"Houston, TX","
Data Engineer Jobs in Houston, TX
Current Search Criteria
More
",https://militaryjobs.homedepot.com/data-engineer/jobs-in/houston/texas/usa/jobs/?vs=25&utm_medium=.JOBS%20Universe&utm_campaign=.JOBS%20RSS%20Feed&utm_source=.JOBS%20RSS%20Feed-DE
JOB3750773785,"Data Engineer Jobs in Houston, TX","Data Engineer Jobs in Houston, TX",,"Houston, TX","
Data Engineer Jobs in Houston, TX
Current Search Criteria
More
",https://militaryjobs.homedepot.com/data-engineer/jobs-in/houston/texas/usa/jobs/?vs=25&utm_medium=.JOBS%20Universe&utm_source=.JOBS%20RSS%20Feed-DE&utm_campaign=.JOBS%20RSS%20Feed
JOB4220683308,Senior Data Engineer - BlackLocus,Senior Data Engineer - BlackLocus,,,"
Job Information
POSITION PURPOSE
The Sr Data Engineer will expand and optimize data, data flow, data collection for cross functional teams, and data pipeline architecture. The Sr Data Engineer will support and collaborate with the software engineering team, data analysts, and data scientist to ensure data delivery architecture is consistent throughout ongoing projects. Continuously improve or re-design data architecture to support the next generation of products and initiatives.
MAJOR TASKS, RESPONSIBILITES AND KEY ACCOUNTABILITIES
40% - Data Validation, ETL, Infrastructure Development: Coding validation and ETL to ensure successful data integration
30% - Data Infrastructure Maintenance: Backup and optimization activities to maintain performance; code, configure, test, etc data to ensure integrity
20% - Data Architecture Design and Analysis: Create and maintain optimal data pipeline architecture; Develop data architecture to meet business requirements
10% - Planning/Requirements Analysis: Collaborate with team leads and cross functional partners to assess business requirements and communicate opportunities
NATURE AND SCOPE
This position reports to the Technology Leader.
This position has 0 direct reports.
ENVIRONMENTAL JOB REQUIREMENTS
Environment:
Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.
Travel:
Typically requires overnight travel less than 10% of the time.
Additional Environmental Job Requirements:MINIMUM QUALIFICATIONS
Must be eighteen years of age or older.
Must be legally permitted to work in the United States.
Additional Minimum Qualifications:
Experience message queuing, stream processing, and scalable data stores
Experience managing projects and organizing data
Experience supporting and working with cross-functional teams
Experience with SQL, NoSQL databases, relational databases, and query authoring
Experience building and optimizing data pipelines, architectures, data sets and workflow management tools such as Azkaban, Luigi, Airflow, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C#, Scala, GoLang, etc.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
Education Required:
The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.
Years of Relevant Work Experience: 5 years
Physical Requirements:
Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.
Additional Qualifications:
Preferred Qualifications:
8+ years of previous related work experience
Ability to convey complex or technical ideas and processes in easy-to-understand terms to diverse audiences
Ability to negotiate, handle complaints, settle disputes, and resolve grievances with both internal and external customers
Excellent written and verbal communication skills
Knowledge, Skills, Abilities and Competencies:Collaborates - Building partnerships and working collaboratively with others to meet shared objectives
Communicates Effectively - Developing and delivering multi-mode communications that convey a clear understanding of the unique needs of different audiences
Cultivates Innovation - Creating new and better ways for the organization to be successful
Drives Engagement - Creating a climate where people are motivated to do their best to help the organization achieve its objectives
Instills Trust - Gaining the confidence and trust of others through honesty, integrity, and authenticity
Nimble Learning - Actively learning through experimentation when tackling new problems, using both successes and failures as learning fodder
Optimizes Work Processes - Knowing the most effective and efficient processes to get things done with a focus on continuous improvement
Plans and Aligns - Planning and prioritizing work to meet commitments aligned with organizational goals
Tech Savvy - Anticipating and adopting innovations in business-building digital and technology applications. We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
",https://militaryjobs.homedepot.com/austin-tx/senior-data-engineer-blacklocus/35068FD906174D91A159D54015CA5347/job/?utm_campaign=.JOBS%20RSS%20Feed&utm_medium=.JOBS%20Universe&utm_source=.JOBS%20RSS%20Feed-DE
JOB9078211517,Senior Data Engineer,Senior Data Engineer,,"Design, build and support data processing pipelines and APIs,Ensure that code adheres to defined standards and best practices for performance, speed, scalability, and quality,Practice Agile development methods and exemplify core Agile values of transparency, collaboration, acceptance of change, and iterative development,Routinely deliver working software solutions that meet user story acceptance criteria,Bachelor’s degree in Computer Science or four or more years of work experience.,Four or more years of relevant work experience.,Four or more years of software engineering experience, including Java, Python, and/or related languages.,Two or more years of experience with relational database technologies (Postgres, MySql, etc) including SQL,A degree.,Four or more years of experience leading large-scale projects.,Four or more years of experience in networking, multi-threaded applications, inter-process communication, and complex software development.,Experience in building high-performance, highly-available and scalable distributed systems.,ETL or Data cleansing & normalizing,Big Data, data analysis, log mining, and automated reporting,PostGIS experience,Experience designing, building and managing Internet-scale APIs.,Experience mentoring and growing software engineers.,Ability and willingness to learn new technologies quickly.,Ability to work in a highly collaborative Agile team,Demonstrated aptitude and desire to learn new skills","
What you’ll be doing...
The Company
Verizon is serious about innovation. About being the first and being the best. Verizon Location Services (VLS) sits at the core of the Strategy and New Business Development organization and is a critical part of driving innovation across our global customer base, both inside and outside of Verizon. Backed by more than 50 years of location-based expertise, we are building solutions that leverage the power of location intelligence to help drive technologies of the future. Technologies like 5G, Multi-Access Edge Computing and Artificial Intelligence that are allowing us to create products that were previously impossible. We’re building tomorrow with the best of today.
Your role
As a Data Engineer, you will be solving deep technical problems and building innovative solutions in a fast paced environment working with smart and passionate team members. You must have hands-on experience building scalable services. Your responsibilities will include participating in the overarching solution, working closely with software engineering teams to bridge key technical relationships, and driving projects towards success.
You will work closely with product owners, additional stakeholders and software engineering teams to develop high-quality software. You will be detail oriented, self-directed, self-motivated, with a strong capacity for working successfully and collaboratively with members across the organization.
Responsibilities:
Design, build and support data processing pipelines and APIs
Ensure that code adheres to defined standards and best practices for performance, speed, scalability, and quality
Practice Agile development methods and exemplify core Agile values of transparency, collaboration, acceptance of change, and iterative development
Routinely deliver working software solutions that meet user story acceptance criteria
Facilitate technical conflict resolution with active listening and critical thinking
What we’re looking for...
You’ll need to have:
Bachelor’s degree in Computer Science or four or more years of work experience.
Four or more years of relevant work experience.
Four or more years of software engineering experience, including Java, Python, and/or related languages.
Two or more years of experience with relational database technologies (Postgres, MySql, etc) including SQL
Experience with Amazon Web Services, Docker and Kubernetes
Even better if you have:
A degree.
Four or more years of experience leading large-scale projects.
Four or more years of experience in networking, multi-threaded applications, inter-process communication, and complex software development.
Experience in building high-performance, highly-available and scalable distributed systems.
ETL or Data cleansing & normalizing
Big Data, data analysis, log mining, and automated reporting
PostGIS experience
Experience designing, building and managing Internet-scale APIs.
Experience mentoring and growing software engineers.
Ability and willingness to learn new technologies quickly.
Ability to work in a highly collaborative Agile team
Demonstrated aptitude and desire to learn new skills
Excellent written and verbal communication skills. Ability to embrace change and work in a fast paced, dynamic environment.
When you join Verizon...
You’ll have the power to go beyond – doing the work that’s transforming how people, businesses and things connect with each other. Not only do we provide the fastest and most reliable network for our customers, but we were first to 5G - a quantum leap in connectivity. Our connected solutions are making communities stronger and enabling energy efficiency. Here, you’ll have the ability to make an impact and create positive change. Whether you think in code, words, pictures or numbers, join our team of the best and brightest. We offer great pay, amazing benefits and opportunity to learn and grow in every role. Together we’ll go far.
Equal Employment Opportunity
We're proud to be an equal opportunity employer - and celebrate our employees' differences, including race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, and Veteran status. Different makes us better.
",https://www.verizon.com/about/work/jobs/4977278-senior-data-engineer
JOB9330476079,Senior Data Engineer - BlackLocus Jobs in Texas,Senior Data Engineer - BlackLocus Jobs in Texas,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/texas/usa/jobs/?utm_medium=.JOBS%20Universe&utm_source=.JOBS%20RSS%20Feed-DE&utm_campaign=.JOBS%20RSS%20Feed&vs=25
JOB14340572892,Sr. Big Data Engineer - (Analytics),Sr. Big Data Engineer - (Analytics),"Great perks, which vary by location and can include: employee discounts, transportation reimbursements, subsidized cafes and fitness facilities, conveniences such as dry cleaning and car washes, and recycling programs.","Architect a multi-tier data pipeline to feed data into an OLTP application in addition to an analytics environment,Design and build schemas to handle large scale interactive reporting,Design and build ETL/ELT process to move data through the data processing pipeline.,Manage complex data dependencies across datasets and incremental data loading workflows.,Be a fearless leader in championing smart design,Love scaling systems,Must have firm understanding of database systems – Data modeling, SQL q uery Processing and Transactions Know how to scale systems and make them fast!,Experience debugging and tracing SQL performance issues,Solid understanding of software development from design and architecture to production.,Large scale DW, MPP, Redshift, or similar technologies,Solid math skills.,T he ability to present impromptu and via a whiteboard,Experience with the Hadoop ecosystem (HBase/Hive/map reduce),Experience working in AWS,Knowledge of Tableau,Experience with Redshift or ParAccel/Actian Matrix,Experience with Pentaho Kettle,Linux basics,Big, Big bonus if you know a programming language or two.,Competitive compensation (salary, equity and bonuses) and comprehensive benefits designed to foster work-life balance, care for your health, protect your finances, and help you save and invest for the future.,Generous paid time away from work including vacation, holidays, sick time, and 2 days of paid time off each year to serve and learn through TiVo Community Outreach."," Hi. We’re TiVo. At our core, we’re innovators who continuously seek to fuel the ultimate entertainment experience. We touch the lives of binge-watching, music-loving, entertainment fanatics every day by inventing and delivering beautiful user experiences, and enable the world’s leading media and entertainment providers to nurture more meaningful relationships with their audiences.
We work hard, celebrate success and challenge everyone in our organization to make an impact. If you are as passionate as we are about the intersection of technology and entertainment, join us today.
TiVo Analytics:
As entertainment options grow and evolve, TV networks and service providers face new challenges in understanding their audiences and subscribers. At TiVo, our Analytics team combines the power of big data and cloud processing in our predictive analytics solutions to help these businesses optimize campaigns by audience and make decisions based on actual consumer behavior.
TiVo has developed a revolutionary cloud-based analytics platform that integrates massive data from set-tops, smart TVs, tablets and stream servers – basically anywhere that video is consumed – to deliver timely intelligence and actionable insights by leveraging big data and predictive analytics techniques.
The TiVo Big Data Engineering team is a group of engineers that are passionate about data. We are responsible for the complete data pipeline from processing raw data to applying analysis of the data. Our team is responsible for the designing and development of tools and systems for the entire lifecycle of data; data collection, data processing, monitoring, data quality and correction, data access platforms and more. We are looking for driven people to help us build the next generation platform for TV analytics.
What is the job?
Architect a multi-tier data pipeline to feed data into an OLTP application in addition to an analytics environment
Design and build schemas to handle large scale interactive reporting
Design and build ETL/ELT process to move data through the data processing pipeline.
Manage complex data dependencies across datasets and incremental data loading workflows.
Be a fearless leader in championing smart design
Love scaling systems
What Skills should you have?
Must have firm understanding of database systems – Data modeling, SQL q uery Processing and Transactions Know how to scale systems and make them fast!
Experience debugging and tracing SQL performance issues
Solid understanding of software development from design and architecture to production.
Large scale DW, MPP, Redshift, or similar technologies
Solid math skills.
T he ability to present impromptu and via a whiteboard
Bonus points for:
Experience with the Hadoop ecosystem (HBase/Hive/map reduce)
Experience working in AWS
Knowledge of Tableau
Experience with Redshift or ParAccel/Actian Matrix
Experience with Pentaho Kettle
Linux basics
Big, Big bonus if you know a programming language or two.
Benefits & Perks
Our employees and their families are important to us and our comprehensive pay, stocks and benefits programs reflect that. TiVo supports personal well-being, builds financial security, and enables employees to share in the success of TiVo. Rewards include:
Competitive compensation (salary, equity and bonuses) and comprehensive benefits designed to foster work-life balance, care for your health, protect your finances, and help you save and invest for the future.
Generous paid time away from work including vacation, holidays, sick time, and 2 days of paid time off each year to serve and learn through TiVo Community Outreach.
Great perks, which vary by location and can include: employee discounts, transportation reimbursements, subsidized cafes and fitness facilities, conveniences such as dry cleaning and car washes, and recycling programs.
- See more at: https://www.tivo.com/jobs/culture/benefits-at-tivo
TiVo Corporation is an Equal Employment Opportunity Employer
Other jobs you may like
Senior Data Engineer
Boston Health Economics - Boston, MA
10 days ago
Sr. Data Engineer
Insight Enterprises, Inc. - Boston, MA
Insight - 30+ days ago
Sr. Big Data, Spark Engineer
Vidscale - Cambridge, MA
30+ days ago
Senior Big Data Engineer
Strategic IT Staffing - Boston, MA
30+ days ago
Senior Data Engineer
Zipcar - Boston, MA
30+ days ago
","https://www.indeed.com/job/Senior-Big-Data-Engineer-at-TiVo-in-Boston,-MA-51416155575f532a"
JOB15363762299,Data Engineer,Data Engineer,"knowledge in relevant engineering best practices, data management fundamentals, data storage principles, and be current with recent advances in distributed systems as it pertains to data storage and computing,2+ years of experience in designing, building and maintaining data architecture(s) and infrastructure(s), both relational and non-relational,2+ years of maintaining data warehouse systems and working on large scale data transformation using SQL, Hadoop, Hive, or other Big Data technologies; experience with ETL tools is a plus,2+ years of data modeling experience, and able to use data models to improve the performance of software services,experience with Cloud Based Solution (AWS Redshift, GCP Big Query) and programming language (Python, Java) is a plus,experience communicating with colleagues from engineering, analytics, and business backgrounds,degree in Engineering, Math, Statistics, Computer Science, or related discipline or equivalent experience is a plus.,be able to legally work in Europe (you are the holder of a EU Passport or you are the holder of EU residency permit or you are the holder of a Schengen Work Visa)","you will build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and other big data technologies,you will design and model data structures to help analyzing our business and technical data,you will support existing processes running in production,you will work together with people from other key areas to assist with data-related technical issues and support their data infrastructure needs","
Job description
Who are we looking for:
We are looking for a savvy Data Engineer to join our growing tech team.
You will support our software developers, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.
The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.
Roles and Responsibilities:
you will build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and other big data technologies
you will design and model data structures to help analyzing our business and technical data
you will support existing processes running in production
you will work together with people from other key areas to assist with data-related technical issues and support their data infrastructure needs
Skills & Requirements
knowledge in relevant engineering best practices, data management fundamentals, data storage principles, and be current with recent advances in distributed systems as it pertains to data storage and computing
2+ years of experience in designing, building and maintaining data architecture(s) and infrastructure(s), both relational and non-relational
2+ years of maintaining data warehouse systems and working on large scale data transformation using SQL, Hadoop, Hive, or other Big Data technologies; experience with ETL tools is a plus
2+ years of data modeling experience, and able to use data models to improve the performance of software services
experience with Cloud Based Solution (AWS Redshift, GCP Big Query) and programming language (Python, Java) is a plus
experience communicating with colleagues from engineering, analytics, and business backgrounds
degree in Engineering, Math, Statistics, Computer Science, or related discipline or equivalent experience is a plus.
be able to legally work in Europe (you are the holder of a EU Passport or you are the holder of EU residency permit or you are the holder of a Schengen Work Visa)
",https://stackoverflow.com/jobs/260456/data-engineer-supermercato24
JOB16512968769,Data Engineer,Data Engineer,"Education: B.Sc. Computer Science or related fields,Knowledge & Experience: 5+ years in deployment, integration and server management as well as experience with writing scripts using Python and Bash,Advanced knowledge of SQL and non-SQL databases.,Strong analytic skills related to working with unstructured datasets.,A strong knowledge of manipulating, processing and extracting value from large disconnected datasets.,Experience with big data tools: Hadoop, Spark, Kafka, etc,Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.,Experience with stream-processing systems: Storm, Spark-Streaming, etc.,Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.,Experience with AWS cloud services: EC2, EMR, RDS, Redshift",,"
Job description
Expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. Building data pipeline and optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products.
Description
- Create and maintain optimal data pipeline architecture
- Assemble large, complex data sets that meet functional / non-functional business requirements.
- Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
- Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
- Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
- Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
- Work with data and analytics experts to strive for greater functionality in our data systems.
Other Task
- Any other reasonable request of work task as allocated by the Line Manager or other Senior Management.
Requirements
Education: B.Sc. Computer Science or related fields
Knowledge & Experience: 5+ years in deployment, integration and server management as well as experience with writing scripts using Python and Bash
Skills:
Minimum qualifications:
Advanced knowledge of SQL and non-SQL databases.
Strong analytic skills related to working with unstructured datasets.
A strong knowledge of manipulating, processing and extracting value from large disconnected datasets.
Experience with big data tools: Hadoop, Spark, Kafka, etc
Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Preferred qualifications:
Experience with AWS cloud services: EC2, EMR, RDS, Redshift
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
",http://stackoverflow.com/jobs/371056/data-engineer-executive-solutions
JOB17144121057,Locals or Nearby Urgent Need Hadoop Data Engineer,Locals or Nearby Urgent Need Hadoop Data Engineer,"Lead implementation teams from concept to completion by leveraging the best practices of Big Data,Participate in the analysis, architecture and design of data hub,Builds robust Big Data solution systems with an eye on the long term maintenance and support of the Application,Work as part of a team to design and develop code, scripts, and data pipelines that leverage structured and unstructured data integrated from multiple sources,Looks to leverage reusable code modules to solve problems across the team, including Data Preparation and Transformation and Data export and synchronization,Design and develop automated test cases that verify solution feasibility and interoperability, to include performance assessments,Act as a Big Data delivery liaison with Infrastructure, security, application development and testing team.,Helps drive cross team design / development via technical leadership / mentoring,Keep current on latest Big Data technologies and products, including hands-on evaluations and in-depth research,Consult and advise solution architects on overall enterprise-wide analytics solutions that include a Data Hub Component,Works with Project Manager to perform detailed planning, risks/issues escalation.,Requirements for Big Data Engineer, Healthcare Analytics Senior:,4+ years of experience working with batch-processing and tools in the Hadoop tech stack (e.g., MapReduce, Yarn, Pig, Hive, HDFS, Oozie)*,4+ years of experience working with tools in the stream-processing tech stack (e.g., Spark, Storm, Samza, Kafka, Avro)* Experience developing applications that work with NoSQL stores (e.g., ElasticSearch, Hbase, Cassandra, MongoDB, CouchDB)* Experience developing for TB-level data stores and/or 10Gbps+ ingest speeds,High-capacity data ingest into Hadoop or Spark is highly desired,Hands-on experience with at least one major Hadoop Distribution such as Cloudera or Horton Works or MapR or IBM Big Insights,System usage and optimization tools such as Splunk is a plus,At least 4 years of experience delivering enterprise IT solutions as a solutions architect,8+ years of experience with SQL and at least two major RDBMS's,5+ years as a systems integrator with Linux systems and shell scripting,8+ years of doing Data related benchmarking, performance analysis and tuning,5+ years of Java experience,Solid programming experience with a preference towards Java or Python,DBA and/or Data Modeling experience,Experience with operational and business-level metadata management,Bachelor's degree in Computer Science, Information Systems, Information Technology or related field and 6+ years of software development/DW & BI experience.,Health care experience is plus,Excellent verbal and written communication skills,Hands-on experience with Cloudera 4.5 and higher, Horton Works 2.1 and higher or MapR 4.01 and higher,Experience with Map/Reduce solution design and development,ETL Solution experience, preferable on Hadoop,Experience with industry leading Business Intelligence: Qualifications",,"Reasons could include: the employer is not accepting applications, is not actively hiring, or is reviewing applications
Job Description
GC and Citizens
Hi Friends,
Hope you are doing great,
I have an urgent requirement from one of my esteem client, I will appreciate if you can have an eye on the below requirement and send me your consultant updated profile ASAP.
Job Title: Data Engineer
Location: Reston, VA ( Local or Nearby)
Duration: 4+ months
Requirements:
Lead implementation teams from concept to completion by leveraging the best practices of Big Data
Participate in the analysis, architecture and design of data hub
Builds robust Big Data solution systems with an eye on the long term maintenance and support of the Application
Work as part of a team to design and develop code, scripts, and data pipelines that leverage structured and unstructured data integrated from multiple sources
Looks to leverage reusable code modules to solve problems across the team, including Data Preparation and Transformation and Data export and synchronization
Design and develop automated test cases that verify solution feasibility and interoperability, to include performance assessments
Act as a Big Data delivery liaison with Infrastructure, security, application development and testing team.
Helps drive cross team design / development via technical leadership / mentoring
Keep current on latest Big Data technologies and products, including hands-on evaluations and in-depth research
Consult and advise solution architects on overall enterprise-wide analytics solutions that include a Data Hub Component
Works with Project Manager to perform detailed planning, risks/issues escalation.
Qualifications
Requirements for Big Data Engineer, Healthcare Analytics Senior:
4+ years of experience working with batch-processing and tools in the Hadoop tech stack (e.g., MapReduce, Yarn, Pig, Hive, HDFS, Oozie)*
4+ years of experience working with tools in the stream-processing tech stack (e.g., Spark, Storm, Samza, Kafka, Avro)* Experience developing applications that work with NoSQL stores (e.g., ElasticSearch, Hbase, Cassandra, MongoDB, CouchDB)* Experience developing for TB-level data stores and/or 10Gbps+ ingest speeds
High-capacity data ingest into Hadoop or Spark is highly desired
Hands-on experience with at least one major Hadoop Distribution such as Cloudera or Horton Works or MapR or IBM Big Insights
System usage and optimization tools such as Splunk is a plus
At least 4 years of experience delivering enterprise IT solutions as a solutions architect
8+ years of experience with SQL and at least two major RDBMS's
5+ years as a systems integrator with Linux systems and shell scripting
8+ years of doing Data related benchmarking, performance analysis and tuning
5+ years of Java experience
Solid programming experience with a preference towards Java or Python
DBA and/or Data Modeling experience
Experience with operational and business-level metadata management
Bachelor's degree in Computer Science, Information Systems, Information Technology or related field and 6+ years of software development/DW & BI experience.
Health care experience is plus
Excellent verbal and written communication skills
Love to Have:
Hands-on experience with Cloudera 4.5 and higher, Horton Works 2.1 and higher or MapR 4.01 and higher
Experience with Map/Reduce solution design and development
ETL Solution experience, preferable on Hadoop
Experience with industry leading Business Intelligence: Qualifications
null
Additional Information
All your information will be kept confidential according to EEO guidelines. please send the profiles to alih (at)usmsystems.com and contact No# 703-955-3955
",http://www.indeed.com/viewjob?jk=0f417ff890863889&qd=NGstvRTMEOvJmVpt7yc_yoTWPCm0QNPdIzzPht0ZasBpY5gwu7FCZnkMImjJUar7D0xbCEX8pxZEkbI23f4B94w2WFTZgoHbmjqtbTlwUTy_Z5i4Qk6_rCJbdisHdWXFruJraDvE4FO-ETfZ9aXbRg&indpubnum=7409121151176687&chnl=tdwi&atk=1b69nrcciah73dnk
JOB20154886266,Backend Developer/Data Engineer (m/f/d),Backend Developer/Data Engineer (m/f/d),We offer the ability to work with the newest tech-stack and the most talented engineers in IoT industry!,"Help relayr build the world's most advanced IoT Cloud Platform.,Design, develop and improve microservices and data processing pipelines in our analytics/machine learning backend using the latest technologies.,Be customer focused and translate business requirements into technological solutions.,Take part in architecture and code reviews to develop solutions that are simple, functional and sustainable.,Collaborate with other teams to define new features and continuously improve internal systems.,Work with QA and DevOps in the development, testing and deployment of services.,Work together with data scientists to design large-scale machine learning systems.,You have 3+ years of experience in backend engineering.,You have strong knowledge of Java and/or Python and are eager to learn new skills.,You have a good understanding of designing and scaling distributed systems.,You have experience working with SQL and/or NoSQL databases, messaging queues (e.g. Kafka) and large scale data processing (e.g. Apache Spark).,You are able to work in a structured manner and care about your contribution end to end.,You have a very good command of the English language.,Flexible office environment and a modern office located in Central Tower of Munich with a relaxation room, standing-desks, and free fruits and drinks,Relayrians come from all over the world, speak 20+ languages (working language is English), and welcome people of all ages and parental statuses. Our customers are as diverse as we are - join us to connect with a network of companies and people from around the globe,An extensive on-boarding period so you can get up to speed with the rest of the team,A learning environment where you can build upon your skills and interests, share knowledge, and attend events and conferences pertaining to your discipline. We also offer free German classes at all levels,Have some fun with regular team lunches and offsites, a yearly company summit, and our branded goodies,Competitive salary,We fully support your move to Munich with a relocation budget and visa assistance. We'll help you settle into your exciting new city!,25 paid vacation days + public holidays,Choose between a Mac, Windows, or a Linux machine","
Job description
Relayr is the Industrial Internet of Things (IIoT) powerhouse delivering the most complete solution for risk-free digital transformations. We unleash data insights from existing equipment, machines and production lines to improve our customers’ business outcomes.
We provide a unique combination of first-class IIoT technology and its delivery with powerful financial and insurance offerings — all from a single source trusted by hundreds of companies worldwide. With around 300 employees, we are a truly global family with locations in Germany, the USA, Poland, Italy, France, and the UK. Named twice the hottest start-up in Berlin by WIRED magazine and a winner of The Spark - the German Digital Award, relayr is now part of the Munich Re group.
Our analytics team pushes the boundaries of technology. We tackle challenging problems in the fields of data engineering, data science, and machine learning research to develop solutions from early prototypes to fully-fledged production-ready systems. We are looking to recruit a diverse group to be able to best handle novel challenges in the emerging market of the Internet of Things. Currently we are seeking a Backend Developer/Data Engineer to join our team and be based in our Munich office.
Your tasks:
Help relayr build the world's most advanced IoT Cloud Platform.
Design, develop and improve microservices and data processing pipelines in our analytics/machine learning backend using the latest technologies.
Be customer focused and translate business requirements into technological solutions.
Take part in architecture and code reviews to develop solutions that are simple, functional and sustainable.
Collaborate with other teams to define new features and continuously improve internal systems.
Work with QA and DevOps in the development, testing and deployment of services.
Work together with data scientists to design large-scale machine learning systems.
Your skills:
You have 3+ years of experience in backend engineering.
You have strong knowledge of Java and/or Python and are eager to learn new skills.
You have a good understanding of designing and scaling distributed systems.
You have experience working with SQL and/or NoSQL databases, messaging queues (e.g. Kafka) and large scale data processing (e.g. Apache Spark).
You are able to work in a structured manner and care about your contribution end to end.
You have a very good command of the English language.
We Offer:
Flexible office environment and a modern office located in Central Tower of Munich with a relaxation room, standing-desks, and free fruits and drinks
Relayrians come from all over the world, speak 20+ languages (working language is English), and welcome people of all ages and parental statuses. Our customers are as diverse as we are - join us to connect with a network of companies and people from around the globe
An extensive on-boarding period so you can get up to speed with the rest of the team
A learning environment where you can build upon your skills and interests, share knowledge, and attend events and conferences pertaining to your discipline. We also offer free German classes at all levels
Have some fun with regular team lunches and offsites, a yearly company summit, and our branded goodies
Competitive salary
We fully support your move to Munich with a relocation budget and visa assistance. We'll help you settle into your exciting new city!
25 paid vacation days + public holidays
Choose between a Mac, Windows, or a Linux machine
We offer the ability to work with the newest tech-stack and the most talented engineers in IoT industry!
At relayr, we are passionate about creating an inclusive workplace that promotes and values diversity. As firm believers in the power of different perspectives, we encourage our employees to share knowledge and exchange bold ideas to help innovation in the IoT industry thrive.We are committed to creating a fair, supportive, and open environment for all.
",http://stackoverflow.com/jobs/409827/backend-developer-data-engineer-m-f-d-relayr-gmbh
JOB23563650059,Senior Data Engineer - BlackLocus Jobs in Texas,Senior Data Engineer - BlackLocus Jobs in Texas,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/texas/usa/jobs/?utm_source=.JOBS%20RSS%20Feed-DE&utm_medium=.JOBS%20Universe&vs=25&utm_campaign=.JOBS%20RSS%20Feed
JOB25347024982,Senior Growth Data Engineer / Analyst,Senior Growth Data Engineer / Analyst,Fluency in English written/spoken,"Diligence, perseverance, and proactiveness are key to succeed in this position.,Lead structure and implementation of metrics tracking systems, working directly with the Sr Director of Growth.,Utilize Amplitude, Python, Tableau, Looker and SQL to pull data and provide key analytical insights.,Report, monitor, track, and analyze traffic, revenue, and other KPIs.,Identify product risks/opportunities and communicate them succinctly and effectively.,Help product team set up A/B tests and perform statistical analysis on results to provide actionable insights.,Build statistical models to predict interactions and segment users based on behaviour.,Provide ad-hoc analytics support as needed, ranging from helping teams develop the question through tracking and implementation to analytics and insights.,Collaborate with the Business Intelligence team on building shareable data tools, maintain documentation, and participate in deep-dives to understand drivers of success.,Collaborate with multiple cross-functional teams and work on solutions which have a larger impact on Xapo business.,7 years’ experience in growth marketing, data analytics, or a related field;,Proven experience of using successfully the analytic platform Amplitude.,In-depth understanding of data structures and algorithms.,Proven experience of having worked for a mobile app with large growth.,Experience in designing and building dimensional data models to improve accessibility, efficiency, and quality of data.,Strong analytical and communication skills.,Experience developing, maintaining, automating, visualizing, analyzing, and communicating reporting to management.,Bachelor’s Degree in computer science or a related field is preferred.","
Job description
RESPONSIBILITIES As a Growth Senior Data Engineer / Analyst, you will help lead growth and customer engagement initiatives for our mobile products. You will be data-driven and results focused, thriving at the intersection of data, product, engineering, and marketing. The ideal candidate will have a strong technical, analytical, and product marketing background – with a motivation to use analytic insight to grow Xapo mobile customer base on a Global scale. The successful candidate will have curiosity, a passion for data, and demonstrate data leadership to impact the business.
Diligence, perseverance, and proactiveness are key to succeed in this position.
Lead structure and implementation of metrics tracking systems, working directly with the Sr Director of Growth.
Utilize Amplitude, Python, Tableau, Looker and SQL to pull data and provide key analytical insights.
Report, monitor, track, and analyze traffic, revenue, and other KPIs.
Identify product risks/opportunities and communicate them succinctly and effectively.
Help product team set up A/B tests and perform statistical analysis on results to provide actionable insights.
Build statistical models to predict interactions and segment users based on behaviour.
Provide ad-hoc analytics support as needed, ranging from helping teams develop the question through tracking and implementation to analytics and insights.
Collaborate with the Business Intelligence team on building shareable data tools, maintain documentation, and participate in deep-dives to understand drivers of success.
Collaborate with multiple cross-functional teams and work on solutions which have a larger impact on Xapo business.
REQUIREMENTS
7 years’ experience in growth marketing, data analytics, or a related field;
Proven experience of using successfully the analytic platform Amplitude.
In-depth understanding of data structures and algorithms.
Proven experience of having worked for a mobile app with large growth.
Experience in designing and building dimensional data models to improve accessibility, efficiency, and quality of data.
Strong analytical and communication skills.
Experience developing, maintaining, automating, visualizing, analyzing, and communicating reporting to management.
Bachelor’s Degree in computer science or a related field is preferred.
Fluency in English written/spoken
",https://stackoverflow.com/jobs/253249/senior-growth-data-engineer-analyst-xapo
JOB25842910213,Senior Data Engineer - BlackLocus,Senior Data Engineer - BlackLocus,,,"
Job Information
POSITION PURPOSE
The Sr Data Engineer will expand and optimize data, data flow, data collection for cross functional teams, and data pipeline architecture. The Sr Data Engineer will support and collaborate with the software engineering team, data analysts, and data scientist to ensure data delivery architecture is consistent throughout ongoing projects. Continuously improve or re-design data architecture to support the next generation of products and initiatives.
MAJOR TASKS, RESPONSIBILITES AND KEY ACCOUNTABILITIES
40% - Data Validation, ETL, Infrastructure Development: Coding validation and ETL to ensure successful data integration
30% - Data Infrastructure Maintenance: Backup and optimization activities to maintain performance; code, configure, test, etc data to ensure integrity
20% - Data Architecture Design and Analysis: Create and maintain optimal data pipeline architecture; Develop data architecture to meet business requirements
10% - Planning/Requirements Analysis: Collaborate with team leads and cross functional partners to assess business requirements and communicate opportunities
NATURE AND SCOPE
This position reports to the Technology Leader.
This position has 0 direct reports.
ENVIRONMENTAL JOB REQUIREMENTS
Environment:
Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.
Travel:
Typically requires overnight travel less than 10% of the time.
Additional Environmental Job Requirements:MINIMUM QUALIFICATIONS
Must be eighteen years of age or older.
Must be legally permitted to work in the United States.
Additional Minimum Qualifications:
Experience message queuing, stream processing, and scalable data stores
Experience managing projects and organizing data
Experience supporting and working with cross-functional teams
Experience with SQL, NoSQL databases, relational databases, and query authoring
Experience building and optimizing data pipelines, architectures, data sets and workflow management tools such as Azkaban, Luigi, Airflow, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C#, Scala, GoLang, etc.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
Education Required:
The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.
Years of Relevant Work Experience: 5 years
Physical Requirements:
Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.
Additional Qualifications:
Preferred Qualifications:
8+ years of previous related work experience
Ability to convey complex or technical ideas and processes in easy-to-understand terms to diverse audiences
Ability to negotiate, handle complaints, settle disputes, and resolve grievances with both internal and external customers
Excellent written and verbal communication skills
Knowledge, Skills, Abilities and Competencies:Collaborates - Building partnerships and working collaboratively with others to meet shared objectives
Communicates Effectively - Developing and delivering multi-mode communications that convey a clear understanding of the unique needs of different audiences
Cultivates Innovation - Creating new and better ways for the organization to be successful
Drives Engagement - Creating a climate where people are motivated to do their best to help the organization achieve its objectives
Instills Trust - Gaining the confidence and trust of others through honesty, integrity, and authenticity
Nimble Learning - Actively learning through experimentation when tackling new problems, using both successes and failures as learning fodder
Optimizes Work Processes - Knowing the most effective and efficient processes to get things done with a focus on continuous improvement
Plans and Aligns - Planning and prioritizing work to meet commitments aligned with organizational goals
Tech Savvy - Anticipating and adopting innovations in business-building digital and technology applications. We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
",https://militaryjobs.homedepot.com/austin-tx/senior-data-engineer-blacklocus/35068FD906174D91A159D54015CA5347/job/?utm_medium=.JOBS%20Universe&utm_campaign=.JOBS%20RSS%20Feed&utm_source=.JOBS%20RSS%20Feed-DE
JOB25890882594,Data Engineer,Data Engineer,,,"
POSITION PURPOSE
Congrats! You re learning about an exciting new role with The Home Depots Global Custom Commerce (GCC) team that will revitalize and invigorate the way we manage and view data. For this role, we are looking for some one who can develop, implement, test and maintain data pipelines (batch & streaming) and data structures within a cloud based column-oriented data store. This person will support the GCC BI and Data Science strategic initiatives to drive better customer experiences and more profitable outcomes
Why work here? Our entrepreneurial roots and maverick mentality, coupled with the resources and backing of the #1 home improvement retailer in the world, The Home Depot, is a unique opportunity for you to be a transformative retail disrupter. Plus, GCC is the world s largest online window covering company, and we ve got a demonstrably awesome 20-year track record. From our open-floor office to our open-door ethos, our culture is rooted in improving, evolving, and having fun (we re pretty serious about cake, cook-offs, ping pong, meaningful work and exciting projects). Most importantly, our team members are always inspired, engaged, and ready for growth. That means you ll have the resources and the runway to create truly magical, out-of-the-box work. Moreover, you will play an important role in leveraging our culture, people, systems, processes, and technology ultimately to provide incredible customer experiences, while growing business for GCC and The Home Depot. This is your chance to be part of something big, in a small start-up environment. We re ranked as one of The Top 5 Workplaces in Texas and have consistently won the following awards:The Best Place to Work in Houston (Houston Business Journal), Houston s Top Workplaces (Houston Chronicle) and Houston s Best and Brightest.
MAJOR TASKS, RESPONSIBILITES AND KEY ACCOUNTABILITIES
20%- Implement a real time streaming data ingestion and processing pipeline using Google Dataflow (Apache Beam)
20%- Interface with business intelligence analyts and others in IT (i.e. data engineers, architects, WebOps) in frequent whiteboard sessions to dicsucuss the design, implementation, and testing of data pipleines
20%- Maintain data architecture standards and ETL/ELT best practices consistent with a column oritented data store in an analytic use case
20%- Active and engaged particitpation in the Scrum delivery process
20%- Support solutions in production
NATURE AND SCOPE
This role reports to the Sr. Manager of EDW.
This role has no direct reports.
ENVIRONMENTAL JOB REQUIREMENTS
Environment:
Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.
Travel:
Typically requires overnight travel less than 10% of the time.MINIMUM QUALIFICATIONS
Must be eighteen years of age or older.
Must be legally permitted to work in the United States.
Education Required:
The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.
Years of Relevant Work Experience: 6 years
Physical Requirements:
Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.
Preferred Qualifications:
Familiarity with Agile methodologies
Experience with Spark dataframes, SparkSQL, Kafka, KSQL, real-time streaming, and message bus technologies
Experience with data science technologies such as SAS, R, Matlab, or similar
Experience with data warehousing and dimensional modeling
Knowledge, Skills, Abilities and Competencies:
Experience in building real time streaming data ingestion and processing pipeline using Apache Beam (running on either Google Datflow or Apache (Apex, Flink, or Spark) or Kafka in an analytics or data science use case
Experience with data processing tools (e.g. Hadoop, Spark, Dataflow, etc.)
Experience building ETL/ELT pipelines
Experience with column-oriented databases (e.g Redhift, BigQuery, Vertica)
Ability to go from whiteboard discussion to code
Ability to effectively communicate with technical and non-technical audiences
Strong programming ability
Success in a highly dynamic environment and ability to shift priorities with agility
Ability to act independently with minimal supervision
Willingness to explore and implement new ideas and technologies
Experience working directly with subject matter experts in both business and technology domains
Experience as a team lead We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
",https://militaryjobs.homedepot.com/houston-tx/data-engineer/4B642DC9C39B4857867CACB6FE730745/job/?utm_medium=.JOBS%20Universe&utm_campaign=.JOBS%20RSS%20Feed&utm_source=.JOBS%20RSS%20Feed-DE
JOB27455964173,Senior Data Engineer - BlackLocus Jobs in United States,Senior Data Engineer - BlackLocus Jobs in United States,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/usa/jobs/?utm_medium=.JOBS%20Universe&utm_source=.JOBS%20RSS%20Feed-DE&vs=25&utm_campaign=.JOBS%20RSS%20Feed
JOB28278507262,Senior+ Data Engineer,Senior+ Data Engineer,"Roughly 5 (or more!) years of Industry experience on a data or machine learning team,Proficiency with modern programming languages (Go, Python, Java, Scala, etc.) and SQL,Some practical experience with probability, statistical modeling, or machine learning,Backend developer experience optimizing the data access layer in mature web applications,Experience building and working with real-time compute and streaming infrastructures (Kafka, Kinesis, Flink, Storm, Beam, etc.),Experience writing and debugging ETL jobs using a distributed data framework.,A deep and abiding appreciation for agile software processes, data-driven development, reliability, and responsible experimentation,A collaborative attitude and a helpful personality,Health, dental, vision, and life insurance,401k matching program,Commuter benefits,Catered lunch and unlimited snacks,Unlimited reimbursement for work related books","Enable data scientists to train and deploy machine learning algorithms at scale, in fault-tolerant, highly-available systems,Use best practices in continuous integration and delivery with Docker and Kubernetes.,Work closely with application engineers to build data products that power Carta’s core applications,Create data pipelines using batch and streaming tools like Airflow, Spark, Kafka, and Google Pub/Sub,Uphold our engineering standards and bring consistency to the many codebases and processes you will encounter","Reasons could include: the employer is not accepting applications, is not actively hiring, or is reviewing applications
Carta is hiring experienced data engineers at the Senior, Staff, Senior Staff, and Principal levels in San Francisco, Palo Alto, Seattle, and New York City to build products and services powered by the ownership graph: the central registry of asset ownership across the globe.
As a data engineer at Carta, you’ll play a foundational role on Carta’s fast-growing Data & Machine Learning organization, working on one of the world’s most valuable data sets. You’ll spend two thirds of your time working on data engineering and backend software projects, and split the remaining third between DevOps, data science, and machine learning.
Candidates must have strong technical skills, be excited by “zero to one” projects, and enjoy working closely with stakeholders across engineering, product, business, and marketing.
Enable data scientists to train and deploy machine learning algorithms at scale, in fault-tolerant, highly-available systems
Use best practices in continuous integration and delivery with Docker and Kubernetes.
Work closely with application engineers to build data products that power Carta’s core applications
Create data pipelines using batch and streaming tools like Airflow, Spark, Kafka, and Google Pub/Sub
Uphold our engineering standards and bring consistency to the many codebases and processes you will encounter
Roughly 5 (or more!) years of Industry experience on a data or machine learning team
Proficiency with modern programming languages (Go, Python, Java, Scala, etc.) and SQL
Some practical experience with probability, statistical modeling, or machine learning
Backend developer experience optimizing the data access layer in mature web applications
Experience building and working with real-time compute and streaming infrastructures (Kafka, Kinesis, Flink, Storm, Beam, etc.)
Experience writing and debugging ETL jobs using a distributed data framework.
A deep and abiding appreciation for agile software processes, data-driven development, reliability, and responsible experimentation
A collaborative attitude and a helpful personality
Carta is creating the ownership network that maps the world's assets. Check out who we are and how we work here.
At Carta we want to create an environment for Carta's owners - you - to do your best work, by offering competitive benefits and perks:
We are committed to WELLNESS:
Health, dental, vision, and life insurance
Competitive PTO and unlimited sick time
401k matching program
Commuter benefits
Catered lunch and unlimited snacks
Cell phone stipend
Unlimited reimbursement for work related books
Fast paced work environment geared towards professional growth
Carta is backed by many of the best investors in the world, including Social Capital (Slack, Intercom, Box), Union Square Ventures (Twitter, Twilio, Coinbase), Menlo Ventures (Uber, Warby Parker), Spark Capital (Oculus VR, Slack, Cruise Automation), Meritech Capital (GoFundMe, Looker, Snowflake), and Tribe Capital.
","http://www.indeed.com/viewjob?t=Senior+Data+Engineer&c=Carta&l=San+Francisco,+CA&jk=0188214e1dabf20c&rtk=1d6u5i0ddb8f2800&from=rss"
JOB28888356411,Data Engineer,Data Engineer,,,"
Data Engineer
今すぐ応募する 採用情報 ID R1907859
VMware (NYSE: VMW) is the global leader in virtualization and cloud infrastructure, two areas that consistently rank as top priorities among CIOs. VMware delivers award-winning, customer-proven solutions that accelerate IT by reducing complexity and enabling more flexible, agile service delivery. Our solutions help organizations of all sizes, lower costs, increase business agility and ensure freedom of choice. We are searching for people who are ready to accelerate, innovate and lead to join our team of more than 20,000 employees in 40+ locations worldwide working to develop innovative solutions that deliver the future of IT through cloud computing. Having the audacity to challenge constraints and problem-solve for tomorrow starts today, and it starts with you. Learn more at www.vmware.com/careers
Are you looking for a high energy team where you can make a direct contribution to envisioning and architecting next generation Data Analytics platform?
Are you looking to join a company with a vision to imagine, design, and create a better world who is also recognized as top places to work for in Silicon Valley?
Your next adventure at VMware is only a click away!
VMware's Data Analytics Team is looking for a Data Engineer to help build on Next generation Near Realtime BI Platform based on SAP HANA and Hadoop. You will be responsible for building and enhancing the solutions on the existing platform based on the business needs in partnering with fellow Developers and Business groups.
Responsibilities:
·Understand the business capability/requirements and transform them into robust design solutions
·Perform hands on work using Python, able to write complex SQL’s, understand API and be able to consume/write API’s as needed
·Perform report development using enterprise tools such as Tableau, SAP BOBJ and other open source reporting platforms.
·Perform hands on work using SAP HANA, Hadoop/HAWQ SDI/SLT, Informatica to build next generation NearRealTime data analytics platform.
·Integrate data sets from difference sources using Informatica, Python, SAP SDI/SLT
·Protect data integrity and accuracy. Perform root cause analysis of issues that hinder the data quality. Work with data source owner to increase quality and accuracy of the source data.
·Help data consumers to correctly understand and use the data.
·Building reports based on the business need.
Qualifications:
·5+ years of experience in as a BI/Data Engineer handling large volumes of data.
·Excellent knowledge of data warehouse technical architecture, infrastructure components, ETL/ELT and reporting/analytic tools.
·Expertise in writing advanced SQL queries.
·Experience working with Informatica, SAP SDI/SLT
·Expertise in SAP HANA, Hive/Hadoop/Hawq
·Working knowledge of BI Reporting tools like BOBJ and Tableau is a plus.
·Experience in Python Scripting
·Familiarity with Amazon Web Services (AWS), Redshift is a plus
·Strong analytical and troubleshooting skills
·Excellent verbal and written communication skills
·Bachelor’s degree in Computer science, Statistics, Mathematics, Engineering or relevant field.
This position is eligible for the IT Apps Hiring FY20 referral campaign
今すぐ応募する ",https://japan.careers.vmware.com/%e3%82%b8%e3%83%a7%e3%83%96/-/data-engineer/22639/12243800
JOB29366716133,"CVML - Failure Analysis, Data Engineer","CVML - Failure Analysis, Data Engineer","You're aware of the challenges associated to building ML datasets and computer vision models: definition and coverage of target data distribution, bias,You have creativity and a good sense of product, which enable you to have an intuition of how each model is expected to work (eg face detector), where a model could potentially fail (eg low light, pale/dark skin etc...), what data can be used to test failure patterns,You have strong Python coding skills which enable you to manipulate data at scale & run ML models,You come up with data-driven solutions when facing situations of trade-offs/decision under uncertainty",," iPhone is the most popular camera in the world. In our Camera & Photos organization (C&P), the precise integration of software and hardware has led to features like Memories and Portrait Mode, which deliver magical, user-focused experiences to 1 Billion+ devices. Within Camera and Photos, Computer Vision and Machine Learning group (CVML) is responsible for crafting machine learning solutions applied to Apple's image and video processing technologies. This includes technology for OS X and iOS system frameworks (e.g. face recognition and scene classification) as well as internal tools. The group combines research and development in a fast-paced environment. Our data team is responsible for building high quality datasets at scale for all features developed in CVML, and more generally in Camera and Photos. We are looking for a failure analysis engineer to challenge both models and datasets created by R&D teams across the organization, in order to make sure they deliver the quality expected from Apple products.
You're aware of the challenges associated to building ML datasets and computer vision models: definition and coverage of target data distribution, bias
You have creativity and a good sense of product, which enable you to have an intuition of how each model is expected to work (eg face detector), where a model could potentially fail (eg low light, pale/dark skin etc...), what data can be used to test failure patterns
You have strong Python coding skills which enable you to manipulate data at scale & run ML models
You come up with data-driven solutions when facing situations of trade-offs/decision under uncertainty
You show strong communication skills and proactivity, and you’re comfortable interacting with multiple R&D teams
Our team works in close interaction with R&D, infrastructure and client teams, as well as with other groups and other functions across Apple (legal, privacy) and externally. In this position, you will partner with R&D DRIs (technical leads) and with clients of current and future models built by C&P to figure out how our models should perform. You will test these models at scale (with millions of images) to discover failure patterns from data. The role also includes the production of tools associated with failure analysis: testing framework, reporting, data visualization.
",https://www.indeed.com/rc/clk?jk=f68990bc40964381&fccid=c1099851e9794854&vjs=3
JOB30688700521,Data Engineer,Data Engineer,"Experience with search technologies (Solr, ElasticSearch, Lucene)","U.S. Citizenship - Must be able to obtain a security clearance,Bachelors Degree in Computer Science, Computer Engineering, Electrical Engineering or related field,Experience with Java, Kotlin, or Scala,Experience with scripting languages (Python, Bash, etc.),Experience with object-oriented software development,Experience working within a UNIX/Linux environment,Experience working with a message-driven architecture (JMS, Kafka, Kinesis, SNS/SQS, etc.),Ability to determine the right tool or technology for the task at hand,Works well in a team environment,Strong communication skills,Experience with massively parallel processing systems like Spark or Hadoop,Familiarity with data pipeline orchestration tools (Apache Airflow, Apache NiFi, Apache Oozie, etc.),Familiarity in the AWS ecosystem of services (EMR, EKS, RDS, Kinesis, EC2, Lambda, CloudWatch),Experience working with recommendation engines (Spark MLlib, Apache Mahout, etc.),Experience building custom machine learning models with TensorFlow,Experience with natural language processing tools and techniques,Experience with Kubernetes and/or Docker container environment,Ability to identify external data specifications for common data representations,Experience building monitoring and alerting mechanisms for data pipelines","
Job description
Our customers are inundated with information from news articles, video feeds, social media and more. We’re looking to help them parse through it faster and focus on the information that’s most important that allows them to make better decisions. We're in the process of building a next-generation analysis and exploitation platform for video, audio, documents, and social media data. This platform will help users identify, discover and triage information via a UI that leverages best in class speech-to-text, machine translation, image recognition, OCR, and entity extraction services.
We're looking for data engineers to develop the infrastructure and systems behind our platform. The ideal contributor should have experience building and maintaining data and ETL pipelines. They will be expected to work in a collaborative environment, able to communicate well with their teammates and customers. This is a great opportunity to work with a high-performing team in a fun environment.
At BTI360, we’re passionate about building great software and developing our people. Software doesn't build itself; teams of people do. That's why our primary focus is on developing better engineers, better teammates, and better leaders. By putting people first, we give our teammates more opportunities to grow and raise the bar of the software we develop.
Interested in learning more? Apply today!
Required Skills/Experience:
U.S. Citizenship - Must be able to obtain a security clearance
Bachelors Degree in Computer Science, Computer Engineering, Electrical Engineering or related field
Experience with Java, Kotlin, or Scala
Experience with scripting languages (Python, Bash, etc.)
Experience with object-oriented software development
Experience working within a UNIX/Linux environment
Experience working with a message-driven architecture (JMS, Kafka, Kinesis, SNS/SQS, etc.)
Ability to determine the right tool or technology for the task at hand
Works well in a team environment
Strong communication skills
Desired Skills:
Experience with massively parallel processing systems like Spark or Hadoop
Familiarity with data pipeline orchestration tools (Apache Airflow, Apache NiFi, Apache Oozie, etc.)
Familiarity in the AWS ecosystem of services (EMR, EKS, RDS, Kinesis, EC2, Lambda, CloudWatch)
Experience working with recommendation engines (Spark MLlib, Apache Mahout, etc.)
Experience building custom machine learning models with TensorFlow
Experience with natural language processing tools and techniques
Experience with Kubernetes and/or Docker container environment
Ability to identify external data specifications for common data representations
Experience building monitoring and alerting mechanisms for data pipelines
Experience with search technologies (Solr, ElasticSearch, Lucene)
BTI360 is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status, or any other protected class.
",http://stackoverflow.com/jobs/410141/data-engineer-bti360
JOB31828247590,Data Engineer,Data Engineer,,,"
POSITION PURPOSE
Congrats! You re learning about an exciting new role with The Home Depots Global Custom Commerce (GCC) team that will revitalize and invigorate the way we manage and view data. For this role, we are looking for some one who can develop, implement, test and maintain data pipelines (batch & streaming) and data structures within a cloud based column-oriented data store. This person will support the GCC BI and Data Science strategic initiatives to drive better customer experiences and more profitable outcomes
Why work here? Our entrepreneurial roots and maverick mentality, coupled with the resources and backing of the #1 home improvement retailer in the world, The Home Depot, is a unique opportunity for you to be a transformative retail disrupter. Plus, GCC is the world s largest online window covering company, and we ve got a demonstrably awesome 20-year track record. From our open-floor office to our open-door ethos, our culture is rooted in improving, evolving, and having fun (we re pretty serious about cake, cook-offs, ping pong, meaningful work and exciting projects). Most importantly, our team members are always inspired, engaged, and ready for growth. That means you ll have the resources and the runway to create truly magical, out-of-the-box work. Moreover, you will play an important role in leveraging our culture, people, systems, processes, and technology ultimately to provide incredible customer experiences, while growing business for GCC and The Home Depot. This is your chance to be part of something big, in a small start-up environment. We re ranked as one of The Top 5 Workplaces in Texas and have consistently won the following awards:The Best Place to Work in Houston (Houston Business Journal), Houston s Top Workplaces (Houston Chronicle) and Houston s Best and Brightest.
MAJOR TASKS, RESPONSIBILITES AND KEY ACCOUNTABILITIES
20%- Implement a real time streaming data ingestion and processing pipeline using Google Dataflow (Apache Beam)
20%- Interface with business intelligence analyts and others in IT (i.e. data engineers, architects, WebOps) in frequent whiteboard sessions to dicsucuss the design, implementation, and testing of data pipleines
20%- Maintain data architecture standards and ETL/ELT best practices consistent with a column oritented data store in an analytic use case
20%- Active and engaged particitpation in the Scrum delivery process
20%- Support solutions in production
NATURE AND SCOPE
This role reports to the Sr. Manager of EDW.
This role has no direct reports.
ENVIRONMENTAL JOB REQUIREMENTS
Environment:
Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.
Travel:
Typically requires overnight travel less than 10% of the time.MINIMUM QUALIFICATIONS
Must be eighteen years of age or older.
Must be legally permitted to work in the United States.
Education Required:
The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.
Years of Relevant Work Experience: 6 years
Physical Requirements:
Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.
Preferred Qualifications:
Familiarity with Agile methodologies
Experience with Spark dataframes, SparkSQL, Kafka, KSQL, real-time streaming, and message bus technologies
Experience with data science technologies such as SAS, R, Matlab, or similar
Experience with data warehousing and dimensional modeling
Knowledge, Skills, Abilities and Competencies:
Experience in building real time streaming data ingestion and processing pipeline using Apache Beam (running on either Google Datflow or Apache (Apex, Flink, or Spark) or Kafka in an analytics or data science use case
Experience with data processing tools (e.g. Hadoop, Spark, Dataflow, etc.)
Experience building ETL/ELT pipelines
Experience with column-oriented databases (e.g Redhift, BigQuery, Vertica)
Ability to go from whiteboard discussion to code
Ability to effectively communicate with technical and non-technical audiences
Strong programming ability
Success in a highly dynamic environment and ability to shift priorities with agility
Ability to act independently with minimal supervision
Willingness to explore and implement new ideas and technologies
Experience working directly with subject matter experts in both business and technology domains
Experience as a team lead We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
",https://militaryjobs.homedepot.com/houston-tx/data-engineer/4B642DC9C39B4857867CACB6FE730745/job/?utm_source=.JOBS%20RSS%20Feed-DE&utm_medium=.JOBS%20Universe&utm_campaign=.JOBS%20RSS%20Feed
JOB32046171178,Senior Data Engineer - BlackLocus Jobs in Texas,Senior Data Engineer - BlackLocus Jobs in Texas,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/texas/usa/jobs/?vs=25&utm_source=.JOBS%20RSS%20Feed-DE&utm_medium=.JOBS%20Universe&utm_campaign=.JOBS%20RSS%20Feed
JOB32088074334,Back End Data Engineer,Back End Data Engineer,,,"
Job description
## DESCRIPTION:
Clevertech is looking for a Back End Data Engineer to join our global team.
This role has database design and implementation responsibilities including alternative data structures such as nosql, redis, elasticsearch and more. Clevertech looks for craftsmen developers who take ownership of their code.
You can deliver quickly while being clever to avoid missteps. You have an effective positive attitude that shines as you show you care about client and colleague concerns. You are always learning and are a transparent communicator even when it is challenging. You thrive on challenging yourself daily and seek to surround yourself with like minded individuals.
## REQUIREMENTS:
* 5+ years experience with complex data structures.
* You have deep experience in the latest libraries and programming techniques.
* You have accomplishments that showcase your capabilities by their success and technical depth.
* You own new features from idea to completion.
* Work well with a core team to design and execute major new features.
* Familiar with SQL/NoSQL databases like MongoDB and their declarative query languages is a plus
* Enjoy contributing to a fast moving exciting project
* Strong experience using GitHub in a professional environment
* Strong communicator and fluent in English with excellent written and verbal communication skills.
* Thrive and excel in our diverse, distributed and agile team environment
",https://stackoverflow.com/jobs/200730/back-end-data-engineer-clevertech
JOB32095676506,Data Engineer,Data Engineer,"BS in computer science, systems engineering, or a similar technical field with relevant work experience.,An understanding of data model design, database schemas, and optimizing database applications.,A breadth of understanding of database technologies including both relational and non-relational solutions.,Experience manipulating large data sets of time-series and intermittent data.,Experience using version control software.,Experience designing and developing database access layers for schemas that contain multiple databases containing unique data types and access requirements.,Experience working with Python as a primary development language with an emphasis on data management and processing.,Experience with MySQL and MongoDB,Experience producing software for a clinical setting that utilizes clinical patient data, e.g., labs, physiologic signals, and administrative data.,An understanding of clinical (or any data-driven) research from a data aggregation and methodologies standpoint (study design, subject protections, and statistical analysis).,Experience with Agile software development methodologies, and continuous integration and delivery.","Interface with software stakeholders to understand infrastructure and user requirements.,Develop and support Etiometry's data-warehouse solution both for clinical personnel and internal research staff.,Build, test and deploy software and database upgrades into a production environment.,Utilize and improve Etiometry’s clinical data cleaning tools and techniques, which include data extraction, de-identification, and clinical measure normalization & cleaning.,Design and implement data requirements for company research.","
Job description
We are currently seeking a Data Engineer who will assist in the implementation and utilization of a hospital-based clinical data-warehouse system. Your role will be to support existing software, integrate new data sources, and mine data for research, with a focus on efficiency and availability. Etiometry has one of the largest collections of pediatric intensive care unit monitoring data and the volume and data types are continually increasing. The data sets provide numerous storage and normalization challenges, but can offer important insights into the efficacy of existing treatments and reveal new and innovative patient management strategies.
Responsibilities
Interface with software stakeholders to understand infrastructure and user requirements.
Develop and support Etiometry's data-warehouse solution both for clinical personnel and internal research staff.
Build, test and deploy software and database upgrades into a production environment.
Utilize and improve Etiometry’s clinical data cleaning tools and techniques, which include data extraction, de-identification, and clinical measure normalization & cleaning.
Design and implement data requirements for company research.
Basic Qualifications
BS in computer science, systems engineering, or a similar technical field with relevant work experience.
An understanding of data model design, database schemas, and optimizing database applications.
A breadth of understanding of database technologies including both relational and non-relational solutions.
Experience manipulating large data sets of time-series and intermittent data.
Experience using version control software.
Desired Qualifications
Experience designing and developing database access layers for schemas that contain multiple databases containing unique data types and access requirements.
Experience working with Python as a primary development language with an emphasis on data management and processing.
Experience with MySQL and MongoDB
Experience producing software for a clinical setting that utilizes clinical patient data, e.g., labs, physiologic signals, and administrative data.
An understanding of clinical (or any data-driven) research from a data aggregation and methodologies standpoint (study design, subject protections, and statistical analysis).
Experience with Agile software development methodologies, and continuous integration and delivery.
",https://stackoverflow.com/jobs/199602/data-engineer-etiometry-inc
JOB32456602724,Principal Big Data Engineer- Big Data & ETL at Kaiser Permanente,Principal Big Data Engineer- Big Data & ETL at Kaiser Permanente,"Minimum four (4) years experience in the planning, design, and implementation of security solutions, including Minimum two (2) years experience leading the design, implementation, troubleshooting, and operation of security technologies.,Minimum two (2) years in a technical leadership role with or without direct reports.,Bachelor's degree in Computer Science, CIS, or related field and Minimum eight (8) years experience in an IT operations environment with technical experience in distributed technologies, systems development, and/or networking. Additional equivalent work experience may be substituted for the degree requirement.
Preferred Qualifications:,Three (3) years of experience building technology solutions to meet corporate or industry IT regulatory requirements.,Three (3) years experience in the design and implementation of complex data infrastructure solutions.,Three (3) years experience in IT infrastructure consulting.
Primary Location:
California,Pleasanton,Pleasanton Tech Cntr Building F 5810 Owens Dr.
Scheduled Weekly Hours:
40
Shift:
Day
Workdays:
Mon, Tue, Wed, Thu, Fri
Working Hours Start:
8:00 AM
Working Hours End:
5:00 PM
Job Schedule:
Full-time
Job Type:
Standard
Employee Status:
Regular
Employee Group/Union Affiliation:
Salaried, Non-Union, Exempt
Job Level:
Individual Contributor
Job Category:
Information Technology
Specialty:
IT ENG Infrastructure
Department:
DCSS A2O
Travel:
Yes, 5 % of the Time","Conducts or oversees business-specific projects by applying deep expertise in subject area; promoting adherence to all procedures and policies; developing work plans to meet business priorities and deadlines; determining and carrying out processes and methodologies; coordinating and delegating resources to accomplish organizational goals; partnering internally and externally to make effective business decisions; solving complex problems; escalating issues or risks, as appropriate; monitoring progress and results; recognizing and capitalizing on improvement opportunities; evaluating recommendations made; and influencing the completion of project tasks by others.,Practices self-leadership and promotes learning in others by building relationships with cross-functional stakeholders; communicating information and providing advice to drive projects forward; influencing team members within assigned unit; listening and responding to, seeking, and addressing performance feedback; adapting to competing demands and new responsibilities; providing feedback to others, including upward feedback to leadership and mentoring junior team members; creating and executing plans to capitalize on strengths and improve opportunity areas; and adapting to and learning from change, difficulties, and feedback.,As part of the IT Engineering job family, this position is responsible for leveraging DEVOPS, and both Waterfall and Agile practices, to design, develop, and deliver resilient, secure, multi-channel, high-volume, high-transaction, on/off-premise, cloud-based solutions.,Provides consultation and expert technical advice on IT infrastructure planning, engineering, and architecture for assigned systems by assessing the implications of IT strategies on infrastructure capabilities.,Provides some recommendations and input on options, risks, costs, and benefits for systems designs.,Leverages partnerships with IT teams and key business partners to troubleshoot complex systems.,Serves as a functional expert and collaborates with architects and software engineers to ensure functional specifications are converted into flexible, scalable, and maintainable system designs.,Translates business requirements, and functional and non-functional requirements, into technical specifications that support integrated and sustainable designs for complex or high impact infrastructure systems by partnering with Business Analysts to understand business needs and functional specifications.,Ensures system designs adhere to company architecture standards.,Builds partnerships with counterparts in various IT Teams (e.g., database, operations, technical support) throughout system development and implementation.,Serves as a technical expert for project teams throughout the implementation and maintenance of assigned enterprise infrastructure systems by defining and overseeing the documentation of detailed standards (e.g., guidelines, processes, procedures) for the introduction and maintenance of services.,Mentors other technical resources throughout infrastructure systems development.,Reviews and validates technical specifications and documentation for complex or multi-dimensional solutions.,Leads the development and modification of solutions by identifying technical solutions to business problems.,Collaborates with business leaders, Solutions, and lead enterprise architects to review business drivers, and establish a foundation for enterprise systems planning.,Reviews benchmarking results, and provides information to support current and future infrastructure needs and projects to IT leadership. Provides preliminary conclusions.,Benchmarks and evaluates IT trends and technologies to identify opportunities and considerations that impact ROI.,Makes recommendations on resources required to maintain service levels and meet new demands.,Guides and drives physical architecture design for new initiatives. khgrsr
Minimum Qualifications:","
Description:
As a Data Engineer - Big Data and ETL, you will participate in
all aspects of the software development lifecycle which includes estimating,
technical design, implementation, documentation, testing, deployment and
support of applications developed for our business partners. As a member
working in a team environment you will take direction from solution/Platform
architects and Leads on development activities. Work inside a team with Strong
Data Warehousing skills, including: Data cleanup, ETL, ELT and handling
scalability issues for enterprise level data warehouse. Implements,
troubleshoots, and optimizes distributed solutions based on modern big data
technologies like Hive, Hadoop, Spark, Elastic Search, Storm, Kafka,
etc. in both an on premise and cloud deployment model to solve large scale
processing problems. The software application landscape within KP-IT spans many
technologies that include:
o
building data platform on cloud (AWS or Azure)
o
using Python, Java or any other language to solving data
problems
o
implementing SDLC best practices and Agile methods
In addition to the responsibilities listed below, this position is responsible for planning, designing, and building database systems that are stable, recoverable, and integrated with other available technology stacks for the purpose of efficient, secure data utilization. This includes understanding the interoperability between databases and other dependent technology stacks (performance scalability, stability, capacity planning, etc.), possessing in-depth knowledge in one dependent technology stack (e.g. windows admin, networking, storage, etc.), negotiating with other engineering platform partners, and consulting as 2nd level technical expert on specific platforms. This role also requires familiarity with at least one other DBMS platform in addition to specialty and administrative skills in at least one other platform.Some of the unique challenges this position will face include database considerations for a large, corporate enterprise and a high degree of complexity and non-uniformity.
Essential Responsibilities:
Conducts or oversees business-specific projects by applying deep expertise in subject area; promoting adherence to all procedures and policies; developing work plans to meet business priorities and deadlines; determining and carrying out processes and methodologies; coordinating and delegating resources to accomplish organizational goals; partnering internally and externally to make effective business decisions; solving complex problems; escalating issues or risks, as appropriate; monitoring progress and results; recognizing and capitalizing on improvement opportunities; evaluating recommendations made; and influencing the completion of project tasks by others.
Practices self-leadership and promotes learning in others by building relationships with cross-functional stakeholders; communicating information and providing advice to drive projects forward; influencing team members within assigned unit; listening and responding to, seeking, and addressing performance feedback; adapting to competing demands and new responsibilities; providing feedback to others, including upward feedback to leadership and mentoring junior team members; creating and executing plans to capitalize on strengths and improve opportunity areas; and adapting to and learning from change, difficulties, and feedback.
As part of the IT Engineering job family, this position is responsible for leveraging DEVOPS, and both Waterfall and Agile practices, to design, develop, and deliver resilient, secure, multi-channel, high-volume, high-transaction, on/off-premise, cloud-based solutions.
Provides consultation and expert technical advice on IT infrastructure planning, engineering, and architecture for assigned systems by assessing the implications of IT strategies on infrastructure capabilities.
Provides some recommendations and input on options, risks, costs, and benefits for systems designs.
Leverages partnerships with IT teams and key business partners to troubleshoot complex systems.
Serves as a functional expert and collaborates with architects and software engineers to ensure functional specifications are converted into flexible, scalable, and maintainable system designs.
Translates business requirements, and functional and non-functional requirements, into technical specifications that support integrated and sustainable designs for complex or high impact infrastructure systems by partnering with Business Analysts to understand business needs and functional specifications.
Ensures system designs adhere to company architecture standards.
Builds partnerships with counterparts in various IT Teams (e.g., database, operations, technical support) throughout system development and implementation.
Serves as a technical expert for project teams throughout the implementation and maintenance of assigned enterprise infrastructure systems by defining and overseeing the documentation of detailed standards (e.g., guidelines, processes, procedures) for the introduction and maintenance of services.
Mentors other technical resources throughout infrastructure systems development.
Reviews and validates technical specifications and documentation for complex or multi-dimensional solutions.
Leads the development and modification of solutions by identifying technical solutions to business problems.
Collaborates with business leaders, Solutions, and lead enterprise architects to review business drivers, and establish a foundation for enterprise systems planning.
Reviews benchmarking results, and provides information to support current and future infrastructure needs and projects to IT leadership. Provides preliminary conclusions.
Benchmarks and evaluates IT trends and technologies to identify opportunities and considerations that impact ROI.
Makes recommendations on resources required to maintain service levels and meet new demands.
Guides and drives physical architecture design for new initiatives. khgrsr
Minimum Qualifications:
Minimum four (4) years experience in the planning, design, and implementation of security solutions, including Minimum two (2) years experience leading the design, implementation, troubleshooting, and operation of security technologies.
Minimum two (2) years in a technical leadership role with or without direct reports.
Bachelor's degree in Computer Science, CIS, or related field and Minimum eight (8) years experience in an IT operations environment with technical experience in distributed technologies, systems development, and/or networking. Additional equivalent work experience may be substituted for the degree requirement.
Preferred Qualifications:
Three (3) years of experience building technology solutions to meet corporate or industry IT regulatory requirements.
Three (3) years experience in the design and implementation of complex data infrastructure solutions.
Three (3) years experience in IT infrastructure consulting.
Primary Location:
California,Pleasanton,Pleasanton Tech Cntr Building F 5810 Owens Dr.
Scheduled Weekly Hours:
40
Shift:
Day
Workdays:
Mon, Tue, Wed, Thu, Fri
Working Hours Start:
8:00 AM
Working Hours End:
5:00 PM
Job Schedule:
Full-time
Job Type:
Standard
Employee Status:
Regular
Employee Group/Union Affiliation:
Salaried, Non-Union, Exempt
Job Level:
Individual Contributor
Job Category:
Information Technology
Specialty:
IT ENG Infrastructure
Department:
DCSS A2O
Travel:
Yes, 5 % of the Time
",https://www.monster.com/jobs/q-big-data-jobs.aspx
JOB32551655165,Hiring Kit: Data Engineer,Hiring Kit: Data Engineer,,Topic TechRepublic Premium,"
Topic TechRepublic Premium
Finding candidates for a Data Engineer position with the expertise and experience to implement reliable data architectures for your business will require a comprehensive recruitment process. This Hiring Kit from TechRepublic Premium provides an adjustable framework your business can use to find, recruit, and ultimately hire the right person for the job.
From the Hiring Kit:
Introduction
Whether it flows through business transactions, customer activity, employee productivity, or Internet of Things (IoT), data is the lifeblood of most modern businesses. Data leads to information and information leads to better business decisions. Gathering data in a useable framework that can be accessed by decision makers in a standardized manner is the job role of the Data Engineer.
In general terms, data engineers develop, construct, test, and maintain system architectures, such as databases and large-scale processing systems. Data engineers deal with raw data that contains human, machine, or instrument errors. The data might not be validated and may contain suspect records. It will likely be unformatted and can contain codes that are system specific.
Part of a data engineer’s role is to implement ways to improve data reliability, efficiency, and quality using a variety of languages and tools to marry systems together or search for opportunities to collect new data. Data engineers are also responsible for ensuring whatever data is collected is stored in an architecture that supports all stakeholders in the business.
",https://www.techrepublic.com/resource-library/downloads/hiring-kit-data-engineer/
JOB34354135377,Developer / Data Engineer,Developer / Data Engineer,,,"
Company: Penguin Random House US
Requisition ID: 8662
The Corporate Data Science team at Penguin Random House tackles the company’s most challenging and data intensive analytical problems. The team is well resourced and works directly under the COO.
The team is looking for an engineer to help with the construction of production systems (feedback loops) wrapping the statistical models and ML solutions developed by the team’s data scientists. The ideal candidate will have an interest in machine learning / predictive analytics. After getting up to speed with the publishing domain and our datasets, the engineer will be in a position to make critical contributions in the areas of feature engineering and system tuning.
The hiring manager is adamant about finding an engineer who can produce viable solutions quickly and efficiently, close them out and then move on to what’s next.Penguin Random House is the leading adult and children’s publishing house in North America, the United Kingdom and many other regions around the world. In publishing the best books in every genre and subject for all ages, we are committed to quality, excellence in execution, and innovation throughout the entire publishing process: editorial, design, marketing, publicity, sales, production, and distribution. Our vibrant and diverse international community of nearly 250 publishing brands and imprints include Ballantine Bantam Dell, Berkley, Clarkson Potter, Crown, DK, Doubleday, Dutton, Grosset &amp; Dunlap, Little Golden Books, Knopf, Modern Library, Pantheon, Penguin Books, Penguin Press, Penguin Random House Audio, Penguin Young Readers, Portfolio, Puffin, Putnam, Random House, Random House Children’s Books, Riverhead, Ten Speed Press, Viking, and Vintage, among others. More information can be found at http://www.penguinrandomhouse.com/.
",https://www.mediabistro.com/jobs/description/359342/developer-data-engineer/
JOB36832474655,"Senior Data Engineer, Cloud","Senior Data Engineer, Cloud",Gym membership compensation,"Drive design and implementation leveraging modern design patterns,Ability to partner effectively with UX, PM, DevOps, QE and other developers to design and implement meeting the spirit of requirements,Experience in modern front end frameworks,Technically curious to keep present on advances in technology,Experience with segregation of model, presentation, and business logic.,TDD experience and strong desire to build in test from the start.,Write code (Test or Product) to deliver against project timescales, quality and requirements in various languages including Java or other selected languages for Sophos Cloud products.,Provide guidance and mentorship to junior developers in daily Scrum meetings.,Possesses a passion for solving complex Big Data problems,Plan for, design and implement our next-generation cloud security products.,Be involved from inception through implementation in a real hands on fashion.,BS in Computer Science, Engineering, or equivalent with 7+ years of development and data modelling background,Building highly scalable SaaS solutions using Big Data technologies,Experience with CI/CD,Experience with Agile Software Development methodologies (scrum/ kanban),Excellent attention to detail,Excellent verbal and written communication skills,Experience with the following technologies (recommended) and strong desire to learn (required),Programming language -- Java (must)
Batch processing -- Hadoop ,MapReduce
Stream processing -- Kafka and Amazon Kinesis
NoSQL -S3 , MongoDB.
Columnar stores - HBASE, Amazon Redshift
Restful web services
Code/Build/Deployment -- git, hg, svn, maven, sbt, jenkins, bamboo, ...
Amazon Web Services
Data Warehousing/ built ETL,Programming language -- Java (must),Batch processing -- Hadoop ,MapReduce,Stream processing -- Kafka and Amazon Kinesis,NoSQL -S3 , MongoDB.,Columnar stores - HBASE, Amazon Redshift,Restful web services,Code/Build/Deployment -- git, hg, svn, maven, sbt, jenkins, bamboo, ...,Amazon Web Services,Data Warehousing/ built ETL,Medical insurance,Dental insurance,Vision insurance,Life insurance,Long-term disability insurance,401k plan,Vacation time","
At Sophos, we operate at the cutting edge of technology, protecting businesses worldwide against complex threats, viruses and spam. We build high quality software security products in a fast-paced, nimble environment and we've been doing it for over 20 years.
Join us to help our customers protect their business and meet compliance needs.
Role
To function as a senior data lead for product features or key technology choices and implementation. Collaborates as part of a team for the development of complex systems; including requirements analysis, concept development and design, implementation and testing, demonstrating flexibility of role as required
Main Duties
Drive design and implementation leveraging modern design patterns
Ability to partner effectively with UX, PM, DevOps, QE and other developers to design and implement meeting the spirit of requirements
Experience in modern front end frameworks
Technically curious to keep present on advances in technology
Experience with segregation of model, presentation, and business logic.
TDD experience and strong desire to build in test from the start.
Write code (Test or Product) to deliver against project timescales, quality and requirements in various languages including Java or other selected languages for Sophos Cloud products.
Provide guidance and mentorship to junior developers in daily Scrum meetings.
Possesses a passion for solving complex Big Data problems
Plan for, design and implement our next-generation cloud security products.
Be involved from inception through implementation in a real hands on fashion.
Experience And Skills
BS in Computer Science, Engineering, or equivalent with 7+ years of development and data modelling background
Building highly scalable SaaS solutions using Big Data technologies
Experience with CI/CD
Experience with Agile Software Development methodologies (scrum/ kanban)
Excellent attention to detail
Excellent verbal and written communication skills
Experience with the following technologies (recommended) and strong desire to learn (required)
Programming language -- Java (must)
Batch processing -- Hadoop ,MapReduce
Stream processing -- Kafka and Amazon Kinesis
NoSQL -S3 , MongoDB.
Columnar stores - HBASE, Amazon Redshift
Restful web services
Code/Build/Deployment -- git, hg, svn, maven, sbt, jenkins, bamboo, ...
Amazon Web Services
Data Warehousing/ built ETL
Benefits
In most cases, the compensation package includes:
Medical insurance
Dental insurance
Vision insurance
Life insurance
Long-term disability insurance
401k plan
Vacation time
Gym membership compensation
",https://www.sophos.com/de-de/about-us/careers/united-states/senior-data-engineer-cloud.aspx
JOB37951252588,"Senior Data Engineer, Graph Team","Senior Data Engineer, Graph Team","BS or MS degree in Computer Science, Math, Statistics or other technical field.,3-5+ years of applied software engineering experience (especially startups, big data, Python).,1+ years as a team lead or managerial role.,Python Expertise: classes & inheritance, generators, decorators, docstrings, pylint, pytest, etc.. Numpy/pandas experience preferred.,SQL/Hive Expertise: where clauses, joins, group bys, windowing functions, exploding.,Spark Expertise: SparkSQL, pyspark, Caching, Checkpointing, Dataframes, RDDs.,Expertise in building, monitoring and maintaining reliable ETL pipelines.,Ability to write well-abstracted, extensible, object-oriented code components.,Enjoy working in a fast-paced, highly collaborative and ambitious startup work environment.,Basic understanding of probability & statistics; experience evaluating data quality at scale.,Experience with Amazon Web Services (RDS, S3, EC2, EMR, Data Pipeline), PyCharm, Github, JIRA (or equivalents).,Experience with open source search platforms such as Solr, ElasticSearch or the like.,Experience with Unix/OSX CLI (bash),Background in data wrangling various structured & unstructured data sets, consuming APIs (e.g. rate limiting and exponential back-offs) and the like.,Knowledge of graph storage and computation frameworks (e.g. GraphX, TitanDB, Neo4J).,Familiarity with Scala and/or Java, Apache Spark internals and job optimization.,Significant interest or background in big data, politics, advertising or finance technology,Experience working directly with data scientists; basic knowledge of common machine-learning techniques,Experience with agile development or similar methodologies for continuous development of product and technology.","Collaboratively architect, build, launch and maintain new Social Graph components that enhance profiles, increase coverage and edge accuracy.,Create, maintain, and scale data pipelines for and between data ingesters, the Social Graph, machine learning predictors, client deliverables, and data warehousing.,Interact cross-functionally with a wide variety of people and teams. Work closely with client services leads and data scientists to identify opportunities and assess improvements to Applecart products and deliverables.,Integrate systems for monitoring of streaming and batch data processing (e.g. DataDog, Nagios). Track data quality and consistency.,Evangelize solid coding practices (e.g. unit & integration testing, code reviews, continuous deployment, automated linting, staging environments), and mentor junior engineers.,Contribute to the architectural designs and decision making around data stores, schemas, data security and cloud storage.,Rapidly prototype proof-of-concept data pipelines for ROI determination, then replace them with modular productionized versions.,Keep abreast of industry trends, best practices, and emerging methodologies.,Support quality assurance as a part of the engineering process and collaboration with product managers such as producing sampled outputs, supporting KPIs, outlining PR limitations and future improvements.","
Job description
Applecart deploys proprietary technology to run smarter advertising campaigns. We work with some of the nation’s most prominent corporations, non-profit organizations, and political candidates to activate and communicate with key target audiences.
Our core offering, the Social Graph, uses human and artificial intelligence to leverage personal connections for our clients. The Social Graph maps over 4.5 billion relationships, and it’s growing every day.
We got our start in politics, where we have tested and refined our methods on countless campaigns, giving our clients a proven technological edge. Now, we’re branching out beyond political campaigns to tackle new advertising challenges, using relational data to provide decisive advantages for our clients.
We recently closed a $6 million funding round, led by global sports and entertainment leader Endeavor and other prominent tech investors including Palantir co-founder Joe Lonsdale, Aspect Ventures, former Yelp SVP Michael Stoppelman and Infinite Computer Solutions founder Sanjay Govil.
The Applecart Graph Team is at the epicenter of Applecart’s technology-- everything we do at Applecart is contingent upon the veracity of our core product, the Social Graph. To date the Social Graph has mapped out over 4.5 billion relationships across the US. The Graph Team works dailly to build and incorporate new social connections into the Social Graph.
As a Data Engineer on our Graph Team, you will be responsible for sourcing, enhancing and integrating data sources to our Social Graph while providing optimizations to the graph for creation of powerful machine learning applications.
Responsibilities:
Collaboratively architect, build, launch and maintain new Social Graph components that enhance profiles, increase coverage and edge accuracy.
Create, maintain, and scale data pipelines for and between data ingesters, the Social Graph, machine learning predictors, client deliverables, and data warehousing.
Interact cross-functionally with a wide variety of people and teams. Work closely with client services leads and data scientists to identify opportunities and assess improvements to Applecart products and deliverables.
Integrate systems for monitoring of streaming and batch data processing (e.g. DataDog, Nagios). Track data quality and consistency.
Evangelize solid coding practices (e.g. unit & integration testing, code reviews, continuous deployment, automated linting, staging environments), and mentor junior engineers.
Contribute to the architectural designs and decision making around data stores, schemas, data security and cloud storage.
Rapidly prototype proof-of-concept data pipelines for ROI determination, then replace them with modular productionized versions.
Keep abreast of industry trends, best practices, and emerging methodologies.
Support quality assurance as a part of the engineering process and collaboration with product managers such as producing sampled outputs, supporting KPIs, outlining PR limitations and future improvements.
Qualifications:
BS or MS degree in Computer Science, Math, Statistics or other technical field.
3-5+ years of applied software engineering experience (especially startups, big data, Python).
1+ years as a team lead or managerial role.
Python Expertise: classes & inheritance, generators, decorators, docstrings, pylint, pytest, etc.. Numpy/pandas experience preferred.
SQL/Hive Expertise: where clauses, joins, group bys, windowing functions, exploding.
Spark Expertise: SparkSQL, pyspark, Caching, Checkpointing, Dataframes, RDDs.
Expertise in building, monitoring and maintaining reliable ETL pipelines.
Ability to write well-abstracted, extensible, object-oriented code components.
Enjoy working in a fast-paced, highly collaborative and ambitious startup work environment.
Basic understanding of probability & statistics; experience evaluating data quality at scale.
Experience with Amazon Web Services (RDS, S3, EC2, EMR, Data Pipeline), PyCharm, Github, JIRA (or equivalents).
Prefered Qualifications:
Experience with open source search platforms such as Solr, ElasticSearch or the like.
Experience with Unix/OSX CLI (bash)
Background in data wrangling various structured & unstructured data sets, consuming APIs (e.g. rate limiting and exponential back-offs) and the like.
Knowledge of graph storage and computation frameworks (e.g. GraphX, TitanDB, Neo4J).
Familiarity with Scala and/or Java, Apache Spark internals and job optimization.
Significant interest or background in big data, politics, advertising or finance technology
Experience working directly with data scientists; basic knowledge of common machine-learning techniques
Experience with agile development or similar methodologies for continuous development of product and technology.
",https://stackoverflow.com/jobs/204941/senior-data-engineer-graph-team-applecart
JOB38624396348,Data Engineer Jobs in Texas,Data Engineer Jobs in Texas,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/data-engineer/jobs-in/texas/usa/jobs/?vs=25&utm_source=.JOBS%20RSS%20Feed-DE&utm_medium=.JOBS%20Universe&utm_campaign=.JOBS%20RSS%20Feed
JOB40671668321,Senior Data Engineer,Senior Data Engineer,"Developer tools (Git, SDLC, OOP, etc) (experience required)","Maintaining ETL program and DB/DW
Adding new tables/indices
Experience in Airflow preferred
Monitoring for CVEs
Updating and troubleshooting existing code,Adding new tables/indices,Experience in Airflow preferred,Monitoring for CVEs,Updating and troubleshooting existing code,Applying Dimensional Modeling principals to integrate various data sources with existing data (APIs, flat files, databases, etc),Data warehousing techniques that ensure the architecture will support the requirements of the business,Building data pipelines (Testing, deploying, and validating code),In-depth knowledge of database design principles (SQL and NoSQL),Basic knowledge of analyst and ML principles is required,Ability to recommend and implement ways to improve data reliability, efficiency and quality,Lead development and software engineering efforts of web applications,Coordinating with developers on data projects,Coordinate and assist in deployment of ML models,Attend design/architecture meetings and assist in project projections and hours,Communicate improvement ideas, needs, and/or concerns,Update projects daily on project management software,Update hours for projects daily or hourly on time tracking software,Update progress and project percentage completion,Complete projects on time and within time budgets,Other duties as assigned,Python/SQL (2+ Years of experience)
Multithreading/parallel processing (experience preferred),Multithreading/parallel processing (experience preferred),Airflow or other ETL tools (experience required),Docker (experience required)","
Job description
Description:
The Senior Data Engineer is someone who develops, constructs, tests and maintains architectures, such as databases and large-scale processing systems. This candidate will ensure that the system architecture supports the requirements of the data scientists, analysts, and business. They are responsible for setting up development environments in Bushel’s platform and are encouraged to adhere to the highest standards of quality software practices with clients and Bushel’s Web team. You will perform code reviews, identify and fix bugs, and oversee releases.
Data Software Engineer Job Responsibilities:
Maintaining ETL program and DB/DW
Adding new tables/indices
Experience in Airflow preferred
Monitoring for CVEs
Updating and troubleshooting existing code
Applying Dimensional Modeling principals to integrate various data sources with existing data (APIs, flat files, databases, etc)
Data warehousing techniques that ensure the architecture will support the requirements of the business
Building data pipelines (Testing, deploying, and validating code)
In-depth knowledge of database design principles (SQL and NoSQL)
Basic knowledge of analyst and ML principles is required
Ability to recommend and implement ways to improve data reliability, efficiency and quality
Lead development and software engineering efforts of web applications
Coordinating with developers on data projects
Coordinate and assist in deployment of ML models
Attend design/architecture meetings and assist in project projections and hours
Communicate improvement ideas, needs, and/or concerns
Update projects daily on project management software
Update hours for projects daily or hourly on time tracking software
Update progress and project percentage completion
Complete projects on time and within time budgets
Other duties as assigned
Data Software Engineer Skills:
Python/SQL (2+ Years of experience)
Multithreading/parallel processing (experience preferred)
Airflow or other ETL tools (experience required)
Docker (experience required)
Developer tools (Git, SDLC, OOP, etc) (experience required)
**This position can be on-site or remote
**This is not a contract position
",http://stackoverflow.com/jobs/434368/senior-data-engineer-bushel
JOB40975771737,Data engineer,Data engineer,Experience with or advanced courses on data science and machine learning.,"Design and build data structures on MPP platform like AWS RedShift and or Druid.io.,Design and build highly scalable data pipelines using AWS tools like Glue (Spark based), Data Pipeline, Lambda.,Translate complex business requirements into scalable technical solutions.,Strong understanding of analytics needs.,Collaborate with the team on building dashboards, using Self-Service tools like Apache Superset or Tableau, and data analysis to support business.,Collaborate with multiple cross-functional teams and work on solutions which have a larger impact on Xapo business.,In-depth understanding of data structures and algorithms.,Experience in designing and building dimensional data models to improve accessibility, efficiency, and quality of data.,Experience in designing and developing ETL data pipelines.,Proficient in writing Advanced SQLs, Expertise in performance tuning of SQLs.,Programming experience in building high-quality software. Skills with Python or Scala preferred.,Strong analytical and communication skills.,Work/project experience with big data and advanced programming languages.,Experience using Java, Spark, Hive, Oozie, Kafka, and Map Reduce.,Work experience with AWS tools to process data (Glue, Pipeline, Kinesis, Lambda, etc).","
BALANCE FOR BETTER At Xapo, we embrace our differences and actively foster an inclusive environment where we all can thrive. We’re a flexible, family-friendly environment, and we recognize that everyone has commitments outside of work. We have a goal of reaching gender parity and strongly encourage women to apply to our open positions. Diversity is not a tagline at Xapo; it is our foundation. RESPONSIBILITIES
Design and build data structures on MPP platform like AWS RedShift and or Druid.io.
Design and build highly scalable data pipelines using AWS tools like Glue (Spark based), Data Pipeline, Lambda.
Translate complex business requirements into scalable technical solutions.
Strong understanding of analytics needs.
Collaborate with the team on building dashboards, using Self-Service tools like Apache Superset or Tableau, and data analysis to support business.
Collaborate with multiple cross-functional teams and work on solutions which have a larger impact on Xapo business.
REQUIREMENTS
In-depth understanding of data structures and algorithms.
Experience in designing and building dimensional data models to improve accessibility, efficiency, and quality of data.
Experience in designing and developing ETL data pipelines.
Proficient in writing Advanced SQLs, Expertise in performance tuning of SQLs.
Programming experience in building high-quality software. Skills with Python or Scala preferred.
Strong analytical and communication skills.
NICE TO HAVE SKILLS
Work/project experience with big data and advanced programming languages.
Experience using Java, Spark, Hive, Oozie, Kafka, and Map Reduce.
Work experience with AWS tools to process data (Glue, Pipeline, Kinesis, Lambda, etc).
Experience with or advanced courses on data science and machine learning.
OTHER REQUIREMENTS
A dedicated workspace. A reliable internet connection with the fastest speed possible in your area. Devices and other essential equipment that meet minimal technical specifications. Alignment with Our Values.
WHY WORK FOR XAPO?
Shape the Future: Improve lives through cutting-edge technology, work remotely from anywhere in the world Own Your Success: Receive attractive remuneration, enjoy an autonomous work culture and flexible hours, apply your expertise to meaningful work every day Expect Excellence: Collaborate, learn, and grow with a high performance team.
",https://stackoverflow.com/jobs/287228/data-engineer-xapo
JOB42931644537,Data Engineer,Data Engineer,"Strong communication skills, including the ability to identify and communicate data driven insight","Focus on designing, building, and launching efficient and reliable data infrastructure to scale and compute for our business,Help us build a world class data lake/data warehouse, by building data pipelines,Design and develop new systems and tools to enable folks to consume and understand data faster,Use your expert coding skills across a number of languages from Python, Java, C++, Go etc.,Work across multiple teams in high visibility roles and own the solution end-to-end,Design, build and launch new data extraction, transformation and loading processes in production,Work with data infrastructure to triage infra issues and drive to resolution.,BS or MS degree in Computer Science or a related technical field,Familiarity with Python,Familiarity with Hadoop stack, Spark, AWS Glue, AWS Athena etc,Diverse data storage technologies (RDBMS, Sql Server, Mysql, ElasticSearch, dynamodb, s3 etc.),Deep familiarity with schemas, metadata catalogs etc.,Ability to manage and communicate data warehouse plans to internal clients","
Job description
DATA ENGINEER
About Earnin:
Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don’t accept that.
Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we’re working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.
Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people’s needs.
You can help make a difference.
About the Team:
We are a data driven mobile financial tech company and we’re looking for a Data Engineer to join us and help us build out our data infrastructure to aid in our mission of enabling people to gain access to their paycheck on demand.
Data engineers are an important function to interact with every team within Earnin and you will be interfacing heavily with our analytics, engineering, and data science teams to help them advance our product utilizing machine learning intelligence.
As a Data Engineer you will:
Focus on designing, building, and launching efficient and reliable data infrastructure to scale and compute for our business
Help us build a world class data lake/data warehouse, by building data pipelines
Design and develop new systems and tools to enable folks to consume and understand data faster
Use your expert coding skills across a number of languages from Python, Java, C++, Go etc.
Work across multiple teams in high visibility roles and own the solution end-to-end
Design, build and launch new data extraction, transformation and loading processes in production
Work with data infrastructure to triage infra issues and drive to resolution.
Some skills we consider critical to being a Data Engineer:
BS or MS degree in Computer Science or a related technical field
Familiarity with Python
Familiarity with Hadoop stack, Spark, AWS Glue, AWS Athena etc
Diverse data storage technologies (RDBMS, Sql Server, Mysql, ElasticSearch, dynamodb, s3 etc.)
Deep familiarity with schemas, metadata catalogs etc.
Ability to manage and communicate data warehouse plans to internal clients
Strong communication skills, including the ability to identify and communicate data driven insight
Earnin does not unlawfully discriminate on the basis of race, color, religion, sex (including pregnancy, childbirth, breastfeeding or related medical conditions), gender identity, gender expression, national origin, ancestry, citizenship, age, physical or mental disability, legally protected medical condition, family care status, military or veteran status, marital status, registered domestic partner status, sexual orientation, genetic information, or any other basis protected by local, state, or federal laws. Earnin is an E-Verify participant.
",http://stackoverflow.com/jobs/337631/data-engineer-earnin-inc
JOB44075722819,Data Engineer (Remote),Data Engineer (Remote),"Experience in business intelligence, analytics, or an equivalent analyst position with experience in SQL and an additional object-oriented programming language (e.g., Python, Java).,High level of expertise in data modeling.,Effective problem solving and analytical skills. Ability to manage multiple projects and report simultaneously across different stakeholders.,Structured thinking with ability to easily break down ambiguous problems and propose impactful data modeling designs.,Attention to detail and effective verbal/written communication skills.,Bachelor’s degree in Engineering, Computer Science, Statistics, Economics, Mathematics, Finance, a related quantitative field, or equivalent practical experience.,2-6 years of experience in consulting, business intelligence, analytics, or an equivalent analyst position with experience in SQL and Python","Use an analytical, data-driven approach to drive a deep understanding of our business.,Build data pipelines and data models that will empower engineers and analysts to make data-driven decisions,Build data models to deliver insightful analytics,Deliver the highest standard in data integrity,Strong analytical skills with ability to analyze and project sales, subscriber, and engagement data. Performs competitive analysis, reviews industry information for current trends and opportunities. Works closely with analytics teams to develop comprehensive analytical reports to enable data-driven decisions to increase engagement and conversions of target customer segments.","
Job description
At iFit, we do remote teams right. Join a great company that is growing fast and with the right work/life balance.
iFit empowers people to change their lives and achieve sustainable, healthy results. iFit's focus is to connect everybody to everything fitness. We believe a healthy lifestyle should be fun, so we constantly push the limits to bring our customers state-of-the-art products that will help them in every aspect of their lives.
Summary
As a Data Engineer, you will take on big data challenges in order to deliver insightful analytics. You will build data pipelines and data models that will empower engineers and analysts to make data-driven decisions and deliver a deep understanding of the business. Your attention to detail will provide the stakeholders with the highest standard in data integrity.
Essential Duties and Responsibilities
Use an analytical, data-driven approach to drive a deep understanding of our business.
Build data pipelines and data models that will empower engineers and analysts to make data-driven decisions
Build data models to deliver insightful analytics
Deliver the highest standard in data integrity
Strong analytical skills with ability to analyze and project sales, subscriber, and engagement data. Performs competitive analysis, reviews industry information for current trends and opportunities. Works closely with analytics teams to develop comprehensive analytical reports to enable data-driven decisions to increase engagement and conversions of target customer segments.
Qualifications
Experience in business intelligence, analytics, or an equivalent analyst position with experience in SQL and an additional object-oriented programming language (e.g., Python, Java).
High level of expertise in data modeling.
Effective problem solving and analytical skills. Ability to manage multiple projects and report simultaneously across different stakeholders.
Structured thinking with ability to easily break down ambiguous problems and propose impactful data modeling designs.
Attention to detail and effective verbal/written communication skills.
Education and/or Experience
Bachelor’s degree in Engineering, Computer Science, Statistics, Economics, Mathematics, Finance, a related quantitative field, or equivalent practical experience.
2-6 years of experience in consulting, business intelligence, analytics, or an equivalent analyst position with experience in SQL and Python
",http://stackoverflow.com/jobs/434289/data-engineer-remote-ifit
JOB44564674083,"Senior Data Engineer, Cloud","Senior Data Engineer, Cloud",Gym membership compensation,"Drive design and implementation leveraging modern design patterns,Ability to partner effectively with UX, PM, DevOps, QE and other developers to design and implement meeting the spirit of requirements,Experience in modern front end frameworks,Technically curious to keep present on advances in technology,Experience with segregation of model, presentation, and business logic.,TDD experience and strong desire to build in test from the start.,Write code (Test or Product) to deliver against project timescales, quality and requirements in various languages including Java or other selected languages for Sophos Cloud products.,Provide guidance and mentorship to junior developers in daily Scrum meetings.,Possesses a passion for solving complex Big Data problems,Plan for, design and implement our next-generation cloud security products.,Be involved from inception through implementation in a real hands on fashion.,BS in Computer Science, Engineering, or equivalent with 7+ years of development and data modelling background,Building highly scalable SaaS solutions using Big Data technologies,Experience with CI/CD,Experience with Agile Software Development methodologies (scrum/ kanban),Excellent attention to detail,Excellent verbal and written communication skills,Experience with the following technologies (recommended) and strong desire to learn (required),Programming language -- Java (must)
Batch processing -- Hadoop ,MapReduce
Stream processing -- Kafka and Amazon Kinesis
NoSQL –S3 , MongoDB.
Columnar stores - HBASE, Amazon Redshift
Restful web services
Code/Build/Deployment -- git, hg, svn, maven, sbt, jenkins, bamboo, ...
Amazon Web Services
Data Warehousing/ built ETL,Programming language -- Java (must),Batch processing -- Hadoop ,MapReduce,Stream processing -- Kafka and Amazon Kinesis,NoSQL –S3 , MongoDB.,Columnar stores - HBASE, Amazon Redshift,Restful web services,Code/Build/Deployment -- git, hg, svn, maven, sbt, jenkins, bamboo, ...,Amazon Web Services,Data Warehousing/ built ETL,Medical insurance,Dental insurance,Vision insurance,Life insurance,Long-term disability insurance,401k plan,Vacation time","
At Sophos, we operate at the cutting edge of technology, protecting businesses worldwide against complex threats, viruses and spam. We build high quality software security products in a fast-paced, nimble environment and we've been doing it for over 20 years.
Join us to help our customers protect their business and meet compliance needs.
Role
To function as a senior data lead for product features or key technology choices and implementation. Collaborates as part of a team for the development of complex systems; including requirements analysis, concept development and design, implementation and testing, demonstrating flexibility of role as required
Main Duties
Drive design and implementation leveraging modern design patterns
Ability to partner effectively with UX, PM, DevOps, QE and other developers to design and implement meeting the spirit of requirements
Experience in modern front end frameworks
Technically curious to keep present on advances in technology
Experience with segregation of model, presentation, and business logic.
TDD experience and strong desire to build in test from the start.
Write code (Test or Product) to deliver against project timescales, quality and requirements in various languages including Java or other selected languages for Sophos Cloud products.
Provide guidance and mentorship to junior developers in daily Scrum meetings.
Possesses a passion for solving complex Big Data problems
Plan for, design and implement our next-generation cloud security products.
Be involved from inception through implementation in a real hands on fashion.
Experience And Skills
BS in Computer Science, Engineering, or equivalent with 7+ years of development and data modelling background
Building highly scalable SaaS solutions using Big Data technologies
Experience with CI/CD
Experience with Agile Software Development methodologies (scrum/ kanban)
Excellent attention to detail
Excellent verbal and written communication skills
Experience with the following technologies (recommended) and strong desire to learn (required)
Programming language -- Java (must)
Batch processing -- Hadoop ,MapReduce
Stream processing -- Kafka and Amazon Kinesis
NoSQL –S3 , MongoDB.
Columnar stores - HBASE, Amazon Redshift
Restful web services
Code/Build/Deployment -- git, hg, svn, maven, sbt, jenkins, bamboo, ...
Amazon Web Services
Data Warehousing/ built ETL
Benefits
In most cases, the compensation package includes:
Medical insurance
Dental insurance
Vision insurance
Life insurance
Long-term disability insurance
401k plan
Vacation time
Gym membership compensation
",https://www.sophos.com/hu-hu/about-us/careers/united-states/senior-data-engineer-cloud.aspx
JOB48624337959,Senior Data Engineer - BlackLocus,Senior Data Engineer - BlackLocus,,,"
Job Information
POSITION PURPOSE
The Sr Data Engineer will expand and optimize data, data flow, data collection for cross functional teams, and data pipeline architecture. The Sr Data Engineer will support and collaborate with the software engineering team, data analysts, and data scientist to ensure data delivery architecture is consistent throughout ongoing projects. Continuously improve or re-design data architecture to support the next generation of products and initiatives.
MAJOR TASKS, RESPONSIBILITES AND KEY ACCOUNTABILITIES
40% - Data Validation, ETL, Infrastructure Development: Coding validation and ETL to ensure successful data integration
30% - Data Infrastructure Maintenance: Backup and optimization activities to maintain performance; code, configure, test, etc data to ensure integrity
20% - Data Architecture Design and Analysis: Create and maintain optimal data pipeline architecture; Develop data architecture to meet business requirements
10% - Planning/Requirements Analysis: Collaborate with team leads and cross functional partners to assess business requirements and communicate opportunities
NATURE AND SCOPE
This position reports to the Technology Leader.
This position has 0 direct reports.
ENVIRONMENTAL JOB REQUIREMENTS
Environment:
Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.
Travel:
Typically requires overnight travel less than 10% of the time.
Additional Environmental Job Requirements: MINIMUM QUALIFICATIONS
Must be eighteen years of age or older.
Must be legally permitted to work in the United States.
Additional Minimum Qualifications:
Experience message queuing, stream processing, and scalable data stores
Experience managing projects and organizing data
Experience supporting and working with cross-functional teams
Experience with SQL, NoSQL databases, relational databases, and query authoring
Experience building and optimizing data pipelines, architectures, data sets and workflow management tools such as Azkaban, Luigi, Airflow, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C#, Scala, GoLang, etc.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
Education Required:
The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.
Years of Relevant Work Experience: 5 years
Physical Requirements:
Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.
Additional Qualifications:
Preferred Qualifications:
8+ years of previous related work experience
Ability to convey complex or technical ideas and processes in easy-to-understand terms to diverse audiences
Ability to negotiate, handle complaints, settle disputes, and resolve grievances with both internal and external customers
Excellent written and verbal communication skills
Knowledge, Skills, Abilities and Competencies:Collaborates - Building partnerships and working collaboratively with others to meet shared objectives
Communicates Effectively - Developing and delivering multi-mode communications that convey a clear understanding of the unique needs of different audiences
Cultivates Innovation - Creating new and better ways for the organization to be successful
Drives Engagement - Creating a climate where people are motivated to do their best to help the organization achieve its objectives
Instills Trust - Gaining the confidence and trust of others through honesty, integrity, and authenticity
Nimble Learning - Actively learning through experimentation when tackling new problems, using both successes and failures as learning fodder
Optimizes Work Processes - Knowing the most effective and efficient processes to get things done with a focus on continuous improvement
Plans and Aligns - Planning and prioritizing work to meet commitments aligned with organizational goals
Tech Savvy - Anticipating and adopting innovations in business-building digital and technology applications. We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
",https://militaryjobs.homedepot.com/austin-tx/senior-data-engineer-blacklocus/EC8362E9CBF04CA89DDFB7AF819ED0FC/job/?utm_medium=.JOBS%20Universe&utm_source=.JOBS%20RSS%20Feed-DE&utm_campaign=.JOBS%20RSS%20Feed
JOB49536845533,Big Data Engineer - No Corp2Corp / 1099,Big Data Engineer - No Corp2Corp / 1099,,"Alpharetta, GA,Bachelor's,Hadoop: 3 years","Title: Big Data Engineer - No Corp2Corp / 1099
Location: Alpharetta, GA
Duration: 11 months
Salary: $50 - $60hr
Responsibilities:
Overall Purpose:
Participate as a member of a small team to release the full potential of Big Data in AT&T through a combination of platform technology, collective human intelligence and the vast data resources available to our company.
Will provide rich insight into consumer behaviors, preferences and experiences in order to improve the customer experience across a broad range of vertical market.
- Development of high performance, distributed computing tasks using Big Data technologies such as Hadoop, NoSQL, text mining and other distributed environment technologies based on the needs of the Big Data organization.
- Use Big Data programming languages and technology, write code, complete programming and documentation, and perform testing and debugging of various applications.
- Analyze, design, program, debug and modify software enhancements and/or new products used in distributed, large scale analytics solutions.
- Interacts with data scientists and industry experts to understand how data needs to be converted, loaded and presented. -
Provide rich insight into consumer behaviors, preferences and experiences in order to improve the customer experience across a broad range of vertical market.
- MS degree or PhD degree (DESIRED) in Computer Science, Applied Mathematics, Physics, Statistics or area of study related to data sciences and data mining
Job Type: Contract
Job Location:
Alpharetta, GA
Required education:
Bachelor's
Required experience:
Hadoop: 3 years
Big Data: 3 years
",http://www.indeed.com/viewjob?jk=e0b0f6e782ab7be2&qd=NGstvRTMEOvJmVpt7yc_yoTWPCm0QNPdIzzPht0ZasBpY5gwu7FCZnkMImjJUar7D0xbCEX8pxZEkbI23f4B94w2WFTZgoHbmjqtbTlwUTy_Z5i4Qk6_rCJbdisHdWXFruJraDvE4FO-ETfZ9aXbRg&indpubnum=7409121151176687&chnl=tdwi&atk=1b69nrcciah73dnk
JOB50371782721,Senior Data Engineer,Senior Data Engineer,Knowledge in the digital and AdTech landscape,"Build and maintain a data pipeline for machine learning.,Assist with the development of a data warehouse on which reports are derived.,Process 8 billion event transactions each month.,Assure data is captured and stored without loss.,Write code to provide reports to business and data science.,Write a system that will run reports on a configurable schedule.,Respond to ad-hoc requests for information.,4-6 years of experience with Python or Java,Three or more years of experience developing and operating data engineering solutions in the cloud (preferably with AWS),Three or more years working with distributed big data systems (e.g. Hadoop, Redshift),Professional experience building data science systems with experience building out data pipelines and ETL processes for machine learning,Experience working remotely","
Job description
If you join us, what will you do?
Build and maintain a real-time big data pipeline and reporting system for Powerinbox. The data pipeline will feed our AI and analytics platform. The reporting system will automatically distribute reports to recipients on a configurable schedule. As needed, you will provide special reports as requested by the sales and operations teams. This role offers opportunities to work with big data, data science, cloud computing, and the latest software technology.
Specific Goals
Build and maintain a data pipeline for machine learning.
Assist with the development of a data warehouse on which reports are derived.
Process 8 billion event transactions each month.
Assure data is captured and stored without loss.
Write code to provide reports to business and data science.
Write a system that will run reports on a configurable schedule.
Respond to ad-hoc requests for information.
In order to be great at your job,
You Are
A fast learner; have great analytical skills; relentless and persistent in accomplishing goals; enthusiastic with an infectious personality.
You Work
Efficiently; with flexibility; proactively; with attention to detail; high standards.
Together We
Emphasize honesty and integrity; require teamwork; have open communication; follow-through on commitments; stay calm under pressure.
You Have-
4-6 years of experience with Python or Java
Three or more years of experience developing and operating data engineering solutions in the cloud (preferably with AWS)
Three or more years working with distributed big data systems (e.g. Hadoop, Redshift)
Professional experience building data science systems with experience building out data pipelines and ETL processes for machine learning
This is extra, but if you have it, it will make us happy
Experience working remotely
Knowledge in the digital and AdTech landscape
",http://stackoverflow.com/jobs/448568/senior-data-engineer-powerinbox
JOB51842122776,Senior Data Engineer - BlackLocus,Senior Data Engineer - BlackLocus,,,"
Job Information
POSITION PURPOSE
The Sr Data Engineer will expand and optimize data, data flow, data collection for cross functional teams, and data pipeline architecture. The Sr Data Engineer will support and collaborate with the software engineering team, data analysts, and data scientist to ensure data delivery architecture is consistent throughout ongoing projects. Continuously improve or re-design data architecture to support the next generation of products and initiatives.
MAJOR TASKS, RESPONSIBILITES AND KEY ACCOUNTABILITIES
40% - Data Validation, ETL, Infrastructure Development: Coding validation and ETL to ensure successful data integration
30% - Data Infrastructure Maintenance: Backup and optimization activities to maintain performance; code, configure, test, etc data to ensure integrity
20% - Data Architecture Design and Analysis: Create and maintain optimal data pipeline architecture; Develop data architecture to meet business requirements
10% - Planning/Requirements Analysis: Collaborate with team leads and cross functional partners to assess business requirements and communicate opportunities
NATURE AND SCOPE
This position reports to the Technology Leader.
This position has 0 direct reports.
ENVIRONMENTAL JOB REQUIREMENTS
Environment:
Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.
Travel:
Typically requires overnight travel less than 10% of the time.
Additional Environmental Job Requirements: MINIMUM QUALIFICATIONS
Must be eighteen years of age or older.
Must be legally permitted to work in the United States.
Additional Minimum Qualifications:
Experience message queuing, stream processing, and scalable data stores
Experience managing projects and organizing data
Experience supporting and working with cross-functional teams
Experience with SQL, NoSQL databases, relational databases, and query authoring
Experience building and optimizing data pipelines, architectures, data sets and workflow management tools such as Azkaban, Luigi, Airflow, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C#, Scala, GoLang, etc.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
Education Required:
The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.
Years of Relevant Work Experience: 5 years
Physical Requirements:
Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.
Additional Qualifications:
Preferred Qualifications:
8+ years of previous related work experience
Ability to convey complex or technical ideas and processes in easy-to-understand terms to diverse audiences
Ability to negotiate, handle complaints, settle disputes, and resolve grievances with both internal and external customers
Excellent written and verbal communication skills
Knowledge, Skills, Abilities and Competencies:Collaborates - Building partnerships and working collaboratively with others to meet shared objectives
Communicates Effectively - Developing and delivering multi-mode communications that convey a clear understanding of the unique needs of different audiences
Cultivates Innovation - Creating new and better ways for the organization to be successful
Drives Engagement - Creating a climate where people are motivated to do their best to help the organization achieve its objectives
Instills Trust - Gaining the confidence and trust of others through honesty, integrity, and authenticity
Nimble Learning - Actively learning through experimentation when tackling new problems, using both successes and failures as learning fodder
Optimizes Work Processes - Knowing the most effective and efficient processes to get things done with a focus on continuous improvement
Plans and Aligns - Planning and prioritizing work to meet commitments aligned with organizational goals
Tech Savvy - Anticipating and adopting innovations in business-building digital and technology applications. We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
",https://militaryjobs.homedepot.com/austin-tx/senior-data-engineer-blacklocus/EC8362E9CBF04CA89DDFB7AF819ED0FC/job/
JOB54973760548,Senior Data Engineer - BlackLocus Jobs in United States,Senior Data Engineer - BlackLocus Jobs in United States,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/usa/jobs/?utm_source=.JOBS%20RSS%20Feed-DE&utm_medium=.JOBS%20Universe&utm_campaign=.JOBS%20RSS%20Feed&vs=25
JOB55229858828,"Data Engineer Jobs in Houston, TX","Data Engineer Jobs in Houston, TX",,"Houston, TX","
Data Engineer Jobs in Houston, TX
Current Search Criteria
More
",https://militaryjobs.homedepot.com/data-engineer/jobs-in/houston/texas/usa/jobs/?utm_medium=.JOBS%20Universe&utm_source=.JOBS%20RSS%20Feed-DE&vs=25&utm_campaign=.JOBS%20RSS%20Feed
JOB55713769578,Data Engineer,Data Engineer,"Creative, analytic problem solver with diligent attention to detail","A fun and collaborative team environment,Autonomy and resources to get the job done,Weekly paid team lunches,Agile development process,Increase the capabilities of Reporting and Advanced Analytics platforms to support business insights for internal and external users,Maintain Data Integrity by identifying the root causes of problems and deploying solutions,Improve accuracy, timeliness, and efficiency in measurement of Healthcare Quality metrics,Develop and Improve infrastructure for novel Fraud, Waste, and Abuse detection and screening methods.,3+ years of experience in data transformation and data management using SQL; including Stored Procedures, ETL processes, and tuning for performance.,Skilled with integrating data from single-tenant data stores, third party data feeds, and APIs,Supporting operational needs with Business Intelligence tools like Tableau,Experience with Salesforce CRM and Salesforce APIs,Experience with data management technologies including data warehouses, data lakes, data marts, and NoSQL data stores,Nice to have: Experience working with cloud technologies (AWS),Nice to have: Experience in Healthcare IT,Flexibility and collaborative work approach to solve complex problems and promote standardization,Collaborate with business owners and application development team to align business objectives and prioritize work.,Excellent verbal and written communication skills,Ability to work in a structured, governed, methodical approach,A self-starter who delivers consistently high quality work,Strong problem-solving and analytical skills","
Job description
Overview
Inspiring medical management company with a great culture is seeking to hire a full time Data Engineer!
Premier Healthcare Management specializes in working with non-profit safety-net health centers and private practices to help vulnerable and underserved communities.
We offer the opportunity to work among a team of passionate, cross-functional developers who value professional growth and mentorship. We are a small team, so the right candidate is someone who prefers some autonomy and accountability.
Why work for Premier Healthcare Management?
A fun and collaborative team environment
Autonomy and resources to get the job done
Weekly paid team lunches
Agile development process
Mentorship from skilled colleagues
Job Activities
Increase the capabilities of Reporting and Advanced Analytics platforms to support business insights for internal and external users
Maintain Data Integrity by identifying the root causes of problems and deploying solutions
Improve accuracy, timeliness, and efficiency in measurement of Healthcare Quality metrics
Develop and Improve infrastructure for novel Fraud, Waste, and Abuse detection and screening methods.
Enable new capabilities for data-driven decision making within the organization
Technical Skills
3+ years of experience in data transformation and data management using SQL; including Stored Procedures, ETL processes, and tuning for performance.
Skilled with integrating data from single-tenant data stores, third party data feeds, and APIs
Supporting operational needs with Business Intelligence tools like Tableau
Experience with Salesforce CRM and Salesforce APIs
Experience with data management technologies including data warehouses, data lakes, data marts, and NoSQL data stores
Nice to have: Experience working with cloud technologies (AWS)
Nice to have: Experience in Healthcare IT
Nice to have: Experience in languages such as: Python, R, PHP, and Node.js
Non-Technical Skills
Flexibility and collaborative work approach to solve complex problems and promote standardization
Collaborate with business owners and application development team to align business objectives and prioritize work.
Excellent verbal and written communication skills
Ability to work in a structured, governed, methodical approach
A self-starter who delivers consistently high quality work
Strong problem-solving and analytical skills
Creative, analytic problem solver with diligent attention to detail
",https://stackoverflow.com/jobs/314233/data-engineer-premier-healthcare-management
JOB55953851453,Data Engineer,Data Engineer,,,"
POSITION PURPOSE
Congrats! You re learning about an exciting new role with The Home Depots Global Custom Commerce (GCC) team that will revitalize and invigorate the way we manage and view data. For this role, we are looking for some one who can develop, implement, test and maintain data pipelines (batch & streaming) and data structures within a cloud based column-oriented data store. This person will support the GCC BI and Data Science strategic initiatives to drive better customer experiences and more profitable outcomes
Why work here? Our entrepreneurial roots and maverick mentality, coupled with the resources and backing of the #1 home improvement retailer in the world, The Home Depot, is a unique opportunity for you to be a transformative retail disrupter. Plus, GCC is the world s largest online window covering company, and we ve got a demonstrably awesome 20-year track record. From our open-floor office to our open-door ethos, our culture is rooted in improving, evolving, and having fun (we re pretty serious about cake, cook-offs, ping pong, meaningful work and exciting projects). Most importantly, our team members are always inspired, engaged, and ready for growth. That means you ll have the resources and the runway to create truly magical, out-of-the-box work. Moreover, you will play an important role in leveraging our culture, people, systems, processes, and technology ultimately to provide incredible customer experiences, while growing business for GCC and The Home Depot. This is your chance to be part of something big, in a small start-up environment. We re ranked as one of The Top 5 Workplaces in Texas and have consistently won the following awards:The Best Place to Work in Houston (Houston Business Journal), Houston s Top Workplaces (Houston Chronicle) and Houston s Best and Brightest.
MAJOR TASKS, RESPONSIBILITES AND KEY ACCOUNTABILITIES
20%- Implement a real time streaming data ingestion and processing pipeline using Google Dataflow (Apache Beam)
20%- Interface with business intelligence analyts and others in IT (i.e. data engineers, architects, WebOps) in frequent whiteboard sessions to dicsucuss the design, implementation, and testing of data pipleines
20%- Maintain data architecture standards and ETL/ELT best practices consistent with a column oritented data store in an analytic use case
20%- Active and engaged particitpation in the Scrum delivery process
20%- Support solutions in production
NATURE AND SCOPE
This role reports to the Sr. Manager of EDW.
This role has no direct reports.
ENVIRONMENTAL JOB REQUIREMENTS
Environment:
Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.
Travel:
Typically requires overnight travel less than 10% of the time.MINIMUM QUALIFICATIONS
Must be eighteen years of age or older.
Must be legally permitted to work in the United States.
Education Required:
The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.
Years of Relevant Work Experience: 6 years
Physical Requirements:
Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.
Preferred Qualifications:
Familiarity with Agile methodologies
Experience with Spark dataframes, SparkSQL, Kafka, KSQL, real-time streaming, and message bus technologies
Experience with data science technologies such as SAS, R, Matlab, or similar
Experience with data warehousing and dimensional modeling
Knowledge, Skills, Abilities and Competencies:
Experience in building real time streaming data ingestion and processing pipeline using Apache Beam (running on either Google Datflow or Apache (Apex, Flink, or Spark) or Kafka in an analytics or data science use case
Experience with data processing tools (e.g. Hadoop, Spark, Dataflow, etc.)
Experience building ETL/ELT pipelines
Experience with column-oriented databases (e.g Redhift, BigQuery, Vertica)
Ability to go from whiteboard discussion to code
Ability to effectively communicate with technical and non-technical audiences
Strong programming ability
Success in a highly dynamic environment and ability to shift priorities with agility
Ability to act independently with minimal supervision
Willingness to explore and implement new ideas and technologies
Experience working directly with subject matter experts in both business and technology domains
Experience as a team lead We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
",https://militaryjobs.homedepot.com/houston-tx/data-engineer/4B642DC9C39B4857867CACB6FE730745/job/
JOB59272980544,(Sydney) Data Engineer,(Sydney) Data Engineer,"Demonstrated fluency in modern programming languages for data science, covering a wide gamut from data storage and engineering frameworks through to machine learning libraries","Excellent communication skills (verbal and written),Empathy for their colleagues and their clients,Signs of initiative and ability to drive things forward,Understanding of the overall problem being solved and what flows into it,Ability to create and implement data engineering solutions using modern software engineering practices,Ability to scale up from “laptop-scale” to “cluster scale” problems, in terms of both infrastructure and problem structure and technique,Ability to deliver tangible value very rapidly, working with diverse teams of varying backgrounds,Ability to codify best practices for future reuse in the form of accessible, reusable patterns, templates, and code bases,A pragmatic approach to software and technology decisions as well as prioritization and delivery,Ability to handle multiple workstreams and prioritize accordingly,Commitment to delivering value and helping clients succeed,Ability to tailor your language to a technical or a non-technical audience,Comfort working with both collocated and distributed team members across time zones,Comfort working with and developing coding standards,Ability to codify best practices for future reuse in the form of accessible, reusable patterns, templates, and codebases,Willingness to travel as required for cases (0 up to 40%),A technical background in computer science, data science, machine learning, artificial intelligence, statistics or other quantitative and computational science,A compelling track record of designing and deploying large scale technical solutions, which deliver tangible, ongoing value
Direct experience having built and deployed complex production systems that implement modern data science methods at scale and do so robustly
Comfort in environments where large projects are time-boxed and therefore consequential design decisions may need to be made and acted upon rapidly
Fluency with cluster computing environments and their associated technologies, and a deep understanding of how to balance computational considerations with theoretical properties of potential solutions
Ability to context-switch, to provide support to dispersed teams which may need an “expert hacker” to unblock an especially challenging technical obstacle
Demonstrated ability to deliver technical projects with a team, often working under tight time constraints to deliver value
An ‘engineering’ mindset, willing to make rapid, pragmatic decisions to improve performance, accelerate progress or magnify impact; recognizing that the ‘good’ is not the enemy of the ‘perfect’
Comfort with working with distributed teams on code-based deliverables, using version control systems and code reviews,Direct experience having built and deployed complex production systems that implement modern data science methods at scale and do so robustly,Comfort in environments where large projects are time-boxed and therefore consequential design decisions may need to be made and acted upon rapidly,Fluency with cluster computing environments and their associated technologies, and a deep understanding of how to balance computational considerations with theoretical properties of potential solutions,Ability to context-switch, to provide support to dispersed teams which may need an “expert hacker” to unblock an especially challenging technical obstacle,Demonstrated ability to deliver technical projects with a team, often working under tight time constraints to deliver value,An ‘engineering’ mindset, willing to make rapid, pragmatic decisions to improve performance, accelerate progress or magnify impact; recognizing that the ‘good’ is not the enemy of the ‘perfect’,Comfort with working with distributed teams on code-based deliverables, using version control systems and code reviews,Demonstrated expertise working with and maintaining open source data analysis platforms, including but not limited to:
Pandas, Scikit-Learn, Matplotlib, TensorFlow, Jupyter and other Python data tools
Spark (Scala and PySpark), HDFS, Hive, Kafka and other high-volume data tools
Relational databases such as SQL Server, Oracle, Postgres
NoSQL storage tools, such as MongoDB, Cassandra, Neo4j and ElasticSearch,Pandas, Scikit-Learn, Matplotlib, TensorFlow, Jupyter and other Python data tools,Spark (Scala and PySpark), HDFS, Hive, Kafka and other high-volume data tools,Relational databases such as SQL Server, Oracle, Postgres,NoSQL storage tools, such as MongoDB, Cassandra, Neo4j and ElasticSearch","
Job description
Data Engineer
The Data Engineer is the universal translator between IT, business, software engineers, and data scientists, working directly with clients and project teams. You will work to understand the business problem being solved and provide the data required to do so, delivering at the pace of the consulting teams and iterating data to ensure quality as understandings crystallize.
Our historical focus has been on high-performance SQL data marts for batch analytics, but we are now driving toward new data stores and cluster-based architectures to enable streaming analytics and scaling beyond our current terabyte-level capabilities. Your ability to tune high-performance data pipelines will help us to rapidly deploy some of the latest machine learning algorithms/frameworks and other advanced analytical techniques at scale.
You will serve as a keystone on our larger projects, enabling us to deliver solutions hand-in-hand with consultants, data scientists, and software engineers.
A good candidate will have:
Excellent communication skills (verbal and written)
Empathy for their colleagues and their clients
Signs of initiative and ability to drive things forward
Understanding of the overall problem being solved and what flows into it
Ability to create and implement data engineering solutions using modern software engineering practices
Ability to scale up from “laptop-scale” to “cluster scale” problems, in terms of both infrastructure and problem structure and technique
Ability to deliver tangible value very rapidly, working with diverse teams of varying backgrounds
Ability to codify best practices for future reuse in the form of accessible, reusable patterns, templates, and code bases
A pragmatic approach to software and technology decisions as well as prioritization and delivery
Ability to handle multiple workstreams and prioritize accordingly
Commitment to delivering value and helping clients succeed
Ability to tailor your language to a technical or a non-technical audience
Comfort working with both collocated and distributed team members across time zones
Comfort working with and developing coding standards
Ability to codify best practices for future reuse in the form of accessible, reusable patterns, templates, and codebases
Willingness to travel as required for cases (0 up to 40%)
Some things that make our Data Engineers effective:
A technical background in computer science, data science, machine learning, artificial intelligence, statistics or other quantitative and computational science
A compelling track record of designing and deploying large scale technical solutions, which deliver tangible, ongoing value
Direct experience having built and deployed complex production systems that implement modern data science methods at scale and do so robustly
Comfort in environments where large projects are time-boxed and therefore consequential design decisions may need to be made and acted upon rapidly
Fluency with cluster computing environments and their associated technologies, and a deep understanding of how to balance computational considerations with theoretical properties of potential solutions
Ability to context-switch, to provide support to dispersed teams which may need an “expert hacker” to unblock an especially challenging technical obstacle
Demonstrated ability to deliver technical projects with a team, often working under tight time constraints to deliver value
An ‘engineering’ mindset, willing to make rapid, pragmatic decisions to improve performance, accelerate progress or magnify impact; recognizing that the ‘good’ is not the enemy of the ‘perfect’
Comfort with working with distributed teams on code-based deliverables, using version control systems and code reviews
Demonstrated expertise working with and maintaining open source data analysis platforms, including but not limited to:
Pandas, Scikit-Learn, Matplotlib, TensorFlow, Jupyter and other Python data tools
Spark (Scala and PySpark), HDFS, Hive, Kafka and other high-volume data tools
Relational databases such as SQL Server, Oracle, Postgres
NoSQL storage tools, such as MongoDB, Cassandra, Neo4j and ElasticSearch
Demonstrated fluency in modern programming languages for data science, covering a wide gamut from data storage and engineering frameworks through to machine learning libraries
",https://stackoverflow.com/jobs/196089/sydney-data-engineer-oliver-wyman-labs
JOB61132211245,Data Engineer,Data Engineer,,,"
POSITION PURPOSE
Congrats! You re learning about an exciting new role with The Home Depots Global Custom Commerce (GCC) team that will revitalize and invigorate the way we manage and view data. For this role, we are looking for some one who can develop, implement, test and maintain data pipelines (batch & streaming) and data structures within a cloud based column-oriented data store. This person will support the GCC BI and Data Science strategic initiatives to drive better customer experiences and more profitable outcomes
Why work here? Our entrepreneurial roots and maverick mentality, coupled with the resources and backing of the #1 home improvement retailer in the world, The Home Depot, is a unique opportunity for you to be a transformative retail disrupter. Plus, GCC is the world s largest online window covering company, and we ve got a demonstrably awesome 20-year track record. From our open-floor office to our open-door ethos, our culture is rooted in improving, evolving, and having fun (we re pretty serious about cake, cook-offs, ping pong, meaningful work and exciting projects). Most importantly, our team members are always inspired, engaged, and ready for growth. That means you ll have the resources and the runway to create truly magical, out-of-the-box work. Moreover, you will play an important role in leveraging our culture, people, systems, processes, and technology ultimately to provide incredible customer experiences, while growing business for GCC and The Home Depot. This is your chance to be part of something big, in a small start-up environment. We re ranked as one of The Top 5 Workplaces in Texas and have consistently won the following awards:The Best Place to Work in Houston (Houston Business Journal), Houston s Top Workplaces (Houston Chronicle) and Houston s Best and Brightest.
MAJOR TASKS, RESPONSIBILITES AND KEY ACCOUNTABILITIES
20%- Implement a real time streaming data ingestion and processing pipeline using Google Dataflow (Apache Beam)
20%- Interface with business intelligence analyts and others in IT (i.e. data engineers, architects, WebOps) in frequent whiteboard sessions to dicsucuss the design, implementation, and testing of data pipleines
20%- Maintain data architecture standards and ETL/ELT best practices consistent with a column oritented data store in an analytic use case
20%- Active and engaged particitpation in the Scrum delivery process
20%- Support solutions in production
NATURE AND SCOPE
This role reports to the Sr. Manager of EDW.
This role has no direct reports.
ENVIRONMENTAL JOB REQUIREMENTS
Environment:
Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.
Travel:
Typically requires overnight travel less than 10% of the time.MINIMUM QUALIFICATIONS
Must be eighteen years of age or older.
Must be legally permitted to work in the United States.
Education Required:
The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.
Years of Relevant Work Experience: 6 years
Physical Requirements:
Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.
Preferred Qualifications:
Familiarity with Agile methodologies
Experience with Spark dataframes, SparkSQL, Kafka, KSQL, real-time streaming, and message bus technologies
Experience with data science technologies such as SAS, R, Matlab, or similar
Experience with data warehousing and dimensional modeling
Knowledge, Skills, Abilities and Competencies:
Experience in building real time streaming data ingestion and processing pipeline using Apache Beam (running on either Google Datflow or Apache (Apex, Flink, or Spark) or Kafka in an analytics or data science use case
Experience with data processing tools (e.g. Hadoop, Spark, Dataflow, etc.)
Experience building ETL/ELT pipelines
Experience with column-oriented databases (e.g Redhift, BigQuery, Vertica)
Ability to go from whiteboard discussion to code
Ability to effectively communicate with technical and non-technical audiences
Strong programming ability
Success in a highly dynamic environment and ability to shift priorities with agility
Ability to act independently with minimal supervision
Willingness to explore and implement new ideas and technologies
Experience working directly with subject matter experts in both business and technology domains
Experience as a team lead We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
",https://militaryjobs.homedepot.com/4B642DC9C39B4857867CACB6FE73074525
JOB62223434796,Senior Data Engineer - BlackLocus Jobs in United States,Senior Data Engineer - BlackLocus Jobs in United States,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/usa/jobs/?utm_medium=.JOBS%20Universe&vs=25&utm_source=.JOBS%20RSS%20Feed-DE&utm_campaign=.JOBS%20RSS%20Feed
JOB67123505252,Lead Big Data Engineer,Lead Big Data Engineer,Experience with Cloudera,"M.S. in Computer Science, Informatics, Mathematics, Electronic/Electrical Engineering or other relevant field with an emphasis on data analytics.,Experience with big data technologies such as Hadoop, Apache Spark, NoSQL databases.,Strong computer science grounding, with knowledge of data structures, algorithms and computer architectures.,Proficiency developing in one or more languages such as C++, Python or Java.,Self-starting, requiring minimal supervision with strong problem-solving skills.,Excellent communication and teamwork skills.,Hands-on experience with Cloud environments, such as AWS, Google Cloud, or Azure","
Job description
Keysight launched a Software Design Center in Atlanta to create a new software platform for electronic product design and test. The new center is located in Atlanta’s growing Midtown district and features an open environment to foster collaboration and agile software development.
We are seeking a developer to build upon a solid working knowledge of big data technologies such as MapReduce, Apache Spark and NoSQL databases on both structured and unstructured data. The focus of this position will be implementation of scalable computing technologies for data analytics. Along with a team of researchers and developers, you will help define, investigate, develop and implement, state-of-the-art informatics, data analysis and data visualization technology.
REQUIRED QUALIFICATIONS:
M.S. in Computer Science, Informatics, Mathematics, Electronic/Electrical Engineering or other relevant field with an emphasis on data analytics.
Experience with big data technologies such as Hadoop, Apache Spark, NoSQL databases.
Strong computer science grounding, with knowledge of data structures, algorithms and computer architectures.
Proficiency developing in one or more languages such as C++, Python or Java.
Self-starting, requiring minimal supervision with strong problem-solving skills.
Excellent communication and teamwork skills.
DESIRED QUALIFICATIONS:
Hands-on experience with Cloud environments, such as AWS, Google Cloud, or Azure
Experience with Cloudera
",https://stackoverflow.com/jobs/202539/lead-big-data-engineer-keysight-technologies
JOB69220624362,Junior Data Engineer,Junior Data Engineer,,,"(0/300)
We are:
Wix’s Data team - over 250 Big Data Engineers, Data Engineers, Business Analysts and Data Scientists who believe in using analytics to understand and improve how users interact with our products. With 192+ million users, we collect over a billion events a day – that’s 1TB of data added daily! We use cutting edge technologies to process, store and query our data, with tools we develop ourselves as well as technologies like Hadoop and Presto.
You are:
An independent, self-learner who understands business processes and able to translate business needs into data models. You're a detail-oriented individual with a track record of success in quantitative fields. You can write complex SQL queries, have basic programming skills In Python and can implement data pipelines and ETL processes.
Bonus points if you have basic knowledge in big data and the Hadoop ecosystem.
As a Data Engineer, you will:
Be responsible for designing, implementing and maintaining data pipelines from different sources
Design, implement and support robust, scalable solutions to enhance business analysis capabilities, identify gaps and design processes to fill them
Work with analysts and product managers to understand business priorities and translate requirements into data models
Collaborate with various stakeholders across the company like data engineers, analysts, data science, finance, etc., in order to deliver team tasks
Collaborate with a broad forum of experts and stakeholders, including architects and engineers, to create high-quality deliverables
Own the data development process end-to-end including business understanding, methodology, QA and maintenance
",https://www.wix.com/jobs/locations/tel-aviv/positions/3205
JOB69382875222,Senior Data Engineer,Senior Data Engineer,"Experience with one or more of the following languages and functional programming in general: Scala, Haskell, Java, JavaScript,Experience with one or more of the following technologies:
Distributed logging systems (Kafka, Pulsar, Kinesis, etc)
Stream processing. Flink, Spark, Storm, Beam, etc
Batch processing: Spark, Hadoop, …
IDL: Avro, Protobuf or Thrift
MPP databases (Redshift, Vertica, …)
Query execution (Columnar storage, push downs): Hive, Presto, Parquet, ...
Workflow management (Airflow, Oozie, Azkaban, ...)
Cloud storage: S3, GCS, ...,Distributed logging systems (Kafka, Pulsar, Kinesis, etc),Stream processing. Flink, Spark, Storm, Beam, etc,Batch processing: Spark, Hadoop, …,IDL: Avro, Protobuf or Thrift,MPP databases (Redshift, Vertica, …),Query execution (Columnar storage, push downs): Hive, Presto, Parquet, ...,Workflow management (Airflow, Oozie, Azkaban, ...),Cloud storage: S3, GCS, ...,Understanding of distributed systems concepts and principles (consistency and availability, liveness and safety, durability, reliability, fault-tolerance, consensus algorithms),Eager to learn new things and passionate about technology,Experience with contributing to open source software,Experience with the following Cassandra, DynamoDB, RocksDB/LevelDB, Graphite, StatsD, CollectD
About WeWork
WeWork Technology is bridging the gap between physical and digital platforms, providing a delightful, flawless & powerful experience for members and employees. We build software and hardware that enables our members to connect with each other and the space around them like never before.
We augment our community and culture teams through the tools we build. We believe there’s a macro shift toward a new way of working—one focused on a movement towards meaning and purpose. WeWork Technology is proud to be shaping this movement.
We are a team of passionate, fearless and collaborative problem-solvers distributed globally with one goal in mind - to humanize technology across the world.
We are an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.","You will build and operate large scale data infrastructure in production (performance, reliability, monitoring),Designing, implementing and debugging distributed systems,Yu will think through long-term impacts of key design decisions and handling failure scenarios,Building self-service platforms to power WeWork’s Technology,You are focused on team over individual achievements.,You create software incrementally and make consistent progress.,You love to learn. mentor and teach others.,You are empathetic and build long-lasting relationship characteristic of highly efficient teams.,You keep up-to-date with the latest developments in the field.","
Job description
About the Role:
If you’re passionate about building large scale data processing systems, and you are motivated to make an impact in creating a robust and scalable data platform used by every team, come join us. You will jump into an early stage team that builds the data transport, collection and orchestration layers. You will help shape the vision and architecture of WeWork's next generation data infrastructure, making it easy for developers to build data-driven products and features. You are responsible for developing a reliable infrastructure that scales with the company’s incredible growth. Your efforts will allow accessibility to business and user behavior insights, using huge amounts of WeWork data to fuel several teams such as Analytics, Data Science, Sales, Revenue, Product, Growth and many others as well as empowering them to depend on each other reliably. You will be a part of an experienced engineering team and work with passionate leaders on challenging distributed systems problems.
About the Team:
Data is at the core of our business, providing insights into the effectiveness of our products and enabling the technology that powers them. We build and operate the platform used by the rest of the company for streaming and batch computation and to train ML models. We’re building an ecosystem where consumers and producers of data can depend on each other safely. We thrive to build high quality systems we can be proud to open source and an amazing experience for our users and ourselves. We regard culture and trust highly and are looking forward to welcoming your contribution to the team.
Responsibilities
You will build and operate large scale data infrastructure in production (performance, reliability, monitoring)
Designing, implementing and debugging distributed systems
Yu will think through long-term impacts of key design decisions and handling failure scenarios
Building self-service platforms to power WeWork’s Technology
You are focused on team over individual achievements.
You create software incrementally and make consistent progress.
You love to learn. mentor and teach others.
You are empathetic and build long-lasting relationship characteristic of highly efficient teams.
You keep up-to-date with the latest developments in the field.
Requirements
Experience with one or more of the following languages and functional programming in general: Scala, Haskell, Java, JavaScript
Experience with one or more of the following technologies:
Distributed logging systems (Kafka, Pulsar, Kinesis, etc)
Stream processing. Flink, Spark, Storm, Beam, etc
Batch processing: Spark, Hadoop, …
IDL: Avro, Protobuf or Thrift
MPP databases (Redshift, Vertica, …)
Query execution (Columnar storage, push downs): Hive, Presto, Parquet, ...
Workflow management (Airflow, Oozie, Azkaban, ...)
Cloud storage: S3, GCS, ...
Understanding of distributed systems concepts and principles (consistency and availability, liveness and safety, durability, reliability, fault-tolerance, consensus algorithms)
Eager to learn new things and passionate about technology
Bonus points:
Experience with contributing to open source software
Experience with the following Cassandra, DynamoDB, RocksDB/LevelDB, Graphite, StatsD, CollectD
About WeWork
WeWork Technology is bridging the gap between physical and digital platforms, providing a delightful, flawless & powerful experience for members and employees. We build software and hardware that enables our members to connect with each other and the space around them like never before.
We augment our community and culture teams through the tools we build. We believe there’s a macro shift toward a new way of working—one focused on a movement towards meaning and purpose. WeWork Technology is proud to be shaping this movement.
We are a team of passionate, fearless and collaborative problem-solvers distributed globally with one goal in mind - to humanize technology across the world.
We are an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.
Life at WeWork
",https://stackoverflow.com/jobs/203446/senior-data-engineer-wework-global-technology
JOB72293712912,Senior Data Engineer - BlackLocus,Senior Data Engineer - BlackLocus,,,"
Job Information
POSITION PURPOSE
The Sr Data Engineer will expand and optimize data, data flow, data collection for cross functional teams, and data pipeline architecture. The Sr Data Engineer will support and collaborate with the software engineering team, data analysts, and data scientist to ensure data delivery architecture is consistent throughout ongoing projects. Continuously improve or re-design data architecture to support the next generation of products and initiatives.
MAJOR TASKS, RESPONSIBILITES AND KEY ACCOUNTABILITIES
40% - Data Validation, ETL, Infrastructure Development: Coding validation and ETL to ensure successful data integration
30% - Data Infrastructure Maintenance: Backup and optimization activities to maintain performance; code, configure, test, etc data to ensure integrity
20% - Data Architecture Design and Analysis: Create and maintain optimal data pipeline architecture; Develop data architecture to meet business requirements
10% - Planning/Requirements Analysis: Collaborate with team leads and cross functional partners to assess business requirements and communicate opportunities
NATURE AND SCOPE
This position reports to the Technology Leader.
This position has 0 direct reports.
ENVIRONMENTAL JOB REQUIREMENTS
Environment:
Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.
Travel:
Typically requires overnight travel less than 10% of the time.
Additional Environmental Job Requirements: MINIMUM QUALIFICATIONS
Must be eighteen years of age or older.
Must be legally permitted to work in the United States.
Additional Minimum Qualifications:
Experience message queuing, stream processing, and scalable data stores
Experience managing projects and organizing data
Experience supporting and working with cross-functional teams
Experience with SQL, NoSQL databases, relational databases, and query authoring
Experience building and optimizing data pipelines, architectures, data sets and workflow management tools such as Azkaban, Luigi, Airflow, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C#, Scala, GoLang, etc.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
Education Required:
The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.
Years of Relevant Work Experience: 5 years
Physical Requirements:
Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.
Additional Qualifications:
Preferred Qualifications:
8+ years of previous related work experience
Ability to convey complex or technical ideas and processes in easy-to-understand terms to diverse audiences
Ability to negotiate, handle complaints, settle disputes, and resolve grievances with both internal and external customers
Excellent written and verbal communication skills
Knowledge, Skills, Abilities and Competencies:Collaborates - Building partnerships and working collaboratively with others to meet shared objectives
Communicates Effectively - Developing and delivering multi-mode communications that convey a clear understanding of the unique needs of different audiences
Cultivates Innovation - Creating new and better ways for the organization to be successful
Drives Engagement - Creating a climate where people are motivated to do their best to help the organization achieve its objectives
Instills Trust - Gaining the confidence and trust of others through honesty, integrity, and authenticity
Nimble Learning - Actively learning through experimentation when tackling new problems, using both successes and failures as learning fodder
Optimizes Work Processes - Knowing the most effective and efficient processes to get things done with a focus on continuous improvement
Plans and Aligns - Planning and prioritizing work to meet commitments aligned with organizational goals
Tech Savvy - Anticipating and adopting innovations in business-building digital and technology applications. We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
",https://militaryjobs.homedepot.com/EC8362E9CBF04CA89DDFB7AF819ED0FC25
JOB72302667853,Data Engineer (m/f/d),Data Engineer (m/f/d),"Computer Science, Engineering, or Bioinformatics (Master level) plus 5 years relevant experience,Excellent programming skills (Python, C++, R),Experience in designing and implementing RESTful APIs and webservices,An ability to interact with various data sources, both structured and unstructured (e.g. HDFS, SQL, noSQL),Experience working across multiple scientific compute environments to create data workflows and pipelines (e.g. HPC, cloud, Unix/Linux systems),Expertise with biological/health data,Experience modelling data and information for graph/network representation,,Experience of working with metadata models, controlled vocabularies and ontologies,Ability to understand, map, integrate, and document complex data relationship and business rules,Familiarity with data quality, cleaning and masking techniques,Modern frameworks and concepts for scalable and distributed computation (containerization and orchestration e.g. k8s, specialized frameworks such as Spark, Hadoop, ...),Experience with image processing and computer graphics,Experience with cloud computing","Help us create AI / ML ready datasets from Petabytes of raw data and meta-data,Automate integration of different data-sources into a coherent flow/ data pipelines (support also data normalization and result calculation),Develop and build systems and architectures for ETLs,Perform system & data testing,Understand and apply FAIR data principles,Strong adherence to compliance & regulatory environments,Build algorithms to","
Job description
Main Duties and Responsibilities
Help us create AI / ML ready datasets from Petabytes of raw data and meta-data
Automate integration of different data-sources into a coherent flow/ data pipelines (support also data normalization and result calculation)
Develop and build systems and architectures for ETLs
Perform system & data testing
Understand and apply FAIR data principles
Strong adherence to compliance & regulatory environments
Build algorithms to
Essential Requirements
Computer Science, Engineering, or Bioinformatics (Master level) plus 5 years relevant experience
Excellent programming skills (Python, C++, R)
Experience in designing and implementing RESTful APIs and webservices
An ability to interact with various data sources, both structured and unstructured (e.g. HDFS, SQL, noSQL)
Experience working across multiple scientific compute environments to create data workflows and pipelines (e.g. HPC, cloud, Unix/Linux systems)
Desirable:
Expertise with biological/health data
Experience modelling data and information for graph/network representation,
Experience of working with metadata models, controlled vocabularies and ontologies
Ability to understand, map, integrate, and document complex data relationship and business rules
Familiarity with data quality, cleaning and masking techniques
Modern frameworks and concepts for scalable and distributed computation (containerization and orchestration e.g. k8s, specialized frameworks such as Spark, Hadoop, ...)
Experience with image processing and computer graphics
Experience with cloud computing
We are looking forward to your application!
",http://stackoverflow.com/jobs/395729/data-engineer-m-f-d-definiens
JOB72385671827,How can I land a job as a data engineer with a math degree?,How can I land a job as a data engineer with a math degree?,,,,https://www.quora.com/unanswered/How-can-I-land-a-job-as-a-data-engineer-with-a-math-degree
JOB72915735610,Federal- Data Engineer,Federal- Data Engineer,"Bachelor's degree,Experience with designing and developing medium-to-large data environments and associated services (e.g., data pipelines, data cataloging) for enterprise applications and analytics projects,Proven experience fusing, mining and preparing data sets using SQL, Oracle, or Elastic technologies,Experience performing machine learning (ML) functions for data preparation and automation of other data services (e.g., data quality measures, utilization, mapping, etc.),Familiarity with hybrid cloud infrastructures,Experience with Python, Java, or other relevant scripting languages",,"
Job Description
Organization: Accenture Federal Services
We are:
Accenture Federal Services, bringing together commercial innovation with the latest technology to help our government clients reach their full potential. As a U.S. based subsidiary of Accenture, we bring 360-degree customer views by going beyond just capturing and curating data. We decode information that helps our clients embrace intelligent technologies confidently. Powered by new data, data science and technology, we drive digital transformation at the core of their business and enable new outcomes.
You are:
A data expert and practiced in agile software engineering. Your entrepreneurial attitude helps you support a team to achieve breakthrough results in this new age of applied intelligence. You are confident working on data engineering tasks in large-scale data environments. You want to help federal agencies transform data from dark and siloed to Dynamic, Dependable Distributed and Democratized.
The work:
-Support medium-to-large size data engineering projects
· -Work with cloud technologies, particularly AWS, to standup and maintain data environments and pipelines
· -Work with streaming, batch, unstructured, and structured data sets that involve both text and various media to model data and determine integration approaches
· -Work with DevOps toolchains and processes to automate and rapidly deliver data engineering tasks
· -Integrate data environment through pipelines to support analytic efforts and production applications
· -Sustain data pipelines and delivery of optimization and monitoring capabilities
· -Incorporate standards and create documentation for data pipeline services
· -Utilize open source data management tools (e.g., Apache AirFlow, Atlas, etc.)
· - Establish and update a data catalog and associated ontologies
Qualifications
Here is what you need:
Bachelor's degree
Experience with designing and developing medium-to-large data environments and associated services (e.g., data pipelines, data cataloging) for enterprise applications and analytics projects
Proven experience fusing, mining and preparing data sets using SQL, Oracle, or Elastic technologies
Experience performing machine learning (ML) functions for data preparation and automation of other data services (e.g., data quality measures, utilization, mapping, etc.)
Must be a US Citizen; no dual citizens
Bonus points if:
Familiarity with hybrid cloud infrastructures
Experience with Python, Java, or other relevant scripting languages
Experience with Continuous Integration/Continuous Delivery (CI/CD) best practices for code build and deployments
An active security clearance or the ability to obtain one may be required for this role.
Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.
Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).
Accenture is a Federal Contractor and an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.
All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.
Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.
Accenture is committed to providing veteran employment opportunities to our service men and women.
",https://www.accenture.com/us-en/careers/jobdetails?id=00832103_en&title=Federal-+Data+Engineer
JOB74322068496,Data Engineer Jobs in Texas,Data Engineer Jobs in Texas,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/data-engineer/jobs-in/texas/usa/jobs/?vs=25&utm_campaign=.JOBS%20RSS%20Feed&utm_medium=.JOBS%20Universe&utm_source=.JOBS%20RSS%20Feed-DE
JOB75380607051,Associate Data & Analytics SWE - Data Engineer for AI 2019 National,Associate Data & Analytics SWE - Data Engineer for AI 2019 National,,,"Responsibilities & Qualifications
KPMG is currently seeking an Associate for our Data & Analytics- Big Data Software Engineer practice.
While this requisition may state a specific geographic office, please note that our positions are location flexible between our major hubs. Opportunities may include, but are not limited to, Atlanta, Chicago, Dallas, Denver, New York City, Orange County, Philadelphia, Seattle, Washington DC. Please proceed with applying here, and let us know your location preference during interview phase if applicable.
Responsibilities:
• Under supervising and mentoring of senior team members, rapidly prototype, develop and optimize Data & Analytics (D&A) implementations to tackle the Big Data and Data Science needs for a variety of Fortune 1000 corporations and other major organizations.
• Using waterfall/agile methodology, develop and maintain D&A solutions on-premise, cloud, KPMG-hosted, hybrid infrastructure. Follow software engineering guidelines and industry best practices for code quality; conducting regular design and code review and building technical documentation.
• Play the role of data owner in cross-disciplinary teams. Discover, profile, acquire, process, model, and own data for the solutions.
• Implement data processing pipelines, data mining and data science algorithms, and visualization engineering to help clients distill insights from rich data sources (social media, news, internal or external documents, emails, financial data, client data, and operational data).
• Help in research and experiment of leading and emerging Big Data methodologies (serverless data lake, microservices, Hadoop, Spark, Kafka, AWS, MS Azure, GCP) and apply them to real world client problems.
• From data engineering point of view, help in the process for pursuing innovations, target solutions, and extendable platforms for Lighthouse, KPMG, and client.
Qualifications:
• Bachelors, Master's or PhD from an accredited college or university in Computer Science, Computer Engineering, or related fields.
• 1+ years of relevant software development experience in related industries preferred, preferably in professional services.
• Hands-on experience and knowledge in software engineering: waterfall vs agile; object-oriented vs procedural vs functional; source code version control, continuous integration, continuous development/deployment, design patterns etc.
• Proficiency of Linux/Unix/Windows/.NET. Market-leading fluency in several programming languages preferred: Bash/ksh/PowerShell; Python/Perl/R, Java/C/C++/Scala.
• Expertise in distributed computing architecture, massive-parallel processing big data platforms (Hadoop, MapReduce, HDFS, Spark, Hive/Impala, H-Base/MongoDB/Casandra, Teradata/Netezza/Redshift etc.).
• Experience in mainstream cloud infrastructures: AWS, MS Azure and GCP; their D&A-related Microservices, and how to implement data lake and serverless data lake.
• Ability to travel up to 80% of the time.
• Targeted graduation Fall 2018 through Summer 2019
Work Authorization
Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future.
",https://www.cc.gatech.edu/job-opportunity/14789/associate-data-analytics-swe-data-engineer-ai-2019-national
JOB76102297721,Data Engineer / Data Scientist,Data Engineer / Data Scientist,"As always, the interviews and screening call will be conducted via a video call.","Build scalable backend data applications to support the growing needs of the business,Build data pipelines that collect, process, and compute business metrics from marketplace activity,Leverage best practices in continuous integration and delivery.,Collaborate with other engineers,Expertise in building data or training pipelines using Spark or Hadoop,Experience in building production grade API to expose results,Extensive programming experience in Python/Scala/Java,A BS or MS in Computer Science or other related technical fields,At least 3 years experience in production environment,Experience and interest in ML,Qualified applicants receive a few questions to answer,Selected candidates will be invited to schedule a 30 minute intro call with our CTO,Next, Candidates will be invited to schedule a behavioral interview with the CEO,Next, candidates will be invited to schedule a technical interview with our CTO. The technical interview can be split between a technical discussion and a technical test.,Next, candidates will be invited to review the technical test with our CTO and other software engineers.,Candidates will then be invited to schedule an additional interview with (CEO, CTO, COO),Successful candidates will subsequently be made an offer via email.","
Job description
Respondent is the world’s first marketplace for scheduling research interviews with any target audience, anywhere in the world. We enable companies of all sizes to discover the power of conducting market research interviews with high-quality participants; that’s why more than 2,500 user experience researchers, marketers, product designers and other stakeholders at some of the best companies in the world - like Airbnb, IBM, Salesforce and many more - use Respondent every day.
Work hard, and take responsibility for your own freedom. That's us. Self-motivated, research-focused, and a smart thinker with experience in dealing with backend engineering and data at scale...is that you?
You will be working with the CTO and three other engineers. This role is not a mid-level position. Remote US only
What you'll do:
Build scalable backend data applications to support the growing needs of the business
Build data pipelines that collect, process, and compute business metrics from marketplace activity
Leverage best practices in continuous integration and delivery.
Collaborate with other engineers
What we're looking for:
Expertise in building data or training pipelines using Spark or Hadoop
Experience in building production grade API to expose results
Extensive programming experience in Python/Scala/Java
A BS or MS in Computer Science or other related technical fields
At least 3 years experience in production environment
Bonus
Experience and interest in ML
Job Conditions:
Work remotely from anywhere
Flexible schedule and a goal-oriented culture
Competitive salary and opportunity to grow with the company
Fun work environment and company culture with an upbeat motivated team
Hiring Process
Applicants for this position can expect the hiring process to follow the order below. Please keep in mind that applicants can be declined from the position at any stage of the process.
Qualified applicants receive a few questions to answer
Selected candidates will be invited to schedule a 30 minute intro call with our CTO
Next, Candidates will be invited to schedule a behavioral interview with the CEO
Next, candidates will be invited to schedule a technical interview with our CTO. The technical interview can be split between a technical discussion and a technical test.
Next, candidates will be invited to review the technical test with our CTO and other software engineers.
Candidates will then be invited to schedule an additional interview with (CEO, CTO, COO)
Successful candidates will subsequently be made an offer via email.
As always, the interviews and screening call will be conducted via a video call.
This is a full time position - No Contractor
We are looking for someone who matches our level of joy for the work we do, fits in well with our team, and elevates our game. A sense of humor, a lack of ego, and a desire to do great work is essential.
",https://stackoverflow.com/jobs/172359/data-engineer-data-scientist-respondent
JOB78424844262,Data Engineer - Wix Marketing,Data Engineer - Wix Marketing,,"Design, implement and support robust, scalable solutions to enhance business analysis capabilities, identify gaps and design processes to fill them.,Work with analysts to understand business priorities and translate requirements into data models.,Collaborate with various stakeholders across the company like data developers, analysts, data science, finance, etc, in order to deliver team tasks.,Build complex multi-cloud ETL pipelines in Apache Airflow.,Build Python API integrations with 3rd party vendors.","We Are:
Wix’s Marketing Data Engineering team. We are responsible for all marketing data pipelines, including 3rd party integrations, internal ETL procedures, cloud and on premises DWH management and modeling. We operate in a data environment with 165M users and an enormous amount of data events. We communicate with multiple stakeholders both internally and externally and fully responsible for all data related developments.
You are:
An independent, self-learner who understands business processes and able to translate business needs into data models. You have a solid technical background and experience with API integrations. You can quickly learn new technologies and have a good level of Python including familiarity with modern CI/CD approach and mainstream libraries. You are highly proficient in SQL, including performance tuning. You are familiar with database modeling in both relational and data warehouse environments. You have experience in cloud environments (GCP/AWS/Azure) and modern data warehouse solutions (BigQuery, Snowflake, Redshift, Presto, etc).
Bonus points if you have a working knowledge of Apache Airflow and Docker.
As Data Engineer, you will:
Design, implement and support robust, scalable solutions to enhance business analysis capabilities, identify gaps and design processes to fill them.
Work with analysts to understand business priorities and translate requirements into data models.
Collaborate with various stakeholders across the company like data developers, analysts, data science, finance, etc, in order to deliver team tasks.
Build complex multi-cloud ETL pipelines in Apache Airflow.
Build Python API integrations with 3rd party vendors.
Implement new tools and development approaches.
",https://www.wix.com/jobs/locations/tel-aviv/positions/3521
JOB79805350926,"Data Engineer Jobs in Houston, TX","Data Engineer Jobs in Houston, TX",,"Houston, TX","
Data Engineer Jobs in Houston, TX
Current Search Criteria
More
",https://militaryjobs.homedepot.com/data-engineer/jobs-in/houston/texas/usa/jobs/?vs=25&utm_source=.JOBS%20RSS%20Feed-DE&utm_campaign=.JOBS%20RSS%20Feed&utm_medium=.JOBS%20Universe
JOB81506472968,Big Data Engineer,Big Data Engineer,,,"
- Job description
Big Data Engineer
Are you ready to step up to the New and take your technology expertise to the next level?
Join Accenture and help transform leading organizations and communities around the world. The sheer scale of our capabilities and client engagements and the way we collaborate, operate and deliver value provides an unparalleled opportunity to grow and advance. Choose Accenture, and make delivering innovative work part of your extraordinary career.
Why Should I Join the Accenture Team?
• Drive innovation. People in our Client Delivery & Operations career track drive delivery and capability excellence through the design, development and/or delivery of a solution, service, capability or offering. They grow into delivery-focused roles, and can progress within their current role, laterally or upward.
• Learn and grow continuously: Follow personalized training to build skills, while expanding your experience defining and implementing solutions on complex client projects with a scope that is unsurpassed in industry.
• Thrive in our inclusive environment: Bring your whole self to a company that aims to be the most diverse in the world and delivers real-time performance feedback based on individual strengths—not stats.
What Will I Do in This Position?
As part of our Advanced Technology & Architecture (AT&A) practice, you will lead technology innovation for our clients through robust delivery of world-class solutions. You will build better software better! There will never be a typical day and that’s why people love it here. The opportunities to make a difference within exciting client initiatives are unlimited in the ever-changing technology landscape. You will be part of a growing network of technology experts who are highly collaborative taking on today’s biggest, most complex business challenges. We will nurture your talent in an inclusive culture that values diversity. Come grow your career in technology at Accenture! Data and Analytics professionals define strategies, develop and deliver solutions that enable the collection, processing and management of information from one or more sources, and the subsequent delivery of information to audiences in support of key business processes. Big Data professionals develop deep next generation Analytics skills to support Accenture's data and analytics agendas, including skills such as Data Modeling, Business Intelligence, and Data Management.
• Produce clean, standards based, modern code with an emphasis on advocacy toward end-users to produce high quality software designs that are well-documented.
• Demonstrate an understanding of technology and digital frameworks in the context of data integration.
• Ensure code and design quality through the execution of test plans and assist in development of standards, methodology and repeatable processes, working closely with internal and external design, business, and technical counterparts.
A professional at this position level within Accenture has the following responsibilities:
• Utilizes existing methods and procedures to create designs within the proposed solution to solve business problems.
• Understands the strategic direction set by senior management as it relates to team goals.
• Contributes to design of solution, executes development of design, and seeks guidance on complex technical challenges where necessary.
• Primary upward interaction is with direct supervisor.
• May interact with peers, client counterparts and/or management levels within Accenture.
• Understands methods and procedures on new assignments and executes deliverables with guidance as needed.
• May interact with peers and/or management levels at a client and/or within Accenture.
• Determines methods and procedures on new assignments with guidance.
• Decisions often impact the team in which they reside.
• Manages small teams and/or work efforts (if in an individual contributor role) at a client or within Accenture
This role does require 100% travel, Monday - Thursday.
",https://www.indeed.com/cmp/_/job?jk=2963fa71b5fa128c&tk=1cs7vv9m8b87i800
JOB81984603841,"Data Engineer, Alexa","Data Engineer, Alexa","Bachelor’s degree in math, statistics, computer science, or finance or equivalent experience.,5+ years of experience as a Data Engineer, BI Engineer, Business/Financial Analyst or Systems Analyst,SQL writing experience and experience with ETL,Expert understanding of best practices to handle extremely large volume of data,Ability to create extensible and scalable data schema that lay the foundation for downstream analysis,A clear passion for learning new BI skills and techniques independently and continuously,Ability to prioritize multiple concurrent projects while still delivering timely and accurate results,Experience working in a lean, successful start-up or on a new product team where continuous innovation is desired and ambiguity is the norm,Experience mentoring others in SQL, modeling, forecasting and the use of large datasets,Proficiency with scripting languages and Unix systems (Python, perl, bash, etc.),Experience with the following is a plus: Looker, Tableau, Microstrategy","Collect, analyze and share data to help product teams drive improvement in key business metrics and customer experience,Propose and prioritize changes to reporting and create additional metrics and processes based on program changes and customer requirements,Work closely with Alexa program teams to create ad-hoc reports to support timely business decisions and project work,Identify and implement new capabilities and best practices to develop and improve automated data analysis processes","Come help us shape the future of the best voice controlled computer in the cloud. Alexa and Echo are shaping the future of voice recognition and cloud-based content/services. Alexa is the name of the Amazon cloud-based voice service and the brain that powers Echo, the award-winning and groundbreaking Amazon device designed around your voice. Echo connects to Alexa, to provide information, answer questions, play music, read the news, check sports scores or the weather, and more—instantly. It's hands-free, and always ready. All you have to do is ask.
To achieve this, we blend of a variety of disciplines (such as NLP, data mining, machine learning, big data, semantic web, graph stores, cloud computing) in an effort to understand our customers and the things they're excited about. To complement our complex algorithms and extensive data analyses, we create elevated and inspirational mobile and web features across the entire communication experience. We use artificial intelligence, data mining and usability studies to develop new features, and we test them through hundreds of R & D experiments a year. We are also incredibly intent on solving some of the most complex computing problems to be found in industry and academia, and we get to test our solutions in the real world every day. And most importantly, we relentlessly ask: ""What haven't we thought of yet?""
The data engineer will work closely with data scientists, software engineers, and product managers to build out reporting to inform key stakeholders and decision-makers. In this role, you’ll design, execute and iterate on high visibility business intelligence reporting for the teams of people that are actively building out Alexa's capabilities. If you love working with huge data sets and delivering the insights you discover through business intelligence reporting and automated systems, then this is the job for you.
Key Responsibilities
Collect, analyze and share data to help product teams drive improvement in key business metrics and customer experience
Propose and prioritize changes to reporting and create additional metrics and processes based on program changes and customer requirements
Work closely with Alexa program teams to create ad-hoc reports to support timely business decisions and project work
Identify and implement new capabilities and best practices to develop and improve automated data analysis processes
Learn and understand a growing range of Amazon data resources and discover how, and when to use which datasets
Basic Qualifications
Bachelor’s degree in math, statistics, computer science, or finance or equivalent experience.
5+ years of experience as a Data Engineer, BI Engineer, Business/Financial Analyst or Systems Analyst
SQL writing experience and experience with ETL
Redshift experience
Preferred Qualifications
Expert understanding of best practices to handle extremely large volume of data
Ability to create extensible and scalable data schema that lay the foundation for downstream analysis
A clear passion for learning new BI skills and techniques independently and continuously
Ability to prioritize multiple concurrent projects while still delivering timely and accurate results
Experience working in a lean, successful start-up or on a new product team where continuous innovation is desired and ambiguity is the norm
Experience mentoring others in SQL, modeling, forecasting and the use of large datasets
Proficiency with scripting languages and Unix systems (Python, perl, bash, etc.)
Experience with the following is a plus: Looker, Tableau, Microstrategy
Experience in an internet-based company with large, complex data sources.
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.
",https://www.indeed.com/rc/clk?jk=dc8c6297521be5f2&fccid=fe2d21eef233e94a&vjs=3
JOB82287051829,"Senior Data Engineer - BlackLocus Jobs in Austin, TX","Senior Data Engineer - BlackLocus Jobs in Austin, TX",,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/austin/texas/usa/jobs/?utm_source=.JOBS%20RSS%20Feed-DE&utm_medium=.JOBS%20Universe&utm_campaign=.JOBS%20RSS%20Feed&vs=25
JOB82979271353,How is Facebook's hiring bar for Data Engineer compared with the regular Software Engineer position?,How is Facebook's hiring bar for Data Engineer compared with the regular Software Engineer position?,,,,https://www.quora.com/unanswered/How-is-Facebooks-hiring-bar-for-Data-Engineer-compared-with-the-regular-Software-Engineer-position
JOB83590775838,Senior Data Engineer - BlackLocus,Senior Data Engineer - BlackLocus,,,"
Job Information
POSITION PURPOSE
The Sr Data Engineer will expand and optimize data, data flow, data collection for cross functional teams, and data pipeline architecture. The Sr Data Engineer will support and collaborate with the software engineering team, data analysts, and data scientist to ensure data delivery architecture is consistent throughout ongoing projects. Continuously improve or re-design data architecture to support the next generation of products and initiatives.
MAJOR TASKS, RESPONSIBILITES AND KEY ACCOUNTABILITIES
40% - Data Validation, ETL, Infrastructure Development: Coding validation and ETL to ensure successful data integration
30% - Data Infrastructure Maintenance: Backup and optimization activities to maintain performance; code, configure, test, etc data to ensure integrity
20% - Data Architecture Design and Analysis: Create and maintain optimal data pipeline architecture; Develop data architecture to meet business requirements
10% - Planning/Requirements Analysis: Collaborate with team leads and cross functional partners to assess business requirements and communicate opportunities
NATURE AND SCOPE
This position reports to the Technology Leader.
This position has 0 direct reports.
ENVIRONMENTAL JOB REQUIREMENTS
Environment:
Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.
Travel:
Typically requires overnight travel less than 10% of the time.
Additional Environmental Job Requirements:MINIMUM QUALIFICATIONS
Must be eighteen years of age or older.
Must be legally permitted to work in the United States.
Additional Minimum Qualifications:
Experience message queuing, stream processing, and scalable data stores
Experience managing projects and organizing data
Experience supporting and working with cross-functional teams
Experience with SQL, NoSQL databases, relational databases, and query authoring
Experience building and optimizing data pipelines, architectures, data sets and workflow management tools such as Azkaban, Luigi, Airflow, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C#, Scala, GoLang, etc.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
Education Required:
The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.
Years of Relevant Work Experience: 5 years
Physical Requirements:
Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.
Additional Qualifications:
Preferred Qualifications:
8+ years of previous related work experience
Ability to convey complex or technical ideas and processes in easy-to-understand terms to diverse audiences
Ability to negotiate, handle complaints, settle disputes, and resolve grievances with both internal and external customers
Excellent written and verbal communication skills
Knowledge, Skills, Abilities and Competencies:Collaborates - Building partnerships and working collaboratively with others to meet shared objectives
Communicates Effectively - Developing and delivering multi-mode communications that convey a clear understanding of the unique needs of different audiences
Cultivates Innovation - Creating new and better ways for the organization to be successful
Drives Engagement - Creating a climate where people are motivated to do their best to help the organization achieve its objectives
Instills Trust - Gaining the confidence and trust of others through honesty, integrity, and authenticity
Nimble Learning - Actively learning through experimentation when tackling new problems, using both successes and failures as learning fodder
Optimizes Work Processes - Knowing the most effective and efficient processes to get things done with a focus on continuous improvement
Plans and Aligns - Planning and prioritizing work to meet commitments aligned with organizational goals
Tech Savvy - Anticipating and adopting innovations in business-building digital and technology applications. We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
",https://militaryjobs.homedepot.com/35068FD906174D91A159D54015CA534725
JOB85681530950,Data Engineer (m/f/d),Data Engineer (m/f/d),"Willingness to travel,","In-depth knowledge of Python, pandas and its open-source ecosystem, with a focus on parallelized processing,,Experience in configuring and working with relational databases in the terabyte scale, e.g. MS SQL Server,,Several years of experience working on and designing data-intensive applications and/or pipelines,,Commitment to ensuring data quality and integrity of complex systems within a time-sensitive environment,,Experience with OS-independent, cross-platform development,,Passion to work effectively in interdisciplinary teams of technical and non-technical individuals with different cultural backgrounds on health-related (business) problems,,Business proficiency in English and German,Passion for using and contributing to the open-source data science ecosystem,,Ability to evaluate the business value of different technical projects and prioritize appropriately,","
Job description
As a Data Engineer at QuantCo, you will integrate our clients’ technical systems with our industry-leading statistical and machine learning models. You will work alongside our data scientists, economists, and software engineers to solve technical and quantitative challenges ensuring that our solutions produce value for our clients.
To achieve this, you will own the entire software development process from high-level system design and prototyping to application development and data integration. You will contribute to our data pipelines with your expertise in scalable data-driven systems. You will have the opportunity to manage technical projects with both internal and client stakeholders and spearhead collaborative efforts to solve critical technical issues with immediate and long-term business impact.
We are looking for team players with an entrepreneurial mindset that will bring:
Required
In-depth knowledge of Python, pandas and its open-source ecosystem, with a focus on parallelized processing,
Experience in configuring and working with relational databases in the terabyte scale, e.g. MS SQL Server,
Several years of experience working on and designing data-intensive applications and/or pipelines,
Commitment to ensuring data quality and integrity of complex systems within a time-sensitive environment,
Experience with OS-independent, cross-platform development,
Passion to work effectively in interdisciplinary teams of technical and non-technical individuals with different cultural backgrounds on health-related (business) problems,
Business proficiency in English and German
Preferred
Passion for using and contributing to the open-source data science ecosystem,
Ability to evaluate the business value of different technical projects and prioritize appropriately,
Willingness to travel,
",http://stackoverflow.com/jobs/409509/data-engineer-m-f-d-quantco
JOB86333604867,"Data Engineer Jobs in Houston, TX","Data Engineer Jobs in Houston, TX",,"Houston, TX","
Data Engineer Jobs in Houston, TX
Current Search Criteria
More
",https://militaryjobs.homedepot.com/data-engineer/jobs-in/houston/texas/usa/jobs/?utm_medium=.JOBS%20Universe&utm_campaign=.JOBS%20RSS%20Feed&vs=25&utm_source=.JOBS%20RSS%20Feed-DE
JOB86392547402,Python Data Engineer,Python Data Engineer,Python Django/Flask,"5+ Years professional experience with Python,Python data structures and best practices,AWS and Linux (Ubuntu/CentOS) , Bash scripting,Professional experience with a SQL-based database, such as MySQL,Writes organized code with appropriate exception handling and logging,Understanding of HTTP network requests and responses,Understanding of HTML and JSON formats,Ability to write technical documentation and comment code,Ability to write test suites and set up automation environments,An undergraduate degree or advanced degree in Statistics, Computer Science or a related field,Experience with scrapy, beautiful soup, requests, selenium,Amazon Redshift/ Hadoop,Prior experience as a front-end, back-end, or full-stack web developer,Javascript / NodeJS","
Job description
What’s the Job?
SRS Investment Management is a fundamental long/short equity fund with $4B+ AUM in NYC. You’ll be joining our data science team as a Data Product Engineer. You’ll be responsible for testing, monitoring, and improving the data collection programs we have in production, as well as developing new software to capture data from the web and extract insights from third-party sources. You’ll be writing Python scripts deployed on AWS, and communicating with data scientists and infrastructure engineers.
Required:
5+ Years professional experience with Python
Python data structures and best practices
AWS and Linux (Ubuntu/CentOS) , Bash scripting
Professional experience with a SQL-based database, such as MySQL
Writes organized code with appropriate exception handling and logging
Understanding of HTTP network requests and responses
Understanding of HTML and JSON formats
Ability to write technical documentation and comment code
Ability to write test suites and set up automation environments
An undergraduate degree or advanced degree in Statistics, Computer Science or a related field
Plusses:
Experience with scrapy, beautiful soup, requests, selenium
Amazon Redshift/ Hadoop
Prior experience as a front-end, back-end, or full-stack web developer
Javascript / NodeJS
Python Django/Flask
",https://stackoverflow.com/jobs/193996/python-data-engineer-srs-investment-management
JOB88209946138,"Senior Data Engineer, Cloud","Senior Data Engineer, Cloud",Gym membership compensation,"Drive design and implementation leveraging modern design patterns,Ability to partner effectively with UX, PM, DevOps, QE and other developers to design and implement meeting the spirit of requirements,Experience in modern front end frameworks,Technically curious to keep present on advances in technology,Experience with segregation of model, presentation, and business logic.,TDD experience and strong desire to build in test from the start.,Write code (Test or Product) to deliver against project timescales, quality and requirements in various languages including Java or other selected languages for Sophos Cloud products.,Provide guidance and mentorship to junior developers in daily Scrum meetings.,Possesses a passion for solving complex Big Data problems,Plan for, design and implement our next-generation cloud security products.,Be involved from inception through implementation in a real hands on fashion.,BS in Computer Science, Engineering, or equivalent with 7+ years of development and data modelling background,Building highly scalable SaaS solutions using Big Data technologies,Experience with CI/CD,Experience with Agile Software Development methodologies (scrum/ kanban),Excellent attention to detail,Excellent verbal and written communication skills,Experience with the following technologies (recommended) and strong desire to learn (required),Programming language -- Java (must)
Batch processing -- Hadoop ,MapReduce
Stream processing -- Kafka and Amazon Kinesis
NoSQL –S3 , MongoDB.
Columnar stores - HBASE, Amazon Redshift
Restful web services
Code/Build/Deployment -- git, hg, svn, maven, sbt, jenkins, bamboo, ...
Amazon Web Services
Data Warehousing/ built ETL,Programming language -- Java (must),Batch processing -- Hadoop ,MapReduce,Stream processing -- Kafka and Amazon Kinesis,NoSQL –S3 , MongoDB.,Columnar stores - HBASE, Amazon Redshift,Restful web services,Code/Build/Deployment -- git, hg, svn, maven, sbt, jenkins, bamboo, ...,Amazon Web Services,Data Warehousing/ built ETL,Medical insurance,Dental insurance,Vision insurance,Life insurance,Long-term disability insurance,401k plan,Vacation time","
At Sophos, we operate at the cutting edge of technology, protecting businesses worldwide against complex threats, viruses and spam. We build high quality software security products in a fast-paced, nimble environment and we've been doing it for over 20 years.
Join us to help our customers protect their business and meet compliance needs.
Role
To function as a senior data lead for product features or key technology choices and implementation. Collaborates as part of a team for the development of complex systems; including requirements analysis, concept development and design, implementation and testing, demonstrating flexibility of role as required
Main Duties
Drive design and implementation leveraging modern design patterns
Ability to partner effectively with UX, PM, DevOps, QE and other developers to design and implement meeting the spirit of requirements
Experience in modern front end frameworks
Technically curious to keep present on advances in technology
Experience with segregation of model, presentation, and business logic.
TDD experience and strong desire to build in test from the start.
Write code (Test or Product) to deliver against project timescales, quality and requirements in various languages including Java or other selected languages for Sophos Cloud products.
Provide guidance and mentorship to junior developers in daily Scrum meetings.
Possesses a passion for solving complex Big Data problems
Plan for, design and implement our next-generation cloud security products.
Be involved from inception through implementation in a real hands on fashion.
Experience And Skills
BS in Computer Science, Engineering, or equivalent with 7+ years of development and data modelling background
Building highly scalable SaaS solutions using Big Data technologies
Experience with CI/CD
Experience with Agile Software Development methodologies (scrum/ kanban)
Excellent attention to detail
Excellent verbal and written communication skills
Experience with the following technologies (recommended) and strong desire to learn (required)
Programming language -- Java (must)
Batch processing -- Hadoop ,MapReduce
Stream processing -- Kafka and Amazon Kinesis
NoSQL –S3 , MongoDB.
Columnar stores - HBASE, Amazon Redshift
Restful web services
Code/Build/Deployment -- git, hg, svn, maven, sbt, jenkins, bamboo, ...
Amazon Web Services
Data Warehousing/ built ETL
Benefits
In most cases, the compensation package includes:
Medical insurance
Dental insurance
Vision insurance
Life insurance
Long-term disability insurance
401k plan
Vacation time
Gym membership compensation
",https://www.sophos.com/cs-cz/about-us/careers/united-states/senior-data-engineer-cloud.aspx
JOB91922163783,Big Data Engineer,Big Data Engineer,,,"
Job description
Who are we?
Pixalate helps Digital Advertising ecosystem become a safer and more trustworthy place to transact in, by providing intelligence on ""bad actors"" using our world class data. Our products provide benchmarks, analytics, research and threat intelligence solutions to the global media industry. We make this happen by processing terabytes of data and trillions of data points a day across desktop, mobile, tablets, connected-tv that are generated using Machine Learning and Artificial Intelligence based models.
We are the World's #1 decision making platform for Digital Advertising. And don't just take our word for it -- Forrester Research consistently depends on our monthly indexes to make industry predictions.
What does the media have to say about us?
How is it working at Pixalate?
We believe in Small teams that produce high output
Slack is a way of life, short emails are encouraged
Fearless attitude holds high esteem
Bold ideas are worshipped
Chess players do really well
Titles don't mean much, you attain respect by producing results
Everyone's a data addict and an analytical thinker (you won't survive if you run away from details)
Collaboration, collaboration, collaboration
What will you do?
Support existing processes running in production
Design, develop, and support of various big data solutions at scale (hundreds of Billions of transactions a day)
Find smart, fault tolerant, self-healing, cost efficient solutions to extremely hard data problems
Take ownership of the various big data solutions, troubleshoot issues, and provide production support
Conduct research on new technologies that can improve current processes
Contribute to publications of case studies and white papers delivering cutting edge research in the ad fraud, security and measurement space
What are the minimum requirements for this role?
Bachelors, Masters or Phd in Computer Science, Computer Engineering, Software Engineering, or other related technical field.
A minimum of 3 years of experience in a software or data engineering role
Excellent teamwork and communication skills
Extremely analytical, critical thinking, and problem solving abilities
Proficiency in Java
Very strong knowledge of SQL and ability to implement advanced queries to extract information from very large datasets
Experience in working with very large datasets using big data technologies such as Spark, BigQuery, Hive, Hadoop, Redshift, etc
Ability to design, develop and deploy end-to-end data pipelines that meet business requirements.
Strong experience in AWS and Google Cloud platforms is a big plus
Deep understanding of computer science concepts such as data structures, algorithms, and algorithmic complexity
Deep understanding of statistics and machine learning algorithms foundations is a huge plus
Experience with Machine Learning big data technologies such as R, Spark ML, H2O, Mahout etc is a plus
What do we have to offer?
Located in sunny Palo Alto and Playa Vista, CA the core of Pixalate's DNA lies in innovation. We focus on doing things differently and we challenge each other to be the best we can be. We offer:
Experienced leadership and founding team
Casual environment (as long as you wear clothes, we're good!)
Flexible hours (yes, we mean it - you will never have to sit in traffic anymore!)
FREE Lunches! (You name it, we've got it)
Fun team events
High performing team who wants to win and have fun doing it
Extremely Competitive Compensation
OPPORTUNITY (Pixalate will be what you make it)
About Pixalate, Inc.
Pixalate is a cross-channel fraud intelligence company that works with brands and platforms to prevent invalid traffic and improve ad inventory quality. We help brands, agencies and platforms detect and prevent fraud, and protect their reputation.
",https://stackoverflow.com/jobs/202222/big-data-engineer-pixalate-inc
JOB96545781311,"Senior Data Engineer, Cloud","Senior Data Engineer, Cloud",Gym membership compensation,"Drive design and implementation leveraging modern design patterns,Ability to partner effectively with UX, PM, DevOps, QE and other developers to design and implement meeting the spirit of requirements,Experience in modern front end frameworks,Technically curious to keep present on advances in technology,Experience with segregation of model, presentation, and business logic.,TDD experience and strong desire to build in test from the start.,Write code (Test or Product) to deliver against project timescales, quality and requirements in various languages including Java or other selected languages for Sophos Cloud products.,Provide guidance and mentorship to junior developers in daily Scrum meetings.,Possesses a passion for solving complex Big Data problems,Plan for, design and implement our next-generation cloud security products.,Be involved from inception through implementation in a real hands on fashion.,BS in Computer Science, Engineering, or equivalent with 7+ years of development and data modelling background,Building highly scalable SaaS solutions using Big Data technologies,Experience with CI/CD,Experience with Agile Software Development methodologies (scrum/ kanban),Excellent attention to detail,Excellent verbal and written communication skills,Experience with the following technologies (recommended) and strong desire to learn (required),Programming language -- Java (must)
Batch processing -- Hadoop ,MapReduce
Stream processing -- Kafka and Amazon Kinesis
NoSQL –S3 , MongoDB.
Columnar stores - HBASE, Amazon Redshift
Restful web services
Code/Build/Deployment -- git, hg, svn, maven, sbt, jenkins, bamboo, ...
Amazon Web Services
Data Warehousing/ built ETL,Programming language -- Java (must),Batch processing -- Hadoop ,MapReduce,Stream processing -- Kafka and Amazon Kinesis,NoSQL –S3 , MongoDB.,Columnar stores - HBASE, Amazon Redshift,Restful web services,Code/Build/Deployment -- git, hg, svn, maven, sbt, jenkins, bamboo, ...,Amazon Web Services,Data Warehousing/ built ETL,Medical insurance,Dental insurance,Vision insurance,Life insurance,Long-term disability insurance,401k plan,Vacation time","
At Sophos, we operate at the cutting edge of technology, protecting businesses worldwide against complex threats, viruses and spam. We build high quality software security products in a fast-paced, nimble environment and we've been doing it for over 20 years.
Join us to help our customers protect their business and meet compliance needs.
Role
To function as a senior data lead for product features or key technology choices and implementation. Collaborates as part of a team for the development of complex systems; including requirements analysis, concept development and design, implementation and testing, demonstrating flexibility of role as required
Main Duties
Drive design and implementation leveraging modern design patterns
Ability to partner effectively with UX, PM, DevOps, QE and other developers to design and implement meeting the spirit of requirements
Experience in modern front end frameworks
Technically curious to keep present on advances in technology
Experience with segregation of model, presentation, and business logic.
TDD experience and strong desire to build in test from the start.
Write code (Test or Product) to deliver against project timescales, quality and requirements in various languages including Java or other selected languages for Sophos Cloud products.
Provide guidance and mentorship to junior developers in daily Scrum meetings.
Possesses a passion for solving complex Big Data problems
Plan for, design and implement our next-generation cloud security products.
Be involved from inception through implementation in a real hands on fashion.
Experience And Skills
BS in Computer Science, Engineering, or equivalent with 7+ years of development and data modelling background
Building highly scalable SaaS solutions using Big Data technologies
Experience with CI/CD
Experience with Agile Software Development methodologies (scrum/ kanban)
Excellent attention to detail
Excellent verbal and written communication skills
Experience with the following technologies (recommended) and strong desire to learn (required)
Programming language -- Java (must)
Batch processing -- Hadoop ,MapReduce
Stream processing -- Kafka and Amazon Kinesis
NoSQL –S3 , MongoDB.
Columnar stores - HBASE, Amazon Redshift
Restful web services
Code/Build/Deployment -- git, hg, svn, maven, sbt, jenkins, bamboo, ...
Amazon Web Services
Data Warehousing/ built ETL
Benefits
In most cases, the compensation package includes:
Medical insurance
Dental insurance
Vision insurance
Life insurance
Long-term disability insurance
401k plan
Vacation time
Gym membership compensation
",https://www.sophos.com/en-us/about-us/careers/united-states/senior-data-engineer-cloud.aspx
JOB99982951463,"Senior Data Engineer - BlackLocus Jobs in Austin, TX","Senior Data Engineer - BlackLocus Jobs in Austin, TX",,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/austin/texas/usa/jobs/?utm_campaign=.JOBS%20RSS%20Feed&utm_medium=.JOBS%20Universe&vs=25&utm_source=.JOBS%20RSS%20Feed-DE
JOB100162725962,"Senior Data Engineer (SQL, ETL, Informatica)","Senior Data Engineer (SQL, ETL, Informatica)","Responsible for staying current with enterprise standards, industry standards and technologies, methodologies and best practices","Collaborate across development teams to understand customer's business objectives and data requirements.,Apply repeatable processes, established knowledge, and expert judgment to design, build and operate data and analytics solutions across the financial and insurance value chain.,Help customers overcome data related business challenges by modelling, integrating, profiling, and cleaning data to provide enterprise information that is accurate, consistent, managed, trusted and understood.,Leverage technology to automate common maintenance tasks and provide insights into the health and wellness of the infrastructure platform.,6+ years of experience with data solution delivery and implementations,Ability to identify issues and provide real time solutions for them,Experience with engineering best practices which includes analyzing, designing, developing, deploying, and supporting data solutions and/or infrastructure implementations/upgrades.,Advanced skills and knowledge related to Data Modelling, Data Integration/ETL, Data workload utilization tools,Hands-on experience designing, implementing, and supporting ETL data solutions with the Informatica PowerCenter or Power Exchange ETL tools,Strong SQL knowledge including writing and review complex SQL statements and performance tuning to handle scale, agility, and changes,Experience with database technologies including relational databases such as DB2 or Sybase.,Experienced working in an agile developing environment leveraging BDD/TDD and whole team approaches within a fully-dedicated agile team","
Job description
This is for a position as a Senior Data Engineer on the Business Information Integration Platform (BIIP) product team located within the Enterprise Data & Analytics Insight Solutions organization. This team is responsible for acquiring and preparing high quality enterprise information for our business partners to understand what is happening (Operational Applications), what has happened (Business Intelligence & Reporting), and what will happen (Advanced Analytics) within their business areas.
What's the role:
Collaborate across development teams to understand customer's business objectives and data requirements.
Apply repeatable processes, established knowledge, and expert judgment to design, build and operate data and analytics solutions across the financial and insurance value chain.
Help customers overcome data related business challenges by modelling, integrating, profiling, and cleaning data to provide enterprise information that is accurate, consistent, managed, trusted and understood.
Leverage technology to automate common maintenance tasks and provide insights into the health and wellness of the infrastructure platform.
What this role needs:
6+ years of experience with data solution delivery and implementations
Ability to identify issues and provide real time solutions for them
Experience with engineering best practices which includes analyzing, designing, developing, deploying, and supporting data solutions and/or infrastructure implementations/upgrades.
Advanced skills and knowledge related to Data Modelling, Data Integration/ETL, Data workload utilization tools
Hands-on experience designing, implementing, and supporting ETL data solutions with the Informatica PowerCenter or Power Exchange ETL tools
Strong SQL knowledge including writing and review complex SQL statements and performance tuning to handle scale, agility, and changes
Experience with database technologies including relational databases such as DB2 or Sybase.
Experienced working in an agile developing environment leveraging BDD/TDD and whole team approaches within a fully-dedicated agile team
Responsible for staying current with enterprise standards, industry standards and technologies, methodologies and best practices
",https://stackoverflow.com/jobs/166881/senior-data-engineer-sql-etl-informatica-northwestern-mutual
JOB100552496358,Customer Data Engineer (m/f),Customer Data Engineer (m/f),,"Coordination and execution of the needed processes and governance procedures to accurately define and ensure data quality,Main point of contact for data scientists regarding data preparation,Preparation of data for analytical purposes,Support of data owner for meta data management,Responsible for definition, utilization and monitoring of data quality management mechanisms/tools,Measurement and monitoring of data KPIs,Taking data movement and transformation steps from the prototype status into production,Preparation of reports and presentations for senior staff and relevant stakeholders that will give insights for business decision making,Completed academic studies of information systems, mathematics, machine learning or other technical/scientific studies, or comparable several years of experience in this field,Previous work experience in Data Engineering,English and German language fluently,Strong experience in underlying foundational data, data warehouses, and business intelligence systems,Experience in relational and unstructured data environments (e.g. SQL, noSQL, Hadoop, Hive, Spark),Experience with SQL server is a plus,Understanding of advanced analytic techniques and having gathered first experiences to effectively collaborate with data scientists,Analytical thinking,Self-driven and fast learner, eager to work with new technologies","
Customer Data Engineer (m/f)
Austrian Airlines is Austria's largest airline and as a member of the Lufthansa Group part of the largest and most successful airline network in Europe. With more than 11 million customers in 2016, we are bringing more and more people into the world. To maintain and expand our market position, we are looking for employees with high qualifications, a lot of potential and the motivation to actively shape our growth and our future.
The Customer Data Engineer is responsible for the quality, consistency and accuracy of data across the company or line of business which is needed by the data scientists.
Coordination and execution of the needed processes and governance procedures to accurately define and ensure data quality
Main point of contact for data scientists regarding data preparation
Preparation of data for analytical purposes
Support of data owner for meta data management
Responsible for definition, utilization and monitoring of data quality management mechanisms/tools
Measurement and monitoring of data KPIs
Taking data movement and transformation steps from the prototype status into production
Preparation of reports and presentations for senior staff and relevant stakeholders that will give insights for business decision making
Knowledge Management that is needed to understand and maintain data environment needed for analytics
Completed academic studies of information systems, mathematics, machine learning or other technical/scientific studies, or comparable several years of experience in this field
Previous work experience in Data Engineering
English and German language fluently
Strong experience in underlying foundational data, data warehouses, and business intelligence systems
Experience in relational and unstructured data environments (e.g. SQL, noSQL, Hadoop, Hive, Spark)
Experience with SQL server is a plus
Understanding of advanced analytic techniques and having gathered first experiences to effectively collaborate with data scientists
Analytical thinking
Self-driven and fast learner, eager to work with new technologies
Good communication skills and ability to work in cross cultural environments
What are we offering?
Depending on the exact qualification and adequate professional experience, the gross annual salary is amounted to minimum 33.500 EUR.
This position is a limited contract for the duration of 2 years.
Ready for Take Off?
Yes? Apply online at www.austriankarriere.com enclosing your CV and letter of motivation attached.
We are looking forward to receiving your application!
",http://derstandard.at/karriere/jobsuche/jobs/223004
JOB100794762963,"Data Engineer, Commerce Engineering","Data Engineer, Commerce Engineering",,,"Facebook's mission is to give people the power to build community and bring the world closer together. Through our family of apps and services, we're building a different kind of company that connects billions of people around the world, gives them ways to share what matters most to them, and helps bring people closer together. Whether we're creating new products or helping a small business expand its reach, people at Facebook are builders at heart. Our global teams are constantly iterating, solving problems, and working together to empower people around the world to build community and connect in meaningful ways. Together, we can help people build stronger communities — we're just getting started.
Are you passionate about data? Do you like working with big data? If yes, we want to talk to you! Data and associated analytics play a huge role in the success of Facebook. We have diverse business needs and very large-scale data. This makes it a wonderful and exciting challenge to provide scalable, actionable, reliable and timely data for our company. The Enterprise mission is to ship people-centric Enterprise solutions that transform and accelerate Facebook's business.
The Data Engineering team within Commerce Engineering illuminates what might otherwise be hidden. By shaping the information we gather and by creating new conceptual models to understand it, we bridge the gap between the products our team builds and the businesses across Facebook we design for. Our partners includes any team in AR/VR dedicated to the sale, marketing, analytics and customer support of Portal and Oculus. We also work closely with Facebook teams who guide the manufacturing, logistics, forecasting and fulfillment of our consumer hardware. We surface insights using a custom-built data platform — one that helps our partners make informed decisions with data that drives the future of Facebook's commerce business.
In this role, you’ll see a direct link between your work, company growth, and user satisfaction. You’ll work with some of the brightest minds in the industry, work with one of the richest data sets in the world, use cutting edge technology, and get an opportunity to solve some of the most challenging business and engineering problems, at a scale that few companies can match. You will do so by partnering with stakeholders/teams and building scalable solutions that provide business critical insights and metrics, while ensuring the best uptime and responsiveness.
This is a full-time position based in our office in Menlo Park, CA.
Manage data warehouse plans for a product or a group of products.
Interface with engineers, product managers and product analysts to understand data needs.
Build data expertise and own data quality for allocated areas of ownership.
Design, build and launch new data models in production.
Design, build and launch new data extraction, transformation and loading processes in production.
Support existing processes running in production.
Define and manage SLA for all data sets in allocated areas of ownership.
Work with data infrastructure to triage infra issues and drive to resolution.
2+ years experience in the data warehouse space.
2+ years experience in custom ETL design, implementation and maintenance.
2+ years experience working with either a MapReduce or an MPP system.
2+ years experience with object-oriented programming languages.
2+ years experience with schema design and dimensional data modeling.
2+ years experience in creating SQL statements.
Experience analyzing data to identify deliverables, gaps and inconsistencies.
Experience managing and communicating data warehouse plans to internal clients.
Facebook is committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at accommodations-ext@fb.com.
","http://www.indeed.com/viewjob?t=Data+Engineer&c=Facebook&l=Menlo+Park,+CA&jk=cb2fd3ea111c6180&rtk=1dci3lblkhcde800&from=rss"
JOB101298841698,Data Engineer,Data Engineer,,,"
Job description
Psyonix is a video game developer located in downtown San Diego. Best known for Rocket League, the award-winning game that combines soccer, driving, and highly competitive and addictive gameplay, we are an industry-leading game studio rooted in a crunch-free philosophy that emphasizes a healthy work-life balance.
We are looking for a qualified and passionate Data Engineer to join us on the analytics team. In this role, you will work with fellow team members on both analytics and programming projects to steward data ingestion, pipeline, storage, and other systems through the software development cycle.
Primary Duties & Responsibilities
•Architect, deploy, maintain, and refactor new and existing software into multiple environments
•Unify existing disparate systems and ensure their continued compatibility
•Interact with and help maintain a multitude of big and small data systems
•Collaborate on analytics initiatives to explore and extract insights across data repositories
•Contribute unique, personal ideas towards all aspects of game production and development
•Liaise with other departments to determine project needs and requirements
Ideal Qualifications & Requirements
•4+ years of experience in object oriented programming, preferably .NET or Python
•4+ years of experience with writing and maintaining SQL objects, preferably MySQL
•Experience working with both batch and streaming data processing
•Proven ability to write and maintain effective technical design documentation
•Demonstrated experience working with large and complex datasets
•Experience simultaneously addressing multiple project and stakeholder needs
•Strong written and verbal communication skills
Additional Preferred Experience
•Experience with analysis and reporting
•Knowledge of the game industry’s inner workings
•Familiarity with PubSub / Kubernetes / Docker / PHP / Visual Studio / Linux
•Working knowledge of Cloud Computing (AWS, Google Cloud, Azure) and associated infrastructure
",https://stackoverflow.com/jobs/275958/data-engineer-psyonix
JOB101406605254,Data Engineer,Data Engineer,"You are a data engineer with previous experience in business intelligence and data warehousing,You know how to work with high volume heterogeneous data, preferably with distributed systems such as Kafka, Spark, and MPP databases such as Snowflake.,You are comfortable building and deploying applications in public clouds, in particular in the AWS cloud.,You know how to write distributed, high-volume services in Golang, Scala, or Java.,You have hands-on experience with a large number of technologies and programming languages. It allows you to choose the right tool for job, and to not be afraid of contributing to systems across the whole FindHotel organisation.,You are knowledgeable about data modeling, data access, and data storage techniques.,You appreciate agile software processes, data-driven development, reliability, and responsible experimentation.,You strive for excellence, clarity and transparency, shipping business value as early as possible, and building incrementally afterwards.,(For remote candidates) Based in a time zone between UTC-4 and UTC+6,Experience with e-commerce, clickstream data and event tracking,Experience or interest in data analysis,We continue to hire and grow, look at how we not only survived the Corona-crisis but also thrived.,This year we will be helping +1M customers around the world find better hotel deals, using data, transparency & industry-leading features.,We are in fast growth mode and have been growing bookings by +100% Year-Over-Year for the past 2 years and plan to continue doing so in the coming years.,From our beginnings as an organisation that excelled in User Acquisition, we have grown into an Engineering and Product-driven organisation. Our independence and the maturity that we have achieved in terms of User Acquisition, Engineering and Product enables us to be disruptive and build customer features that nobody else in the industry will.,Plenty of chances to learn and grow – you'll be surrounded by some of the brightest minds in the city, be part of a culture which values sharing knowledge every day and has a budget to attend conferences and develop yourself.,A profitable company with fast growth and a great scale opportunity.,A competitive compensation package + perks and benefits (including Stock Appreciation Rights).,Flexible time off (take as many holidays as you need) and a chance to work remotely - we measure results, not time spent in the office.,You will be part of a highly international team in a fun work environment.,We value good food and offer catered lunches from various cuisines, great coffee, ice-cream in the fridge and the occasional bbq in our garden.,How to survive, refocus & thrive again as a travel startup in corona times,Our hiring process","Build large-scale and real-time systems to provide FindHotel’s analysts, data scientists, and decision makers with high-quality low latency data.,Work in multi-functional agile teams to continuously experiment, iterate and deliver on new product objectives.,Design and implement data models to help our analysts tracking user behaviour across our product,Build ETL and Business Intelligence environment and dashboards used widely by the product teams,When needed improve the way that data is delivered & visualised, better way of presenting multi-dimensional data,Use best practices in continuous integration and delivery.,Help drive optimization, testing and tooling to improve data quality.,Collaborate with other Software Engineers, Data Engineers and stakeholders, taking learning and leadership opportunities that will arise.","← View all jobs
Tech
Data Engineer
Job description
Will you join us on a journey to disrupt the trillion-dollar travel industry? We are looking for the best and brightest who share our passion for travelers, data and product.
FindHotel believes travel is the one thing that opens minds to new ideas, cultures, and ways of thinking. Our mission is to
GET EVERY TRAVELLER THE BEST ACCOMMODATION DEAL, WORLDWIDE. From adventure travel and backpacking to honeymoons and family vacations, we genuinely care so that every traveller can make the best-informed accommodation choice at the absolute best conditions for every trip.
FindHotel has the ambition that every decision should be based on data and every feature be fuelled with data. To make this happen we invest heavily in our data infrastructure. We are looking for a senior Data Engineer to help us scale and grow. The product catalogue of the Data Infrastructure team ranges from the basics of event delivery, storage and processing to A/B testing and Data Science infrastructure (model development and deployment).
What you’ll do:
Build large-scale and real-time systems to provide FindHotel’s analysts, data scientists, and decision makers with high-quality low latency data.
Work in multi-functional agile teams to continuously experiment, iterate and deliver on new product objectives.
Design and implement data models to help our analysts tracking user behaviour across our product
Build ETL and Business Intelligence environment and dashboards used widely by the product teams
When needed improve the way that data is delivered & visualised, better way of presenting multi-dimensional data
Use best practices in continuous integration and delivery.
Help drive optimization, testing and tooling to improve data quality.
Collaborate with other Software Engineers, Data Engineers and stakeholders, taking learning and leadership opportunities that will arise.
Requirements
Who you are:
You are a data engineer with previous experience in business intelligence and data warehousing
You know how to work with high volume heterogeneous data, preferably with distributed systems such as Kafka, Spark, and MPP databases such as Snowflake.
You are comfortable building and deploying applications in public clouds, in particular in the AWS cloud.
You know how to write distributed, high-volume services in Golang, Scala, or Java.
You have hands-on experience with a large number of technologies and programming languages. It allows you to choose the right tool for job, and to not be afraid of contributing to systems across the whole FindHotel organisation.
You are knowledgeable about data modeling, data access, and data storage techniques.
You appreciate agile software processes, data-driven development, reliability, and responsible experimentation.
You strive for excellence, clarity and transparency, shipping business value as early as possible, and building incrementally afterwards.
(For remote candidates) Based in a time zone between UTC-4 and UTC+6
Bonus points for:
Experience with e-commerce, clickstream data and event tracking
Experience or interest in data analysis
Why joining us now?
We continue to hire and grow, look at how we not only survived the Corona-crisis but also thrived.
This year we will be helping +1M customers around the world find better hotel deals, using data, transparency & industry-leading features.
We are in fast growth mode and have been growing bookings by +100% Year-Over-Year for the past 2 years and plan to continue doing so in the coming years.
From our beginnings as an organisation that excelled in User Acquisition, we have grown into an Engineering and Product-driven organisation. Our independence and the maturity that we have achieved in terms of User Acquisition, Engineering and Product enables us to be disruptive and build customer features that nobody else in the industry will.
Is FindHotel the right place for you? Find out by reading our CEO's blog post.
What we offer:
Plenty of chances to learn and grow – you'll be surrounded by some of the brightest minds in the city, be part of a culture which values sharing knowledge every day and has a budget to attend conferences and develop yourself.
A profitable company with fast growth and a great scale opportunity.
A competitive compensation package + perks and benefits (including Stock Appreciation Rights).
Flexible time off (take as many holidays as you need) and a chance to work remotely - we measure results, not time spent in the office.
You will be part of a highly international team in a fun work environment.
We value good food and offer catered lunches from various cuisines, great coffee, ice-cream in the fridge and the occasional bbq in our garden.
Blog posts worth reading
How to survive, refocus & thrive again as a travel startup in corona times
Our hiring process
",https://www.sitepoint.com/jobs/findhotel/data-engineer
JOB105499715649,Senior Data Engineer,Senior Data Engineer,,,"
Job description
Job Title: Data Engineer
Are you looking to work at a technology data company on the cutting edge? Would you like to be on the forefront of a fast changing and exciting industry? Become an integral part of our team focusing on data analytics, machine learning, and enterprise software development! You will work with a team of highly skilled professionals to build ground breaking applications and technologies.
Job Responsibilities:
· Create and maintain data pipelines and advanced analytics that capture data for reporting purposes using scripting languages such as Python
· Strong SQL and relational database experience
· Data and API Integrations with REST services
· Responsible for large data sets and maintaining mission critical data processing pipelines
· Create dashboards and data visualization along with monitor data management initiatives
· Ability to perform data architecture on our existing platform to drive forward an efficient, optimal, and streamlined system with data quality and architectural standards
· Knowledge of systems and best practices as it relates to SQL and NoSQL tools, database design, and efficiency.
· Recommend and implement ways to improve data reliability, efficiency, and quality
· Ability to understand a broad spectrum of technical toolsets and devise mechanisms for data extraction
· Experience with data ingestion, processing, and storing large and diverse datasets
· Expert knowledge of Excel Functions, and reporting tools for Visualization and Analysis
· Strong ability to work well with development team and help implement solutions and results including assisting with setting data standards and best practices
· Work closely with the dev team to build front end components in JavaScript and React which allows for custom tools and systems to be built for our operations team
Qualifications:
· B.S., M.S. in Computer Science or equivalent degree and work experience
· 5+ years working as a data engineer including strong knowledge of Python
· 4+ years working with JavaScript frameworks such as React or Angular.
· Strong understanding of ETL processes
· Strong understanding and experience processing large amounts of structured and unstructured data: SQL, NoSQL, MySQL, etc.
· Strong understanding of data flow/management
· Strong communication skills
· Strong understanding of front end best practices, CSS3, HTML5.
Bonus Skills
· Ability to build a suite of tools to support machine learning development
· Experience in ReactJS
· Backend experience with PHP/Symfony
· Less/SASS experience
· JavaScript ES6 experience or later
· Backend experience with PHP or other languages.
· Understanding of web servers such as Nginx/Apache
· Experience with REST API architecture.
",https://stackoverflow.com/jobs/314215/senior-data-engineer-slashdot-media
JOB105817483352,Data Engineer: productionize statistical models. Remote North America,Data Engineer: productionize statistical models. Remote North America,Final meeting with engineering leadership via video or in person. 1 hour.,"3+ years of experience with:
Scala or Python, both preferred
Distributed systems (e.g. Spark, Hadoop),Scala or Python, both preferred,Distributed systems (e.g. Spark, Hadoop),Database systems (e.g. Postgres, MySQL),Experience with the following is preferred:
IP (v4/v6) allocation and addressing conventions
DNS conventions and best practices
Anti-abuse investigations,IP (v4/v6) allocation and addressing conventions,DNS conventions and best practices,Anti-abuse investigations,Bachelor’s degree (CS, CE/EE, Math, or Statistics preferred),Comfortable working as part of a distributed team,Excellent communication and teamwork skills,Ability to make data driven decisions,Ability to do independent research,Phone conversation with a Talent Acquisition team member to learn more about your experience and career objectives. 30 minutes.,Technical interview with hiring manager via video (preferred). Will include some coding. 30-45 minutes.,1-2 technical interviews with data engineer and data science team members via video or in person. 45 minutes each.","
Job description
About The Role
The Attribution team develops software to collect and infer ownership information of Internet assets, such as IP addresses and domain names. Our team is looking for a data engineer to productionize prototype statistical models for attribution, and integrate new data sources into the attribution pipeline. We value experience in the networking and anti Internet-abuse communities.
This position is either in our HQ in NYC or remote in North America.
Technical Skills and Experience
3+ years of experience with:
Scala or Python, both preferred
Distributed systems (e.g. Spark, Hadoop)
Database systems (e.g. Postgres, MySQL)
Experience with the following is preferred:
IP (v4/v6) allocation and addressing conventions
DNS conventions and best practices
Anti-abuse investigations
Bachelor’s degree (CS, CE/EE, Math, or Statistics preferred)
Traits
Comfortable working as part of a distributed team
Excellent communication and teamwork skills
Ability to make data driven decisions
Ability to do independent research
Interview Process
Phone conversation with a Talent Acquisition team member to learn more about your experience and career objectives. 30 minutes.
Technical interview with hiring manager via video (preferred). Will include some coding. 30-45 minutes.
1-2 technical interviews with data engineer and data science team members via video or in person. 45 minutes each.
Final meeting with engineering leadership via video or in person. 1 hour.
About SecurityScorecard
At SecurityScorecard, we are revolutionizing the cyber security industry. Our platform has created a new category of enterprise software, which companies worldwide rely on to manage the cyber security posture of their vendors. We are on a mission to create a new language for companies and their partners to communicate, understand, and improve each other’s security posture.
Backed by Sequoia and Google Ventures, we are growing tremendously year over year. As we scale, so does our need for talent - if you are intellectually curious and excited by the idea of contributing to a high-growth startup, we’d love to talk to you.
",https://stackoverflow.com/jobs/290942/data-engineer-productionize-statistical-models-securityscorecard
JOB107670225944,"Data Engineer Jobs in Houston, TX","Data Engineer Jobs in Houston, TX",,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/data-engineer/jobs-in/houston/texas/usa/jobs/
JOB107837637550,Senior Big Data Engineer,Senior Big Data Engineer,,"Build analytical solutions to enable Data Scientist by manipulating large data sets and integrating diverse data sources.,Work closely with the data scientists, and database and systems administrators to create data solutions.,Bachelor’s degree or four or more years of work experience.,Experience of designing, building, and deploying production-level data pipelines using tools from Hadoop stack (HDFS, Hive, Spark, HBase, Kafka, NiFi, Oozie, Splunk etc.).","
When you join Verizon
You’ll have the power to go beyond – doing the work that’s transforming how people, businesses and things connect with each other. Not only do we provide the fastest and most reliable network for our customers, but we were first to 5G - a quantum leap in connectivity. Our connected solutions are making communities stronger and enabling energy efficiency. Here, you’ll have the ability to make an impact and create positive change. Whether you think in code, words, pictures or numbers, join our team of the best and brightest. We offer great pay, amazing benefits and opportunity to learn and grow in every role. Together we’ll go far.
What you’ll be doing...
The Visible Engineering team is seeking a Senior Data Engineer to work with a small team responsible for building, deploying, and supporting a Big Data solution that will enable operations for a large enterprise environment. You will design, build and maintain Enterprise Level Data Pipe-Lines utilizing the tools available within the Big Data Eco-System. As a Senior Big Data Engineer - You will work on Advanced Analytics using Big Data technologies such as Hadoop and Data Warehousing.
Build analytical solutions to enable Data Scientist by manipulating large data sets and integrating diverse data sources.
Perform ad-hoc analysis and develop reproducible analytical approaches to meet business requirements.
Perform exploratory and targeted data analyses using descriptive statistics and other methods.
Use complex algorithms to develop systems & applications that deliver business functions or architectural components.
Work closely with the data scientists, and database and systems administrators to create data solutions.
Follow best practices on design and implementation to aid in company-wide data governance.
Improve existing data pipelines by simplifying and increasing performance.
Design, build, and deploy new data pipelines within Big Data Eco-Systems.
Documents new/existing pipelines, Data Sets and Data Sets.
Abides by department development standards and SOP's.
Attends all department meetings.
Keeps updated on latest technologies relevant to position’s duties.
Keeps management updated on projects and assigned work.
What we’re looking for...
You’ll need to have:
Bachelor’s degree or four or more years of work experience.
Six or more years of relevant work experience.
Even better if you have:
Experience of designing, building, and deploying production-level data pipelines using tools from Hadoop stack (HDFS, Hive, Spark, HBase, Kafka, NiFi, Oozie, Splunk etc.).
Experience with various noSQL databases (Hive, MongoDB, Couchbase, Cassandra, Neo4j).
Experience with analytic or feature engineer programming (python or scala or java).
Experience implementing open source frameworks & exposure to various open source & package software architectures (AngularJS, ReactJS, Node, Elasticsearch, Spark, Scala, Splunk, Apigee, and Jenkins etc.).
Experience troubleshooting JVM-related issues.
Experience with SQL databases and Change Data Capture.
Experience and strategies to deal with mutable data in Hadoop.
Experience with Stream sets.
Experience of Agile and DevOps methodologies.
Experience in full development life cycle and significant experience in delivering applications and architecture services.
Experience in data visualization tools like Kibana, Grafana, Tableau and associated architectures.
Experience evaluating and implementing cutting-edge digital technologies.
Experience with Cloud technologies (AWS, GCP, PCF, Docker, Kubernetes and application migration.
Compensation
Our benefits are designed to help you move forward in your career, and in areas of your life outside of Verizon.From health and wellness benefits, short term incentives, 401 (k) Savings Plan, Stock Together, paid time off, parental leave, adoption assistance and tuition assistance, plus other incentives,we’ve got you covered with our award-winning total rewards package.For part-timers, your coverage will vary as you may be eligible for some of these benefits depending on your individual circumstances.
If you are hired into a Colorado work location, the compensation range for this position is between $107,200 and $199,200 based on a full-time schedule. The salary will vary depending on your location and confirmed job-related skills and experience. This is an incentive based position with the potential to earn more. For part-time roles, your compensation will be adjusted to reflect your hours.
Equal Employment Opportunity
We're proud to be an equal opportunity employer - and celebrate our employees' differences, including race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, and Veteran status. Different makes us better.
",https://www.verizon.com/about/work/jobs/5417974-senior-big-data-engineer
JOB108197185233,Data Engineer,Data Engineer,,"building products to help non-technical users extract insights,building applications that leverage ML to solve problems,data automation and product development,installing database systems and writing queries,Ability to communicate with business stakeholders & translate business needs into data requirements, tables & data visualization,Experience with statistical, scripting or programming packages (SQL, Python, R, Matlab),great benefits and competitive salary,bonus","Data Engineer
Loud. Disruptive. Groundbreaking. We help fashion brands make use of the most awesome emerging technologies to be the biggest, baddest brands they can be. If you're a data engineer with deep curiosity and the desire to be part of something huge - we've been looking for you! We need our next rockstar to join us in our NY office, ready to jump into a fast-paced and creative environment.
What You Will Be Doing
building products to help non-technical users extract insights
building applications that leverage ML to solve problems
data automation and product development
installing database systems and writing queries
cleaning, transforming & aggregating data
What You Need for this Position
BS in Computer Science or related field
Ability to communicate with business stakeholders & translate business needs into data requirements, tables & data visualization
Experience with statistical, scripting or programming packages (SQL, Python, R, Matlab)
Knowledge of ML applications is helpful (Tensor Flow, Keras)
What's In It for You
great benefits and competitive salary
bonus
fun culture and meaningful work
So, if you are a Data Engineer passionate about what you do, please apply today!
Applicants must be authorized to work in the U.S.
CyberCoders, Inc is proud to be an Equal Opportunity Employer
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.
Your Right to Work – In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.
",https://www.indeed.com/viewjob?jk=67901b860ba933f8&q=data+python&l=East+Elmhurst%2C+NY&tk=1crnfrsbk4064803&from=web&advn=8690912762161442&sjdu=Q9sRjvVN04RJ1S2r28OpVsqoN8kMd8bO1poiQFI09VhgJoVgAcQBuhdYQ39i9BbhEbBUjfUSY4PlQ_1mXRfZtXcdWs37qjfCXzIu-01jZIv0QLDz-lFwh5d0O2srkG-AlpDKfD6KvxxokoGvjNg3dCcbs8Mr1epMrfjVMGR8bhczsjdecMSNDvX0VJHgs4FTBkVk7w9AjU7-Saua7bBrvxrR2xZiL8srQiAIdXMCvlkqb9itOAyTuKxa7hcTuVX-1b3TBgVu9-9Pses7ABUteg&acatk=1crnfsdv9534o800&pub=4a1b367933fd867b19b072952f68dceb&vjs=3
JOB110239967320,Data Engineer,Data Engineer,,," By using our site, you acknowledge that you have read and understand our Cookie Policy, Privacy Policy, and our Terms of Service. ",https://stackoverflow.com/jobs/developer-jobs-using-amazon-s3?f=cp
JOB110306637322,"Senior Data Engineer, Cloud","Senior Data Engineer, Cloud",Gym membership compensation,"Drive design and implementation leveraging modern design patterns,Ability to partner effectively with UX, PM, DevOps, QE and other developers to design and implement meeting the spirit of requirements,Experience in modern front end frameworks,Technically curious to keep present on advances in technology,Experience with segregation of model, presentation, and business logic.,TDD experience and strong desire to build in test from the start.,Write code (Test or Product) to deliver against project timescales, quality and requirements in various languages including Java or other selected languages for Sophos Cloud products.,Provide guidance and mentorship to junior developers in daily Scrum meetings.,Possesses a passion for solving complex Big Data problems,Plan for, design and implement our next-generation cloud security products.,Be involved from inception through implementation in a real hands on fashion.,BS in Computer Science, Engineering, or equivalent with 7+ years of development and data modelling background,Building highly scalable SaaS solutions using Big Data technologies,Experience with CI/CD,Experience with Agile Software Development methodologies (scrum/ kanban),Excellent attention to detail,Excellent verbal and written communication skills,Experience with the following technologies (recommended) and strong desire to learn (required),Programming language -- Java (must)
Batch processing -- Hadoop ,MapReduce
Stream processing -- Kafka and Amazon Kinesis
NoSQL –S3 , MongoDB.
Columnar stores - HBASE, Amazon Redshift
Restful web services
Code/Build/Deployment -- git, hg, svn, maven, sbt, jenkins, bamboo, ...
Amazon Web Services
Data Warehousing/ built ETL,Programming language -- Java (must),Batch processing -- Hadoop ,MapReduce,Stream processing -- Kafka and Amazon Kinesis,NoSQL –S3 , MongoDB.,Columnar stores - HBASE, Amazon Redshift,Restful web services,Code/Build/Deployment -- git, hg, svn, maven, sbt, jenkins, bamboo, ...,Amazon Web Services,Data Warehousing/ built ETL,Medical insurance,Dental insurance,Vision insurance,Life insurance,Long-term disability insurance,401k plan,Vacation time","
At Sophos, we operate at the cutting edge of technology, protecting businesses worldwide against complex threats, viruses and spam. We build high quality software security products in a fast-paced, nimble environment and we've been doing it for over 20 years.
Join us to help our customers protect their business and meet compliance needs.
Role
To function as a senior data lead for product features or key technology choices and implementation. Collaborates as part of a team for the development of complex systems; including requirements analysis, concept development and design, implementation and testing, demonstrating flexibility of role as required
Main Duties
Drive design and implementation leveraging modern design patterns
Ability to partner effectively with UX, PM, DevOps, QE and other developers to design and implement meeting the spirit of requirements
Experience in modern front end frameworks
Technically curious to keep present on advances in technology
Experience with segregation of model, presentation, and business logic.
TDD experience and strong desire to build in test from the start.
Write code (Test or Product) to deliver against project timescales, quality and requirements in various languages including Java or other selected languages for Sophos Cloud products.
Provide guidance and mentorship to junior developers in daily Scrum meetings.
Possesses a passion for solving complex Big Data problems
Plan for, design and implement our next-generation cloud security products.
Be involved from inception through implementation in a real hands on fashion.
Experience And Skills
BS in Computer Science, Engineering, or equivalent with 7+ years of development and data modelling background
Building highly scalable SaaS solutions using Big Data technologies
Experience with CI/CD
Experience with Agile Software Development methodologies (scrum/ kanban)
Excellent attention to detail
Excellent verbal and written communication skills
Experience with the following technologies (recommended) and strong desire to learn (required)
Programming language -- Java (must)
Batch processing -- Hadoop ,MapReduce
Stream processing -- Kafka and Amazon Kinesis
NoSQL –S3 , MongoDB.
Columnar stores - HBASE, Amazon Redshift
Restful web services
Code/Build/Deployment -- git, hg, svn, maven, sbt, jenkins, bamboo, ...
Amazon Web Services
Data Warehousing/ built ETL
Benefits
In most cases, the compensation package includes:
Medical insurance
Dental insurance
Vision insurance
Life insurance
Long-term disability insurance
401k plan
Vacation time
Gym membership compensation
",https://www.sophos.com/pl-pl/about-us/careers/united-states/senior-data-engineer-cloud.aspx
JOB110419395614,Senior Data Engineer - BlackLocus Jobs in Texas,Senior Data Engineer - BlackLocus Jobs in Texas,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/texas/usa/jobs/?utm_campaign=.JOBS%20RSS%20Feed&utm_source=.JOBS%20RSS%20Feed-DE&vs=25&utm_medium=.JOBS%20Universe
JOB110700886275,Data engineer Jobs,Data engineer Jobs,,,"This opportunity is within Audibles Data Engineering group. The Data Engineering group owns technology platforms and datasets that enable systems and people to uncover new insights and fine-tune operations to meet business goals. We need your help designing and building these.
KEY RESPONSIBILITIES
· Apply broad knowledge of technology options, technology platforms, design techniques and approaches across the Data Engineering ecosystem to build systems that meet business needs
· Build systems and datasets using software engineering best practices, data management fundamentals, data storage principles, recent advances in distributed systems, and operational excellence best practices
· Analyze source systems, define underlying data sources and transformation requirements, design suitable data models and document the design/specifications
· Demonstrate passion for quality and productivity by use of efficient development techniques, standards and guidelines
· Effectively communicate with various teams and stakeholders, escalate technical and managerial issues at the right time and resolve conflicts
· Peer review work. Actively mentor other members of the team, improving their skills, their knowledge of our systems and their ability to get things done
HOW DOES AMAZON FIT IN?
We're a part of Amazon, they are our parent company and it's a great partnership. You'll get to play with all of Amazon's technologies like EC2, SQS and S3 but it doesn't stop there. Audible's built on Amazon technology and you'll have insight into the inner workings of the world's leading ecommerce experience. There's a LOT to learn!
If you want to own and solve problems, work with a creative dynamic team, fail fast in a supportive environment whilst growing your career and working on a platform that powers web applications used by millions of customers worldwide we want to hear from you.
Start your job application: click Apply Now
","https://www.glassdoor.com/Job/data-engineer-jobs-SRCH_KO0,13.htm"
JOB113388091690,Senior Data Engineer - A/B Testing Experimentation Platform,Senior Data Engineer - A/B Testing Experimentation Platform,,"Support and improve existing experimentation analytics pipelines and systems in production,Design and develop new data pipelines and streaming processes that are highly available, scalable, and reliable,Maintain and evolve dimensional data models and schema designs to improve performance efficiency,Scale the self-serve experimentation platform to drive product innovations in over 190 countries,BS/MS in Computer Science, Computer Engineering or related technical discipline,4+ years experience building and maintaining large scale analytics systems,4+ years programming experience in Scala, Java or Python,Experience working with Hadoop, Spark or ElasticSearch,Experience with NoSQL or RDBMS platforms - DynamoDB, Redis, or Postgres,Experience with streaming platforms - Apache Kafka/Flink/Beam or Aws Kinesis,Strong understanding of architecting, developing, and maintaining cloud technologies, architecting (especially in Amazon Web Services),The hustle of a startup with the impact of a global business,Tremendous opportunity to solve some of the industry's most exciting problems,Working with an extraordinary team of smart, creative, fun and highly motivated people,Comprehensive health coverage, competitive salary, 401(k) match and meaningful equity,Unlimited vacation and flexible working hours,Daily catered lunches, endless supply of refreshments, basketball court, fitness classes and social events"," Data influences all of the decisions we make at Tinder. As a senior data engineer working on Tinder's Experimentation Platform, you will architect and build critical analytical pipelines at massive scale and develop self-serve technologies to enable a large number of A/B or multivariate experiments running in production. You will have tons of responsibility, freedom, and opportunity to have a direct and immediate impact on exploring new ideas to drive user satisfaction and company growth. You will help Tinder to evolve relentlessly through rapid iterations on product features, revenue, user growth and advanced matching algorithms. We would love to talk to you if you are interested in helping Tinder users achieve stronger matches, engage more effectively, and create more love, at a truly global scale.
This is a full time position based in our office in Palo Alto, CA.
In this Data Engineer role, you will:
Support and improve existing experimentation analytics pipelines and systems in production
Design and develop new data pipelines and streaming processes that are highly available, scalable, and reliable
Maintain and evolve dimensional data models and schema designs to improve performance efficiency
Scale the self-serve experimentation platform to drive product innovations in over 190 countries
Partner with engineering, analytics, and product stakeholders to define experimentation standards, guidelines and best practices
We're looking for:
BS/MS in Computer Science, Computer Engineering or related technical discipline
4+ years experience building and maintaining large scale analytics systems
4+ years programming experience in Scala, Java or Python
Experience working with Hadoop, Spark or ElasticSearch
Experience with NoSQL or RDBMS platforms - DynamoDB, Redis, or Postgres
Experience with streaming platforms - Apache Kafka/Flink/Beam or Aws Kinesis
Strong understanding of architecting, developing, and maintaining cloud technologies, architecting (especially in Amazon Web Services)
Bonus points for exposure to analytics, statistics, or A/B or Multivariate testing
As part of our team, you'll enjoy:
The hustle of a startup with the impact of a global business
Tremendous opportunity to solve some of the industry's most exciting problems
Working with an extraordinary team of smart, creative, fun and highly motivated people
Comprehensive health coverage, competitive salary, 401(k) match and meaningful equity
Unlimited vacation and flexible working hours
Daily catered lunches, endless supply of refreshments, basketball court, fitness classes and social events
Modern, uplifting work environment in an ideal location
","https://www.glassdoor.com/job-listing/senior-data-engineer-ab-testing-experimentation-platform-tinder-JV_IC1147434_KO0,56_KE57,63.htm?jl=2828237768"
JOB113526002367,Digital Marketing Data Engineer,Digital Marketing Data Engineer,,"Analysis, design, coding, performance tuning, and implementation of new BI solutions.,Evaluation, maintenance, and enhancement of existing ETL processes and model/cube structures.,Creation of BI dashboards and workbooks using Power BI, Tableau, and Excel.,Code data ingest solutions (C#, NodeJS) leveraging 3rd party APIs.,Daily triage of bugs and tasks.,Lead a team of data warehousing engineers, acting as liaison to internal and 3rd party clients and providing regular updates to management.,Create documentation for applications and processes.,Enforce best practices in all aspects of work and evaluate new data warehousing platforms and solutions.,5+ years’ experience in a data warehouse team environment.,Must have Tabular data warehouse design experience including: a solid understanding of MDX/DAX, calculated measures, hierarchies, slowly changing dimensions, and date/time dimension analysis.,Advanced level of experience with Microsoft SQL Server, SSAS and SSMS (Management Studio),Hands-on experience with SSIS or other similar ETL tools,Demonstrated strength with T-SQL for database queries, procedures, tables, views, etc.,Proven skills with data visualization tools: Microsoft Excel (PowerPivot, Pivot Tables, Slicers) Power BI and Tableau (dashboard design, configuration and advanced calculations),Ability to work with .Net development tool Visual Studio 2017 to write code, make changes, and deploy updates.,Experience with storage devices and connectivity tools such as AWS development tools: NodeJS and Lambda Functions.,A basic understanding of HTML, CSS, and web page deployment.,Excellent written and verbal skills and the ability to present to upper management.,A good understanding of basketball.","
At the NBA, we’re passionate about growing and celebrating the game of basketball. Through the intensity of the game and the amazing athletic skill of our players, we deliver excitement to hundreds of millions of fans around the world.
As a global sports and media business, the NBA is so much more. While Basketball Operations runs the league’s on-court activities, other departments manage relationships with television and digital media partners, develop marketing partnerships with some of the world’s most recognizable companies, oversee the licensing of NBA merchandise, and handle a wide range of responsibilities that drive the NBA’s success.
This position will oversee the Microsoft-centric on-premise business intelligence environment and assist with the design of future data warehouses which may include cloud-based solutions. We are looking for a strong hands-on lead data engineer that comes from a digital marketing background, managing large data sets from prominent digital marketing platforms such as Adobe DTM, Google Analytics, Amplitude, etc. The individual will oversee a small, but growing, group of data warehousing engineers, being able to assign tasks, manage deliverables and timelines, and be a key liaison between the development team and the NBA’s internal and 3rd party clients. As this role requires the candidate to be tech savvy and very hands-on, they will have an aptitude for the specific technologies listed below, proven work experience in constructing and working with business intelligence tools and architectures, and strong communication skills.
Major Responsibilities:
Analysis, design, coding, performance tuning, and implementation of new BI solutions.
Evaluation, maintenance, and enhancement of existing ETL processes and model/cube structures.
Creation of BI dashboards and workbooks using Power BI, Tableau, and Excel.
Code data ingest solutions (C#, NodeJS) leveraging 3rd party APIs.
Daily triage of bugs and tasks.
Lead a team of data warehousing engineers, acting as liaison to internal and 3rd party clients and providing regular updates to management.
Create documentation for applications and processes.
Enforce best practices in all aspects of work and evaluate new data warehousing platforms and solutions.
Required Skills/Knowledge:
5+ years’ experience in a data warehouse team environment.
Must have Tabular data warehouse design experience including: a solid understanding of MDX/DAX, calculated measures, hierarchies, slowly changing dimensions, and date/time dimension analysis.
Advanced level of experience with Microsoft SQL Server, SSAS and SSMS (Management Studio)
Hands-on experience with SSIS or other similar ETL tools
Demonstrated strength with T-SQL for database queries, procedures, tables, views, etc.
Proven skills with data visualization tools: Microsoft Excel (PowerPivot, Pivot Tables, Slicers) Power BI and Tableau (dashboard design, configuration and advanced calculations)
Ability to work with .Net development tool Visual Studio 2017 to write code, make changes, and deploy updates.
Experience with storage devices and connectivity tools such as AWS development tools: NodeJS and Lambda Functions.
A basic understanding of HTML, CSS, and web page deployment.
Excellent written and verbal skills and the ability to present to upper management.
A good understanding of basketball.
Educational Background:
Bachelors Degree in Computer Science or related field preferred
We Consider Applicants For All Positions On The Basis Of Merit, Qualifications And Business Needs, And Without Regard To Race, Color, National Origin, Religion, Sex, Gender Identity, Age, Disability, Alienage Or Citizenship Status, Ancestry, Marital Status, Creed, Genetic Predisposition Or Carrier Status, Sexual Orientation, Veteran Status, Familial Status, Status As A Victim Of Domestic Violence Or Any Other Status Or Characteristic Protected By Applicable Federal, State, Or Local Law.
Nearest Major Market: New York City
Nearest Secondary Market: Newark
Job Segment: Database, Developer, Computer Science, Engineer, Technology, Marketing, Engineering
APPLY NOW »
",https://nbacareers.nba.com/job/Secaucus-Media-Data-Warehouse-Engineer-New-07094/497868301/
JOB114704991253,"Senior Data Engineer - BlackLocus Jobs in Austin, TX","Senior Data Engineer - BlackLocus Jobs in Austin, TX",,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/austin/texas/usa/jobs/?utm_medium=.JOBS%20Universe&utm_source=.JOBS%20RSS%20Feed-DE&vs=25&utm_campaign=.JOBS%20RSS%20Feed
JOB115983509603,Data Engineer - Business Intelligence Platform,Data Engineer - Business Intelligence Platform,"Competitive compensation, visa and relocation support when needed.","Participating in the development and maintenance of the analytics data platform for the whole company.,Evolving the platform to make it more robust and scalable.,Supporting the data warehouse, data lake and ETL jobs to ensure that the data is available to the consumers in a reliable, trustworthy and predictable manner.,Creating self-serving tools for data ingestion, quality tracking and consumption.,Closely collaborating and supporting BI analysts, data scientists and other consumers of data.,Ability to understand business requirements and translate them into technical solutions.,Hands-on experience in building large-scale, distributed data platforms in the cloud.,Experience with Apache Spark, Hadoop, Hive, AWS Kinesis, Kafka or similar distributed data processing tool chain.,Programming experience in analyzing and manipulating data - preferably in Python, Scala or Java.,Deep knowledge of SQL queries and traditional data warehousing and data modeling fundamentals. Experience in working with data warehouses like Redshift, Snowflake or BigQuery is an advantage.,Familiarity with stream and batch data processing patterns,Experience with investigating and fixing data quality issues,Willingness to learn new technologies,Great communication skills for proactively communicating with stakeholders,Fluent in English, both speaking and writing (English is our office work language),Exciting technical challenges to work on and great everyday opportunities to learn, grow and develop.,A diverse team of over 40 nationalities.,Free lunches, yoga, German lessons and more.","
Job description
BI Platform team at GoEuro is responsible for maintaining the engineering infrastructure and data platform for business intelligence, reporting and analytics with a vision of making GoEuro a truly data driven organization.
We are searching for a Data Engineer with in-depth skills in distributed data processing and big data technologies and experience in writing complex data pipelines that process terabytes of data per day.
As a data engineer, you will get the opportunity to shape the future of data-driven decision making at GoEuro by enabling the BI analysts, data scientists, product owners and other stakeholders to draw insights from our data.
You will not only be responsible for keeping the data pipeline running but also will play a key role in the evolution of the our data platform in order to make it future-proof in an increasingly complex data-driven environment. You will draw on your data engineering experience and knowledge to establish a state of the art data platform that will help mature the analytics function at GoEuro and open the doors for advanced analytics.
As a Data Engineer at GoEuro you will be responsible for
Participating in the development and maintenance of the analytics data platform for the whole company.
Evolving the platform to make it more robust and scalable.
Supporting the data warehouse, data lake and ETL jobs to ensure that the data is available to the consumers in a reliable, trustworthy and predictable manner.
Creating self-serving tools for data ingestion, quality tracking and consumption.
Closely collaborating and supporting BI analysts, data scientists and other consumers of data.
You are smart, nice to work with and love data? Great! In addition to that, you also need:
Ability to understand business requirements and translate them into technical solutions.
Hands-on experience in building large-scale, distributed data platforms in the cloud.
Experience with Apache Spark, Hadoop, Hive, AWS Kinesis, Kafka or similar distributed data processing tool chain.
Programming experience in analyzing and manipulating data - preferably in Python, Scala or Java.
Deep knowledge of SQL queries and traditional data warehousing and data modeling fundamentals. Experience in working with data warehouses like Redshift, Snowflake or BigQuery is an advantage.
Familiarity with stream and batch data processing patterns
Experience with investigating and fixing data quality issues
Willingness to learn new technologies
Great communication skills for proactively communicating with stakeholders
Fluent in English, both speaking and writing (English is our office work language)
What can you expect from GoEuro?
Exciting technical challenges to work on and great everyday opportunities to learn, grow and develop.
A diverse team of over 40 nationalities.
Free lunches, yoga, German lessons and more.
Competitive compensation, visa and relocation support when needed.
Do you recognize yourself?
We can’t wait to hear from you!
",https://stackoverflow.com/jobs/207558/data-engineer-business-intelligence-platform-goeuro-travel-gmbh
JOB116121397314,Backend Developer/Data Engineer (m/f/d),Backend Developer/Data Engineer (m/f/d),We offer the ability to work with the newest tech-stack and the most talented engineers in IoT industry!,"Help relayr build the world's most advanced IoT Cloud Platform.,Design, develop and improve microservices and data processing pipelines in our analytics/machine learning backend using the latest technologies.,Be customer focused and translate business requirements into technological solutions.,Take part in architecture and code reviews to develop solutions that are simple, functional and sustainable.,Collaborate with other teams to define new features and continuously improve internal systems.,Work with QA and DevOps in the development, testing and deployment of services.,Work together with data scientists to design large-scale machine learning systems.,You have 3+ years of experience in backend engineering,You have strong knowledge of Python or Java,You have experience developing microservice architecture,You have a good understanding of designing and scaling distributed systems,You have experience working with SQL and/or NoSQL databases, messaging queues (e.g. Kafka) and large scale data processing (e.g. Apache Spark),You are able to work in a structured manner and care about your contribution end to end,You have a very good command of the English language,Flexibility and safety are important to us! As a company we were quick to react when the Corona pandemic began, sending all our employees to work from home. If you start out as a new employee at relayr, you will be working from home, enjoy a structured digital onboarding programme and flexible working hours.,Modern office located in Central Tower of Munich with a relaxation room, standing-desks, and free fruits and drinks,Relayrians come from all over the world, speak 20+ languages (working language is English), and welcome people of all ages and parental statuses. Our customers are as diverse as we are - join us to connect with a network of companies and people from around the globe,An extensive on-boarding period so you can get up to speed with the rest of the team,A learning environment where you can build upon your skills and interests, share knowledge, and attend events and conferences pertaining to your discipline. We also offer free German classes at all levels,Have some fun with regular team lunches and offsites, a yearly company summit, and our branded goodies,Competitive salary,We fully support your move to Munich with a relocation budget and visa assistance. We'll help you settle into your exciting new city!,25 paid vacation days + public holidays,Discounted Urban Sports Club membership,Choose between a Mac, Windows, or a Linux machine","
Job description
Relayr is the Industrial Internet of Things (IIoT) powerhouse delivering the most complete solution for risk-free digital transformations. We unleash data insights from existing equipment, machines and production lines to improve our customers’ business outcomes.
We provide a unique combination of first-class IIoT technology and its delivery with powerful financial and insurance offerings — all from a single source trusted by hundreds of companies worldwide. With around 300 employees, we are a truly global family with locations in Germany, the USA, Poland, Italy, France, and the UK. Named twice the hottest start-up in Berlin by WIRED magazine and a winner of The Spark - the German Digital Award, relayr is now part of the Munich Re group.
Our analytics team pushes the boundaries of technology. We tackle challenging problems in the fields of data engineering, data science, and machine learning research to develop solutions from early prototypes to fully-fledged production-ready systems. We are looking to recruit a diverse group to be able to best handle novel challenges in the emerging market of the Internet of Things. Currently we are seeking a Backend Developer/Data Engineer to join our team and be based in our Munich office.
Your tasks:
Help relayr build the world's most advanced IoT Cloud Platform.
Design, develop and improve microservices and data processing pipelines in our analytics/machine learning backend using the latest technologies.
Be customer focused and translate business requirements into technological solutions.
Take part in architecture and code reviews to develop solutions that are simple, functional and sustainable.
Collaborate with other teams to define new features and continuously improve internal systems.
Work with QA and DevOps in the development, testing and deployment of services.
Work together with data scientists to design large-scale machine learning systems.
Your skills:
You have 3+ years of experience in backend engineering
You have strong knowledge of Python or Java
You have experience developing microservice architecture
You have a good understanding of designing and scaling distributed systems
You have experience working with SQL and/or NoSQL databases, messaging queues (e.g. Kafka) and large scale data processing (e.g. Apache Spark)
You are able to work in a structured manner and care about your contribution end to end
You have a very good command of the English language
We Offer:
Flexibility and safety are important to us! As a company we were quick to react when the Corona pandemic began, sending all our employees to work from home. If you start out as a new employee at relayr, you will be working from home, enjoy a structured digital onboarding programme and flexible working hours.
Modern office located in Central Tower of Munich with a relaxation room, standing-desks, and free fruits and drinks
Relayrians come from all over the world, speak 20+ languages (working language is English), and welcome people of all ages and parental statuses. Our customers are as diverse as we are - join us to connect with a network of companies and people from around the globe
An extensive on-boarding period so you can get up to speed with the rest of the team
A learning environment where you can build upon your skills and interests, share knowledge, and attend events and conferences pertaining to your discipline. We also offer free German classes at all levels
Have some fun with regular team lunches and offsites, a yearly company summit, and our branded goodies
Competitive salary
We fully support your move to Munich with a relocation budget and visa assistance. We'll help you settle into your exciting new city!
25 paid vacation days + public holidays
Discounted Urban Sports Club membership
Choose between a Mac, Windows, or a Linux machine
We offer the ability to work with the newest tech-stack and the most talented engineers in IoT industry!
At relayr, we are passionate about creating an inclusive workplace that promotes and values diversity. As firm believers in the power of different perspectives, we encourage our employees to share knowledge and exchange bold ideas to help innovation in the IoT industry thrive.We are committed to creating a fair, supportive, and open environment for all.
",http://stackoverflow.com/jobs/409827/backend-developer-data-engineer-m-f-d-relayr
JOB116952237762,MySQL ETL Data Engineer jobs,MySQL ETL Data Engineer jobs,,,"
Based on 11,073 salaries
",https://www.indeed.com/q-MySQL-ETL-Data-Engineer-jobs.html
JOB119425280074,Data Engineer (m/f/d),Data Engineer (m/f/d),"Willingness to travel,","In-depth knowledge of Python, pandas and its open-source ecosystem, with a focus on parallelized processing,,Experience in configuring and working with relational databases in the terabyte scale, e.g. MS SQL Server,,Several years of experience working on and designing data-intensive applications and/or pipelines,,Commitment to ensuring data quality and integrity of complex systems within a time-sensitive environment,,Experience with OS-independent, cross-platform development,,Passion to work effectively in interdisciplinary teams of technical and non-technical individuals with different cultural backgrounds on health-related (business) problems,,Business proficiency in English and German,Passion for using and contributing to the open-source data science ecosystem,,Ability to evaluate the business value of different technical projects and prioritize appropriately,","
Job description
As a Data Engineer at QuantCo, you will integrate our clients’ technical systems with our industry-leading statistical and machine learning models. You will work alongside our data scientists, economists, and software engineers to solve technical and quantitative challenges ensuring that our solutions produce value for our clients.
To achieve this, you will own the entire software development process from high-level system design and prototyping to application development and data integration. You will contribute to our data pipelines with your expertise in scalable data-driven systems. You will have the opportunity to manage technical projects with both internal and client stakeholders and spearhead collaborative efforts to solve critical technical issues with immediate and long-term business impact.
We are looking for team players with an entrepreneurial mindset that will bring:
Required
In-depth knowledge of Python, pandas and its open-source ecosystem, with a focus on parallelized processing,
Experience in configuring and working with relational databases in the terabyte scale, e.g. MS SQL Server,
Several years of experience working on and designing data-intensive applications and/or pipelines,
Commitment to ensuring data quality and integrity of complex systems within a time-sensitive environment,
Experience with OS-independent, cross-platform development,
Passion to work effectively in interdisciplinary teams of technical and non-technical individuals with different cultural backgrounds on health-related (business) problems,
Business proficiency in English and German
Preferred
Passion for using and contributing to the open-source data science ecosystem,
Ability to evaluate the business value of different technical projects and prioritize appropriately,
Willingness to travel,
",http://stackoverflow.com/jobs/437590/data-engineer-m-f-d-quantco
JOB119998113881,Data Engineer,Data Engineer,"Due to business requirements, the successful candidate must be based in Ireland.,Candidates based in the EU but willing to relocate to Ireland will also be considered.,Python experience (3+ years),5+ years of software development experience,Good command of Linux,Front-end development experience required for creating and supporting internal tools,Back-end development experience required for creating and supporting internal tools: Python web frameworks (like twisted, aiohttp, django, flask), databases.,Understanding of the web technologies: JavaScript, HTML, CSS, HTTP,Strong analytics skills related to working with unstructured datasets,Excellent written English,Strong web crawling and web scraping skills: Scrapy knowledge, browser automation experience. Splash experience is a plus.,Experience handling mid-size and large datasets, organizing their parallel processing,Good spoken English,Strong record of open source activity","Create data tools for Data Science team members that assist them in building and optimizing our product.,Assemble large datasets that meet requirements set by the Data Science team, including creating web crawlers.,Be proactive in bringing forth new ideas and solutions to problems,Be a strong team player and share knowledge freely and easily with your co-workers,Write software for post-processing and cleaning of the data, taking part in data analysis if required,Automate manual processes, optimize data delivery, improve architecture for greater scalability,Work on integration of Data Science components into our larger systems,Handle mid-size and large datasets (200GB+)","
Job description
About the job: Scrapinghub is looking for a Data Engineer to work closely with our Data Scientist team and provide assistance with dataset collection, cleaning and post-processing. You’ll also help with writing tools for working with data as required for Data Science projects. You will work with one of the most advanced and comprehensive web crawling and scraping infrastructures in the world, leveraging massive data sets with cutting edge technology.
Job Responsibilities:
Create data tools for Data Science team members that assist them in building and optimizing our product.
Assemble large datasets that meet requirements set by the Data Science team, including creating web crawlers.
Be proactive in bringing forth new ideas and solutions to problems
Be a strong team player and share knowledge freely and easily with your co-workers
Write software for post-processing and cleaning of the data, taking part in data analysis if required
Automate manual processes, optimize data delivery, improve architecture for greater scalability
Work on integration of Data Science components into our larger systems
Handle mid-size and large datasets (200GB+)
Job Requirements:
Due to business requirements, the successful candidate must be based in Ireland.
Candidates based in the EU but willing to relocate to Ireland will also be considered.
Python experience (3+ years)
5+ years of software development experience
Good command of Linux
Front-end development experience required for creating and supporting internal tools
Back-end development experience required for creating and supporting internal tools: Python web frameworks (like twisted, aiohttp, django, flask), databases.
Understanding of the web technologies: JavaScript, HTML, CSS, HTTP
Strong analytics skills related to working with unstructured datasets
Excellent written English
Bonus points for:
Strong web crawling and web scraping skills: Scrapy knowledge, browser automation experience. Splash experience is a plus.
Experience handling mid-size and large datasets, organizing their parallel processing
Good spoken English
Strong record of open source activity
",https://stackoverflow.com/jobs/200442/data-engineer-scrapinghub
JOB120301831203,Senior Data Engineer - BlackLocus Jobs in United States,Senior Data Engineer - BlackLocus Jobs in United States,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/usa/jobs/?utm_medium=.JOBS%20Universe&utm_campaign=.JOBS%20RSS%20Feed&utm_source=.JOBS%20RSS%20Feed-DE&vs=25
JOB120360649750,Senior Data Engineer - BlackLocus Jobs in Texas,Senior Data Engineer - BlackLocus Jobs in Texas,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/texas/usa/jobs/?vs=25&utm_medium=.JOBS%20Universe&utm_campaign=.JOBS%20RSS%20Feed&utm_source=.JOBS%20RSS%20Feed-DE
JOB123055129620,"Data Engineer Jobs in Houston, TX","Data Engineer Jobs in Houston, TX",,"Houston, TX","
Data Engineer Jobs in Houston, TX
Current Search Criteria
More
",https://militaryjobs.homedepot.com/data-engineer/jobs-in/houston/texas/usa/jobs/?utm_source=.JOBS%20RSS%20Feed-DE&vs=25&utm_campaign=.JOBS%20RSS%20Feed&utm_medium=.JOBS%20Universe
JOB123074561027,Senior Data Engineer - BlackLocus,Senior Data Engineer - BlackLocus,,,"
Job Information
POSITION PURPOSE
The Sr Data Engineer will expand and optimize data, data flow, data collection for cross functional teams, and data pipeline architecture. The Sr Data Engineer will support and collaborate with the software engineering team, data analysts, and data scientist to ensure data delivery architecture is consistent throughout ongoing projects. Continuously improve or re-design data architecture to support the next generation of products and initiatives.
MAJOR TASKS, RESPONSIBILITES AND KEY ACCOUNTABILITIES
40% - Data Validation, ETL, Infrastructure Development: Coding validation and ETL to ensure successful data integration
30% - Data Infrastructure Maintenance: Backup and optimization activities to maintain performance; code, configure, test, etc data to ensure integrity
20% - Data Architecture Design and Analysis: Create and maintain optimal data pipeline architecture; Develop data architecture to meet business requirements
10% - Planning/Requirements Analysis: Collaborate with team leads and cross functional partners to assess business requirements and communicate opportunities
NATURE AND SCOPE
This position reports to the Technology Leader.
This position has 0 direct reports.
ENVIRONMENTAL JOB REQUIREMENTS
Environment:
Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.
Travel:
Typically requires overnight travel less than 10% of the time.
Additional Environmental Job Requirements:MINIMUM QUALIFICATIONS
Must be eighteen years of age or older.
Must be legally permitted to work in the United States.
Additional Minimum Qualifications:
Experience message queuing, stream processing, and scalable data stores
Experience managing projects and organizing data
Experience supporting and working with cross-functional teams
Experience with SQL, NoSQL databases, relational databases, and query authoring
Experience building and optimizing data pipelines, architectures, data sets and workflow management tools such as Azkaban, Luigi, Airflow, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C#, Scala, GoLang, etc.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
Education Required:
The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.
Years of Relevant Work Experience: 5 years
Physical Requirements:
Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.
Additional Qualifications:
Preferred Qualifications:
8+ years of previous related work experience
Ability to convey complex or technical ideas and processes in easy-to-understand terms to diverse audiences
Ability to negotiate, handle complaints, settle disputes, and resolve grievances with both internal and external customers
Excellent written and verbal communication skills
Knowledge, Skills, Abilities and Competencies:Collaborates - Building partnerships and working collaboratively with others to meet shared objectives
Communicates Effectively - Developing and delivering multi-mode communications that convey a clear understanding of the unique needs of different audiences
Cultivates Innovation - Creating new and better ways for the organization to be successful
Drives Engagement - Creating a climate where people are motivated to do their best to help the organization achieve its objectives
Instills Trust - Gaining the confidence and trust of others through honesty, integrity, and authenticity
Nimble Learning - Actively learning through experimentation when tackling new problems, using both successes and failures as learning fodder
Optimizes Work Processes - Knowing the most effective and efficient processes to get things done with a focus on continuous improvement
Plans and Aligns - Planning and prioritizing work to meet commitments aligned with organizational goals
Tech Savvy - Anticipating and adopting innovations in business-building digital and technology applications. We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
",https://militaryjobs.homedepot.com/austin-tx/senior-data-engineer-blacklocus/35068FD906174D91A159D54015CA5347/job/?utm_source=.JOBS%20RSS%20Feed-DE&utm_campaign=.JOBS%20RSS%20Feed&utm_medium=.JOBS%20Universe
JOB123439154226,Senior Data Engineer - BlackLocus Jobs in United States,Senior Data Engineer - BlackLocus Jobs in United States,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/usa/jobs/?utm_source=.JOBS%20RSS%20Feed-DE&utm_campaign=.JOBS%20RSS%20Feed&utm_medium=.JOBS%20Universe&vs=25
JOB124021687333,Senior Data Engineer - BlackLocus,Senior Data Engineer - BlackLocus,,,"
Job Information
POSITION PURPOSE
The Sr Data Engineer will expand and optimize data, data flow, data collection for cross functional teams, and data pipeline architecture. The Sr Data Engineer will support and collaborate with the software engineering team, data analysts, and data scientist to ensure data delivery architecture is consistent throughout ongoing projects. Continuously improve or re-design data architecture to support the next generation of products and initiatives.
MAJOR TASKS, RESPONSIBILITES AND KEY ACCOUNTABILITIES
40% - Data Validation, ETL, Infrastructure Development: Coding validation and ETL to ensure successful data integration
30% - Data Infrastructure Maintenance: Backup and optimization activities to maintain performance; code, configure, test, etc data to ensure integrity
20% - Data Architecture Design and Analysis: Create and maintain optimal data pipeline architecture; Develop data architecture to meet business requirements
10% - Planning/Requirements Analysis: Collaborate with team leads and cross functional partners to assess business requirements and communicate opportunities
NATURE AND SCOPE
This position reports to the Technology Leader.
This position has 0 direct reports.
ENVIRONMENTAL JOB REQUIREMENTS
Environment:
Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.
Travel:
Typically requires overnight travel less than 10% of the time.
Additional Environmental Job Requirements:MINIMUM QUALIFICATIONS
Must be eighteen years of age or older.
Must be legally permitted to work in the United States.
Additional Minimum Qualifications:
Experience message queuing, stream processing, and scalable data stores
Experience managing projects and organizing data
Experience supporting and working with cross-functional teams
Experience with SQL, NoSQL databases, relational databases, and query authoring
Experience building and optimizing data pipelines, architectures, data sets and workflow management tools such as Azkaban, Luigi, Airflow, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C#, Scala, GoLang, etc.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
Education Required:
The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.
Years of Relevant Work Experience: 5 years
Physical Requirements:
Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.
Additional Qualifications:
Preferred Qualifications:
8+ years of previous related work experience
Ability to convey complex or technical ideas and processes in easy-to-understand terms to diverse audiences
Ability to negotiate, handle complaints, settle disputes, and resolve grievances with both internal and external customers
Excellent written and verbal communication skills
Knowledge, Skills, Abilities and Competencies:Collaborates - Building partnerships and working collaboratively with others to meet shared objectives
Communicates Effectively - Developing and delivering multi-mode communications that convey a clear understanding of the unique needs of different audiences
Cultivates Innovation - Creating new and better ways for the organization to be successful
Drives Engagement - Creating a climate where people are motivated to do their best to help the organization achieve its objectives
Instills Trust - Gaining the confidence and trust of others through honesty, integrity, and authenticity
Nimble Learning - Actively learning through experimentation when tackling new problems, using both successes and failures as learning fodder
Optimizes Work Processes - Knowing the most effective and efficient processes to get things done with a focus on continuous improvement
Plans and Aligns - Planning and prioritizing work to meet commitments aligned with organizational goals
Tech Savvy - Anticipating and adopting innovations in business-building digital and technology applications. We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
",https://militaryjobs.homedepot.com/austin-tx/senior-data-engineer-blacklocus/35068FD906174D91A159D54015CA5347/job/?utm_campaign=.JOBS%20RSS%20Feed&utm_source=.JOBS%20RSS%20Feed-DE&utm_medium=.JOBS%20Universe
JOB126095812675,Data Engineer (m/f/d) wanted who is NOT looking for the next gig,Data Engineer (m/f/d) wanted who is NOT looking for the next gig,pension plans and employee benefits,"not only looking for the next gig for your CV but for a permanent occupation in an interesting and continuously changing environment,a good fit for our culture and also you will add value to it,an expert in Java development and a proficient Linux user. Although you have worked with various technologies in the past, your resume points to the most relevant ones and not all of them.,in open and honest communication,that agile has more to do with values and mindset than with roles and processes,that high-performing teams are usually built from diversity, agile collaboration principles, and application of best practices from software development,work on one of our international and cross-functional agile teams,create data pipelines in Hadoop environments using for example Spark, Java, and AWS services,integrate data science and statistical solutions with huge amounts of data,maintain and enhance our existing code base,a permanent position with a competitive salary, and flexible working conditions,a good work life balance, 32 days of vacation, and parent-friendly regulations,support with relocation, visa sponsorship, and language courses","
Job description
GfK is looking for a Data Engineer (m/f/d) in Berlin
GfK is a technology company active in the market research area. With immediate effect we are looking for development support for our media measurement solution group.
You are
not only looking for the next gig for your CV but for a permanent occupation in an interesting and continuously changing environment
a good fit for our culture and also you will add value to it
an expert in Java development and a proficient Linux user. Although you have worked with various technologies in the past, your resume points to the most relevant ones and not all of them.
We believe
in open and honest communication
that agile has more to do with values and mindset than with roles and processes
that high-performing teams are usually built from diversity, agile collaboration principles, and application of best practices from software development
You will
work on one of our international and cross-functional agile teams
create data pipelines in Hadoop environments using for example Spark, Java, and AWS services
integrate data science and statistical solutions with huge amounts of data
maintain and enhance our existing code base
We offer
a permanent position with a competitive salary, and flexible working conditions
a good work life balance, 32 days of vacation, and parent-friendly regulations
support with relocation, visa sponsorship, and language courses
pension plans and employee benefits
If this sounds interesting to you, do not hesitate to reach out to Maximilian.Osterkamp@ext.gfk.com.
We would love to hear from you!
GfK. Growth from Knowledge.
GfK turns data into smart business decisions for clients.
Can there be a better place FOR YOU to take center stage in the digital revolution?
We offer an exciting work environment that brings people together and encourages an entrepreneurial and innovative spirit. We passionately focus on addressing our clients’ needs and improving their knowledge through the best digital research solutions in the world. We do this by integrating data from all sources and by providing prescriptive analytics giving insightful answers to their key business questions. We call this Growth from Knowledge.​
",https://stackoverflow.com/jobs/181676/data-engineer-m-f-d-wanted-who-is-not-looking-gfk
JOB126724133903,Snowflake Data Engineer/Architect,Snowflake Data Engineer/Architect,,"Design and implement secure data pipelines into a Snowflake data warehouse from on premise and cloud data sources,Design and implement data pipelines to prepare, process and organize data in the warehouse,Design and implement high performing BI dashboard integrations to leading BI & Visualization tools working with BI developers,Design and implement high performing data pipelines feeding downstream systems,Troubleshooting, problem solving and performance tuning of data pipelines and queries accessing data warehouse,Creation of best practices and standards for data pipelining and integration with Snowflake data warehouses,Ensure enterprise security and access control policies are adhered to in the solution,Creation of architecture and design artifacts and documents,Conduct design and code reviews,Work with Business Analysts and Users to translate functional specifications into technical requirements and designs.","
- Job description
Schedule: Full-time
Organization: Analytics Business
Travel: 80% (Monday - Thursday)
Position: Analytics Consulting – Snowflake Data Engineer
Join Accenture Digital and leave your digital mark on the world, enhancing millions of lives through digital transformation. Where you can create the best customer experiences and be a catalyst for first-to-market digital products and solutions using machine-learning, AI, big data and analytics, cloud, mobility, robotics and the industrial internet of things. Your work will redefine the way entire industries work in every corner of the globe.
You’ll be part of a team with incredible end-to-end digital transformation capabilities that shares your passion for digital technology and takes pride in making a tangible difference. If you want to contribute on an incredible array of the biggest and most complex projects in the digital space, consider a career with Accenture Digital.
JOB DESCRIPTION:
Do you have a pulse on new technologies and a desire to change the way business gets done? Do you want to implement emerging solutions for some of the most successful companies around? If you answered yes to these questions and you are passionate about helping clients effectively manage enormous amounts of data to generate knowledge and value, then we want to meet you.
Snowflake Data Engineers will be responsible for architecting and implementing very large scale data intelligence solutions around Snowflake Data Warehouse. A solid experience and understanding of architecting, designing and operationalization of large scale data and analytics solutions on Snowflake Cloud Data Warehouse is a must.
Responsibilities
Design and implement secure data pipelines into a Snowflake data warehouse from on premise and cloud data sources
Design and implement data pipelines to prepare, process and organize data in the warehouse
· Design and optimize high performing data models for different consumption patterns from the warehouse
Design and implement high performing BI dashboard integrations to leading BI & Visualization tools working with BI developers
Design and implement high performing data pipelines feeding downstream systems
Troubleshooting, problem solving and performance tuning of data pipelines and queries accessing data warehouse
Creation of best practices and standards for data pipelining and integration with Snowflake data warehouses
Ensure enterprise security and access control policies are adhered to in the solution
Creation of architecture and design artifacts and documents
Conduct design and code reviews
Work with Business Analysts and Users to translate functional specifications into technical requirements and designs.
",https://www.indeed.com/cmp/_/job?jk=930a7796f4ba32c9&tk=1cs7vedoub83m800
JOB126982541945,"Senior Data Engineer, Data Pipelines & Infrastructure - Data & Analytics","Senior Data Engineer, Data Pipelines & Infrastructure - Data & Analytics",,,"
WHO YOU ARE
We are looking for Senior Data Engineers who are passionate about data and the opportunities building data-focused systems. As a problem-solver you enjoy digging into and understanding data and code as well as building high-quality solutions that deliver value to users. As a person you get energized by working together with others in a cross-functional team towards a shared goal. You have a growth mindset which drives you to lead by example and continuously renew and improve ways of working. We believe you are passionate about: • Scalable, distributed and resilient data processing systems • Database systems and data storage technologies • Streaming data technologies and frameworks • Cloud computing platforms • Workflow/pipeline scheduling, orchestration and management • DevOps, CI/CD and Agile development practices The role requires +5 years of relevant experience The IKEA culture and values are very much a part of our business and day to day work life. For you to thrive and grow with IKEA it’s important for us that you share our values! You can read more regarding our values and life at IKEA on our website www.ikea.com
YOUR RESPONSIBILITIES
In this role you will • work on designing, developing, testing and maintaining data processing systems and services that meet requirements and user needs • implement measures to improve data reliability, efficiency and quality, and ensuring that systems are reliable and secured • act as a technical expert in regards to data processing frameworks, integration and connectivity/protocols, security and related practices • drive data ingestion and processing from a variety of sources systems, to prepare for usage in reporting, analysis and machine learning/data science applications • be an active member and contributor in our data engineering community
OUR TEAM WITHIN IKEA
The Data & Analytics team enables and drives IKEA’s digital agenda through data and analytics, from reporting and analysis solutions to real-time streaming data and machine learning systems that enable personalized experiences for our customers. We work end-to-end over the digital product lifecycle in cross-functional teams, using new and existing technologies and practices to deliver at speed. We are a diverse team coming from all over the world with a shared passion for data and analytics. We work hard with a spirit of togetherness and enthusiasm, and we have fun doing it in an inclusive, open, honest and down-to-earth work environment. We are currently modernizing our technology landscape including new tools, cloud platforms and open source technologies and standards. Our data and analytics systems are primarily built in Python and Scala on Google Cloud Platform where we leverage BigQuery, DataFlow/Apache Beam, Spark, Composer/Apache Airflow, Kafka and Google Pub/Sub.
QUESTIONS AND SUPPORT? LET'S CONNECT!
For more information about the role, please contact recruiting manager Simon Hellbe, Data Engineering & Architecture Manager at simon.hellbe@ikea.com. If you have any questions about the recruitment process, please contact hamid.alamin@ikea.com
",https://th-jobs.about.ikea.com/%e0%b8%87%e0%b8%b2%e0%b8%99/malmo/senior-data-engineer-data-pipelines-and-infrastructure-data-and-analytics/24107/12556515
JOB127094302828,Senior Data Engineer,Senior Data Engineer,"Weekly catered lunches and a stocked kitchen full of fruit, energy bars, popcorn, coconut water, and other healthy snacks","Design, develop and maintain New Knowledge’s data pipeline,Support and monitor pipeline performance in production,Take ownership of components of the data pipeline,Work with product managers understand upcoming work and design a system capable of meeting long term product vision,Create and maintain documentation capable of describing how the pipeline work to non-technical audience,Work as part of a team to integrate new services into New Knowledge’s data pipeline using tools like Docker, Kubernetes, Kafka, PostgreSQL and more.,3+ year(s) developing software as part of a team, preferably working on some aspect of a data pipeline,Experience or familiarity with Kafka or similar distributed systems (knowledge of schema registry/data types and serialization options and partition strategies a plus),Experience or familiarity with popular stream processing framework such as Spark Streaming, Kafka Streams, Flink or similar,Experience supporting large scale batch analytics in Hadoop ecosystem (loading and retrieving data),Experience working with or building schedulers, workflow automation/coordination tools,Experience implementing tests and sanity checks on large complex data pipelines,Experience helping other developers write performant SQL queries.,Ability to monitor current solution to understand its limits and stay ahead of business needs,Comfortable representing data engineering function in front of Senior leaders and product management during prioritization and design discussions,Knowledge of how to evaluate tools and ability to document pro/cons of infrastructure decisions,Desire to mentor junior developers,3+ years professional software development,You have experience working with data pipelines,Experience processing social media, text and image data is particularly relevant,Highly motivated to research, prototype and implement state of the art data pipeline,Comfortable with knowing what you do not know and asking for help or finding your own answers when required,Previously held leadership positions technical or otherwise,Competitive salary, 401(k) matching, and Fortune 500 level healthcare,We are a business that trusts and embraces technology and harnesses it for good. We embrace diverse ideas, autonomy and collaboration,Professional development opportunities–– we host lunch and learns, hold weekly 1-1’s, and have a policy where you can expense professional development books,A diverse leadership team that wants to uphold ethical practices in our software development process,A strong commitment to creating a diverse environment,Free parking in our building in downtown Austin,Free access to a gym in our office building,A $2,000 annual credit that you can spend on the technology and work gear of your choice,Parental leave (plan with your manager) and unlimited vacation (and no, that is not code for you never take a vacation, we encourage and value time off)","
Job description
You're looking for a team where you can drive decisions, be challenged and build a powerful and novel product. You want to collaborate with smart, creative, and energetic people. You’re comfortable with being uncomfortable. You look for projects where you can learn new technologies and techniques. You’re comfortable designing, developing, testing, and launching software. You’re creative. And if this sounds like you, you sound like someone we want on our team.
New Knowledge is on a mission to defend public discourse. We build products that repair online communities, identify manipulation, and help them communicate more authentically. In a world where social media is being manipulated on a massive scale, this is no small task. We care about protecting communities, brands, and companies from being targeted by the spreading of disinformation. The kind of people who work with us have to be passionate about that challenge and mission.
While we take our mission very seriously, we are also a team of fun-loving, laid-back, self described geeks who love tacos and topo chico.
Summary
We are looking for senior engineers with previous experience working as a team lead or desire to grow into that role. The best candidates will have an interest in the state of the art stream and batch processing architecture with awareness of ecosystem of tools available to solve data engineering problem. You will be empowered to make big design decisions and own major pieces of the data pipeline.
What you'll work on
Design, develop and maintain New Knowledge’s data pipeline
Support and monitor pipeline performance in production
Take ownership of components of the data pipeline
Work with product managers understand upcoming work and design a system capable of meeting long term product vision
Create and maintain documentation capable of describing how the pipeline work to non-technical audience
Work as part of a team to integrate new services into New Knowledge’s data pipeline using tools like Docker, Kubernetes, Kafka, PostgreSQL and more.
Skills
These are not hard requirements or an exhaustive list. Consider this an outline to give you a better understanding of what you’ll be doing. We expect a senior engineer to meet at least half of these requirements and be comfortable and excited to learn the rest.
3+ year(s) developing software as part of a team, preferably working on some aspect of a data pipeline
Experience or familiarity with Kafka or similar distributed systems (knowledge of schema registry/data types and serialization options and partition strategies a plus)
Experience or familiarity with popular stream processing framework such as Spark Streaming, Kafka Streams, Flink or similar
Experience supporting large scale batch analytics in Hadoop ecosystem (loading and retrieving data)
Experience working with or building schedulers, workflow automation/coordination tools
Experience implementing tests and sanity checks on large complex data pipelines
Experience helping other developers write performant SQL queries.
Other notable skills
Ability to monitor current solution to understand its limits and stay ahead of business needs
Comfortable representing data engineering function in front of Senior leaders and product management during prioritization and design discussions
Knowledge of how to evaluate tools and ability to document pro/cons of infrastructure decisions
Desire to mentor junior developers
Who you are
3+ years professional software development
You have experience working with data pipelines
Experience processing social media, text and image data is particularly relevant
Highly motivated to research, prototype and implement state of the art data pipeline
Comfortable with knowing what you do not know and asking for help or finding your own answers when required
Previously held leadership positions technical or otherwise
Why we love working here
Competitive salary, 401(k) matching, and Fortune 500 level healthcare
We are a business that trusts and embraces technology and harnesses it for good. We embrace diverse ideas, autonomy and collaboration
Professional development opportunities–– we host lunch and learns, hold weekly 1-1’s, and have a policy where you can expense professional development books
A diverse leadership team that wants to uphold ethical practices in our software development process
A strong commitment to creating a diverse environment
Free parking in our building in downtown Austin
Free access to a gym in our office building
A $2,000 annual credit that you can spend on the technology and work gear of your choice
Parental leave (plan with your manager) and unlimited vacation (and no, that is not code for you never take a vacation, we encourage and value time off)
Weekly catered lunches and a stocked kitchen full of fruit, energy bars, popcorn, coconut water, and other healthy snacks
",https://stackoverflow.com/jobs/203433/senior-data-engineer-new-knowledge
JOB127610943022,"Senior Data Engineer, Cloud","Senior Data Engineer, Cloud",Gym membership compensation,"Drive design and implementation leveraging modern design patterns,Ability to partner effectively with UX, PM, DevOps, QE and other developers to design and implement meeting the spirit of requirements,Experience in modern front end frameworks,Technically curious to keep present on advances in technology,Experience with segregation of model, presentation, and business logic.,TDD experience and strong desire to build in test from the start.,Write code (Test or Product) to deliver against project timescales, quality and requirements in various languages including Java or other selected languages for Sophos Cloud products.,Provide guidance and mentorship to junior developers in daily Scrum meetings.,Possesses a passion for solving complex Big Data problems,Plan for, design and implement our next-generation cloud security products.,Be involved from inception through implementation in a real hands on fashion.,BS in Computer Science, Engineering, or equivalent with 7+ years of development and data modelling background,Building highly scalable SaaS solutions using Big Data technologies,Experience with CI/CD,Experience with Agile Software Development methodologies (scrum/ kanban),Excellent attention to detail,Excellent verbal and written communication skills,Experience with the following technologies (recommended) and strong desire to learn (required),Programming language -- Java (must)
Batch processing -- Hadoop ,MapReduce
Stream processing -- Kafka and Amazon Kinesis
NoSQL -S3 , MongoDB.
Columnar stores - HBASE, Amazon Redshift
Restful web services
Code/Build/Deployment -- git, hg, svn, maven, sbt, jenkins, bamboo, ...
Amazon Web Services
Data Warehousing/ built ETL,Programming language -- Java (must),Batch processing -- Hadoop ,MapReduce,Stream processing -- Kafka and Amazon Kinesis,NoSQL -S3 , MongoDB.,Columnar stores - HBASE, Amazon Redshift,Restful web services,Code/Build/Deployment -- git, hg, svn, maven, sbt, jenkins, bamboo, ...,Amazon Web Services,Data Warehousing/ built ETL,Medical insurance,Dental insurance,Vision insurance,Life insurance,Long-term disability insurance,401k plan,Vacation time","
At Sophos, we operate at the cutting edge of technology, protecting businesses worldwide against complex threats, viruses and spam. We build high quality software security products in a fast-paced, nimble environment and we've been doing it for over 20 years.
Join us to help our customers protect their business and meet compliance needs.
Role
To function as a senior data lead for product features or key technology choices and implementation. Collaborates as part of a team for the development of complex systems; including requirements analysis, concept development and design, implementation and testing, demonstrating flexibility of role as required
Main Duties
Drive design and implementation leveraging modern design patterns
Ability to partner effectively with UX, PM, DevOps, QE and other developers to design and implement meeting the spirit of requirements
Experience in modern front end frameworks
Technically curious to keep present on advances in technology
Experience with segregation of model, presentation, and business logic.
TDD experience and strong desire to build in test from the start.
Write code (Test or Product) to deliver against project timescales, quality and requirements in various languages including Java or other selected languages for Sophos Cloud products.
Provide guidance and mentorship to junior developers in daily Scrum meetings.
Possesses a passion for solving complex Big Data problems
Plan for, design and implement our next-generation cloud security products.
Be involved from inception through implementation in a real hands on fashion.
Experience And Skills
BS in Computer Science, Engineering, or equivalent with 7+ years of development and data modelling background
Building highly scalable SaaS solutions using Big Data technologies
Experience with CI/CD
Experience with Agile Software Development methodologies (scrum/ kanban)
Excellent attention to detail
Excellent verbal and written communication skills
Experience with the following technologies (recommended) and strong desire to learn (required)
Programming language -- Java (must)
Batch processing -- Hadoop ,MapReduce
Stream processing -- Kafka and Amazon Kinesis
NoSQL -S3 , MongoDB.
Columnar stores - HBASE, Amazon Redshift
Restful web services
Code/Build/Deployment -- git, hg, svn, maven, sbt, jenkins, bamboo, ...
Amazon Web Services
Data Warehousing/ built ETL
Benefits
In most cases, the compensation package includes:
Medical insurance
Dental insurance
Vision insurance
Life insurance
Long-term disability insurance
401k plan
Vacation time
Gym membership compensation
",https://www.sophos.com/fr-fr/about-us/careers/united-states/senior-data-engineer-cloud.aspx
JOB129072317501,Senior Data Engineer - BlackLocus Jobs in United States,Senior Data Engineer - BlackLocus Jobs in United States,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/usa/jobs/?vs=25&utm_medium=.JOBS%20Universe&utm_source=.JOBS%20RSS%20Feed-DE&utm_campaign=.JOBS%20RSS%20Feed
JOB130054121592,Staff Data Engineer,Staff Data Engineer,Significant competence with SQL,"Architect and develop a framework to automate ingestion and integration of structured data from a wide variety of enterprise data sources,Architect and develop data pipeline components and integrate them with the Formation Platform,Scale pipelines to meet performance requirements,Provide leadership to senior and junior Data Engineers,Architect and design data quality monitoring and automated data cleaning,Responsible for technical direction of the team,8+ years of software development experience,5+ years of experience with building scalable and reliable data pipelines using Big Data engine technologies like Spark, AWS EMR, Redshift, etc.,3+ years of experience with scalable data integration technologies like ETL or Data Virtualization,Experience with cloud technologies such as AWS or Google Cloud,SaaS experience,Significant industrial experience using Scala, or willingness to learn Scala and demonstrated competence with functional programming","
Job description
Formation is seeking an experienced Lead Data Software Engineer to help develop our flagship product. We are using reinforcement learning to solve interesting problems at scale. You will be leading the architecture, development, and maintenance of complex data pipelines that are integrated into the flagship Formation Platform.
Key Responsibilities:
Architect and develop a framework to automate ingestion and integration of structured data from a wide variety of enterprise data sources
Architect and develop data pipeline components and integrate them with the Formation Platform
Scale pipelines to meet performance requirements
Provide leadership to senior and junior Data Engineers
Architect and design data quality monitoring and automated data cleaning
Responsible for technical direction of the team
Skills and Experience:
8+ years of software development experience
5+ years of experience with building scalable and reliable data pipelines using Big Data engine technologies like Spark, AWS EMR, Redshift, etc.
3+ years of experience with scalable data integration technologies like ETL or Data Virtualization
Experience with cloud technologies such as AWS or Google Cloud
Bonus Points:
SaaS experience
Significant industrial experience using Scala, or willingness to learn Scala and demonstrated competence with functional programming
Significant competence with SQL
About Formation
Formation distills complex customer data into uniquely tailored experiences; we orchestrate physical and digital exchanges into one seamless journey. Our business is building lasting, trusted relationships between people and brands—and making it look easy.
We're already reaching millions of people a day, and we're just getting started. Our founding leadership is equal parts business, design, and engineering—because we believe differing perspectives + passionate discourse achieve the greatest outcomes. We are collectively talented, but also humble. We give our whole selves. We love learning new things.
Formation is committed to inclusion and diversity and is an equal opportunity employer. All applicants will receive consideration without regard to race, color, religion, gender, gender identity, sexual orientation, national origin, disability, or veteran status.
If you're up for the challenge of a lifetime, we're looking for outstanding talent to join our team.
",https://stackoverflow.com/jobs/204813/staff-data-engineer-formation
JOB130628675652,Data Engineer,Data Engineer,Understanding of data visualization tools,"Develop and implement custom data capturing solutions for advanced video analytics in a cloud environment.,Participate in developing requirements for and the implementation of necessary analytics development in order to properly and accurately report on relevant KPIs,Provide guidance for data integrity issues, ongoing maintenance, and data governance,Maintain detailed documentation of data collection methods and dependencies,Work closely with developers and product management team to validate and maintain analytics and reporting,Work with key stakeholders to integrate analytics requirements, and updates into production cycles,Technical validation of digital analytics implementations, conduct audits and troubleshoot tracking gaps to maintain data confidence and implement data standardization practices,Provide general troubleshooting assistance for analytics tracking and break fix,Performing functional, regression, integration, smoke and acceptance tests,Work with application development team to ensure proper deployment, integration, performance, and compliance with architectural standards and best practices,Successfully implement process improvements impacting own work and work of others.,3-5 years of experience building with modern JS libraries and frameworks: React / Redux, Typescript, ES6,Experience with real-time streaming Big Data analytics implementation,Excellent understanding of the implementation of click stream and video analytics,Very good understanding of the technical details regarding the implementing data collection & analytics solutions like Adobe Analytics, Google analytics, Snowplow, Alooma, Kafka. AWS Kinesis, etc.,Experience building, maintaining, testing and debugging modern technology stacks,Solving large-application/user-level problems, performance, scalability, etc.,Keen attention to detail and thoroughness required,BA or BS or higher degree in math, engineering, computer science, or related field required,Experienced working in a fast-paced, high-tech environment (preferably software development) and comfortable navigating conflicting priorities and ambiguous problems","
Job description
Summary:
As a Data Engineer (Web), you have a solid understanding of both the business and the technical aspects of BI in relation to digital media business for web platforms. You will drive the completion of projects within the established scope, while simultaneously planning for and managing unknown future BI requirements in a dynamic environment.
Responsibilities Include:
Develop and implement custom data capturing solutions for advanced video analytics in a cloud environment.
Participate in developing requirements for and the implementation of necessary analytics development in order to properly and accurately report on relevant KPIs
Provide guidance for data integrity issues, ongoing maintenance, and data governance
Maintain detailed documentation of data collection methods and dependencies
Work closely with developers and product management team to validate and maintain analytics and reporting
Work with key stakeholders to integrate analytics requirements, and updates into production cycles
Technical validation of digital analytics implementations, conduct audits and troubleshoot tracking gaps to maintain data confidence and implement data standardization practices
Provide general troubleshooting assistance for analytics tracking and break fix
Performing functional, regression, integration, smoke and acceptance tests
Work with application development team to ensure proper deployment, integration, performance, and compliance with architectural standards and best practices
Successfully implement process improvements impacting own work and work of others.
Qualities / Experience We're Seeking:
3-5 years of experience building with modern JS libraries and frameworks: React / Redux, Typescript, ES6
Experience with real-time streaming Big Data analytics implementation
Excellent understanding of the implementation of click stream and video analytics
Very good understanding of the technical details regarding the implementing data collection & analytics solutions like Adobe Analytics, Google analytics, Snowplow, Alooma, Kafka. AWS Kinesis, etc.
Experience building, maintaining, testing and debugging modern technology stacks
Solving large-application/user-level problems, performance, scalability, etc.
Keen attention to detail and thoroughness required
BA or BS or higher degree in math, engineering, computer science, or related field required
Experienced working in a fast-paced, high-tech environment (preferably software development) and comfortable navigating conflicting priorities and ambiguous problems
Understanding of data visualization tools
",https://stackoverflow.com/jobs/200560/data-engineer-pluto-tv
JOB132323771401,"Senior Data Engineer - BlackLocus Jobs in Austin, TX","Senior Data Engineer - BlackLocus Jobs in Austin, TX",,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/austin/texas/usa/jobs/?utm_source=.JOBS%20RSS%20Feed-DE&vs=25&utm_campaign=.JOBS%20RSS%20Feed&utm_medium=.JOBS%20Universe
JOB133229478973,Senior Data Engineer - BlackLocus Jobs in Texas,Senior Data Engineer - BlackLocus Jobs in Texas,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/texas/usa/jobs/?utm_medium=.JOBS%20Universe&vs=25&utm_source=.JOBS%20RSS%20Feed-DE&utm_campaign=.JOBS%20RSS%20Feed
JOB133429543958,Senior Data Engineer - BlackLocus,Senior Data Engineer - BlackLocus,,,"
Job Information
POSITION PURPOSE
The Sr Data Engineer will expand and optimize data, data flow, data collection for cross functional teams, and data pipeline architecture. The Sr Data Engineer will support and collaborate with the software engineering team, data analysts, and data scientist to ensure data delivery architecture is consistent throughout ongoing projects. Continuously improve or re-design data architecture to support the next generation of products and initiatives.
MAJOR TASKS, RESPONSIBILITES AND KEY ACCOUNTABILITIES
40% - Data Validation, ETL, Infrastructure Development: Coding validation and ETL to ensure successful data integration
30% - Data Infrastructure Maintenance: Backup and optimization activities to maintain performance; code, configure, test, etc data to ensure integrity
20% - Data Architecture Design and Analysis: Create and maintain optimal data pipeline architecture; Develop data architecture to meet business requirements
10% - Planning/Requirements Analysis: Collaborate with team leads and cross functional partners to assess business requirements and communicate opportunities
NATURE AND SCOPE
This position reports to the Technology Leader.
This position has 0 direct reports.
ENVIRONMENTAL JOB REQUIREMENTS
Environment:
Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.
Travel:
Typically requires overnight travel less than 10% of the time.
Additional Environmental Job Requirements:MINIMUM QUALIFICATIONS
Must be eighteen years of age or older.
Must be legally permitted to work in the United States.
Additional Minimum Qualifications:
Experience message queuing, stream processing, and scalable data stores
Experience managing projects and organizing data
Experience supporting and working with cross-functional teams
Experience with SQL, NoSQL databases, relational databases, and query authoring
Experience building and optimizing data pipelines, architectures, data sets and workflow management tools such as Azkaban, Luigi, Airflow, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C#, Scala, GoLang, etc.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
Education Required:
The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.
Years of Relevant Work Experience: 5 years
Physical Requirements:
Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.
Additional Qualifications:
Preferred Qualifications:
8+ years of previous related work experience
Ability to convey complex or technical ideas and processes in easy-to-understand terms to diverse audiences
Ability to negotiate, handle complaints, settle disputes, and resolve grievances with both internal and external customers
Excellent written and verbal communication skills
Knowledge, Skills, Abilities and Competencies:Collaborates - Building partnerships and working collaboratively with others to meet shared objectives
Communicates Effectively - Developing and delivering multi-mode communications that convey a clear understanding of the unique needs of different audiences
Cultivates Innovation - Creating new and better ways for the organization to be successful
Drives Engagement - Creating a climate where people are motivated to do their best to help the organization achieve its objectives
Instills Trust - Gaining the confidence and trust of others through honesty, integrity, and authenticity
Nimble Learning - Actively learning through experimentation when tackling new problems, using both successes and failures as learning fodder
Optimizes Work Processes - Knowing the most effective and efficient processes to get things done with a focus on continuous improvement
Plans and Aligns - Planning and prioritizing work to meet commitments aligned with organizational goals
Tech Savvy - Anticipating and adopting innovations in business-building digital and technology applications. We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
",https://militaryjobs.homedepot.com/austin-tx/senior-data-engineer-blacklocus/35068FD906174D91A159D54015CA5347/job/?utm_source=.JOBS%20RSS%20Feed-DE&utm_medium=.JOBS%20Universe&utm_campaign=.JOBS%20RSS%20Feed
JOB133928174607,"Data Engineer Jobs in Houston, TX","Data Engineer Jobs in Houston, TX",,"Houston, TX","
Data Engineer Jobs in Houston, TX
Current Search Criteria
More
",https://militaryjobs.homedepot.com/data-engineer/jobs-in/houston/texas/usa/jobs/?utm_campaign=.JOBS%20RSS%20Feed&utm_medium=.JOBS%20Universe&vs=25&utm_source=.JOBS%20RSS%20Feed-DE
JOB134618556517,Senior Data Engineer,Senior Data Engineer,"Minimum 5 years experience in data engineering,Extensive knowledge in different programming and scripting languages such as Java, C++, Python, PHP, Ruby, Perl, Scala, Bash, etc.,Proficient in SQL,Solid understanding of both relational and NoSQL database technologies,Experience designing, building, and maintaining end-to-end data pipelines and ETL infrastructure, using tools such as Hadoop, Spark, Kafka, Samza, Amazon Kinesis, etc.,Experience with AWS,Strong familiarity working in a Linux environment,Excellent critical thinking, problem-solving, and analytical skills,Must be authorized to work in the United States,Gaming industry experience,Experience with Redshift,Machine learning experience","Create robust data workflows that move and transform data at scale to inform key metrics, recommend changes, and predict future results,Own the architecture of Dots' data infrastructure, including exploring/implementing new big-data solutions and optimizing existing ones,Manage data applications on AWS,Design and implement complex big-data solutions with a focus on collecting, parsing, and surfacing meaningful data using multiple platforms,Evaluate new technologies and products","
Job description
Dots is a data-driven studio, looking for other passionate, curious, and resourceful people to improve experiences for our players. The ideal candidate is someone who can apply their skills to manage and explore data from our millions of users. Alongside the Engineering and Data Science teams, the Senior Data Engineer will help architect a data pipeline that will allow other Dots employees to pull the insights they need.
This person will play a key role in the success of our current and future games, and should be excited about owning that responsibility!
Responsibilities:
Create robust data workflows that move and transform data at scale to inform key metrics, recommend changes, and predict future results
Own the architecture of Dots' data infrastructure, including exploring/implementing new big-data solutions and optimizing existing ones
Manage data applications on AWS
Design and implement complex big-data solutions with a focus on collecting, parsing, and surfacing meaningful data using multiple platforms
Evaluate new technologies and products
Requirements:
Minimum 5 years experience in data engineering
Extensive knowledge in different programming and scripting languages such as Java, C++, Python, PHP, Ruby, Perl, Scala, Bash, etc.
Proficient in SQL
Solid understanding of both relational and NoSQL database technologies
Experience designing, building, and maintaining end-to-end data pipelines and ETL infrastructure, using tools such as Hadoop, Spark, Kafka, Samza, Amazon Kinesis, etc.
Experience with AWS
Strong familiarity working in a Linux environment
Excellent critical thinking, problem-solving, and analytical skills
Must be authorized to work in the United States
Nice to haves:
Gaming industry experience
Experience with Redshift
Machine learning experience
",https://stackoverflow.com/jobs/199400/senior-data-engineer-dots
JOB135221446398,Business Intelligence Data Engineer,Business Intelligence Data Engineer,,"Business Intelligence development,Design and maintain a set of automated tools and reports,Scraping software to extract key data,2+ years' experience programming with a statistical computer language (ideally R),Strong understanding of databases and data storage,Knowledge of the SDLC,Experience developing software applications (ideally in Python),Excellent communication and problem solving skills,Collaborative team player and self-starter","Bittrex, the premier U.S. blockchain trading platform, seeks a Business Intelligence Data Engineer. Founded by three cybersecurity engineers in 2014, the mission of Bittrex is to catalyze advancement of the blockchain industry by fostering innovation and incubating new and emerging technology.
The BI Data Engineer will play a critical role, providing decision-differentiating data to leadership, enabling them to respond quickly and accurately for optimal business impact, based on algorithmically derived data and predictive analytics.
This is a unique, high visibility opportunity for someone who wants to have business impact, dive deep into large-scale economic problems, and enable measurable actions on global cryptocurrency adoption. We are particularly interested in candidates with experience building predictive models, and developing tools to optimize data queries.
What you'll be doing:
Business Intelligence development
Design and maintain a set of automated tools and reports
Scraping software to extract key data
Review and analyze large quantities of data
Your skills & experience:
2+ years' experience programming with a statistical computer language (ideally R)
Strong understanding of databases and data storage
Knowledge of the SDLC
Experience developing software applications (ideally in Python)
Excellent communication and problem solving skills
Collaborative team player and self-starter
And if you have experience with Big Data technologies or machine learning, then that's a plus!
Bittrex is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances.
",https://www.indeed.com/rc/clk?jk=b636d7e072b4691d&fccid=315baf4b0afa894b&vjs=3
JOB135850190961,"Senior / Lead / Principal Data Engineer, Machine Learning / Deep Learning","Senior / Lead / Principal Data Engineer, Machine Learning / Deep Learning","Strong understanding of security, including threat propagation and malware analysis","Developing data infrastructure that ingest and transforms data from different sources and customers at scale.,Creating machine/deep learning infrastructure that generalizes across hundreds of thousands of Salesforce customers, but is expressive enough to generate high lift.,Partner end-to-end with Product Managers and Data Scientists to understand customer requirements and design prototypes and bring ideas to production,Working with internal product teams to ingest their data and sprinkle machine/deep learning fairy dust on their products.,Participating in meal conversations with your team members about really important topics, such as: Should the cuteness of panda bears be a factor in their survivability? Is love a decision tree or a regression model? How far ahead would society be today if we had 12 fingers instead of 10?,We develop real products. You need to be an expert in coding, including Java and Object-Oriented Programming. We also use Scala and Functional Programming principles. ​,We prioritize professional industry experience; advanced degrees alone do not replace real world experience.,We have massive scale. You need to have experience in distributed, scalable systems. Consistency / availability tradeoffs are made here. You’ve tinkered with modern data storage, messaging, and processing tools (Kafka, Spark, Hadoop, Cassandra, etc.) and demonstrated experience designing and coding in big-data components such as HBase, DynamoDB, or similar.,We’re a growing, diverse team and we work together on projects. We love to collaborate and help each other, and we want someone to share that ideology.,You have to be a very quick learner - we face new challenges every day, anything that ranges between the operating model of a financial services companies, conversation model for chatbots, tinkering with convolutional and recurrent networks, to how to make Spark work with the S3 file system. No school could prepare you for all of these, so you need to be very quick on your feet.,​Self-starter who can see the big picture, and prioritize their work to make the largest impact on the business’ and customer’s vision and requirements,Excellent communication, leadership, and collaboration skills,We run on AWS. We dockerize applications. You should have some notion of how to build, test, and deploy code to run on cloud infrastructure.,Experience with open source tools for information retrieval (e.g. Solr),Search, Data Scoring/ Ranking expertise,Data visualization,Experience with Deep Learning for NLP,Experience developing in open-source machine-learning libraries such as Apache Mahout or MLLib","
Job description
Salesforce is looking for both Senior, Lead and Principal Data / Deep Learning / Machine Learning Engineers with Java, Python, Scala and/or Spark experience, to help us take on one of the world’s most extensive data sets and transform it into amazing products that feel like magic. You will work on cutting-edge AI applications and products. Brainstorming data product ideas with data scientists and engineers to build data products used by hundreds of millions people every day.
A typical day for you might include the following:
Developing data infrastructure that ingest and transforms data from different sources and customers at scale.
Creating machine/deep learning infrastructure that generalizes across hundreds of thousands of Salesforce customers, but is expressive enough to generate high lift.
Partner end-to-end with Product Managers and Data Scientists to understand customer requirements and design prototypes and bring ideas to production
Working with internal product teams to ingest their data and sprinkle machine/deep learning fairy dust on their products.
Participating in meal conversations with your team members about really important topics, such as: Should the cuteness of panda bears be a factor in their survivability? Is love a decision tree or a regression model? How far ahead would society be today if we had 12 fingers instead of 10?
What we care about:
We develop real products. You need to be an expert in coding, including Java and Object-Oriented Programming. We also use Scala and Functional Programming principles. ​
We prioritize professional industry experience; advanced degrees alone do not replace real world experience.
We have massive scale. You need to have experience in distributed, scalable systems. Consistency / availability tradeoffs are made here. You’ve tinkered with modern data storage, messaging, and processing tools (Kafka, Spark, Hadoop, Cassandra, etc.) and demonstrated experience designing and coding in big-data components such as HBase, DynamoDB, or similar.
We’re a growing, diverse team and we work together on projects. We love to collaborate and help each other, and we want someone to share that ideology.
You have to be a very quick learner - we face new challenges every day, anything that ranges between the operating model of a financial services companies, conversation model for chatbots, tinkering with convolutional and recurrent networks, to how to make Spark work with the S3 file system. No school could prepare you for all of these, so you need to be very quick on your feet.
​Self-starter who can see the big picture, and prioritize their work to make the largest impact on the business’ and customer’s vision and requirements
Excellent communication, leadership, and collaboration skills
Preferred Skills: (different teams will care about some of the following over others)
We run on AWS. We dockerize applications. You should have some notion of how to build, test, and deploy code to run on cloud infrastructure.
Experience with open source tools for information retrieval (e.g. Solr)
Search, Data Scoring/ Ranking expertise
Data visualization
Experience with Deep Learning for NLP
Experience developing in open-source machine-learning libraries such as Apache Mahout or MLLib
Strong understanding of security, including threat propagation and malware analysis
Salesforce, the Customer Success Platform and world's #1 CRM, empowers companies to connect with their customers in a whole new way. The company was founded on three disruptive ideas: a new technology model in cloud computing, a pay-as-you-go business model, and a new integrated corporate philanthropy model. These founding principles have taken our company to great heights, including being named one of Forbes’s “World’s Most Innovative Company” ten years in a row and one of Fortune’s “100 Best Companies to Work For” nine years in a row. We are the fastest growing of the top 10 enterprise software companies, and this level of growth equals incredible opportunities to grow a career at Salesforce. Together, with our whole Ohana (Hawaiian for ""family"") made up of our employees, customers, partners and communities, we are working to improve the state of the world.
*LI-Y
Accessibility - If you require accessibility assistance applying for open positions please contact the Salesforce.com Recruiting Department.
Posting Statement
Salesforce.com and Salesforce.org are Equal Employment Opportunity and Affirmative Action Employers. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Headhunters and recruitment agencies may not submit resumes/CVs through this Web site or directly to managers. Salesforce.com and Salesforce.org do not accept unsolicited headhunter and agency resumes. Salesforce.com and Salesforce.org will not pay fees to any third-party agency or company that does not have a signed agreement with Salesforce.com or Salesforce.org.
Pursuant to the San Francisco Fair Chance Ordinance and the Los Angeles Fair Chance Initiative for Hiring, Salesforce will consider for employment qualified applicants with arrest and conviction records.
",http://stackoverflow.com/jobs/364237/senior-lead-principal-data-engineer-machine-salesforce
JOB137818129419,"Data Engineer Jobs in Houston, TX","Data Engineer Jobs in Houston, TX",,"Houston, TX","
Data Engineer Jobs in Houston, TX
Current Search Criteria
More
",https://militaryjobs.homedepot.com/data-engineer/jobs-in/houston/texas/usa/jobs/?utm_campaign=.JOBS%20RSS%20Feed&vs=25&utm_medium=.JOBS%20Universe&utm_source=.JOBS%20RSS%20Feed-DE
JOB140765381679,"Data Engineer Jobs in Houston, TX","Data Engineer Jobs in Houston, TX",,"Houston, TX","
Data Engineer Jobs in Houston, TX
Current Search Criteria
More
",https://militaryjobs.homedepot.com/data-engineer/jobs-in/houston/texas/usa/jobs/?utm_medium=.JOBS%20Universe&vs=25&utm_source=.JOBS%20RSS%20Feed-DE&utm_campaign=.JOBS%20RSS%20Feed
JOB141693073681,Data Engineer Job Description,Data Engineer Job Description,"Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.,Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.,Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.,Strong analytic skills related to working with unstructured datasets.,Build processes supporting data transformation, data structures, metadata, dependency and workload management.,A successful history of manipulating, processing and extracting value from large disconnected datasets.,Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.,Strong project management and organizational skills.,Experience supporting and working with cross-functional teams in a dynamic environment.,Experience with big data tools: Hadoop, Spark, Kafka, etc.,Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.,Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.,Experience with AWS cloud services: EC2, EMR, RDS, Redshift,Experience with stream-processing systems: Storm, Spark-Streaming, etc.","Create and maintain optimal data pipeline architecture,,Assemble large, complex data sets that meet functional / non-functional business requirements.,Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.,Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.,Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.,Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.,Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.,Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.","Job Overview
We are looking for a savvy Data Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.
Responsibilities for Data Engineer
Create and maintain optimal data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
Qualifications for Data Engineer
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software/tools:
Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.
Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
Experience with AWS cloud services: EC2, EMR, RDS, Redshift
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
",https://www.glassdoor.com/Job-Descriptions/Data-Engineer.htm
JOB142275511346,"Senior Data Engineer - BlackLocus Jobs in Austin, TX","Senior Data Engineer - BlackLocus Jobs in Austin, TX",,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/austin/texas/usa/jobs/?utm_campaign=.JOBS%20RSS%20Feed&vs=25&utm_medium=.JOBS%20Universe&utm_source=.JOBS%20RSS%20Feed-DE
JOB143924193375,Senior Backend Data Engineer (.Net Core),Senior Backend Data Engineer (.Net Core),,"5+ years experience with complex data structures.,Real-world experience developing in .Net Core,You have deep experience in the latest libraries and programming techniques.,You have accomplishments that showcase your capabilities by their success and technical depth.,You own new features from idea to completion.,Work well with a core team to design and execute major new features.,Familiar with SQL/NoSQL databases like MongoDB and their declarative query languages is a plus,Enjoy contributing to a fast moving exciting project,Strong experience using GitHub in a professional environment,Strong communicator and fluent in English with excellent written and verbal communication skills.,Thrive and excel in our diverse, distributed and agile team environment","
Job description
DESCRIPTION
As a Senior Back End Data Engineer at Clevertech, you’ll be part of a global team striving to provide world-class, bespoke software solutions. We look to employ craftsmen developers who take pride and ownership of their code!
You can deliver quickly while being clever to avoid missteps. You have an effective positive attitude that shines through in your communication and care for client and colleague concerns. You are always learning and are a transparent communicator even when it is challenging. You thrive on challenging yourself daily and seek to surround yourself with like-minded individuals.
This role involves database design and implementation responsibilities including alternative data structures such as nosql, redis, elasticsearch and more.
REQUIREMENTS:
5+ years experience with complex data structures.
Real-world experience developing in .Net Core
You have deep experience in the latest libraries and programming techniques.
You have accomplishments that showcase your capabilities by their success and technical depth.
You own new features from idea to completion.
Work well with a core team to design and execute major new features.
Familiar with SQL/NoSQL databases like MongoDB and their declarative query languages is a plus
Enjoy contributing to a fast moving exciting project
Strong experience using GitHub in a professional environment
Strong communicator and fluent in English with excellent written and verbal communication skills.
Thrive and excel in our diverse, distributed and agile team environment
Life at Clevertech
About Clevertech
BENEFITS
Own Your Time
We are a completely remote team. That means we have a large amount of trust and a lot of flexibility. World travellers, young parents, nature lovers, and commute avoiders love working here. Manage your own desk successfully with Clevertech’s support resources - learn how to manage your time, organize your digital life, etc. We also will pay for a co-working space in case you feel like working outside of your normal setting.
Recharge Time
We insist that you take recharge time. This means, you’re required to take at least two weeks per year to refresh, plus you’ll have the day off for major holidays and that includes your birthday because your existence is worth celebrating!
Care For Yourself
You’ll receive a health/wellness monthly stipend that goes towards covering medical insurance, dental insurance, or joining a gym!
Stability
Kick that consulting/agency work stigma out the door! We’re looking for future Clevertech Brand Champions - a majority of our developers have been here for 4-7 years and we’re not looking to change this. When one project is finished, the next is close on the horizon, take the time in between to brush up on technologies with our corporate access logins, work on over 30 exciting open source projects, or take some time to relax and reward yourself for a job well done. Just because a project is done, does not mean you’re employment is done!
Focused Work
You will work together on a dedicated team with your eye on one finish line at a time. Our teams are nimble and agile, and cover the technical range you would expect from world class product delivery teams.
Learn at Your Edges
We believe in learning and provide unique programs that improve your tech skills, leadership skills and even challenge you in personal development. CleverWednesdays, guest speakers, leadership training, mentorship opportunities and in-depth industry exposure are all on offer here. And of course, if you speak at a tech conference, we cover all expenses.
Clevertech Swag
Keep your eye on the mail - we send out swag everywhere in the world and there are celebratory pictures of Clevertech socks, hoodies, and mugs all over Slack. Earn swag through providing support to your team, being one step ahead, working at a delightful speed, OWNING IT, and much more!
Want to learn more about Clevertech and the team? Check out clevertech.careers.
Benefits
",https://stackoverflow.com/jobs/206645/senior-backend-data-engineer-net-core-clevertech
JOB144148399131,"Data Engineer Jobs in Houston, TX","Data Engineer Jobs in Houston, TX",,"Houston, TX","
Data Engineer Jobs in Houston, TX
Current Search Criteria
More
",https://militaryjobs.homedepot.com/data-engineer/jobs-in/houston/texas/usa/jobs/?utm_medium=.JOBS%20Universe&utm_campaign=.JOBS%20RSS%20Feed&utm_source=.JOBS%20RSS%20Feed-DE&vs=25
JOB145386989675,Senior Data Engineer,Senior Data Engineer,"Knowledge of commonly used third-party analytics tools like Periscope, Tableau, Segment, Heap","Own Babylist’s data science and analytics infrastructure from DevOps to development,Architect and implement data pipelines and systems for analytics, data science, and ML use cases,Bring engineering rigor and best practices to the art of data management,Mentor analysts and data scientists on the team,Bachelor's or advanced degree in Computer Science or Engineering,Hands-on experience writing and deploying production grade code,Solid experience with an object-oriented scripting language like Python and advanced SQL,Worked with data orchestration tools like Airflow, Luigi, dbt,Strong understanding of data modeling/ETL principles and modern data warehousing systems like Redshift, Snowflake,DevOps in disguise: well-versed with the AWS ecosystem including managing and deploying cloud data resources (EMR, EC2, RDS, S3, Athena, Lambda, Spark),Experience integrating data from multiple sources including third-party APIs preferred","
Job description
The Data Team at Babylist powers data-driven decision making through all aspects of the company’s business. We are not a service team. We are a product function with a strong focus on 3 core aspects of data -- engineering, analysis, and data science. We are looking for a Sr. Data Engineer to own and build the next generation of our data platform. This work and the role is foundational for our team and strategic for our business. You are an experienced professional whose interests lie on the cusp of data engineering, data architecture and DevOps. You must be self-directed; comfortable balancing competing priorities, and making engineering trade-offs. You will work cross-functionally with our product managers, analysts, data scientists, and business functions to define requirements and set out a technical roadmap for the team. As our Sr. Data Engineer, you will be joining a small but growing data team at Babylist and will directly shape the data vision for the company through your work.
What You'll Do
Own Babylist’s data science and analytics infrastructure from DevOps to development
Architect and implement data pipelines and systems for analytics, data science, and ML use cases
Bring engineering rigor and best practices to the art of data management
Mentor analysts and data scientists on the team
What You've Done
Bachelor's or advanced degree in Computer Science or Engineering
Hands-on experience writing and deploying production grade code
Solid experience with an object-oriented scripting language like Python and advanced SQL
Worked with data orchestration tools like Airflow, Luigi, dbt
Strong understanding of data modeling/ETL principles and modern data warehousing systems like Redshift, Snowflake
DevOps in disguise: well-versed with the AWS ecosystem including managing and deploying cloud data resources (EMR, EC2, RDS, S3, Athena, Lambda, Spark)
Experience integrating data from multiple sources including third-party APIs preferred
Knowledge of commonly used third-party analytics tools like Periscope, Tableau, Segment, Heap
About Babylist At Babylist, we help expecting parents get exactly what they need for the arrival of their new baby. We have a large and rapidly growing user base of passionate parents-to-be who are making important purchasing decisions for one of the biggest events in their lives, which is both exciting and overwhelming. Our core product is our universal baby registry. Currently one in two first-time expecting families in the United States actually create a baby registry at Babylist.com. In 2019, over $400 million worth of gifts were purchased off of Babylist registries.
Why You Will Love Working at Babylist:
• We get stuff done
• We have a real impact on people’s lives
• We're passionate about our users and we genuinely appreciate them
• We work at a sustainable pace for long-term success (yes, we’re profitable)
• We are growing and have meaningful opportunities for career advancement
• We’re a technological and data-driven business
• We believe in autonomy and reward taking initiative
• We have experienced leadership that is always open to new ideas
Benefits:
• Competitive pay
• Competitive health benefits including company-funded medical, dental, and vision
• 401(k), FSA plans, and disability insurance
• Easy access to BART and commuter assistance
• Flexible, paid parental leave policy
• We work at a sustainable pace; in general we don't work late or on weekends, and most employees WFH on Wednesdays
If your experience is close to what we’re looking for, please consider applying. Experience comes in many forms – skills are transferable, and passion goes a long way. We know that diversity makes for the best problem-solving and creative thinking, which is why we’re dedicated to adding new perspectives to the team and encourage everyone to apply.
",http://stackoverflow.com/jobs/366705/senior-data-engineer-babylist
JOB146630837302,"Data Engineer Jobs in Houston, TX","Data Engineer Jobs in Houston, TX",,"Houston, TX","
Data Engineer Jobs in Houston, TX
Current Search Criteria
More
",https://militaryjobs.homedepot.com/data-engineer/jobs-in/houston/texas/usa/jobs/?utm_campaign=.JOBS%20RSS%20Feed&utm_source=.JOBS%20RSS%20Feed-DE&utm_medium=.JOBS%20Universe&vs=25
JOB146748412935,Data engineer,Data engineer,"You will design and develop applications for data processing on one of languages: Python, Java, Scala.,Create chains for data ingestion from relational DBs to noSQL storage.,Utilize Unix/Linux OS and write data preprocessing scripts.,Develop a data processing systems with Hadoop, Spark, Storm, Impala, etc.","Welcoming and friendly environment,Unlimited opportunity to develop your skills and expertise,Be a part of multinational and international teams,Work we do here is challenging, interesting, and meaningful,Customers from all over the world,Solid benefits package – health insurance, clear guidelines on the career growth, paid overtime, strong compensation package,Continuous investments in employee’s future – career counselling, wide range of trainings, and industry recognized certificates,You will be part of a team working on projects related to Big Data technologies. You will work with world leaders in various industires, like TV&Entertainment, Telecommunication, Finances, Insurance, etc.,As a data engineer you will work with Big Data systems like Hadoop, Spark, Storm, etc., and design data processing applications.,You will get a unique possibility to learn programming languages, e.g. Scala, Python, Java and utilize newest technologies, like noSQL doing data engineering at Accenture.,In a final together we will do visualization of the data and will build visual analytics systems to explain our customers the data in a fancy manner.,Data-related job is profession of future. Accenture brings future to today – we are searching for our new colleagues in Big Data field.","
Job Description
Why Accenture:
Welcoming and friendly environment
Unlimited opportunity to develop your skills and expertise
Be a part of multinational and international teams
Work we do here is challenging, interesting, and meaningful
Customers from all over the world
Solid benefits package – health insurance, clear guidelines on the career growth, paid overtime, strong compensation package
Continuous investments in employee’s future – career counselling, wide range of trainings, and industry recognized certificates
You will be part of a team working on projects related to Big Data technologies. You will work with world leaders in various industires, like TV&Entertainment, Telecommunication, Finances, Insurance, etc.
As a data engineer you will work with Big Data systems like Hadoop, Spark, Storm, etc., and design data processing applications.
You will get a unique possibility to learn programming languages, e.g. Scala, Python, Java and utilize newest technologies, like noSQL doing data engineering at Accenture.
In a final together we will do visualization of the data and will build visual analytics systems to explain our customers the data in a fancy manner.
Data-related job is profession of future. Accenture brings future to today – we are searching for our new colleagues in Big Data field.
Qualifications
What will you do:
You will design and develop applications for data processing on one of languages: Python, Java, Scala.
Create chains for data ingestion from relational DBs to noSQL storage.
Utilize Unix/Linux OS and write data preprocessing scripts.
Develop a data processing systems with Hadoop, Spark, Storm, Impala, etc.
Develop and integrate data visualization solutions.
",https://www.accenture.com/lv-en/careers/jobdetails?id=00747663_en&title=Data+engineer
JOB147026871338,"Data Engineer Jobs in Houston, TX","Data Engineer Jobs in Houston, TX",,"Houston, TX","
Data Engineer Jobs in Houston, TX
Current Search Criteria
More
",https://militaryjobs.homedepot.com/data-engineer/jobs-in/houston/texas/usa/jobs/?vs=25&utm_source=.JOBS%20RSS%20Feed-DE&utm_medium=.JOBS%20Universe&utm_campaign=.JOBS%20RSS%20Feed
JOB147103306776,Data Engineer Consultant,Data Engineer Consultant,"Bachelor's degree in Computer Science, Engineering, Technical Science or 12 years of experience in programming and building large scale data/analytics solutions operating in production environments.,Minimum 2+ years of expertise in designing, implementing large scale data pipelines for data curation, feature engineering and machine learning, using Spark in combination with pySpark, Java, Scala or Python; either on premise or on Cloud (AWS, Google or Azure).,Minimum 1 year of designing and building performant data tiers (or refactoring existing ones), that supports scaled AI and Analytics, using different Cloud native data stores on AWS, Azure and Google (Redshift, S3, Big Query, SQLDW etc.) as well as using NoSQL and Graph Stores.,Minimum 1 year of designing and building streaming data ingestion, analysis and processing pipelines using Kafka, Kafka Streams, Spark Streaming and similar cloud native technologies.,Minimum 1 year of designing and building secured and governed Big Data ETL pipelines, using Talend or Informatica technologies; for data curation and analysis of large production deployed solutions.,Experience implementing smart data preparation tools such as Palate, Trifacta, Tamr for enhancing analytics solutions.,Minimum 1 year of building Business Data Catalogs or Data Marketplaces for powering business analytics using technologies such as Alation, Collibra, Informatica or custom solutions.","Consult as part of a team that is in charge of building end-to-end digital transformation capabilities and lead fast moving development teams using Agile methodologies.,Design and build real-time analytics solutions using industry standard technologies and work with data architects to make sure Cloud Data solutions align with technology direction.,Lead by example, role-modeling best practices for unit testing, CI/CD, performance testing, capacity planning, documentation, monitoring, alerting and incident response.,Keep everyone from individual contributors to top executives in the loop about progress, communicating across organizations and levels. If critical issues block progress, refer them up the chain of command to be resolved in a timely manner.,Develop Cloud Native architecture, data supply chain, Architect, Prototype and Test end to end data supply chain, use cases that drive business value, and provide architecture support to the data scientists.,Pinpoint and clarify key issues that need action, lead the response and articulate results clearly in actionable form.,Show a strong aptitude for carrying out solutions and translating objectives into a scalable solution that meets end customers’ needs within deadlines.","
Job Description
We are:
Applied Intelligence, the people who love using data to tell a story. We’re also the world’s largest team of data scientists, data engineers, and experts in machine learning and AI. A great day for us? Solving big problems using the latest tech, serious brain power, and deep knowledge of just about every industry. We believe a mix of data, analytics, automation, and responsible AI can do almost anything—spark digital metamorphoses, widen the range of what humans can do, and breathe life into smart products and services. Want to join our crew of sharp analytical minds? Visit us here to find out more about Applied Intelligence.
You Are:
A Spark or Cloud Data engineering pro—someone who thrives in a team setting where you can use your creative and analytical prowess to obliterate problems. You’re passionate about digital technology, and you take pride in making a tangible difference. You have communication and people skills in spades, along with strong leadership chops. Complex issues don’t faze you thanks to your razor-sharp critical thinking skills. Working in an information systems environment makes you more than happy.
The Work:
Consult as part of a team that is in charge of building end-to-end digital transformation capabilities and lead fast moving development teams using Agile methodologies.
Design and build real-time analytics solutions using industry standard technologies and work with data architects to make sure Cloud Data solutions align with technology direction.
Lead by example, role-modeling best practices for unit testing, CI/CD, performance testing, capacity planning, documentation, monitoring, alerting and incident response.
Keep everyone from individual contributors to top executives in the loop about progress, communicating across organizations and levels. If critical issues block progress, refer them up the chain of command to be resolved in a timely manner.
Develop Cloud Native architecture, data supply chain, Architect, Prototype and Test end to end data supply chain, use cases that drive business value, and provide architecture support to the data scientists.
Pinpoint and clarify key issues that need action, lead the response and articulate results clearly in actionable form.
Show a strong aptitude for carrying out solutions and translating objectives into a scalable solution that meets end customers’ needs within deadlines.
Collaborate with Data Scientist, Security or Research teams working on a variety of AI/ML solutions.
Qualifications
Here's what you need:
Bachelor's degree in Computer Science, Engineering, Technical Science or 12 years of experience in programming and building large scale data/analytics solutions operating in production environments.
Minimum 2+ years of expertise in designing, implementing large scale data pipelines for data curation, feature engineering and machine learning, using Spark in combination with pySpark, Java, Scala or Python; either on premise or on Cloud (AWS, Google or Azure).
Minimum 1 year of designing and building performant data tiers (or refactoring existing ones), that supports scaled AI and Analytics, using different Cloud native data stores on AWS, Azure and Google (Redshift, S3, Big Query, SQLDW etc.) as well as using NoSQL and Graph Stores.
Minimum 1 year of designing and building streaming data ingestion, analysis and processing pipelines using Kafka, Kafka Streams, Spark Streaming and similar cloud native technologies.
Bonus points if:
Minimum 1 year of designing and building secured and governed Big Data ETL pipelines, using Talend or Informatica technologies; for data curation and analysis of large production deployed solutions.
Experience implementing smart data preparation tools such as Palate, Trifacta, Tamr for enhancing analytics solutions.
Minimum 1 year of building Business Data Catalogs or Data Marketplaces for powering business analytics using technologies such as Alation, Collibra, Informatica or custom solutions.
Important information
Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture.
Equal Employment Opportunity Statement
Accenture is an Equal Opportunity Employer. We believe that no one should be discriminated against because of their differences, such as age, disability, ethnicity, gender, gender identity and expression, religion or sexual orientation. Our rich diversity makes us more innovative, more competitive and more creative, which helps us better serve our clients and our communities.
All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.
Accenture is committed to providing veteran employment opportunities to our service men and women.
For details, view a copy of the Accenture Equal Opportunity and Affirmative Action Policy Statement
Requesting An Accommodation
Accenture is committed to providing equal employment opportunities for persons with disabilities or religious observances, including reasonable accommodation when needed. If you are hired by Accenture and require accommodation to perform the essential functions of your role, you will be asked to participate in our reasonable accommodation process. Accommodations made to facilitate the recruiting process are not a guarantee of future or continued accommodations once hired.
If you would like to be considered for employment opportunities with Accenture and have accommodation needs for a disability or religious observance, please call us toll free at 1 (877) 889-9009, send us an email or speak with your recruiter.
Other Employment Statements
Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.
Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.
The Company will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. Additionally, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the Company's legal duty to furnish information.
",https://www.accenture.com/us-en/careers/jobdetails?id=00900811_en&title=Data+Engineer+Consultant
JOB148058604551,Senior Data Engineer - BlackLocus Jobs in United States,Senior Data Engineer - BlackLocus Jobs in United States,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/usa/jobs/?utm_campaign=.JOBS%20RSS%20Feed&utm_source=.JOBS%20RSS%20Feed-DE&vs=25&utm_medium=.JOBS%20Universe
JOB148316086147,TA-9723 REG: Support for Human and Social Development in Southeast Asia - INO RECOVER - Data engineer analyst (52335-001),TA-9723 REG: Support for Human and Social Development in Southeast Asia - INO RECOVER - Data engineer analyst (52335-001),,,"Additional Information
Possibility of contract extension
In general, ADB consulting contracts may be extended to a reasonable degree when doing so is justified within ADB's core 
procurement principles. Any extensions are subject to operational needs, consultant performance, and continued availability of 
funds.
",https://www.adb.org/node/720871
JOB150013995084,"Senior Data Engineer (AWS, SQL, Python, Hadoop)","Senior Data Engineer (AWS, SQL, Python, Hadoop)",Sense of humor is a must-ash. (Mustache… Get it? Mustache.),"You thrive in any data environment:
Cloud – we use AWS
Someone who understands complex data and the challenges of accessing it
A real bottom-line person, not someone who throws terms like “big data” around because it’s popular
Hadoop or traditional/relational databases make no difference to you,Cloud – we use AWS,Someone who understands complex data and the challenges of accessing it
A real bottom-line person, not someone who throws terms like “big data” around because it’s popular,A real bottom-line person, not someone who throws terms like “big data” around because it’s popular,Hadoop or traditional/relational databases make no difference to you,You dream in code:
SQL (seriously, SQL – not just SQL queries; impress us). Teach us something new, show us what you’ve got
Python
Scala
Spark,SQL (seriously, SQL – not just SQL queries; impress us). Teach us something new, show us what you’ve got,Python,Scala,Spark,You know databases inside and out:
Database concepts – indexes, execution engines, etc
Database Administration experience (Redshift, MySQL/PostgreSQL, Oracle)
You understand that databases are an integral part of being a Data Engineer,Database concepts – indexes, execution engines, etc,Database Administration experience (Redshift, MySQL/PostgreSQL, Oracle),You understand that databases are an integral part of being a Data Engineer,You enjoy looking at and solving big picture problems:
No micromanaging or hand-holding - you like to ask questions and devise a complete solution
You want to understand the data (not only the pipes) and you can definitely perform some analytics and build dashboards because you like it. Yes really, because you do.,No micromanaging or hand-holding - you like to ask questions and devise a complete solution,You want to understand the data (not only the pipes) and you can definitely perform some analytics and build dashboards because you like it. Yes really, because you do.,You love learning new things:
You know that you don’t know enough, and it bothers you that there isn’t enough time in the day to learn about the next topic.
You’re up-to-date on new trends in data – you know who’s using what to solve various problems and are excited for the next release of your favorite tool
If you like being thrown in the deep end of the pool, this team’s for you.,You know that you don’t know enough, and it bothers you that there isn’t enough time in the day to learn about the next topic.,You’re up-to-date on new trends in data – you know who’s using what to solve various problems and are excited for the next release of your favorite tool,If you like being thrown in the deep end of the pool, this team’s for you.,You take it personally:
You don’t sleep well at night when you leave work with a question unanswered
You feel accountable for everything you do and that sense of urgency has been driving you your entire life,You don’t sleep well at night when you leave work with a question unanswered,You feel accountable for everything you do and that sense of urgency has been driving you your entire life,You work hard but play harder:
You like to have a good time while getting things done
When we say a “team player” we mean it - you have a crisp high-five and funny stories to tell
You have your team’s back. And the team has yours.
Sense of humor is a must-ash. (Mustache… Get it? Mustache.),You like to have a good time while getting things done,When we say a “team player” we mean it - you have a crisp high-five and funny stories to tell,You have your team’s back. And the team has yours.","
Job description
We’re looking for data fanatics to join a S.W.A.T. Team of engineers that are responsible for building both LearnVest’s and Northwestern Mutual’s data infrastructure. We need people who understand data at a granular level – they don’t rely on any one tool but rather understand them all, and each of their pros and cons. This is a unique opportunity to build the data strategy and architecture of a Fortune 100 company while sitting 10 feet away from a beer fridge with your dog.
The more boxes you check, the higher the chances of us buying you lunch:
You thrive in any data environment:
Cloud – we use AWS
Someone who understands complex data and the challenges of accessing it
A real bottom-line person, not someone who throws terms like “big data” around because it’s popular
Hadoop or traditional/relational databases make no difference to you
You dream in code:
SQL (seriously, SQL – not just SQL queries; impress us). Teach us something new, show us what you’ve got
Python
Scala
Spark
You know databases inside and out:
Database concepts – indexes, execution engines, etc
Database Administration experience (Redshift, MySQL/PostgreSQL, Oracle)
You understand that databases are an integral part of being a Data Engineer
You enjoy looking at and solving big picture problems:
No micromanaging or hand-holding - you like to ask questions and devise a complete solution
You want to understand the data (not only the pipes) and you can definitely perform some analytics and build dashboards because you like it. Yes really, because you do.
You love learning new things:
You know that you don’t know enough, and it bothers you that there isn’t enough time in the day to learn about the next topic.
You’re up-to-date on new trends in data – you know who’s using what to solve various problems and are excited for the next release of your favorite tool
If you like being thrown in the deep end of the pool, this team’s for you.
You take it personally:
You don’t sleep well at night when you leave work with a question unanswered
You feel accountable for everything you do and that sense of urgency has been driving you your entire life
You work hard but play harder:
You like to have a good time while getting things done
When we say a “team player” we mean it - you have a crisp high-five and funny stories to tell
You have your team’s back. And the team has yours.
Sense of humor is a must-ash. (Mustache… Get it? Mustache.)
",https://stackoverflow.com/jobs/166878/senior-data-engineer-aws-sql-python-hadoop-northwestern-mutual
JOB150340338747,Senior Data Engineer - BlackLocus Jobs in United States,Senior Data Engineer - BlackLocus Jobs in United States,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/usa/jobs/?utm_campaign=.JOBS%20RSS%20Feed&utm_medium=.JOBS%20Universe&vs=25&utm_source=.JOBS%20RSS%20Feed-DE
JOB150720300074,Senior Data Engineer - BlackLocus Jobs in Texas,Senior Data Engineer - BlackLocus Jobs in Texas,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/texas/usa/jobs/?utm_medium=.JOBS%20Universe&utm_campaign=.JOBS%20RSS%20Feed&utm_source=.JOBS%20RSS%20Feed-DE&vs=25
JOB152007258805,Which AWS certification should I pursue if my job is a Data engineer?,Which AWS certification should I pursue if my job is a Data engineer?,,,"I started AWS with a Data Center background. Storage in particular. In my opinion the best place to start is with the AWS Solutions Architect certification. Ultimately, I suggest you pursue at least the 3 associate certifications. One thing that could help you is to become multi-cloud certified. Many enterprise organizations are now implementing multiple clouds.
If you need training, consider Linux Academy. I am a training architect for Linux Academy but I believe we have the best training for the dollar. Your subscription would give you access to all of our training. We train on cloud, Linux, DevOps and more. We have training that can take you from a complete beginner to advanced training. Our certification courses include practice exams, flash cards, quizzes, as well as our video lessons and a community and slack channel where you can get help if you need it. Check us out. Linux Academy.com.
",https://www.quora.com/Which-AWS-certification-should-I-pursue-if-my-job-is-a-Data-engineer
JOB152105527400,Data Engineer,Data Engineer,The curiosity and determination to understand and improve data flows.,"Hands-on, production experience with the Hadoop family of big data technologies (Hive, Impala, HBase, etc.).,Collaboration with business partners to craft and iterate on solutions that extract value from data.,Experience with Spark, Python, and Java.,Strong analytical skills and a fervor for data integrity and accessibility.","
Job description
Automattic is the company behind WordPress.com, Jetpack, WooCommerce, and more. We are looking for a full-stack data engineer.
You’ll work with business leads, analysts, data scientists and fellow engineers to build data-powered products that empower better decision making. You’re committed to data quality. You’ll understand how to manage a cluster to deliver performance and reliability. You’ll evaluate and help to craft technology choices, and you’ll implement systems that tackle business use cases.
What we’re looking for:
Hands-on, production experience with the Hadoop family of big data technologies (Hive, Impala, HBase, etc.).
Collaboration with business partners to craft and iterate on solutions that extract value from data.
Experience with Spark, Python, and Java.
Strong analytical skills and a fervor for data integrity and accessibility.
The curiosity and determination to understand and improve data flows.
We’re serious about growing diversity in the tech industry. We want to build Automattic as an environment where people love their work and show respect and empathy to those with whom we interact. Diversity typically includes, but is not limited to, differences in race, gender, sexual orientation, gender identity or expression, political and religious affiliation, socioeconomic background, cultural background, geographic location, disabilities and abilities, relationship status, veteran status, and age. To work on diversity means that we welcome these differences, and strive to increase the visibility of traditionally underrepresented groups. Read more about our dedication to diversity and inclusion.
HOW TO APPLY
If you’re reading this on a site other than automattic.com please ensure you visit automattic.com/work-with-us for the latest details on applying.
",https://stackoverflow.com/jobs/201269/data-engineer-automattic
JOB153657469044,Data Engineer,Data Engineer,"Python,SQL,Relational databases (e.g., Postgres, MySQL),Distributed computation (e.g., Spark, Hive, Athena),Cloud infrastructure (we use AWS),General application (e.g., web API) development,Git collaboration","Competitive base salary,Profit sharing or equity, based on experience,100%-covered Health insurance for employees, 75%-covered dependents,Four weeks PTO,401(k) with employer matching,Personalized monthly perks and matched charitable donations","
Job description
Strong Analytics is seeking a full-time, remote data engineer to collaborate with our team building and managing data pipelines, embedding statistical algorithms in robust applications, and deploying machine learning applications to the cloud.
This role requires advanced Python programming and SQL, as well as experience deploying applications to AWS and distributed data processing (e.g., Spark).
We offer a comprehensive compensation package, including:
Competitive base salary
Profit sharing or equity, based on experience
100%-covered Health insurance for employees, 75%-covered dependents
Four weeks PTO
401(k) with employer matching
Personalized monthly perks and matched charitable donations
Requirements
Candidates will be evaluated based on their skills with the following technologies/workflows:
Python
SQL
Relational databases (e.g., Postgres, MySQL)
Distributed computation (e.g., Spark, Hive, Athena)
Cloud infrastructure (we use AWS)
General application (e.g., web API) development
Git collaboration
All applicants will be considered based on their experience and demonstrated skill/aptitude, not formal education.
Applicants should have the ability to travel infrequently (<5% of your time) for team meetings, conferences, and occasional client site visits.
",http://stackoverflow.com/jobs/435389/data-engineer-strong-analytics
JOB154621068342,Senior Data Engineer - BlackLocus Jobs in Texas,Senior Data Engineer - BlackLocus Jobs in Texas,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/texas/usa/jobs/?utm_source=.JOBS%20RSS%20Feed-DE&utm_campaign=.JOBS%20RSS%20Feed&utm_medium=.JOBS%20Universe&vs=25
JOB155026818056,Senior Data Engineer - BlackLocus Jobs in United States,Senior Data Engineer - BlackLocus Jobs in United States,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/usa/jobs/?utm_source=.JOBS%20RSS%20Feed-DE&utm_campaign=.JOBS%20RSS%20Feed&vs=25&utm_medium=.JOBS%20Universe
JOB155863335946,Senior Data Engineer - BlackLocus Jobs in Texas,Senior Data Engineer - BlackLocus Jobs in Texas,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/texas/usa/jobs/?utm_medium=.JOBS%20Universe&vs=25&utm_campaign=.JOBS%20RSS%20Feed&utm_source=.JOBS%20RSS%20Feed-DE
JOB156919485503,Big Data Engineer,Big Data Engineer,,"Produce clean, standards based, modern code with an emphasis on advocacy toward end-users to produce high quality software designs that are well-documented.,Demonstrate an understanding of technology and digital frameworks in the context of data integration.,Ensure code and design quality through the execution of test plans and assist in development of standards, methodology and repeatable processes, working closely with internal and external design, business, and technical counterparts.,Utilizes existing methods and procedures to create designs within the proposed solution to solve business problems.,Understands the strategic direction set by senior management as it relates to team goals.,Contributes to design of solution, executes development of design, and seeks guidance on complex technical challenges where necessary.,Primary upward interaction is with direct supervisor.,May interact with peers, client counterparts and/or management levels within Accenture.,Understands methods and procedures on new assignments and executes deliverables with guidance as needed.,May interact with peers and/or management levels at a client and/or within Accenture.,Determines methods and procedures on new assignments with guidance.,Decisions often impact the team in which they reside.,Manages small teams and/or work efforts (if in an individual contributor role) at a client or within Accenture.","
- Job description
Are you ready to step up to the New and take your technology expertise to the next level?
Join Accenture and help transform leading organizations and communities around the world. The sheer scale of our capabilities and client engagements and the way we collaborate, operate and deliver value provides an unparalleled opportunity to grow and advance. Choose Accenture, and make delivering innovative work part of your extraordinary career.
People in our Client Delivery & Operations career track drive delivery and capability excellence through the design, development and/or delivery of a solution, service, capability or offering. They grow into delivery-focused roles, and can progress within their current role, laterally or upward.
As part of our Advanced Technology & Architecture (AT&A) practice, you will lead technology innovation for our clients through robust delivery of world-class solutions. You will build better software better! There will never be a typical day and that’s why people love it here. The opportunities to make a difference within exciting client initiatives are unlimited in the ever-changing technology landscape. You will be part of a growing network of technology experts who are highly collaborative taking on today’s biggest, most complex business challenges. We will nurture your talent in an inclusive culture that values diversity. Come grow your career in technology at Accenture!
Job Description:
Data and Analytics professionals define strategies, develop and deliver solutions that enable the collection, processing and management of information from one or more sources, and the subsequent delivery of information to audiences in support of key business processes.
Produce clean, standards based, modern code with an emphasis on advocacy toward end-users to produce high quality software designs that are well-documented.
Demonstrate an understanding of technology and digital frameworks in the context of data integration.
Ensure code and design quality through the execution of test plans and assist in development of standards, methodology and repeatable processes, working closely with internal and external design, business, and technical counterparts.
Big Data professionals develop deep next generation Analytics skills to support Accenture's data and analytics agendas, including skills such as Data Modeling, Business Intelligence, and Data Management.
A professional at this position level within Accenture has the following responsibilities:
Utilizes existing methods and procedures to create designs within the proposed solution to solve business problems.
Understands the strategic direction set by senior management as it relates to team goals.
Contributes to design of solution, executes development of design, and seeks guidance on complex technical challenges where necessary.
Primary upward interaction is with direct supervisor.
May interact with peers, client counterparts and/or management levels within Accenture.
Understands methods and procedures on new assignments and executes deliverables with guidance as needed.
May interact with peers and/or management levels at a client and/or within Accenture.
Determines methods and procedures on new assignments with guidance.
Decisions often impact the team in which they reside.
Manages small teams and/or work efforts (if in an individual contributor role) at a client or within Accenture.
",https://www.indeed.com/cmp/_/job?jk=a2c73f8c85d457e9&tk=1cs7vv9m8b87i800
JOB158975448095,Experienced ETL Data Engineer ready for the CLOUD LEVEL? [Online/phone recruitment],Experienced ETL Data Engineer ready for the CLOUD LEVEL? [Online/phone recruitment],,,"
Popis Pracovnej Pozície
Are you a Data Engineer who is passionate about developing innovative analytics solutions to help organizations drive strategic business outcomes and to enable data-driven insights?
Are you thinking about transition to the leading edge Cloud technologies e.g. Microsoft Azure (Azure Data Factory, Azure Synapse Analytics)?
You will participate in design phase and develop components to satisfy the business requirements within the various projects from a wide range of industries (Software Platforms, Finance, Telecommunications, Automotive…)
VHAT YOU WILL DO
• Design and implement end-to-end data solutions (storage, integration, processing, visualization) in Azure SQL Data Warehouse, Azure SQL
• Architect and implement ETL and data movement solutions using Azure Data Factory
• Build conceptual and logical data models
• Develop and document mechanisms for deployment, monitoring and maintenance
• Be part of a community focusing on ensuring code quality by extensive testing, leveraging design patterns and principles and applying Agile delivery and DevOps principles
• Cooperate and communicate with client teams to follow up on business requirements
Požiadavky
• Interested in and keen to learn technologies and platforms like Microsoft Azure (Azure Data Factory, Azure Synapse Analytics etc.
• Strong knowledge of database, storage, collection and aggregation models, techniques and technologies – and how to apply them in business
• Hands on experience with data warehouse technical architectures, ETL, reporting/analytic tools and, scripting
• Familiar with writing complex SQL queries (to clean and transform data)
• Ability to work in teams of different sizes on different projects
• Working knowledge of agile development including DevOps concepts
• Advanced English communication skills
Accenture offers a competitive compensation package. As required by the Slovak law we hereby state, that the legal monthly minimum gross base pay starting from 1700€ depending on your professional and personal qualifications in the required areas.
• Guaranteed Paid overtime or overtime vacation
• Cafeteria – Budget for benefits based on your choice
• Transparent bonus structure
• Refer-a-Friend – get a bonus in the employee referral program
• Wide range of leading-edge trainings (including various language
• Regular performance management and evaluation process
gyms, studios and swimming pools
",https://www.accenture.com/sk-sk/careers/jobdetails?id=00913593_en&title=Experienced+ETL+Data+Engineer+ready+for+the+CLOUD+LEVEL%3f++%5bOnline%2fphone+recruitment%5d
JOB159153612907,Software Engineering - Big Data Engineer Lead,Software Engineering - Big Data Engineer Lead,,,"
Job description
As an experienced member of our Software Engineering Group, we look first and foremost for people who are passionate around solving business problems through innovation and engineering practices. You'll be required to apply your depth of knowledge and expertise to all aspects of the software development lifecycle, as well as partner continuously with your many stakeholders on a daily basis to stay focused on common goals. We embrace a culture of experimentation and constantly strive for improvement and learning. You'll work in a collaborative, trusting, thought-provoking environment-one that encourages diversity of thought and creative solutions that are in the best interests of our customers globally.
This role requires a wide variety of strengths and capabilities, including:
* BS/BA degree or equivalent experience
* Expertise in application, data, and infrastructure architecture disciplines
* Advanced knowledge of architecture and design across all systems
* Proficiency in multiple modern programming languages like Java, Python, SQL
* Knowledge of industry-wide technology trends and best practices
* Keen understanding of financial control and budget management
* Ability to work in large, collaborative teams to achieve organizational goals
* Passionate about building an innovative culture
* Experience creating complex SQL queries to support data analysis
* Familiar with Data Science concepts and applying them to analyze large volumes of data
* Comfortable with streaming and big data concepts using design patterns with software like Oracle, Java, Python, Spark, Flink, Kafka, HDFS, NIFI, Couchbase and AWS Cloud
* Expert at developing Functional and Technical Specifications, Process Flows, Data Analysis, Mapping Documents, Automated testing frameworks, CI/CD processes, Agile concepts and other similar project deliverables
* Good organization, prioritization and time management skills
JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.
We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs.
Equal Opportunity Employer/Disability/Veterans
",http://stackoverflow.com/jobs/434419/software-engineering-big-data-engineer-lead-jpmorgan-chase-bank-na
JOB159241733144,Senior Data Engineer - BlackLocus Jobs in Texas,Senior Data Engineer - BlackLocus Jobs in Texas,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/texas/usa/jobs/?vs=25&utm_campaign=.JOBS%20RSS%20Feed&utm_medium=.JOBS%20Universe&utm_source=.JOBS%20RSS%20Feed-DE
JOB159593333820,"Senior Data Engineer - BlackLocus Jobs in Austin, TX","Senior Data Engineer - BlackLocus Jobs in Austin, TX",,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/austin/texas/usa/jobs/?utm_source=.JOBS%20RSS%20Feed-DE&utm_campaign=.JOBS%20RSS%20Feed&utm_medium=.JOBS%20Universe&vs=25
JOB159691424784,"Data Engineer Jobs in Houston, TX","Data Engineer Jobs in Houston, TX",,"Houston, TX","
Data Engineer Jobs in Houston, TX
Current Search Criteria
More
",https://militaryjobs.homedepot.com/data-engineer/jobs-in/houston/texas/usa/jobs/?utm_campaign=.JOBS%20RSS%20Feed&utm_source=.JOBS%20RSS%20Feed-DE&vs=25&utm_medium=.JOBS%20Universe
JOB161171571754,"Senior Data Engineer - BlackLocus Jobs in Austin, TX","Senior Data Engineer - BlackLocus Jobs in Austin, TX",,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/austin/texas/usa/jobs/?utm_campaign=.JOBS%20RSS%20Feed&utm_source=.JOBS%20RSS%20Feed-DE&vs=25&utm_medium=.JOBS%20Universe
JOB161678656539,Data Engineer Jobs in United States,Data Engineer Jobs in United States,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/data-engineer/jobs-in/usa/jobs/?utm_medium=.JOBS%20Universe&utm_source=.JOBS%20RSS%20Feed-DE&utm_campaign=.JOBS%20RSS%20Feed&vs=25
JOB161785021447,Senior Data Engineer - BlackLocus,Senior Data Engineer - BlackLocus,,,"
Job Information
POSITION PURPOSE
The Sr Data Engineer will expand and optimize data, data flow, data collection for cross functional teams, and data pipeline architecture. The Sr Data Engineer will support and collaborate with the software engineering team, data analysts, and data scientist to ensure data delivery architecture is consistent throughout ongoing projects. Continuously improve or re-design data architecture to support the next generation of products and initiatives.
MAJOR TASKS, RESPONSIBILITES AND KEY ACCOUNTABILITIES
40% - Data Validation, ETL, Infrastructure Development: Coding validation and ETL to ensure successful data integration
30% - Data Infrastructure Maintenance: Backup and optimization activities to maintain performance; code, configure, test, etc data to ensure integrity
20% - Data Architecture Design and Analysis: Create and maintain optimal data pipeline architecture; Develop data architecture to meet business requirements
10% - Planning/Requirements Analysis: Collaborate with team leads and cross functional partners to assess business requirements and communicate opportunities
NATURE AND SCOPE
This position reports to the Technology Leader.
This position has 0 direct reports.
ENVIRONMENTAL JOB REQUIREMENTS
Environment:
Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.
Travel:
Typically requires overnight travel less than 10% of the time.
Additional Environmental Job Requirements: MINIMUM QUALIFICATIONS
Must be eighteen years of age or older.
Must be legally permitted to work in the United States.
Additional Minimum Qualifications:
Experience message queuing, stream processing, and scalable data stores
Experience managing projects and organizing data
Experience supporting and working with cross-functional teams
Experience with SQL, NoSQL databases, relational databases, and query authoring
Experience building and optimizing data pipelines, architectures, data sets and workflow management tools such as Azkaban, Luigi, Airflow, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C#, Scala, GoLang, etc.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
Education Required:
The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.
Years of Relevant Work Experience: 5 years
Physical Requirements:
Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.
Additional Qualifications:
Preferred Qualifications:
8+ years of previous related work experience
Ability to convey complex or technical ideas and processes in easy-to-understand terms to diverse audiences
Ability to negotiate, handle complaints, settle disputes, and resolve grievances with both internal and external customers
Excellent written and verbal communication skills
Knowledge, Skills, Abilities and Competencies:Collaborates - Building partnerships and working collaboratively with others to meet shared objectives
Communicates Effectively - Developing and delivering multi-mode communications that convey a clear understanding of the unique needs of different audiences
Cultivates Innovation - Creating new and better ways for the organization to be successful
Drives Engagement - Creating a climate where people are motivated to do their best to help the organization achieve its objectives
Instills Trust - Gaining the confidence and trust of others through honesty, integrity, and authenticity
Nimble Learning - Actively learning through experimentation when tackling new problems, using both successes and failures as learning fodder
Optimizes Work Processes - Knowing the most effective and efficient processes to get things done with a focus on continuous improvement
Plans and Aligns - Planning and prioritizing work to meet commitments aligned with organizational goals
Tech Savvy - Anticipating and adopting innovations in business-building digital and technology applications. We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
",https://militaryjobs.homedepot.com/austin-tx/senior-data-engineer-blacklocus/EC8362E9CBF04CA89DDFB7AF819ED0FC/job/?utm_source=.JOBS%20RSS%20Feed-DE&utm_medium=.JOBS%20Universe&utm_campaign=.JOBS%20RSS%20Feed
JOB162029512830,Lead Data Engineer,Lead Data Engineer,Pet friendly office environment,"Java,Python,Oracle,Redis,RabbitMQ,Docker,CloverETL,Amazon Web Services (Aurora, Redshift, DynamoDB, S3, Lambda, Kinesis, ElastiCache),Have a BA/BS in Computer Science, Engineering, Information Systems or equivalent experience,Self-starter with 3+ years of experience as a Data Engineer dealing with large complex data scenarios,Proven ability to work with varied data infrastructures - including relational databases, column stores, NoSQL databases and file-based storage solutions,Experience with both compiled and scripting languages,Expert level SQL skills,Excellent communication (verbal and written) and interpersonal skills and an ability to effectively communicate with both business and technical teams,Write great code, view it as a craft, and love cranking out solid work,Competitive compensation and generous employee benefits package including fully paid Medical, Dental & Vision plans for employees & their dependents!,Stock options for all employees!,We bring toys to the office but still think the most fun thing to do is build product,Collaborative work environment that fosters bonds beyond the workplace,We treat our people well with employee recognition programs and referral bonuses,Better than average team building activities such as paintball, go cart racing, shuffleboard, organized sporting teams and off-site retreats.,Provide lunches, drinks and snacks so our team can be hungry for other things,Learn from and teach each other at CrowdTwist U","
Job description
About Us:
CrowdTwist is seeking a Data Engineer for our growing team based in New York City. In this role, you will have full ownership of the CrowdTwist Data Pipeline to satisfy our ever growing data needs. You will be involved in many different projects as we continue to grow and enhance our platform. You'll be working with large data sets across millions of users and will directly influence the loyalty program offerings for many of our clients, such as Pepsi, Marvel, Carhartt, Nestlé Purina, AMC’s The Walking Dead, TOMS, Steve Madden and Zumiez.
We are a venture-backed NYC based company that provides the most comprehensive omni-channel loyalty & analytics solutions for industry leading brands. We're relaxed, experienced, hard driving and are changing our industry.
This role is for an engineer who loves to roll up their sleeves, dive in, and tackle any problem with speed and precision. You will work closely with the Data, Engineering and Product teams to implement, mature and optimize our Data Warehouse, Reporting and AI Data Models which drive actionable insights across the platform. You will be utilizing your experience with object-oriented software design and implementation, data modeling, and building high-performance, highly scalable data processing applications. We operate in an agile manner, so you must thrive in a fast-paced environment and enjoy shipping product.
In this role, you will work with a broad tech stack, including but not limited to:
Java
Python
Oracle
Redis
RabbitMQ
Docker
CloverETL
Amazon Web Services (Aurora, Redshift, DynamoDB, S3, Lambda, Kinesis, ElastiCache)
This is what we're using today, but we're looking to take our data processing to the next level. We're looking for free thinkers that are open to new approaches and tech stacks.
About You:
Have a BA/BS in Computer Science, Engineering, Information Systems or equivalent experience
Self-starter with 3+ years of experience as a Data Engineer dealing with large complex data scenarios
Proven ability to work with varied data infrastructures - including relational databases, column stores, NoSQL databases and file-based storage solutions
Experience with both compiled and scripting languages
Expert level SQL skills
Excellent communication (verbal and written) and interpersonal skills and an ability to effectively communicate with both business and technical teams
Write great code, view it as a craft, and love cranking out solid work
We have a fun, generous company culture that's built on our fundamental principle that when you give more, you get more:
Competitive compensation and generous employee benefits package including fully paid Medical, Dental & Vision plans for employees & their dependents!
Stock options for all employees!
We bring toys to the office but still think the most fun thing to do is build product
Collaborative work environment that fosters bonds beyond the workplace
We treat our people well with employee recognition programs and referral bonuses
Better than average team building activities such as paintball, go cart racing, shuffleboard, organized sporting teams and off-site retreats.
Provide lunches, drinks and snacks so our team can be hungry for other things
Learn from and teach each other at CrowdTwist U
Pet friendly office environment
If this sounds like you, get in touch. We're cool, relaxed, experienced, hard driving, changing our industry and looking for smart people like yourself to help tackle tough technical challenges.
This is a full-time position based in our New York City office. Apply by sending us your resume and cover letter. Relocation assistance will be available if needed.
",https://stackoverflow.com/jobs/200015/lead-data-engineer-crowdtwist
JOB162121335867,"Senior Data Engineer - BlackLocus Jobs in Austin, TX","Senior Data Engineer - BlackLocus Jobs in Austin, TX",,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/austin/texas/usa/jobs/?utm_source=.JOBS%20RSS%20Feed-DE&utm_medium=.JOBS%20Universe&vs=25&utm_campaign=.JOBS%20RSS%20Feed
JOB163711419410,Senior Data Engineer - BlackLocus,Senior Data Engineer - BlackLocus,,,"
Job Information
POSITION PURPOSE
The Sr Data Engineer will expand and optimize data, data flow, data collection for cross functional teams, and data pipeline architecture. The Sr Data Engineer will support and collaborate with the software engineering team, data analysts, and data scientist to ensure data delivery architecture is consistent throughout ongoing projects. Continuously improve or re-design data architecture to support the next generation of products and initiatives.
MAJOR TASKS, RESPONSIBILITES AND KEY ACCOUNTABILITIES
40% - Data Validation, ETL, Infrastructure Development: Coding validation and ETL to ensure successful data integration
30% - Data Infrastructure Maintenance: Backup and optimization activities to maintain performance; code, configure, test, etc data to ensure integrity
20% - Data Architecture Design and Analysis: Create and maintain optimal data pipeline architecture; Develop data architecture to meet business requirements
10% - Planning/Requirements Analysis: Collaborate with team leads and cross functional partners to assess business requirements and communicate opportunities
NATURE AND SCOPE
This position reports to the Technology Leader.
This position has 0 direct reports.
ENVIRONMENTAL JOB REQUIREMENTS
Environment:
Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.
Travel:
Typically requires overnight travel less than 10% of the time.
Additional Environmental Job Requirements: MINIMUM QUALIFICATIONS
Must be eighteen years of age or older.
Must be legally permitted to work in the United States.
Additional Minimum Qualifications:
Experience message queuing, stream processing, and scalable data stores
Experience managing projects and organizing data
Experience supporting and working with cross-functional teams
Experience with SQL, NoSQL databases, relational databases, and query authoring
Experience building and optimizing data pipelines, architectures, data sets and workflow management tools such as Azkaban, Luigi, Airflow, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C#, Scala, GoLang, etc.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
Education Required:
The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.
Years of Relevant Work Experience: 5 years
Physical Requirements:
Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.
Additional Qualifications:
Preferred Qualifications:
8+ years of previous related work experience
Ability to convey complex or technical ideas and processes in easy-to-understand terms to diverse audiences
Ability to negotiate, handle complaints, settle disputes, and resolve grievances with both internal and external customers
Excellent written and verbal communication skills
Knowledge, Skills, Abilities and Competencies:Collaborates - Building partnerships and working collaboratively with others to meet shared objectives
Communicates Effectively - Developing and delivering multi-mode communications that convey a clear understanding of the unique needs of different audiences
Cultivates Innovation - Creating new and better ways for the organization to be successful
Drives Engagement - Creating a climate where people are motivated to do their best to help the organization achieve its objectives
Instills Trust - Gaining the confidence and trust of others through honesty, integrity, and authenticity
Nimble Learning - Actively learning through experimentation when tackling new problems, using both successes and failures as learning fodder
Optimizes Work Processes - Knowing the most effective and efficient processes to get things done with a focus on continuous improvement
Plans and Aligns - Planning and prioritizing work to meet commitments aligned with organizational goals
Tech Savvy - Anticipating and adopting innovations in business-building digital and technology applications. We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
",https://militaryjobs.homedepot.com/austin-tx/senior-data-engineer-blacklocus/EC8362E9CBF04CA89DDFB7AF819ED0FC/job/?utm_source=.JOBS%20RSS%20Feed-DE&utm_campaign=.JOBS%20RSS%20Feed&utm_medium=.JOBS%20Universe
JOB163725968384,Data Engineer Jobs in Texas,Data Engineer Jobs in Texas,,,"
Current Search Criteria
More
",https://militaryjobs.homedepot.com/data-engineer/jobs-in/texas/usa/jobs/?utm_medium=.JOBS%20Universe&utm_campaign=.JOBS%20RSS%20Feed&utm_source=.JOBS%20RSS%20Feed-DE&vs=25
JOB164350039088,Big Data Engineer,Big Data Engineer,,"Produce clean, standards based, modern code with an emphasis on advocacy toward end-users to produce high quality software designs that are well-documented.,Demonstrate an understanding of technology and digital frameworks in the context of data integration","
- Job description
Are you ready to step up to the New and take your technology expertise to the next level?
Do you have a passion for using new technologies to make a positive impact on business and community? Want a role that provides you with a sense of purpose and satisfaction? Then join Accenture Technology and build a rewarding career improving the way the world works and lives, as you help clients shift to the New using leading-edge technologies on some of the coolest projects you can imagine.
Thrive in our highly collaborative, digitally-driven and innovation-led environment. Nurture your talent for thoughtful and game changing solutions in our inclusive culture that values diversity of ideas, experiences and backgrounds.
As part of our Advanced Technology & Architecture (AT&A) practice, you will lead technology innovation for our clients through robust delivery of world-class solutions. You will build better software better! There will never be a typical day and that’s why people love it here. The opportunities to make a difference within exciting client initiatives are unlimited in the ever-changing technology landscape. You will be part of a growing network of technology experts who are highly collaborative taking on today’s biggest, most complex business challenges. We will nurture your talent in an inclusive culture that values diversity. Come grow your career in technology at Accenture!
Data and Analytics professionals define strategies, develop and deliver solutions that enable the collection, processing and management of information from one or more sources, and the subsequent delivery of information to audiences in support of key business processes.
Responsibilities
As a Big Data Engineer, you will develop deep next generation Analytics skills to support Accenture's data and analytics agendas, including skills such as Data Modeling, Business Intelligence, and Data Management.
Produce clean, standards based, modern code with an emphasis on advocacy toward end-users to produce high quality software designs that are well-documented.
Demonstrate an understanding of technology and digital frameworks in the context of data integration
Ensure code and design quality through the execution of test plans and assist in development of standards, methodology and repeatable processes, working closely with internal and external design, business, and technical counterparts
",https://www.indeed.com/cmp/_/job?jk=e789c0d0f2f61790&tk=1cs7vs98jb87i800
JOB164725130292,Senior Data Engineer - BlackLocus,Senior Data Engineer - BlackLocus,,,"
Job Information
POSITION PURPOSE
The Sr Data Engineer will expand and optimize data, data flow, data collection for cross functional teams, and data pipeline architecture. The Sr Data Engineer will support and collaborate with the software engineering team, data analysts, and data scientist to ensure data delivery architecture is consistent throughout ongoing projects. Continuously improve or re-design data architecture to support the next generation of products and initiatives.
MAJOR TASKS, RESPONSIBILITES AND KEY ACCOUNTABILITIES
40% - Data Validation, ETL, Infrastructure Development: Coding validation and ETL to ensure successful data integration
30% - Data Infrastructure Maintenance: Backup and optimization activities to maintain performance; code, configure, test, etc data to ensure integrity
20% - Data Architecture Design and Analysis: Create and maintain optimal data pipeline architecture; Develop data architecture to meet business requirements
10% - Planning/Requirements Analysis: Collaborate with team leads and cross functional partners to assess business requirements and communicate opportunities
NATURE AND SCOPE
This position reports to the Technology Leader.
This position has 0 direct reports.
ENVIRONMENTAL JOB REQUIREMENTS
Environment:
Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.
Travel:
Typically requires overnight travel less than 10% of the time.
Additional Environmental Job Requirements: MINIMUM QUALIFICATIONS
Must be eighteen years of age or older.
Must be legally permitted to work in the United States.
Additional Minimum Qualifications:
Experience message queuing, stream processing, and scalable data stores
Experience managing projects and organizing data
Experience supporting and working with cross-functional teams
Experience with SQL, NoSQL databases, relational databases, and query authoring
Experience building and optimizing data pipelines, architectures, data sets and workflow management tools such as Azkaban, Luigi, Airflow, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C#, Scala, GoLang, etc.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
Education Required:
The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.
Years of Relevant Work Experience: 5 years
Physical Requirements:
Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.
Additional Qualifications:
Preferred Qualifications:
8+ years of previous related work experience
Ability to convey complex or technical ideas and processes in easy-to-understand terms to diverse audiences
Ability to negotiate, handle complaints, settle disputes, and resolve grievances with both internal and external customers
Excellent written and verbal communication skills
Knowledge, Skills, Abilities and Competencies:Collaborates - Building partnerships and working collaboratively with others to meet shared objectives
Communicates Effectively - Developing and delivering multi-mode communications that convey a clear understanding of the unique needs of different audiences
Cultivates Innovation - Creating new and better ways for the organization to be successful
Drives Engagement - Creating a climate where people are motivated to do their best to help the organization achieve its objectives
Instills Trust - Gaining the confidence and trust of others through honesty, integrity, and authenticity
Nimble Learning - Actively learning through experimentation when tackling new problems, using both successes and failures as learning fodder
Optimizes Work Processes - Knowing the most effective and efficient processes to get things done with a focus on continuous improvement
Plans and Aligns - Planning and prioritizing work to meet commitments aligned with organizational goals
Tech Savvy - Anticipating and adopting innovations in business-building digital and technology applications. We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
",https://militaryjobs.homedepot.com/austin-tx/senior-data-engineer-blacklocus/EC8362E9CBF04CA89DDFB7AF819ED0FC/job/?utm_campaign=.JOBS%20RSS%20Feed&utm_source=.JOBS%20RSS%20Feed-DE&utm_medium=.JOBS%20Universe
JOB166634734644,Senior Data Engineer - BlackLocus Jobs in Texas,Senior Data Engineer - BlackLocus Jobs in Texas,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/texas/usa/jobs/?utm_campaign=.JOBS%20RSS%20Feed&utm_medium=.JOBS%20Universe&vs=25&utm_source=.JOBS%20RSS%20Feed-DE
JOB168364353610,"Data Engineer with ML, Spark and Scala","Data Engineer with ML, Spark and Scala",Fixed term contract with an option for perm,"Extend our product data architecture foundation (Revise existing ontologies and their usage in existing product),Selecting features, building and optimizing classifiers using machine learning techniques,Processing, cleansing, and verifying the integrity of data used for analysis,Deliver scalable application platform on basis of big data technologies that fit current and future data usage scenarios such as ETL, data mining, anomaly detection processes (foundation for product extensions),Assess and (re)design services to consume data (both high volume traffic challenges and spikes in computation demand challenges),Design a scalable Reporting platform (possibly near-real-time reporting),Be hands on on statistical data analysis and data patterns extraction to drive new business insights,Contribute to data security design & implementation,Safe-guard our enterprise product quality,Contribute to Product Roadmap,Contribute to environment and tools designs for resources efficiency,Bachelor degree or equivalent relevant work experience,Experience with Agile methodologies (Scrum / Kanban),Product development experience - knowing what it takes to build and release versions of a future-proof product...,Have worked before in distributed team is a plus,Proficient understanding of distributed computing principles,Experience with building stream-processing systems, (experience with Spark/Amazon EMR, Kafka/Amazon Kinesis is a big plus),Experience with integration of data from multiple data sources,Experience with NoSQL databases, such as MongoDB, etc,Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc. and experience with big data ML tools such as SparkML or pattern (python),Experience with common data science toolkits, such as R, NumPy,Experience with ELK stack,Comfort with Scala is a plus,Excellent communication skills in English,Business-focus,Enterpreneurial spirit,Technical curiocity,Good communicator,Pragmatism,Goal driven personality,Lame jokes (what can I say...) & beer on Fridays ;-),Laptop of your preferences and two extra screens on your desk,Flexible working hours,Time and budget for training,5 weeks paid holiday per year,Good salary and additional incentives","
Job description
Do you like solving complex problems in the field of data engineering? Do you like building new product solutions? Do you enjoy freedom? You find AI in general and machine learning in particular, intriguing? Seek no more! We want to talk to you!
Data Engineer with ML, Spark and Scala
Amsterdam and / or Rotterdam (you decide), fulltime position (32 - 40)
Description
As our Data Engineer you'll be leading critical product design efforts and you will be hands on with the implementation of our core platform, data architecture, data pipeline and deal with data engineering challenges. Your role is to technically design future-proof solutions that deal with big data problems. Your ML experience will come handy as you will be the bridge between our Data Engineering and our Data Science subteams.
You can be based either in Amsterdam or Rotterdam. The choice is yours! You'll be working closely with our CTO and our product development team (with team members on both locations) on a new generation recruitment marketing online solution (SaaS product).
What you actually do
Extend our product data architecture foundation (Revise existing ontologies and their usage in existing product)
Selecting features, building and optimizing classifiers using machine learning techniques
Processing, cleansing, and verifying the integrity of data used for analysis
Deliver scalable application platform on basis of big data technologies that fit current and future data usage scenarios such as ETL, data mining, anomaly detection processes (foundation for product extensions)
Assess and (re)design services to consume data (both high volume traffic challenges and spikes in computation demand challenges)
Design a scalable Reporting platform (possibly near-real-time reporting)
Be hands on on statistical data analysis and data patterns extraction to drive new business insights
Contribute to data security design & implementation
Safe-guard our enterprise product quality
Contribute to Product Roadmap
Contribute to environment and tools designs for resources efficiency
Which boxes do you tick?
(Psst...You do not need to tick all the boxes below in order to apply...)
What you see below, paints the ideal picture. Obviously, we also work well with people that have apetite to excel, foundation to build on and potential to succeed.
""Our perfect picture"":
Bachelor degree or equivalent relevant work experience
Experience with Agile methodologies (Scrum / Kanban)
Product development experience - knowing what it takes to build and release versions of a future-proof product...
Have worked before in distributed team is a plus
Proficient understanding of distributed computing principles
Experience with building stream-processing systems, (experience with Spark/Amazon EMR, Kafka/Amazon Kinesis is a big plus)
Experience with integration of data from multiple data sources
Experience with NoSQL databases, such as MongoDB, etc
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc. and experience with big data ML tools such as SparkML or pattern (python)
Experience with common data science toolkits, such as R, NumPy
Experience with ELK stack
Comfort with Scala is a plus
Excellent communication skills in English
Things we cherish
Business-focus
Enterpreneurial spirit
Technical curiocity
Good communicator
Pragmatism
Goal driven personality
Lame jokes (what can I say...) & beer on Fridays ;-)
What’s in it for you
First of all, you’ll be working with experienced colleagues with a strong vision on web development and software architecture, giving you a full intellectual challenge every day. Secondly you will be part of a vibrant and ambitious team counting 12 different nationalities. Thirdly, you'll participate to meetups/conferences. You will enjoy BBQs at our terrace and multi-cultural potluck lunches. Oh.. and you will have fun!
What’s more
Laptop of your preferences and two extra screens on your desk
Flexible working hours
Time and budget for training
5 weeks paid holiday per year
Good salary and additional incentives
Fixed term contract with an option for perm
So, does this sounds appealing to you?
Please apply by clicking on the 'Apply' button.
If you have any questions, please send an email to Marthe Blokker (Recruiter) -> marthe@vonq.com.
",https://stackoverflow.com/jobs/148674/data-engineer-with-ml-spark-and-scala-vonq
JOB168732165153,Senior Data Engineer - BlackLocus Jobs in Texas,Senior Data Engineer - BlackLocus Jobs in Texas,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/texas/usa/jobs/?vs=25&utm_medium=.JOBS%20Universe&utm_source=.JOBS%20RSS%20Feed-DE&utm_campaign=.JOBS%20RSS%20Feed
JOB169306171498,Data Engineer,Data Engineer,"Components/Frameworks including: Hadoop/HDFS, Spark, Storm, HBase, Pig, Hive, Scala, Kafka, PyScripts, Unix Shell scripts","Performing data engineering, data modeling, and implementation of Big Data platform and analytic applications for clients,Analyzing the latest Big Data and Cloud technologies and their innovative applications in both business intelligence analysis and new service offerings,Developing highly scalable and extensible Big Data platforms that enable the collection, storage, modeling, and analysis of massive data sets.,Constructing big data pipelines, both real-time and batch,Implementing data access and processing frameworks.,Supporting data users, data scientists, and analytic applications,Building Cloud-Native Solutions,Cloud platform technologies such as Microsoft Azure, Amazon Web Services and Google Cloud.,Big Data Analytic frameworks and query tools such as Spark, Storm, Hive, HBase, Impala, Hue,Streaming data tools and techniques such as Kafka, AWS Kinesis, Microsoft Streaming Analytics, StreamSets, StreamAnalytixs,ETL (Extract-Transform-Load) tools such as Talend, Informatica); also experience with ELT, SQL,Infrastructure setup using things like Kubernetes, Docker,Continuous Integration and Continuous Development (CI/CD),Data Warehouse and DataMart design and implementation,NoSQL environments such as MongoDB, Cassandra,Metadata management, data lineage, data governance, especially as related to Big Data,Structured, Unstructured, Semi-Structured Data techniques and processes,Around 5-10+ years of engineering and/or software development experience,Around 2-5+ years of experience in data engineering (ETL and Big Data) pipelines, both real-time and batch,Hands-on experience with Python, SQL, AWS, Redshift, Snowflake type tech,Experience in Consulting or supporting Client Requirements","
Job description
Responsibilities - What You Can Look Forward to!
Performing data engineering, data modeling, and implementation of Big Data platform and analytic applications for clients
Analyzing the latest Big Data and Cloud technologies and their innovative applications in both business intelligence analysis and new service offerings
Developing highly scalable and extensible Big Data platforms that enable the collection, storage, modeling, and analysis of massive data sets.
Constructing big data pipelines, both real-time and batch
Implementing data access and processing frameworks.
Supporting data users, data scientists, and analytic applications
Building Cloud-Native Solutions
Technical Experience - That It Would Be Nice To Have!
Cloud platform technologies such as Microsoft Azure, Amazon Web Services and Google Cloud.
Big Data Analytic frameworks and query tools such as Spark, Storm, Hive, HBase, Impala, Hue
Streaming data tools and techniques such as Kafka, AWS Kinesis, Microsoft Streaming Analytics, StreamSets, StreamAnalytixs
ETL (Extract-Transform-Load) tools such as Talend, Informatica); also experience with ELT, SQL
Infrastructure setup using things like Kubernetes, Docker
Continuous Integration and Continuous Development (CI/CD)
Data Warehouse and DataMart design and implementation
NoSQL environments such as MongoDB, Cassandra
Metadata management, data lineage, data governance, especially as related to Big Data
Structured, Unstructured, Semi-Structured Data techniques and processes
What Does Our Ideal Candidate Look Like?
Around 5-10+ years of engineering and/or software development experience
Around 2-5+ years of experience in data engineering (ETL and Big Data) pipelines, both real-time and batch
Hands-on experience with Python, SQL, AWS, Redshift, Snowflake type tech
Experience in Consulting or supporting Client Requirements
Components/Frameworks including: Hadoop/HDFS, Spark, Storm, HBase, Pig, Hive, Scala, Kafka, PyScripts, Unix Shell scripts
",http://stackoverflow.com/jobs/346317/data-engineer-trinityrock-advisors
JOB170301237371,"Data Engineer - Streaming Technology - Hadoop, hdfs, Java, Python","Data Engineer - Streaming Technology - Hadoop, hdfs, Java, Python","🍺, 🏓, ⚽️ and 🕺💃","Take over responsibility in designing and developing our data processing pipeline,Build up a centralized data warehouse in the long run that acts as the unique source of all relevant data,Work closely together with other engineers and the BI team to understand the data that we are collecting,Zattoo a 360 ° view on it's users actions and journey's,Be in-house consultant for best track, store and access data,Minimum of 3 years working as a Data Engineer,Bachelor Degree in Computer Science or related studies,Ability to maintain ETL stack,Ability to engineer ETL processing through the whole data pipeline,Fluent verbal and written English skills,Strong communication and presentation skills,Experience in the following technologies:
Jenkins
Various database technologies search as MySQL / Postgres / vertica / SAP HANA
SQL
Hadoop / hdfs (AWS-EMR, Pig, Impala, Apache Parquet)
tableau,Jenkins,Various database technologies search as MySQL / Postgres / vertica / SAP HANA,SQL,Hadoop / hdfs (AWS-EMR, Pig, Impala, Apache Parquet),tableau,Bonus: Deep knowledge in ETL processing big amounts of data,Bonus: Ability to write hadoop map reduce jobs,Bonus: Dev skills to transform data via scripting language like ruby ​​/ python or java / golang,Bonus: Experience with streaming frameworks such as spark / storm / samza / nimble,Bonus: Experience with Kafka,Flexible work schedules,Cool and comfortable offices,Relaxed atmosphere, no dress code,Working with an awesome product,Motivated and international team","
Job description
Zattoo is creating the future of television, live and on demand.
We build apps for mobile, web and big screens like Apple, Android, Samsung, Amazon Fire TV, Xbox One and many more.
The Role
Data is a core advantage of OTT / unicast TV over traditional broadcast. We know exactly what content our viewers watch, how popular a show and how many seconds of each and every ad campaign is viewed.
At Zattoo we are already reading a lot of our data, but we do not want it anymore, as we believe in the power of data. We want to make it an even stronger part of our everyday life. We want to build day to day business more on hard facts and less on good feeling. Therefore we are looking for an experienced Data Engineer to join our motivated team. You want to be in the center of our data collection and processing pipeline, and you want to get started with a scalable, reliable and robust pipeline that feeds into many other systems.
The Tasks
Take over responsibility in designing and developing our data processing pipeline
Build up a centralized data warehouse in the long run that acts as the unique source of all relevant data
Work closely together with other engineers and the BI team to understand the data that we are collecting
Zattoo a 360 ° view on it's users actions and journey's
Be in-house consultant for best track, store and access data
What we expect from you
Minimum of 3 years working as a Data Engineer
Bachelor Degree in Computer Science or related studies
Ability to maintain ETL stack
Ability to engineer ETL processing through the whole data pipeline
Fluent verbal and written English skills
Strong communication and presentation skills
Experience in the following technologies:
Jenkins
Various database technologies search as MySQL / Postgres / vertica / SAP HANA
SQL
Hadoop / hdfs (AWS-EMR, Pig, Impala, Apache Parquet)
tableau
Bonus: Deep knowledge in ETL processing big amounts of data
Bonus: Ability to write hadoop map reduce jobs
Bonus: Dev skills to transform data via scripting language like ruby ​​/ python or java / golang
Bonus: Experience with streaming frameworks such as spark / storm / samza / nimble
Bonus: Experience with Kafka
What's in it for you?
Flexible work schedules
Cool and comfortable offices
Relaxed atmosphere, no dress code
Working with an awesome product
Motivated and international team
🍺, 🏓, ⚽️ and 🕺💃
",https://stackoverflow.com/jobs/201510/data-engineer-streaming-technology-hadoop-zattoo
JOB170935419952,Senior Data Engineer - BlackLocus Jobs in Texas,Senior Data Engineer - BlackLocus Jobs in Texas,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/texas/usa/jobs/?utm_medium=.JOBS%20Universe&utm_campaign=.JOBS%20RSS%20Feed&vs=25&utm_source=.JOBS%20RSS%20Feed-DE
JOB173146777713,Data Engineer,Data Engineer,Experience with Agile Methodologies such as Scrum or Kanban,"Being a member of the Metareview team, you will be working in a cross-discipline delivery team focused on one of many core data products.,Gather and process raw data at scale using frameworks such as Hadoop MR and Spark.,Maintain and write new data processing pipelines handling hundreds of GB of data.,Optimize and improve existing features or data processes for performance and stability,Apply machine learning algorithms to improve our product and drive decisions,3+ years of experience building data intensive applications.,Very strong programming and architectural experience, ideally in Python, Java or Scala but we are open to other experience if you would like to become a Python hacker.,You find creative solutions to tough problems. You are not only a great developer, you are also an architect, who is not afraid to pave the way for bigger and better things.,Experience and skills to clean and scrub noisy datasets.,Experience building data pipelines and ETLs using MapReduce, Spark or Flink.,Expert-level knowledge in Python. Experience in frameworks such as Pandas, Scikit-learn, Scipy, Luigi / Airflow is a plus.,Love for the command line with optional affinity for Linux scripting,Experience with Big data technologies (Hadoop, Spark, Flink, Hive, Impala, HBase, Pig, Redshift, Kafka),Experience building scalable REST-APIs using Python or similar technologies.,Experience with data mining, machine learning, natural language processing, or information retrieval is a plus.,Experience with AWS or other IaaS/PaaS.","
Job description
Imagine a workplace which encourages you to take on responsibility and where your ideas will be heard and implemented. Imagine a fast paced environment where your performance makes the difference. This is TrustYou!
We are looking for adventurers to join our smart and inspiring team!
TrustYou creates summaries of hotel reviews, with the goal of being as useful, or more, than a summary written by humans. And it's our data engineers that make this happen!
As data engineer at TrustYou, you will be part of an international, talented and motivated team that uses their combined knowledge of machine learning, natural language processing and big data technologies to build the TrustYou Meta-Review.
You are the perfect candidate if you enjoy researching, prototyping and finetuning algorithms to solve novel problems. Our engineers are willing to walk the extra mile to make sure our solution is not only good, but great and beneficial for millions of travelers. You will systematically look for weaknesses and areas for improvement in our approaches, and will be motivated by them to create even better solutions.
TrustYou runs on Python. We employ both linguists and machine learning experts, who collaborate to build the best product possible. Our solutions need to scale to process all hotel reviews on the Internet. New projects are written in Apache Spark, while we also maintain a codebase of MapReduce jobs.
What challenges await you?
Being a member of the Metareview team, you will be working in a cross-discipline delivery team focused on one of many core data products.
Gather and process raw data at scale using frameworks such as Hadoop MR and Spark.
Maintain and write new data processing pipelines handling hundreds of GB of data.
Optimize and improve existing features or data processes for performance and stability
Apply machine learning algorithms to improve our product and drive decisions
What do we expect from you?
3+ years of experience building data intensive applications.
Very strong programming and architectural experience, ideally in Python, Java or Scala but we are open to other experience if you would like to become a Python hacker.
You find creative solutions to tough problems. You are not only a great developer, you are also an architect, who is not afraid to pave the way for bigger and better things.
Experience and skills to clean and scrub noisy datasets.
Experience building data pipelines and ETLs using MapReduce, Spark or Flink.
Good to have:
Expert-level knowledge in Python. Experience in frameworks such as Pandas, Scikit-learn, Scipy, Luigi / Airflow is a plus.
Love for the command line with optional affinity for Linux scripting
Experience with Big data technologies (Hadoop, Spark, Flink, Hive, Impala, HBase, Pig, Redshift, Kafka)
Experience building scalable REST-APIs using Python or similar technologies.
Experience with data mining, machine learning, natural language processing, or information retrieval is a plus.
Experience with AWS or other IaaS/PaaS.
Experience with Agile Methodologies such as Scrum or Kanban
",https://stackoverflow.com/jobs/142103/data-engineer-trustyou
JOB173150464078,Senior Data Engineer (Intelligence Platform),Senior Data Engineer (Intelligence Platform),,"Build ETL processes from 3rd party API integration to ingestion into our data store.,Research, design, and implement NLP functions such as keyword and named entity extraction.,Develop machine learning driven search ranking and recommendation algorithms.,Help diagnose/fix production issues as they arise.,Minimum of 3 years experience developing in a production environment.,Proficient in Python, Go, JVM based, or other server side languages.,Experience with NLTK, scikit-learn, or similar technologies.,Ability to research and implement solutions on your own.,Good testing habits.","
Job description
As a Senior Fullstack Engineer, on the data platform, your work building highly scalable data pipelines directly impacts the accuracy and performance of our search intelligence and recommendations platform.
Your Responsibilities
Build ETL processes from 3rd party API integration to ingestion into our data store.
Research, design, and implement NLP functions such as keyword and named entity extraction.
Develop machine learning driven search ranking and recommendation algorithms.
Help diagnose/fix production issues as they arise.
Your Experience
Minimum of 3 years experience developing in a production environment.
Proficient in Python, Go, JVM based, or other server side languages.
Experience with NLTK, scikit-learn, or similar technologies.
Ability to research and implement solutions on your own.
Good testing habits.
Life at Seva
Our mission stems from the rapid effects software and automation and are having on the way we work today. Did you know that the average knowledge worker uses 10 - 13 apps as part of their daily stack, and that we can spend up to 8 hours a week searching for, organizing, and verifying information? In an age where we using AI/ML based solutions to power a growing number of applications at work, we still can't extract valuable information stored in all of our cloud silos.
At Seva we are a small, but seasoned group of engineers, data scientists, and entrepreneurs. We're passionate about our mission to reimagine how the modern employee discovers and organizes information across our fragmented cloud stack at work.
By joining our small team in NYC you'll be guaranteed to work with some really smart, and passionate people - and given our size, every deploy will make a massive impact on our business. We look forward to meeting you, and learning from you too!
Joel Test
",https://stackoverflow.com/jobs/200900/senior-data-engineer-intelligence-platform-seva
JOB173193652313,Data Engineer - Hadoop,Data Engineer - Hadoop,We have a strong preference for someone experienced with Python rather than Java,"Explore new ways of transforming and analyzing data and continuously expand and improve the performance of our data pipelines.,Build prototypes, fast, and determine what their worth are in the business and within the infrastructure before iterating and improving them.,Work closely with Data Scientists and Product Managers to decide how best to structure and store data in order to make it easily accessible to business users.,Evaluate and develop highly distributed Big Data solutions; You will advance our software architecture and tool set to meet growing business requirements regarding performance and data-quality.,A Data Engineer who likes to experiment with and explore new tools and technologies. You will be familiar with tools in the Hadoop ecosystem including Spark, Kafka, Hive or similar.,You are a Software Engineer with experience in modern backend web technologies.,You know how to design and build low-maintenance, high performing ETL processes and Data pipelines.,You can communicate an idea clearly on various levels of abstraction, depending on the audience.,Professional experience with relational databases: reading, writing and optimizing complex statements.","
Job description
Our Data Story
With thousands of active lots every day, hundreds of thousands of daily bids, millions of users, and countless marketing campaigns, the Catawiki platform generates vast amount of data every day. This data is being collected and stored in the Data warehouse, which is used extensively by our team of 10 analysts and data scientists. There are also hundreds of active internal users of our Web interface to the Data warehouse.
As Catawiki grows and produces more data, our Analysts would like to perform even more sophisticated analyses, our Data Scientists want more data, and yes, Product owners want more dashboards! With this in mind, Catawiki is building a new distributed data platform using tools from the Hadoop ecosystem that can accommodate the rapidly growing amount of data and requirements of analysts, data scientists, and product owners.
We have started streaming event data and writing data pipelines in Apache Airflow that transform this data with Apache Spark, and now Catawiki needs more Data Engineers to help us tackle the challenge of bringing even more data sources into our platform and transforming and organizing this data for analysis and consumption by other applications. It’s a big challenge but one that we’re really excited about solving.
What you will do
Evolve our current infrastructure to a distributed system and help build scalable data pipelines using the Hadoop ecosystem. You will work in cooperation with our Software Engineers, Devops Engineers, Data Scientists and Product Managers to:
Explore new ways of transforming and analyzing data and continuously expand and improve the performance of our data pipelines.
Build prototypes, fast, and determine what their worth are in the business and within the infrastructure before iterating and improving them.
Work closely with Data Scientists and Product Managers to decide how best to structure and store data in order to make it easily accessible to business users.
Evaluate and develop highly distributed Big Data solutions; You will advance our software architecture and tool set to meet growing business requirements regarding performance and data-quality.
Who you are
A Data Engineer who likes to experiment with and explore new tools and technologies. You will be familiar with tools in the Hadoop ecosystem including Spark, Kafka, Hive or similar.
You are a Software Engineer with experience in modern backend web technologies.
You know how to design and build low-maintenance, high performing ETL processes and Data pipelines.
You can communicate an idea clearly on various levels of abstraction, depending on the audience.
Professional experience with relational databases: reading, writing and optimizing complex statements.
We have a strong preference for someone experienced with Python rather than Java
",https://stackoverflow.com/jobs/199278/data-engineer-hadoop-catawiki
JOB173198050362,"Senior Data Engineer - BlackLocus Jobs in Austin, TX","Senior Data Engineer - BlackLocus Jobs in Austin, TX",,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/austin/texas/usa/jobs/?utm_campaign=.JOBS%20RSS%20Feed&utm_source=.JOBS%20RSS%20Feed-DE&utm_medium=.JOBS%20Universe&vs=25
JOB173729753188,Senior Data Engineer,Senior Data Engineer,,"SQL. Teach us something new, show us what you’ve got,Python/Scala/C# You’ve coded before, you know the importance of efficient, clean code,Cloud – we use Azure,Someone who understands complex data and the challenges of accessing it,A real bottom-line person, not someone who throws terms like “big data” around because it’s popular,Traditional/relational databases, Lakes, or Pub/Subs make no difference to you,Database concepts – indexes, execution engines, etc,Database Administration experience (Azure DWH, SqlServer, Postgresql),You understand that databases are an integral part of being a Data Engineer,You like to ask questions and devise a complete solution,You want to understand the data (not only the pipes) and you can definitely perform some analytics and build dashboards because you like it.,You know that you don’t know enough, and it bothers you that there isn’t enough time in the day to learn about the next topic.,You’re up-to-date on new trends in data – you know who’s using what to solve various problems and are excited for the next release of your favorite tool,If you like being thrown in the deep end of the pool, this team’s for you.,You believe and want to participate in a blameless culture which focuses on process and technology,You don’t sleep well at night when you leave work with a question unanswered,You feel accountable for everything you do and that sense of urgency has been driving you your entire life,You like to have a good time while getting things done,When we say a “team player” we mean it - you have a crisp high-five and funny stories to tell,You have your team’s back. And the team has yours.,Sense of humor is hugely preferred","
Job description
We’re looking for data fanatics to join the A Team of engineers and analysts that are responsible for building Quadpay’s data infrastructure. We need people who understand data at a granular level – they don’t rely on any one tool but rather understand them all, and each of their pros and cons. This is a unique opportunity to build the data strategy and architecture at a data driven startup that’s changing the world of finance, shoulder to shoulder with a tight team that has your back.
You dream in code:
SQL. Teach us something new, show us what you’ve got
Python/Scala/C# You’ve coded before, you know the importance of efficient, clean code
You thrive in any data environment:
Cloud – we use Azure
Someone who understands complex data and the challenges of accessing it
A real bottom-line person, not someone who throws terms like “big data” around because it’s popular
Traditional/relational databases, Lakes, or Pub/Subs make no difference to you
You know databases inside and out:
Database concepts – indexes, execution engines, etc
Database Administration experience (Azure DWH, SqlServer, Postgresql)
You understand that databases are an integral part of being a Data Engineer
You enjoy looking at and solving big picture problems:
You like to ask questions and devise a complete solution
You want to understand the data (not only the pipes) and you can definitely perform some analytics and build dashboards because you like it.
You love learning new things:
You know that you don’t know enough, and it bothers you that there isn’t enough time in the day to learn about the next topic.
You’re up-to-date on new trends in data – you know who’s using what to solve various problems and are excited for the next release of your favorite tool
If you like being thrown in the deep end of the pool, this team’s for you.
You’re a culture fit:
You believe and want to participate in a blameless culture which focuses on process and technology
You don’t sleep well at night when you leave work with a question unanswered
You feel accountable for everything you do and that sense of urgency has been driving you your entire life
You like to have a good time while getting things done
When we say a “team player” we mean it - you have a crisp high-five and funny stories to tell
You have your team’s back. And the team has yours.
Sense of humor is hugely preferred
Technology is changing the way people interact with the world and we’re bringing that revolution to the way people shop and transact. We allow shoppers to buy anywhere, at anytime - and pay in 4 interest-free, automatic installments over 6 weeks. You get the product right away and QuadPay will pay the merchant upfront. We're looking for someone who can join our high-functioning team of passionate support professionals and we value a range of diverse backgrounds, experiences, and ideas. We pride ourselves on diversity and creating an inclusive workplace that provides equal opportunities to all persons regardless of age, race, color, religion, sex, sexual orientation, gender identity and expression, national origin, disability, military and/or veteran status, or any other protected classes. We're growing very quickly and always looking for talented people to join our team and help transform the way consumers shop and pay!
Life at Quadpay
About Quadpay
Our Mission
At QuadPay, our mission is to empower modern consumers with simple, transparent, and financially responsible payment tools.
We want to create a world where everyone has access to the things they need and want from life—and we’re always seeking talented, ambitious people to help us make this vision a reality.
Our Values
Put the customer first
Customer-centricity is in our DNA. Everything we build is simple and transparent.
Dare to try
Anyone can drive change. We channel curiosity, creativity, and passion to make it happen.
Execute with speed & precision
We have a bias for action, leaving no stone unturned.
Think and act as an owner
Every employee is a shareholder. We believe in our mission.
Be smart, stay humble
No egos or big personalities. Just smart people solving hard problems.
Enjoy the journey
We are building a business we believe in, and we’re having fun in the process.
Our Culture
A company is only as good as its employees—and at QuadPay, our team is second to none. As an organization, we are committed to maintaining a diverse and inclusive environment in which every employee can thrive.
Our sQuad is passionate, collaborative, and committed to growth.
Benefits
",http://stackoverflow.com/jobs/415728/senior-data-engineer-quadpay
JOB173940266497,Data Engineer,Data Engineer,,,"
Data Engineer
今すぐ応募する 採用情報 ID R1907861
Are you looking for a high energy team where you can make a direct contribution to envisioning and architecting next generation Data Analytics platform?
Are you looking to join a company with a vision to imagine, design, and create a better world who is also recognized as top places to work for in Silicon Valley?
Your next adventure at VMware is only a click away!
VMware's Data Analytics Team is looking for a Data Engineer to help build on Next generation Near Realtime BI Platform based on SAP HANA and Hadoop. You will be responsible for building and enhancing the solutions on the existing platform based on the business needs in partnering with fellow Developers and Business groups.
Responsibilities:
·Understand the business capability/requirements and transform them into robust design solutions
·Perform hands on work using Python, able to write complex SQL’s, understand API and be able to consume/write API’s as needed
·Perform report development using enterprise tools such as Tableau, SAP BOBJ and other open source reporting platforms.
·Perform hands on work using SAP HANA, Hadoop/HAWQ SDI/SLT, Informatica to build next generation NearRealTime data analytics platform.
·Integrate data sets from difference sources using Informatica, Python, SAP SDI/SLT
·Protect data integrity and accuracy. Perform root cause analysis of issues that hinder the data quality. Work with data source owner to increase quality and accuracy of the source data.
·Help data consumers to correctly understand and use the data.
·Building reports based on the business need.
Qualifications:
·5+ years of experience in as a BI/Data Engineer handling large volumes of data.
·Excellent knowledge of data warehouse technical architecture, infrastructure components, ETL/ELT and reporting/analytic tools.
·Expertise in writing advanced SQL queries.
·Experience working with Informatica, SAP SDI/SLT
·Expertise in SAP HANA, Hive/Hadoop/Hawq
·Working knowledge of BI Reporting tools like BOBJ and Tableau
·Experience in Python Scripting
·Familiarity with Amazon Web Services (AWS), Redshift is a plus
·Strong analytical and troubleshooting skills
·Excellent verbal and written communication skills
·Bachelor’s degree in Computer science, Statistics, Mathematics, Engineering or relevant field.
This position is eligible for the IT Apps Hiring FY20 referral campaign
VMware (NYSE: VMW) is the global leader in virtualization and cloud infrastructure, two areas that consistently rank as top priorities among CIOs. VMware delivers award-winning, customer-proven solutions that accelerate IT by reducing complexity and enabling more flexible, agile service delivery. Our solutions help organizations of all sizes, lower costs, increase business agility and ensure freedom of choice. We are searching for people who are ready to accelerate, innovate and lead to join our team of more than 20,000 employees in 40+ locations worldwide working to develop innovative solutions that deliver the future of IT through cloud computing. Having the audacity to challenge constraints and problem-solve for tomorrow starts today, and it starts with you. Learn more at www.vmware.com/careers
今すぐ応募する ",https://japan.careers.vmware.com/%e3%82%b8%e3%83%a7%e3%83%96/-/data-engineer/22639/12243798
JOB175250421263,"Senior Data Engineer, Cloud","Senior Data Engineer, Cloud",Gym membership compensation,"Drive design and implementation leveraging modern design patterns,Ability to partner effectively with UX, PM, DevOps, QE and other developers to design and implement meeting the spirit of requirements,Experience in modern front end frameworks,Technically curious to keep present on advances in technology,Experience with segregation of model, presentation, and business logic.,TDD experience and strong desire to build in test from the start.,Write code (Test or Product) to deliver against project timescales, quality and requirements in various languages including Java or other selected languages for Sophos Cloud products.,Provide guidance and mentorship to junior developers in daily Scrum meetings.,Possesses a passion for solving complex Big Data problems,Plan for, design and implement our next-generation cloud security products.,Be involved from inception through implementation in a real hands on fashion.,BS in Computer Science, Engineering, or equivalent with 7+ years of development and data modelling background,Building highly scalable SaaS solutions using Big Data technologies,Experience with CI/CD,Experience with Agile Software Development methodologies (scrum/ kanban),Excellent attention to detail,Excellent verbal and written communication skills,Experience with the following technologies (recommended) and strong desire to learn (required),Programming language -- Java (must)
Batch processing -- Hadoop ,MapReduce
Stream processing -- Kafka and Amazon Kinesis
NoSQL -S3 , MongoDB.
Columnar stores - HBASE, Amazon Redshift
Restful web services
Code/Build/Deployment -- git, hg, svn, maven, sbt, jenkins, bamboo, ...
Amazon Web Services
Data Warehousing/ built ETL,Programming language -- Java (must),Batch processing -- Hadoop ,MapReduce,Stream processing -- Kafka and Amazon Kinesis,NoSQL -S3 , MongoDB.,Columnar stores - HBASE, Amazon Redshift,Restful web services,Code/Build/Deployment -- git, hg, svn, maven, sbt, jenkins, bamboo, ...,Amazon Web Services,Data Warehousing/ built ETL,Medical insurance,Dental insurance,Vision insurance,Life insurance,Long-term disability insurance,401k plan,Vacation time","
At Sophos, we operate at the cutting edge of technology, protecting businesses worldwide against complex threats, viruses and spam. We build high quality software security products in a fast-paced, nimble environment and we've been doing it for over 20 years.
Join us to help our customers protect their business and meet compliance needs.
Role
To function as a senior data lead for product features or key technology choices and implementation. Collaborates as part of a team for the development of complex systems; including requirements analysis, concept development and design, implementation and testing, demonstrating flexibility of role as required
Main Duties
Drive design and implementation leveraging modern design patterns
Ability to partner effectively with UX, PM, DevOps, QE and other developers to design and implement meeting the spirit of requirements
Experience in modern front end frameworks
Technically curious to keep present on advances in technology
Experience with segregation of model, presentation, and business logic.
TDD experience and strong desire to build in test from the start.
Write code (Test or Product) to deliver against project timescales, quality and requirements in various languages including Java or other selected languages for Sophos Cloud products.
Provide guidance and mentorship to junior developers in daily Scrum meetings.
Possesses a passion for solving complex Big Data problems
Plan for, design and implement our next-generation cloud security products.
Be involved from inception through implementation in a real hands on fashion.
Experience And Skills
BS in Computer Science, Engineering, or equivalent with 7+ years of development and data modelling background
Building highly scalable SaaS solutions using Big Data technologies
Experience with CI/CD
Experience with Agile Software Development methodologies (scrum/ kanban)
Excellent attention to detail
Excellent verbal and written communication skills
Experience with the following technologies (recommended) and strong desire to learn (required)
Programming language -- Java (must)
Batch processing -- Hadoop ,MapReduce
Stream processing -- Kafka and Amazon Kinesis
NoSQL -S3 , MongoDB.
Columnar stores - HBASE, Amazon Redshift
Restful web services
Code/Build/Deployment -- git, hg, svn, maven, sbt, jenkins, bamboo, ...
Amazon Web Services
Data Warehousing/ built ETL
Benefits
In most cases, the compensation package includes:
Medical insurance
Dental insurance
Vision insurance
Life insurance
Long-term disability insurance
401k plan
Vacation time
Gym membership compensation
",https://www.sophos.com/es-es/about-us/careers/united-states/senior-data-engineer-cloud.aspx
JOB176051356716,"Senior Data Engineer - BlackLocus Jobs in Austin, TX","Senior Data Engineer - BlackLocus Jobs in Austin, TX",,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/austin/texas/usa/jobs/?utm_source=.JOBS%20RSS%20Feed-DE&utm_campaign=.JOBS%20RSS%20Feed&vs=25&utm_medium=.JOBS%20Universe
JOB178684373082,Scientific Computing Lead - Data Engineer,Scientific Computing Lead - Data Engineer,"A Bachelor’s degree in computer science, information technology, or other quantitative field.,5 or more years of relevant experience, ideally in a scientific computing environment.,Ability to design informative and accessible technical training materials.,Proven deep technical background including Linux administration.,Ability to work in a demanding environment with minimal supervision.,Strong track record of implementing cloud-based processing techniques.,Administration experience with Azure, AWS, Google Cloud or one of the other major IaaS providers. Google Cloud Platform preferred.,A passion for data science including knowledge of at least one high-level programming language. Python and/or R are preferred.,Familiarity with database usage and basic administration tasks. PostgreSQL preferred.,Experience leveraging established distributed computing frameworks such as Apache Spark and Hadoop.,Experience handling large volumes of spatiotemporal data.","Provide technical leadership and training to all staff.,Work closely with scientific teams to streamline scientific computing workflows for cloud computing environments.,Design, develop, and deliver scalable data management and processing architectures.,Optimize and support our existing private cloud agreement.,Manage our public cloud billing and resource usage at the project level.,Identify technology gaps/risks and establish mitigation strategies.,Generate metrics to facilitate an understanding of computational strategies and efficiency.,Maintain and optimize custom software stack.,Setup, training, and orientation for new users.,Write tutorials and lead training sessions on programming and data management best practices.,Attend workshops, conferences, and scientific field expeditions to build further expertise as well as rapport with scientific staff.,Remain up to date with cutting edge methods and proactively work to implement them at WHRC.","
At the Woods Hole Research Center our mission is to advance scientific discovery and seek science-based solutions for the world’s environmental and economic challenges through research and education. We have been named the world's #1 climate change think tank for four years in a row. We require state of the art computing systems for our scientists to meet that need. We seek an experienced scientific computing lead to manage its public and private cloud resources. The successful candidate will work closely with our scientists to optimize their processing workflows. This is not your typical technical position. This role is integral to WHRC’s mission of investigating the causes and effects of climate change. The ideal candidate will have passions for both high performance computing and climate solutions. Time away from the desk to travel for workshops and scientific field expeditions will be an integral and rewarding part of this position. Building a close relationship with scientific teams will be paramount to success. We would like this individual to begin as soon as possible.
Responsibilities:
Provide technical leadership and training to all staff.
Work closely with scientific teams to streamline scientific computing workflows for cloud computing environments.
Design, develop, and deliver scalable data management and processing architectures.
Optimize and support our existing private cloud agreement.
Manage our public cloud billing and resource usage at the project level.
Identify technology gaps/risks and establish mitigation strategies.
Generate metrics to facilitate an understanding of computational strategies and efficiency.
Maintain and optimize custom software stack.
Setup, training, and orientation for new users.
Write tutorials and lead training sessions on programming and data management best practices.
Attend workshops, conferences, and scientific field expeditions to build further expertise as well as rapport with scientific staff.
Remain up to date with cutting edge methods and proactively work to implement them at WHRC.
Desired Qualifications and Experience:
A Bachelor’s degree in computer science, information technology, or other quantitative field.
5 or more years of relevant experience, ideally in a scientific computing environment.
Ability to design informative and accessible technical training materials.
Proven deep technical background including Linux administration.
Ability to work in a demanding environment with minimal supervision.
Strong track record of implementing cloud-based processing techniques.
Administration experience with Azure, AWS, Google Cloud or one of the other major IaaS providers. Google Cloud Platform preferred.
A passion for data science including knowledge of at least one high-level programming language. Python and/or R are preferred.
Familiarity with database usage and basic administration tasks. PostgreSQL preferred.
Experience leveraging established distributed computing frameworks such as Apache Spark and Hadoop.
Experience handling large volumes of spatiotemporal data.
Classification and Compensation: This is a full-time, salaried, exempt position. WHRC offers a competitive salary as well as a very generous benefit package. Salary is negotiable.
",https://stackoverflow.com/jobs/194613/scientific-computing-lead-data-engineer-woods-hole-research-center
JOB179096897265,data engineer jobs,data engineer jobs,,,"
",http://www.indeed.com/jobs?q=data%20engineer&indpubnum=6943489856182715&chnl=9653_DataEngineer
JOB182250832944,Senior Data Engineer - BlackLocus Jobs in Texas,Senior Data Engineer - BlackLocus Jobs in Texas,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/texas/usa/jobs/?utm_medium=.JOBS%20Universe&utm_source=.JOBS%20RSS%20Feed-DE&vs=25&utm_campaign=.JOBS%20RSS%20Feed
JOB183487530007,"Data Engineer Jobs in Houston, TX","Data Engineer Jobs in Houston, TX",,"Houston, TX","
Data Engineer Jobs in Houston, TX
Current Search Criteria
More
",https://militaryjobs.homedepot.com/data-engineer/jobs-in/houston/texas/usa/jobs/?utm_campaign=.JOBS%20RSS%20Feed&utm_medium=.JOBS%20Universe&utm_source=.JOBS%20RSS%20Feed-DE&vs=25
JOB183912498900,Sr HL7 Data Engineer,Sr HL7 Data Engineer,,,"Senior HL7 Data Engineer
Lincoln, NE
NRC Health helps you understand the people you care for with greaterclarity, immediacy, and depth. NRC Health has helped healthcare organizationsilluminate and improve the moments that matter to patients,residents, physicians, nurses, and staff for 35 years. Our empatheticheritage, proprietary methods, and holistic approach enable our partners tobetter understand the people they care for and design experiences that inspireloyalty and trust.
Position Description:
You willbe joining the technical team responsible for the design & implementationof a multi-tenant SaaS (Software-as-a-Service) platform for real-time feedbackof patients. The entire platform runs on AWS (Amazon Web Services) and is beingrefactored to fully embrace the serverless architecture of AWS. The platformalso leverages latest BigData technologies, such as HDFS/Spark/Vertica forfaster data processing, and a leading business intelligence platform, TableauSoftware, for accelerated development of reporting & analytics.
The seniorHL7 data engineer is responsible for all engineering & technical supportactivities on our HL7 module as serves thousands of customers. You will workwith our scrum-based team and will be involved in all aspects of the HL7-relatedsoftware development process including architecture, design, andimplementation. As a senior technical member of the team, you will providearchitecture/design guidance and mentorship to junior team members.
Your ability to autonomously& proactively lead all aspects of the HL7-related software developmentprocess will be a critical requirement.
Your Day to Day:
Proactively work with product owners &customer HL7 implementation personnel to define & refine product featurerequirements Lead the architecture and design for theteam to not only meet product requirements but also horizontal scalability& long-term maintainability balancing time vs. scope Personally responsible for producingexemplary quality & scalable code and delivering features on-time throughtest review and analysis, test witnessing and certification of software Proactively participate in the testingprocess Design foroperational feasibility by evaluating analysis, problem definition,requirements, solution development, and proposed solutions. Documents anddemonstrates solutions by developing documentation, flowcharts, layouts,diagrams, charts, code comments and clear code Maintaingood communication with other part of organizations outside of engineering tofoster good collaboration on resolution of operational issues Proactiveautonomy aligned to business needs with minimum supervision is critical
What You Bring to the Team:
Deep understanding & experience ofimplementing HL7 v2.x ADT inbound interface for multiple hospitals into asingle standardized data destination Minimum of 5+ years of experienceworking in HL7 implementation including HL7 v2.x implementation guide authoring inbound HL7 interface data analysis forat least ADT messages development of HL7 data/event mappingusing COTS (Commercial-Off-The-Self) HL7 interface engines such as MirthConnect, Interfaceware Iguana, OrionHealth Rhapsody, Microsoft Biztalk, etc. integration with downstream databasesusing ETL technologies such as Microsoft SSIS, Pentaho Kettle, etc. interacting with Hospital-side and/orHospital-vendor HL7 technical staff to implement HL7 exchange Proven ability to take business requirementsas input, transform them into software solutions and deliver those solutions Track record of delivering high qualitytechnical results within the committed time parameters 8+ years experience working on aprofessional development team Strong understanding of data structures and algorithms Expertise in programming language likeJavascript, C#, Java, etc. Expertise in developing backend servicecomponents and/or message-based applications Exposue to WebServices & REAST APIis a huge plus 5+ years of experience in databasedesign and development is required Experience designing, developing, andtuning in RDBMS (such as Microsoft SQL Server, MySQL, Oracle, DB2, etc) Strong understanding of relationaldatabase structures, theories, principles, and queries (SQL) Expertability to autonomously install, configure, administer, upgrade andtroubleshoot all software needed for development Experienceimplementing outbound HL7 v2.x interface is a plus Bachelors Degree in ComputerScience, MIS, IT, Engineering, or related field or equivalentexperience with pertinent certifications Experience working in a collaborativeenvironment using agile methodology Strong communication skills, verbal andin writing Experience in healthcare industry,either working for providers or payers, is a plus
Why NRC Health
At NRC Health, cultureis everything. Its at the heart of what we do for our associates, clients,community, and industry. And our work is driven with a purpose to betterhealthcare for everyone.
As an associate at NRC Health, you willexperience:
A performance-oriented, results-driven culture Opportunities for travel Beautiful downtown working environment Flexible working hours Paid time off - four weeks (20 days) annually Dress for your day attire Community involvement opportunities Wellness program
",http://www.indeed.com/viewjob?jk=df507dca4ce23a85&qd=4CyXsCX_0WT_LZeoRpX9XGN4LEEoNOpq3Ld001kmZarpCsxvEWWmPBpP5Pi8D8wO9dMjeBexh9fquwhrTOlw35CHCCBZRkS8e03k5wO0A9s&indpubnum=9914042147182748&chnl=websearch&atk=1bf7e11n75u4k8b1
JOB186079560766,Data Engineer Jobs in United States,Data Engineer Jobs in United States,,,"
Current Search Criteria
More
",https://militaryjobs.homedepot.com/data-engineer/jobs-in/usa/jobs/?utm_medium=.JOBS%20Universe&utm_campaign=.JOBS%20RSS%20Feed&utm_source=.JOBS%20RSS%20Feed-DE&vs=25
JOB186807243820,Big Data Engineer (Sr.) Consultant,Big Data Engineer (Sr.) Consultant,"Master’s degree in areas like Mathematics, Physics, Computer Science, Engineering or Econometrics, Business Analytics, or Information Management,Minimum 3+ years of hands on relevant Big Data technologies or implementations,Experienced in distributed computing, distributed storage, and containerisation; Spark/PySpark, Kafka, SQL & NoSQL (e.g., Elastic, Hive, BigQuery, Kafka KTables, AWS S3), Docker, Kubernetes,Experienced in programming with Python or Scala and familiar with micro services development (REST API’s/IoT),Fluent in English. Fluent Dutch is a strong preference, but not mandatory,Good business communication skills, able to transform business requirements into use cases,A flexible transport arrangement that suits your personal situation (electric car or bicycle, flexible budget including NS business card)",,"
Job Description
Disrupt the way the world works by using your skills to transform Accenture clients in the digital businesses of tomorrow. Unleash your talent and bring business closer to the people they serve via cutting edge digital solutions developed by you. Leave your digital mark on the world.
Does the world of Big Data excite you? Do you want to help our clients become high performance and data-driven businesses? If so, we would love to meet you!
Your job
As a Big Data Engineer Consultant, you will be part of the Strategy & Consulting team in Amsterdam. You will work directly with our clients in the Netherlands and sometimes also abroad to advise them from a business and technology perspective on how to become data driven and implement the fantastic opportunities that big data can bring. Your work can vary from advice on the Big Data platform they need to work on, including defining the solution architecture, to building scalable, streaming Big Data solutions making use of state of the art technologies.
As part of your day to day activities, you will be working with the largest Big Data vendors in the world, cool innovative start-ups in the Big Data space, and the top clients in the Netherlands and abroad.
Your team
The everchanging pace of market developments will only continue to accelerate in the future – and many organizations struggle to challenge new innovative competition within the market. How do different innovations influence the market, what are the results and how can companies adapt themselves to remain agile in the future?
Accenture Strategy & Consulting is the driving force in helping companies answer such questions. You will advise C-level management in their strategic blueprints – based on data analysis, experience, expertise and an innovative approach. Together with a diverse team of experts, you will challenge current industry obstacles and find the key solution for clients in their current markets: Surpassing the disruption through our end-to-end services, consolidating future success for organizations.
Qualifications
Your background
Master’s degree in areas like Mathematics, Physics, Computer Science, Engineering or Econometrics, Business Analytics, or Information Management
Minimum 3+ years of hands on relevant Big Data technologies or implementations
Experienced in distributed computing, distributed storage, and containerisation; Spark/PySpark, Kafka, SQL & NoSQL (e.g., Elastic, Hive, BigQuery, Kafka KTables, AWS S3), Docker, Kubernetes
Experienced in programming with Python or Scala and familiar with micro services development (REST API’s/IoT)
Fluent in English. Fluent Dutch is a strong preference, but not mandatory
Good business communication skills, able to transform business requirements into use cases
Our offer
Accenture is an incredible place to work - and keep learning. By joining us, you’ll become part of a global company with a world-class brand and reputation. Besides the work we do for our clients, we’re really proud of our vibrant, diverse workplace culture: we take an agile approach, provide end-to-end services and maintain a realistic mindset. We want to get to know the real you and help you explore and grow - whatever it is you're great at. So, you will always have lots of learning opportunities (formal and informal) to improve your role-specific skills and expertise.
Besides our high-profile, challenging projects and our nurturing work environment, we offer excellent employee benefits, including:
A flexible transport arrangement that suits your personal situation (electric car or bicycle, flexible budget including NS business card)
Interested?
Are you ready to join Accenture for a career where you can be yourself and do what you love? Apply now and change the world around you.
Questions? Connect with Mieke Ronda, mieke.ronda@accenture.com.
",https://www.accenture.com/nl-en/careers/jobdetails?id=00522946_en&title=Big+Data+Engineer+(Sr.)+Consultant
JOB186824271822,Backend\Data Engineer - Wix Answers,Backend\Data Engineer - Wix Answers,,"Experience with Event Sourcing concepts and stream processing (Kafka / Flink etc).,An excellent understanding of database systems, relational and otherwise, including sharding for big data applications.,Build data pipeline based on Kafka Streams applications and Kafka Connect to create a real time feed to Snowflake.,Model domain events for a complex business domain.,Stream both domain events and materialized state to snowflake.","(0/300)
We are:
The Wix Answers team. Wix Answers is a customer support platform developed and built in-house to support our over 200 million users. Recently, Wix started selling its customer support platform to SMBs and enterprise companies that want to create better customer experiences for their brands. Wix Answers is just one piece of the innovative, cloud-based web development products that has made Wix’s value more than $16 billion.
You are:
Backend/Data engineer with experience in Scala and Domain Modeling. You’re passionate, proactive, never taking the present state for granted and always striving to understand why things are done the way they are. You’re a clean coder with readable, simple, and maintainable code. You recognize bad code and continuously search for better solutions.
You quickly grasp large & complex systems and their inner workings. You’re experienced with software engineering best practices (testing, code reviews, immutability, etc) and are aware of bad practices and anti-patterns. You’re deeply familiar with the tools, libraries, and frameworks that you’ve worked with and able to debug and investigate production issues.
You’re able to cope with and translate business requirements, with an understanding of how they can be implemented within the event sourcing domain. You care about data and how the business application generates it. You understand the difference between domain events and materialized state and how each is used to generate insight and answer different business questions. You can work on a data pipeline starting from the backend application, streaming it to a data warehouse, transforming it and making it available for business analysis.
It would be advantageous if you had:
Experience with Event Sourcing concepts and stream processing (Kafka / Flink etc).
An excellent understanding of database systems, relational and otherwise, including sharding for big data applications.
Willingness to dive deep into both technical and business aspects of a system.
As a Data Engineer, you will:
Build data pipeline based on Kafka Streams applications and Kafka Connect to create a real time feed to Snowflake.
Model domain events for a complex business domain.
Stream both domain events and materialized state to snowflake.
Apply your event sourcing knowledge to handle data pipeline challenges such as late arriving data; run backfill of historical data to recreate the domain events; and run periodic aggregation and stream the results back to Kafka to drive complex reactive applications.
",https://www.wix.com/jobs/locations/tel-aviv/positions/3827
JOB188015704333,Senior Big Data Engineer,Senior Big Data Engineer,,,"Glassdoor has millions of jobs plus salary information, company reviews, and interview questions from people on the inside making it easy to find a job that’s right for you.
Copyright © 2008–2019, Glassdoor, Inc. ""Glassdoor"" and logo are proprietary trademarks of Glassdoor, Inc.
","https://www.glassdoor.com/job-listing/senior-big-data-engineer-homeaway-JV_IC1128808_KO0,24_KE25,33.htm?jl=2982107223"
JOB189130687536,"Data Engineer Jobs in Houston, TX","Data Engineer Jobs in Houston, TX",,"Houston, TX","
Data Engineer Jobs in Houston, TX
Current Search Criteria
More
",https://militaryjobs.homedepot.com/data-engineer/jobs-in/houston/texas/usa/jobs/?utm_source=.JOBS%20RSS%20Feed-DE&vs=25&utm_medium=.JOBS%20Universe&utm_campaign=.JOBS%20RSS%20Feed
JOB189396468091,"Data Engineer, Decision Sciences","Data Engineer, Decision Sciences","Minimum 5 years of experience with a programming language such as Scala, R, Python or Java, and the experience writing reusable and efficient code to automate analyses and data processes,Minimum 2 years of experience processing large amounts of structured and unstructured data in a cluster-computing environment or similar experience in academia,Interested candidates must submit a resume/CV through www.nbcunicareers.com to be considered,Must be willing to work in New York, NY,Experience formulating opinions on constructing data processing systems and good knowledge of the principles of systems at scale using big data technologies, like Spark, Hive, Impala, Hadoop, and Databricks,Good understanding of AWS, Azure and other cloud technologies including AWS services, such as Athena, Glue, S3, and Lambda,Experience with open source and Enterprise software,Experience building and maintaining production data pipelines,Familiarity with relational databases and SQL,Team-oriented and collaborative approach with a demonstrated aptitude and willingness to learn new methods and tools,Ability to communicate insights and findings through data visualization tools such as Tableau, DOMO, Shiny,Ability to work effectively across functions, disciplines, and levels,Experience in media and entertainment industry a plus,Experience with television ratings and digital measurement tools (Nielsen, Rentrak, comScore, Omniture, etc.),Familiarity with NoSQL and Graph databases,Experience with large-scale video assets,Experience with computer vision and metadata generation from video,Master’s Degree with a specialization in Computer Science, Engineering, Physics or other quantitative field or equivalent","Partner with various NBCU Technology teams in the design and execution of an overall Corporate Data Syndication Strategy for Nielsen and Alternative Measurement Data,Process structured and unstructured data into a form suitable for analysis and reporting, empowering state-of-the-art analytics and machine learning environments for business analysts, data scientists and engineers,Operationalize data science models and products in a cluster-computing environment,Evangelize a very high standard of quality, reliability and performance for data models and algorithms that can be streamlined into the engineering and sciences workflow,Manage multiple priorities across a mix of ad-hoc and operational projects","
Data Engineer, Decision Sciences
Location: New York, New York
Function: Sales & Business Development
Specialty: Business Development, Planning & Strategy
Level: Manager (Supervisor)
Duration: Full Time
Salary Description: competitive
As part of the Enterprise Business Intelligence organization at NBCUniversal, the Decision Science team helps drive ""the art of the possible"" for advanced analytics by building and integrating pragmatic data science principles and products throughout the Company. The Team focuses primarily on decision science analyses to support and inform strategy and key business decisions and building advanced data products to help enable more data-enhanced decision support. The Data Engineer will be directly responsible for data pipelines, data management, development, operationalizing of machine learning models, and scaling out platforms and products.
Responsibilities
Partner with various NBCU Technology teams in the design and execution of an overall Corporate Data Syndication Strategy for Nielsen and Alternative Measurement Data
Process structured and unstructured data into a form suitable for analysis and reporting, empowering state-of-the-art analytics and machine learning environments for business analysts, data scientists and engineers
Operationalize data science models and products in a cluster-computing environment
Evangelize a very high standard of quality, reliability and performance for data models and algorithms that can be streamlined into the engineering and sciences workflow
Manage multiple priorities across a mix of ad-hoc and operational projects
Basic Qualifications
Minimum 5 years of experience with a programming language such as Scala, R, Python or Java, and the experience writing reusable and efficient code to automate analyses and data processes
Minimum 2 years of experience processing large amounts of structured and unstructured data in a cluster-computing environment or similar experience in academia
Fine Print for Eligibility
Interested candidates must submit a resume/CV through www.nbcunicareers.com to be considered
Must be willing to work in New York, NY
Desired Qualifications
Experience formulating opinions on constructing data processing systems and good knowledge of the principles of systems at scale using big data technologies, like Spark, Hive, Impala, Hadoop, and Databricks
Good understanding of AWS, Azure and other cloud technologies including AWS services, such as Athena, Glue, S3, and Lambda
Experience with open source and Enterprise software
Experience building and maintaining production data pipelines
Familiarity with relational databases and SQL
Team-oriented and collaborative approach with a demonstrated aptitude and willingness to learn new methods and tools
Ability to communicate insights and findings through data visualization tools such as Tableau, DOMO, Shiny
Ability to work effectively across functions, disciplines, and levels
Experience in media and entertainment industry a plus
Experience with television ratings and digital measurement tools (Nielsen, Rentrak, comScore, Omniture, etc.)
Familiarity with NoSQL and Graph databases
Experience with large-scale video assets
Experience with computer vision and metadata generation from video
Master’s Degree with a specialization in Computer Science, Engineering, Physics or other quantitative field or equivalent
At NBCUniversal, we believe in the talent of our people. It’s our passion and commitment to excellence that drives NBCU’s vast portfolio of brands to succeed. From broadcast and cable networks, news and sports platforms, to film, world-renowned theme parks and a diverse suite of digital properties, we take pride in all that we do and all that we represent. It’s what makes us uniquely NBCU. Here you can create the extraordinary. Join us.
NBCUniversal’s policy is to provide equal employment opportunities to all applicants and employees without regard to race, color, religion, creed, gender, gender identity or expression, age, national origin or ancestry, citizenship, disability, sexual orientation, marital status, pregnancy, veteran status, membership in the uniformed services, genetic information, or any other basis protected by applicable law. NBCUniversal will consider for employment qualified applicants with criminal histories in a manner consistent with relevant legal requirements, including the City of Los Angeles Fair Chance Initiative For Hiring Ordinance, where applicable.
We are one of the world’s leading media and entertainment companies in the development, production, and marketing of entertainment, news and information to a global audience.
Work With Us
",https://www.mediabistro.com/jobs/description/379646/data-engineer-decision-sciences/
JOB189572891675,"Senior Data Engineer - BlackLocus Jobs in Austin, TX","Senior Data Engineer - BlackLocus Jobs in Austin, TX",,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/austin/texas/usa/jobs/?utm_medium=.JOBS%20Universe&utm_source=.JOBS%20RSS%20Feed-DE&utm_campaign=.JOBS%20RSS%20Feed&vs=25
JOB189861790776,Senior Data Engineer - BlackLocus Jobs in Texas,Senior Data Engineer - BlackLocus Jobs in Texas,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/texas/usa/jobs/?utm_source=.JOBS%20RSS%20Feed-DE&utm_campaign=.JOBS%20RSS%20Feed&vs=25&utm_medium=.JOBS%20Universe
JOB190406170161,Staff II SRE Data Engineer - Data Scientist,Staff II SRE Data Engineer - Data Scientist,"Extensive experience in software development with expertise in architecting and delivering new technologies and product features at scale in highly reliable cloud services.,Experience developing scalable SaaS monitoring, automation, and logging solutions for highly reliable service offerings.,Prior technical paper publications and public speaking engagements.,Extensive software development experience in one or more of the following C, JAVA, C++, and Python. Experience doing so across Windows and Linux is a plus.,Strong algorithmic and problem solving skills,Distributed systems experience,Ability to see and present ""the big picture"" and offer solutions to make it better.,An extraordinarily intelligent, rigorous thinker who can operate successfully among very bright and charismatic people.,Strong customer facing and relationship building skills,You are effective in working both independently and in a team setting,Ability to uncover business challenges and develop custom solutions to solve those challenges,15+ years of work experience in technology industry","Architecture design, and development experience around SaaS and platform software.,Routine involvement in high level architectural and design discussions providing authoritative technical guidance.,Experience delivering technical collateral including architecture and design documents, technical case studies, conference papers and whitepapers.,Demonstrated track record of successful customer and external engagement driving influence through deep technical product and industry knowledge.,Seasoned working with fellow senior engineers, architects, product management, senior management, and other partners to define the technical roadmap for the product in response to requirements.","
Staff II SRE Data Engineer - Data Scientist
今すぐ応募する 採用情報 ID R1910132
Staff II SRE Data Engineer - Data Scientist
Are you interested in solving complex technical challenges? Do you like working with new technology? We are looking for a Senior Data Engineer - Data Scientist to drive the overall data engineering architecture, data and analytics road map, and tool integration with the SRE platforms and tools for the VMC on AWS service. As a successful Senior Data Engineer - Data Scientist you will be a creative and seasoned engineering leader with 10+ years architecting, implementing, and delivering complex data technologies. You should have experience leading strategic architecture development, and are able to make bold recommendations on key product innovations and investments in the context of a rapidly evolving technology sector. You will provide guidance and roadmaps for the SRE monitoring, automation, service optics, and service health platforms by providing a data and analytics strategy and implementation . You will develop data models and analytics for Reliability engineering across the VMC service and SRE services.
You will possess the following experience:
Architecture design, and development experience around SaaS and platform software.
Routine involvement in high level architectural and design discussions providing authoritative technical guidance.
Experience delivering technical collateral including architecture and design documents, technical case studies, conference papers and whitepapers.
Demonstrated track record of successful customer and external engagement driving influence through deep technical product and industry knowledge.
Seasoned working with fellow senior engineers, architects, product management, senior management, and other partners to define the technical roadmap for the product in response to requirements.
Ability and willingness to become a hands-on engineer as necessary.
Qualifications and Experience:
Extensive experience in software development with expertise in architecting and delivering new technologies and product features at scale in highly reliable cloud services.
Experience developing scalable SaaS monitoring, automation, and logging solutions for highly reliable service offerings.
Prior technical paper publications and public speaking engagements.
Extensive software development experience in one or more of the following C, JAVA, C++, and Python. Experience doing so across Windows and Linux is a plus.
Strong algorithmic and problem solving skills
Distributed systems experience
Ability to see and present ""the big picture"" and offer solutions to make it better.
An extraordinarily intelligent, rigorous thinker who can operate successfully among very bright and charismatic people.
Strong customer facing and relationship building skills
You are effective in working both independently and in a team setting
Ability to uncover business challenges and develop custom solutions to solve those challenges
15+ years of work experience in technology industry
Excellent communication skills, both written and oral are required
Education:
Technical undergraduate Computer Science and/or Electrical Engineering degree required and an advanced degree would be highly desirable.
Position Summary
VMware Cloud on AWS is an on-demand service that enables you to run applications across vSphere-based cloud environments with access to a broad range of AWS services. Powered by VMware Cloud Foundation, this service integrates vSphere, vSAN and NSX along with VMware vCenter management, and is optimized to run on dedicated, elastic, bare-metal AWS infrastructure. With this service, IT teams can manage their cloud-based resources with familiar VMware tools. The VMC SRE organization provides the platforms and services that enables the monitoring, automation, and service optics for the engineering, PM, and CSM teams.For more information: https://cloud.vmware.com/vmc-aws
This position is eligible for the DiversifyCPBU referral campaign
今すぐ応募する ",https://japan.careers.vmware.com/%e3%82%b8%e3%83%a7%e3%83%96/-/staff-ii-sre-data-engineer-data-scientist/22639/12907645
JOB192003483766,Senior Data Engineer,Senior Data Engineer,"Experience with large-scale data and query optimization techniques,Experience with ETL to data warehouse systems,Experience with AWS cloud services: EC2, RDS, Redshift, AuroraExpert in SQL, NoSQL, and RDBMS,Knowledge in multiple scripting languages (e.g. Python),Knowledge of cloud, distributed systems, and stream-processing systems,Passionate about learning new technologies and solving hard problems in a fast-paced environment,Has a Computer Science degree,Has 5+ years experience in enterprise SaaS environments,Is a ""student of the game"" and thrives on new challenges,Enjoys learning from teammates, and isn't afraid to teach others at the same time,Sees the glass half-full. This is a new industry space...your vision could make all the difference!,Wants to make a lasting impact and lifelong connections, this is not just another paycheck","Design systems that reliably and efficiently provide interactive query performance on large amounts of multi-modal data,Build systems that handle scale,Build the infrastructure required for optimal extraction, transformation, and loading of data from a variety of data sources using SQL and AWS ‘big data’ technologies,Collect, parse, analyze, and visualize large sets of data,Turn data into insights,Create data tools for analytics and data scientist team members that assist them in building and optimizing our product","
Job description
SocialChorus is a platform for communicators. We help them become heroes within their organizations by giving them the tools and expertise they need to unify their enterprises. Companies thrive and win when all of their workers feel aligned, informed and supported. In simple terms, we help companies work as one.
Joining SocialChorus means joining a movement where every worker matters. This movement has taken root and is evident in our world-class customer base and their millions of employees worldwide. Now we need your help to achieve our goal of connecting every worker. Ready to make a difference?
We are currently seeking a Senior Data Engineer to help elevate our communications platform which is being used by the largest companies in the world in some of the most technically complex environments you can find. You will architect and design “big data” systems which require queries returning within sub-second response times. Ready for a challenge?
We are a distributed team. We build solutions for distributed workforces so we model our workforce the same way. In this role you really can work where you want, but for this role we are only considering candidates based in the United States (US citizens and green card holders only please).
Responsibilities
Design systems that reliably and efficiently provide interactive query performance on large amounts of multi-modal data
Build systems that handle scale
Build the infrastructure required for optimal extraction, transformation, and loading of data from a variety of data sources using SQL and AWS ‘big data’ technologies
Collect, parse, analyze, and visualize large sets of data
Turn data into insights
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product
Qualifications
Experience with large-scale data and query optimization techniques
Experience with ETL to data warehouse systems
Experience with AWS cloud services: EC2, RDS, Redshift, AuroraExpert in SQL, NoSQL, and RDBMS
Knowledge in multiple scripting languages (e.g. Python)
Knowledge of cloud, distributed systems, and stream-processing systems
Passionate about learning new technologies and solving hard problems in a fast-paced environment
The ideal fit...
Has a Computer Science degree
Has 5+ years experience in enterprise SaaS environments
Is a ""student of the game"" and thrives on new challenges
Enjoys learning from teammates, and isn't afraid to teach others at the same time
Sees the glass half-full. This is a new industry space...your vision could make all the difference!
Wants to make a lasting impact and lifelong connections, this is not just another paycheck
Why SocialChorus? Because you care. About people, the work you do, and the connections you make. Work is such a large part of life, it only makes sense to make it awesome. If you want to engage brilliant minds in a true start-up environment where ideas are rewarded regardless of who they come from, join us. This is a rapidly changing space so if you thrive on ambiguity, are hungry for a challenge, and have the guts to speak your mind it could be a perfect fit. Come for the challenges, come for engaging people in a casual and friendly environment. Come for the unlimited PTO, the health benefits, the 401k plan, the annual retreats (including family), the twice-a-year hackathons, the 10% exploratory time, the ability to contribute to open source, and the potential to work from anywhere. Whatever the reason you come to SocialChorus, your new co-workers along with a leadership team who truly believes in your growth both professionally and personally will keep you here.
",http://stackoverflow.com/jobs/385231/senior-data-engineer-socialchorus
JOB193427466354,Data Engineer (f/m/d),Data Engineer (f/m/d),"CI/CD (Drone, Gitlab CI)","As a Data Engineer (f/m/d) at real.digital, you act as an important interface between our DevOps, Data Science and software development divisions,You develop scalable applications and systems for processing structured and unstructured data,You deal comprehensively with many different data-related topics and have the right ideas for every situation: Whether it's data exchange between microservices, processing huge amounts of data for recommender models, or lightning-fast, interactive business intelligence applications, we have the right solution,You have a university degree in (business) informatics or a comparable field of study,You have a very high capacity for abstraction, a sound algorithmic understanding and affinity for working with data,Ideally, you have experience in some of the following technologies and, as an autodidact, you are prepared to quickly familiarise yourself with the other technological forms:
with containers (docker and kubernetes)
Database systems (MySQL, MongoDB, BigQuery, etc.)
Management and automation of infrastructure (Linux, Networking, Cloud Services, Terraform)
Software development (Python, Java)
CI/CD (Drone, Gitlab CI),with containers (docker and kubernetes),Database systems (MySQL, MongoDB, BigQuery, etc.),Management and automation of infrastructure (Linux, Networking, Cloud Services, Terraform),Software development (Python, Java)","
Job description
Your tasks – this is what awaits you in detail
As a Data Engineer (f/m/d) at real.digital, you act as an important interface between our DevOps, Data Science and software development divisions
You develop scalable applications and systems for processing structured and unstructured data
You deal comprehensively with many different data-related topics and have the right ideas for every situation: Whether it's data exchange between microservices, processing huge amounts of data for recommender models, or lightning-fast, interactive business intelligence applications, we have the right solution
Your profile – this is what we expect from you
You have a university degree in (business) informatics or a comparable field of study
You have a very high capacity for abstraction, a sound algorithmic understanding and affinity for working with data
Ideally, you have experience in some of the following technologies and, as an autodidact, you are prepared to quickly familiarise yourself with the other technological forms:
with containers (docker and kubernetes)
Database systems (MySQL, MongoDB, BigQuery, etc.)
Management and automation of infrastructure (Linux, Networking, Cloud Services, Terraform)
Software development (Python, Java)
CI/CD (Drone, Gitlab CI)
",http://stackoverflow.com/jobs/395470/data-engineer-f-m-d-realdigital
JOB194181022768,"Data Engineer Jobs in Houston, TX","Data Engineer Jobs in Houston, TX",,"Houston, TX","
Data Engineer Jobs in Houston, TX
Current Search Criteria
More
",https://militaryjobs.homedepot.com/data-engineer/jobs-in/houston/texas/usa/jobs/?utm_campaign=.JOBS%20RSS%20Feed&vs=25&utm_source=.JOBS%20RSS%20Feed-DE&utm_medium=.JOBS%20Universe
JOB194319746068,Senior Data Engineer - BlackLocus Jobs in Texas,Senior Data Engineer - BlackLocus Jobs in Texas,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/texas/usa/jobs/?utm_source=.JOBS%20RSS%20Feed-DE&utm_medium=.JOBS%20Universe&utm_campaign=.JOBS%20RSS%20Feed&vs=25
JOB195009327784,What do I need to know to get an entry-level data engineer job?,What do I need to know to get an entry-level data engineer job?,,,"I am not sure what you are describing is what I would consider to be the path of being a data engineer. Statistics is great but that relates more directly to a data scientist than an engineer. Do you have any background in software engineering? I would start with clearly defining your career goals, skills you are currently working on, skills you already have, etc. Also, check out sites that define what the role would entail like: Data Science vs Data Engineering
Once you gather that data, crunch the numbers and see where you are and then work to improve any deficiencies. Also, you will want to begin showing your aptitude for the field by participating in forums discussing your chosen subject, get another internship specifically in the field, essentially you need to prove you have what it takes to succeed in the field then opportunities will arise.
",https://www.quora.com/What-do-I-need-to-know-to-get-an-entry-level-data-engineer-job
JOB197300109300,Data Engineer,Data Engineer,Tuition reimbursement and learning & development programs,"Work with a team of engineers to create products that will directly affect the mission of Healthgrades,Develop data pipeline features to process incoming healthcare information quickly and reliably,Review other team members' code for correctness and quality,Write automated test scripts that power a continuous delivery pipeline,Refactor and improve the existing code base for simplicity and clarity,Remove roadblocks to development through collaboration, communication, and creative solution recommendations,Recommend and drive development best practices and continuous integration and delivery as part of a forward-thinking, agile organization,3+ years of experience developing data pipelines or ETLs,3+ years of experience in Python, Scala or Java,Knowledge of HL7 a plus,Proficiency with Apache Spark, Databricks, and Alteryx is required,Strong understanding of SQL, relational databases, columnar data warehouses, and data modeling,Knowledge of TDD, automated testing principles, and testing best practices,Ability to instrument basic automation and CI/CD including a familiarity with Jenkins/Git,Strong familiarity with cloud based services (AWS) and container technologies (Docker/Kubernetes),Client facing experience a plus,Previous experience with micro services architecture and API gateways is a plus,Knowledge (and experience) designing and building distributed systems for scalability and security,A bias towards self-education of new technologies, techniques and methods,Test-and-learn mentality – you pivot quickly when an approach is not successful,Keen attention to detail, eye for design and understanding the value of collaboration with UX/creative and product teams,Purpose-Driven Business – we help people make more confident healthcare decisions,Changing the Game – dynamic, employee-focused culture with career advancement opportunities,Community Builders – partners of local charity organizations, matching gifts program, Go-Green efforts, and wellness initiatives,Salary: $101K - $128K annually*,Bonus: up to 5% annually,401(k) plan options,Medical, dental, and vision insurance, with HSA contributions for qualifying plans,Company-funded basic Life, AD&D, and disability coverage,Family planning resources,Subsidized wellness benefits,PTO plus paid holiday and volunteer time","Tech
Data Engineer
Healthgrades is focused on providing trusted information that helps consumers and providers make meaningful connections. As a Data Engineer, you will be building the future of Healthgrades’ enterprise data solutions, enabling health systems, hospitals and providers to better reach those consumers who are seeking care.
The Healthgrades enterprise data platform will enable health systems to create a holistic patient view, eliminate data silos, and improve patient experience. This enterprise platform will bring together once disparate data into a single platform, breaking down data silos and making data more useful across an entire organization. The Healthgrades data platform will also serve as the underlying data management solution for powering Healthgrades CRM and other customer experience execution systems while enabling health systems to reach beyond traditional efforts to improve and manage patient experience and patient engagement.
If you are a technologist and your idea of fun is to play with the latest technology, while delivering a world-class product designed from scratch, you will fit right in.
What You Will Do:
Work with a team of engineers to create products that will directly affect the mission of Healthgrades
Develop data pipeline features to process incoming healthcare information quickly and reliably
Review other team members' code for correctness and quality
Write automated test scripts that power a continuous delivery pipeline
Refactor and improve the existing code base for simplicity and clarity
Remove roadblocks to development through collaboration, communication, and creative solution recommendations
Recommend and drive development best practices and continuous integration and delivery as part of a forward-thinking, agile organization
What You Will Bring:
3+ years of experience developing data pipelines or ETLs
3+ years of experience in Python, Scala or Java
Knowledge of HL7 a plus
Proficiency with Apache Spark, Databricks, and Alteryx is required
Strong understanding of SQL, relational databases, columnar data warehouses, and data modeling
Knowledge of TDD, automated testing principles, and testing best practices
Ability to instrument basic automation and CI/CD including a familiarity with Jenkins/Git
Strong familiarity with cloud based services (AWS) and container technologies (Docker/Kubernetes)
Client facing experience a plus
Previous experience with micro services architecture and API gateways is a plus
Knowledge (and experience) designing and building distributed systems for scalability and security
A bias towards self-education of new technologies, techniques and methods
Test-and-learn mentality – you pivot quickly when an approach is not successful
Keen attention to detail, eye for design and understanding the value of collaboration with UX/creative and product teams
Why Healthgrades?
At Healthgrades, we recognize that our people drive our greatest achievements. We are passionate about maintaining a fulfilling, rewarding and high-energy work environment while setting the stage for your continued success.
Purpose-Driven Business – we help people make more confident healthcare decisions
Changing the Game – dynamic, employee-focused culture with career advancement opportunities
Community Builders – partners of local charity organizations, matching gifts program, Go-Green efforts, and wellness initiatives
Compensation & Benefits
Salary: $101K - $128K annually*
Bonus: up to 5% annually
401(k) plan options
Medical, dental, and vision insurance, with HSA contributions for qualifying plans
Company-funded basic Life, AD&D, and disability coverage
Family planning resources
Subsidized wellness benefits
PTO plus paid holiday and volunteer time
Tuition reimbursement and learning & development programs
*Actual base pay will be determined based on qualifications and experience
",https://www.sitepoint.com/jobs/healthgrades/data-engineer
JOB199314112510,Senior Data Engineer,Senior Data Engineer,Professional Development Program,"Work with an architect to design and own how data flows through our business, soup to nuts, working collaboratively across the company to partner with all departments.,Manage an efficient data platform to support our products as well as a BI function using modern, low maintenance cloud technologies (AWS or GCP), as well as cleanly interfacing with our existing data science research technologies.,Evolve a sophisticated data model to consume structured data from a growing set of source systems (scanners, VI feeds, etc).,Author and maintain entity-relationship diagrams, data dictionaries, API specs, and data translation documentation at multiple levels of abstraction (conceptual, logical, physical) and across multiple data store technologies (relational, NoSQL).,Implement solutions to proactively monitor data quality with traceability to source systems.,Work with cross functional product development teams on data modeling rules, standards, and best practices, embedding when needed.,BS in Computer Science, Computer Engineering or related industry experience.,You have a product oriented, cloud first perspective on data.,You have strong experience with distributed compute along with ETL/ELT and BI architectures using public cloud technologies, concepts and frameworks, especially around streaming of big data.,Strong, proven data modeling experience at large scale.,5+ years experience with large-scale, distributed data pipelines, as well as data management, modeling, and storage,3+ years building large scale data processing and analytical systems in GCP or AWS with Dataproc, Airflow, BigQuery, Dataflow, Kafka, etc.,Competitive compensation package,Medical, Dental, Vision & Disability Insurance,Wellness Programs,Pet Insurance,Retirement Planning,Company Equity,Generous Paid Parental Leave,Work From Home Setup,Employee Referral Program,Discretionary Time Off,Friendly & Casual Environment,Work/Life Balance","Senior Data Engineer
NOTE: Kenna will not consider or accept resumes from external recruiters for this job posting. Kenna will not be responsible for any fees related to unsolicited resumes.
Kenna Security is revolutionizing cyber risk with a SaaS-based platform that uses data science to combine vulnerability data with exploit intelligence to measure risk, predict attacks and prioritize remediation. We are leading the way in helping enterprises reduce their risk while increasing their efficiency and preventing attacks. Kenna Security was recently named one of the top 10 hottest start-ups and named to the Inc. 500 fastest growing companies list.
About You
We’re looking for a Senior Data Engineer to jump into our data platform with an eye towards a well-tested, secure and performant product. If you’re comfortable in working within a highly autonomous, agile, and iterative software development process; Kenna might be the fit for you! This position is an opportunity for an engineer to join a growing engineering team and contribute to the maintenance, expansion, and scale of the Kenna data platform. Engineers are expected to take ownership of technical problems, craft solutions to complex problems, and craft code that meets our internal standards for maintainability and best practices. Our applications are widely used across the industry and your work will be used by millions of people every month.
About Us
There are a lot of security companies out there, but no one is doing what Kenna is doing: giving our customers the ability to measure their risk landscape and truly protect their environments from the ever-present threat of a breach. As a result, we’re seeing phenomenal growth as some of the top companies in the world flock to our platform. We have solid venture funding, an astonishing team who will support you to accomplish the impossible, and we even offer great benefits and stock options.
What are some of the interesting problems you'll be working on:
Work with an architect to design and own how data flows through our business, soup to nuts, working collaboratively across the company to partner with all departments.
Manage an efficient data platform to support our products as well as a BI function using modern, low maintenance cloud technologies (AWS or GCP), as well as cleanly interfacing with our existing data science research technologies.
Evolve a sophisticated data model to consume structured data from a growing set of source systems (scanners, VI feeds, etc).
Author and maintain entity-relationship diagrams, data dictionaries, API specs, and data translation documentation at multiple levels of abstraction (conceptual, logical, physical) and across multiple data store technologies (relational, NoSQL).
Implement solutions to proactively monitor data quality with traceability to source systems.
Work with cross functional product development teams on data modeling rules, standards, and best practices, embedding when needed.
What does it take to work at Kenna:
BS in Computer Science, Computer Engineering or related industry experience.
You have a product oriented, cloud first perspective on data.
You have strong experience with distributed compute along with ETL/ELT and BI architectures using public cloud technologies, concepts and frameworks, especially around streaming of big data.
Strong, proven data modeling experience at large scale.
5+ years experience with large-scale, distributed data pipelines, as well as data management, modeling, and storage
3+ years building large scale data processing and analytical systems in GCP or AWS with Dataproc, Airflow, BigQuery, Dataflow, Kafka, etc.
At Kenna you can enjoy the following:
Competitive compensation package
Medical, Dental, Vision & Disability Insurance
Wellness Programs
Pet Insurance
Retirement Planning
Company Equity
Generous Paid Parental Leave
Work From Home Setup
Employee Referral Program
Discretionary Time Off
Friendly & Casual Environment
Work/Life Balance
Professional Development Program
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex or national origin.
",https://www.sitepoint.com/jobs/kenna-security/senior-data-engineer
JOB199847209066,Data Engineer,Data Engineer,,,"
This site uses cookies to deliver our services and to show you relevant ads and job listings. By using our site, you acknowledge that you have read and understand our Cookie Policy, Privacy Policy, and our Terms of Service. Your use of Stack Overflow’s Products and Services, including the Stack Overflow Network, is subject to these policies and terms.
",https://stackoverflow.com/jobs/developer-jobs-using-airflow?f=cp
JOB201609642315,Data Engineer - Contributed Research,Data Engineer - Contributed Research,"Knowledge of Tableau, QlikSense or similar technologies.","Gain exposure to investment research content acquisition. You'll learn how we get it, how we selectively distribute it, and how our customers discover it.,Learn about our customers, product offerings, and operational best practices.,Proactively partner with internal customers and utilize business intelligence to help spot trends, identify gaps and opportunities.,Ensure content is delivered to Bloomberg in the optimized fashion.,Own implementation of new content projects from start to finish.,Collaborate with content providers to suggest areas of improvements as it relates to headline composition, tagging and content positioning to our mutual clients.,Build influential and meaningful working relationships.,Develop a complete understanding of our problems by being deeply embedded with our business teams, meeting clients and data contributors and learning how the world's largest financial data operation works.,Be empowered to solve business problems through quantifiable objectives, with the freedom to design workflows and select the right technologies for the job.,Write code to develop robust and scalable technology solutions for data management problems using modern micro services, databases and user interface technology through test-driven and iterative processes.,A BA/BS degree or higher in Engineering, Information Systems, Mathematics, or relevant data technology field, or equivalent experience.,Up to two years of professional work experience in information technology, engineering, or data analysis.,Minimum 2 years of production level coding, with advanced Python programming proficiency outside of academia.,Aptitude for problem solving, particularly to modify and enhance processes and workflows.,Communication, communication, communication! (Especially when explaining technical processes and solutions to customers internally and externally).,System design skills with competency both in back-end and UI.,Passion for data, and the know-how to wrangle large amounts of data.,Knowledge of tests, linting and version control.,Willingness to be outside of your comfort zone, and adaptability.,A can-do attitude with intellectual curiosity.,Ability to legally work in the US without visa sponsorship.,Understanding of the financial markets, in particular sell-side content distribution.","
Data Engineer - Contributed Research
Posted: 10/13/2019 | Expires: 12/31/2019
Location: New York, New York
Function: Creative & Design
Specialty: Creative
Level: Experienced (Non-Manager)
Duration: Full Time
Salary Description: competitive
At Bloomberg, our products are fueled by powerful information. We combine data and context to paint the whole picture for our clients, around the clock – from around the world. In Global Data, we're responsible for delivering this data, news and analytics through innovative technology - quickly and accurately.
Our team is at the forefront of designing, building and supporting the systems that power the contribution of research content to the Bloomberg platform. We partner closely with our team of technical account managers, content specialists, research contributors and business stakeholders to deliver creative software tools and solutions every day. This is not just any python development role! Your multifaceted abilities and efforts will help us on-board new providers in diverse markets around the globe, and empower content acquisition professionals to identify new possibilities and opportunities for research data content.
What's the role?
We have an exciting opportunity for an astute technical and client oriented professional like you, to join our New York team. This Python development role is supported by a unique three month market experience program working in our research contributions team. This will allow you to get first-hand experience with all the challenges faced by our research business. Through this program, you will become fully equipped with the knowledge necessary to take full end to end ownership of identifying problems in the contributed research space through data analysis and product discovery techniques. This will lead you to design and build systems using modern Python in a micro- services architecture that solve these problems and enable you to directly realize a significant and measurable impact to the business.
For the first three months, you will:
Gain exposure to investment research content acquisition. You'll learn how we get it, how we selectively distribute it, and how our customers discover it.
Learn about our customers, product offerings, and operational best practices.
Proactively partner with internal customers and utilize business intelligence to help spot trends, identify gaps and opportunities.
Ensure content is delivered to Bloomberg in the optimized fashion.
Own implementation of new content projects from start to finish.
Collaborate with content providers to suggest areas of improvements as it relates to headline composition, tagging and content positioning to our mutual clients.
Build influential and meaningful working relationships.
After this rotation, we'll trust you to:
Develop a complete understanding of our problems by being deeply embedded with our business teams, meeting clients and data contributors and learning how the world's largest financial data operation works.
Be empowered to solve business problems through quantifiable objectives, with the freedom to design workflows and select the right technologies for the job.
Write code to develop robust and scalable technology solutions for data management problems using modern micro services, databases and user interface technology through test-driven and iterative processes.
As a valued member of our team, you'll need to have:
A BA/BS degree or higher in Engineering, Information Systems, Mathematics, or relevant data technology field, or equivalent experience.
Up to two years of professional work experience in information technology, engineering, or data analysis.
Minimum 2 years of production level coding, with advanced Python programming proficiency outside of academia.
Aptitude for problem solving, particularly to modify and enhance processes and workflows.
Communication, communication, communication! (Especially when explaining technical processes and solutions to customers internally and externally).
System design skills with competency both in back-end and UI.
Passion for data, and the know-how to wrangle large amounts of data.
Knowledge of tests, linting and version control.
Willingness to be outside of your comfort zone, and adaptability.
A can-do attitude with intellectual curiosity.
Ability to legally work in the US without visa sponsorship.
We'd love to see:
Understanding of the financial markets, in particular sell-side content distribution.
Knowledge of Tableau, QlikSense or similar technologies.
Does this sound like you?
Apply! We'll get in touch and let you know the next steps.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.
Bloomberg is an information leader in providing high-quality, real-time and historical data to business and financial professionals worldwide. We have been at the leading edge of the information revolution that has changed the way problems get solved.
Work With Us
",https://www.mediabistro.com/jobs/description/405255/data-engineer-contributed-research/
JOB202149824231,Big Data Engineer,Big Data Engineer,Do you have strong communication skills and the ability to present deep technical findings to a business audience?,"Distributed file systems and storage technologies (HDFS, HBase, Accumulo, Hive).,Large-scale distributed data analytic platforms and compute environments (Spark, Map/Reduce).,A hands-on engineering position responsible for supporting client engagements for Big Data engineering and planning.,A solid platform for you to drive the engineering/design decisions needed to achieve cost-effective and high performance result.,Thinking out of the box on improvements to current processes & enhancing existing platform.,You have a formal background and proven experience in engineering, mathematics and computer science, particularly within the financial services sector.,You have hands on Programming/Scripting Experience (Python, Java, Scala, Bash).,DevOps Tools (Chef, Docker, Puppet, Bamboo, Jenkins).,Linux/Windows (Command line). An understanding of Unix/Linux including system administration and shell scripting.,You gave proficiency with Hadoop v2, MapReduce, HDFS, Spark.,Management of Hadoop cluster, with all included services.,You have good knowledge of Big Data querying tools, such as Pig, Hive, Impala and Spark.,Data Concepts (ETL, near-/real-time streaming, data structures, metadata and workflow management).,You have the ability to function within a multidisciplinary, global team. Be a self-starter with a strong curiosity for extracting knowledge from data and the ability to elicit technical requirements from a non-technical audience.,Collaboration with team members, business stakeholders and data SMEs to elicit, translate, and prescribe requirements. Cultivate sustained innovation to deliver exceptional products to customers.,Do you have experience with integration of data from multiple data sources?","Big Data Engineer # 115238
115238
Credit Suisse is a leading global wealth manager with strong investment banking and asset management capabilities. Founded in 1856, Credit Suisse has expanded to be a global force employing over 45,000 people in 50 countries. With new leadership, a new strategy and a streamlined global organization, we are set for growth. We partner across businesses, divisions and regions to create innovative solutions to meet the needs of our clients—and to help our employees grow. It is a high priority for us to continually invest in our employees by providing ongoing opportunities for training, networking and mobility. Join us and let's shape the future of Credit Suisse together.
We Offer
We are seeking talented, experienced big data engineer to join a growing, high-visibility cross-Bank team that is developing and deploying solutions to some of Credit Suisse’s most challenging analytic and big data problems. As a member of this team, you will work with clients and data spanning Credit Suisse’s global organization to solve emerging mission-critical challenges via the utilization of emerging technologies such as:
Distributed file systems and storage technologies (HDFS, HBase, Accumulo, Hive).
Large-scale distributed data analytic platforms and compute environments (Spark, Map/Reduce).
Tools for semantic reasoning and ontological data normalization (RDF, SPARQL, Tamr).
The role offers:
A hands-on engineering position responsible for supporting client engagements for Big Data engineering and planning.
A solid platform for you to drive the engineering/design decisions needed to achieve cost-effective and high performance result.
Thinking out of the box on improvements to current processes & enhancing existing platform.
You will be part of a global team of Big Data engineers who are engineering the platform and innovating in core areas of big data, real time analytics and large-scale data processing.
Credit Suisse maintains a Working Flexibility Policy, subject to the terms as set forth in the Credit Suisse United States Employment Handbook.
You Offer
You have a formal background and proven experience in engineering, mathematics and computer science, particularly within the financial services sector.
You have hands on Programming/Scripting Experience (Python, Java, Scala, Bash).
DevOps Tools (Chef, Docker, Puppet, Bamboo, Jenkins).
Linux/Windows (Command line). An understanding of Unix/Linux including system administration and shell scripting.
You gave proficiency with Hadoop v2, MapReduce, HDFS, Spark.
Management of Hadoop cluster, with all included services.
You have good knowledge of Big Data querying tools, such as Pig, Hive, Impala and Spark.
Data Concepts (ETL, near-/real-time streaming, data structures, metadata and workflow management).
You have the ability to function within a multidisciplinary, global team. Be a self-starter with a strong curiosity for extracting knowledge from data and the ability to elicit technical requirements from a non-technical audience.
Collaboration with team members, business stakeholders and data SMEs to elicit, translate, and prescribe requirements. Cultivate sustained innovation to deliver exceptional products to customers.
Do you have experience with integration of data from multiple data sources?
Do you have strong communication skills and the ability to present deep technical findings to a business audience?
",https://www.indeed.com/viewjob?jk=c27bd3c4cf611352
JOB202774889482,"Senior Data Engineer - BlackLocus Jobs in Austin, TX","Senior Data Engineer - BlackLocus Jobs in Austin, TX",,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/austin/texas/usa/jobs/?utm_medium=.JOBS%20Universe&utm_campaign=.JOBS%20RSS%20Feed&vs=25&utm_source=.JOBS%20RSS%20Feed-DE
JOB203059676201,Senior Data Engineer - BlackLocus Jobs in United States,Senior Data Engineer - BlackLocus Jobs in United States,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/usa/jobs/?utm_medium=.JOBS%20Universe&vs=25&utm_campaign=.JOBS%20RSS%20Feed&utm_source=.JOBS%20RSS%20Feed-DE
JOB203654834281,Senior Data Engineer,Senior Data Engineer,Bachelor degree or equivalent experience,"Live by and champion our values: #day-one, #ownership, #empathy, #humility.,Hands-on leadership, influence, and development of all things data services.,Develop modern data architectural approaches for business intelligence reporting and analytics, including that for machine learning models and data science, ensuring effectiveness, scalability, and reliability.,Design, develop, implement, and optimize existing ETL processes that merge data from disparate sources for consumption by data analysts and scientists, business owners, and decisions makers.,Complete current evaluation of new ETL software options, propose recommendations, and implement the solution.,Facilitate data transformation, normalization, cleansing, aggregation, workflow management, and business rule application.,Detect data quality issues, identify their root causes, implement fixes, and design data audits to capture issues.,Distill technical requirements into the product development and operational process via continuous collaboration with product, engineering, and analytics team members.,Influence and communicate with all levels of stakeholders including analysts, developers, business users, and executives.,Use analytics to influence product development, surfacing data around product usage and customer behavior.,ETL tool evaluation and implementation to prepare for scaling and efficiency.,Typically, 6+ years experience in a data engineering related role (Data Warehouse Developer, ETL Developer, Business Intelligence Analytics, Software Engineer) with a track record of manipulating, processing and extracting value from datasets,Experience working with a variety of ETL platforms (Matillion {preferred}, CloverETL, FiveTran, Stitch, DBT, Spark, AWS Glue, DataFlow),3+ years of hands-on experience designing and building ETL pipelines for ingesting, transforming and delivery of large amounts of data, from multiple sources into a Data Warehouse/Data Lake.,Experience with a variety of data storage platforms (Snowflake {preferred}, Redshift, MySQL, Postgres, Oracle, RDS),Expert proficiency in SQL,Deep understanding and application of modern data processing technology and real-time/low-latency data pipeline and ETL architectures,Strong stakeholder interaction and influence experience at executive, business stakeholder, and engineering team levels","
Job description
Overview
The centralized Data and Analytics team at ReCharge delivers critical analytic capabilities and insights that drive definition and implementation of our business strategies. The Data Engineer opportunity is ideal for someone who is passionate about wrangling and building pipelines for multiple large sets of data from disparate sources to provide end to end data solutions, empowering the organization to meet key business objectives.
As a Senior Data Engineer, you will own and architect Recharge’s data landscape. You will combine product usage, behavioral, transactional, business systems, and third-party data into the analytics pipeline. You will work closely with our analytics and engineering teams to implement solutions to answer complex questions and drive business decisions.
What You'll Do
Live by and champion our values: #day-one, #ownership, #empathy, #humility.
Hands-on leadership, influence, and development of all things data services.
Develop modern data architectural approaches for business intelligence reporting and analytics, including that for machine learning models and data science, ensuring effectiveness, scalability, and reliability.
Design, develop, implement, and optimize existing ETL processes that merge data from disparate sources for consumption by data analysts and scientists, business owners, and decisions makers.
Complete current evaluation of new ETL software options, propose recommendations, and implement the solution.
Facilitate data transformation, normalization, cleansing, aggregation, workflow management, and business rule application.
Detect data quality issues, identify their root causes, implement fixes, and design data audits to capture issues.
Distill technical requirements into the product development and operational process via continuous collaboration with product, engineering, and analytics team members.
Influence and communicate with all levels of stakeholders including analysts, developers, business users, and executives.
Use analytics to influence product development, surfacing data around product usage and customer behavior.
ETL tool evaluation and implementation to prepare for scaling and efficiency.
What You'll Bring
Typically, 6+ years experience in a data engineering related role (Data Warehouse Developer, ETL Developer, Business Intelligence Analytics, Software Engineer) with a track record of manipulating, processing and extracting value from datasets
Experience working with a variety of ETL platforms (Matillion {preferred}, CloverETL, FiveTran, Stitch, DBT, Spark, AWS Glue, DataFlow)
3+ years of hands-on experience designing and building ETL pipelines for ingesting, transforming and delivery of large amounts of data, from multiple sources into a Data Warehouse/Data Lake.
Experience with a variety of data storage platforms (Snowflake {preferred}, Redshift, MySQL, Postgres, Oracle, RDS)
Expert proficiency in SQL
Deep understanding and application of modern data processing technology and real-time/low-latency data pipeline and ETL architectures
Strong stakeholder interaction and influence experience at executive, business stakeholder, and engineering team levels
Bachelor degree or equivalent experience
",http://stackoverflow.com/jobs/446786/senior-data-engineer-recharge-payments
JOB203663886040,Senior+ Data Engineer,Senior+ Data Engineer,"Roughly 5 (or more!) years of Industry experience on a data or machine learning team,Proficiency with modern programming languages (Go, Python, Java, Scala, etc.) and SQL,Some practical experience with probability, statistical modeling, or machine learning,Backend developer experience optimizing the data access layer in mature web applications,Experience building and working with real-time compute and streaming infrastructures (Kafka, Kinesis, Flink, Storm, Beam, etc.),Experience writing and debugging ETL jobs using a distributed data framework.,A deep and abiding appreciation for agile software processes, data-driven development, reliability, and responsible experimentation,A collaborative attitude and a helpful personality,Health, dental, vision, and life insurance,401k matching program,Commuter benefits,Catered lunch and unlimited snacks,Unlimited reimbursement for work related books","Enable data scientists to train and deploy machine learning algorithms at scale, in fault-tolerant, highly-available systems,Use best practices in continuous integration and delivery with Docker and Kubernetes.,Work closely with application engineers to build data products that power Carta’s core applications,Create data pipelines using batch and streaming tools like Airflow, Spark, Kafka, and Google Pub/Sub,Uphold our engineering standards and bring consistency to the many codebases and processes you will encounter","Reasons could include: the employer is not accepting applications, is not actively hiring, or is reviewing applications
Carta is hiring experienced data engineers at the Senior, Staff, Senior Staff, and Principal levels in San Francisco, Palo Alto, Seattle, and New York City to build products and services powered by the ownership graph: the central registry of asset ownership across the globe.
As a data engineer at Carta, you’ll play a foundational role on Carta’s fast-growing Data & Machine Learning organization, working on one of the world’s most valuable data sets. You’ll spend two thirds of your time working on data engineering and backend software projects, and split the remaining third between DevOps, data science, and machine learning.
Candidates must have strong technical skills, be excited by “zero to one” projects, and enjoy working closely with stakeholders across engineering, product, business, and marketing.
Enable data scientists to train and deploy machine learning algorithms at scale, in fault-tolerant, highly-available systems
Use best practices in continuous integration and delivery with Docker and Kubernetes.
Work closely with application engineers to build data products that power Carta’s core applications
Create data pipelines using batch and streaming tools like Airflow, Spark, Kafka, and Google Pub/Sub
Uphold our engineering standards and bring consistency to the many codebases and processes you will encounter
Roughly 5 (or more!) years of Industry experience on a data or machine learning team
Proficiency with modern programming languages (Go, Python, Java, Scala, etc.) and SQL
Some practical experience with probability, statistical modeling, or machine learning
Backend developer experience optimizing the data access layer in mature web applications
Experience building and working with real-time compute and streaming infrastructures (Kafka, Kinesis, Flink, Storm, Beam, etc.)
Experience writing and debugging ETL jobs using a distributed data framework.
A deep and abiding appreciation for agile software processes, data-driven development, reliability, and responsible experimentation
A collaborative attitude and a helpful personality
Carta is creating the ownership network that maps the world's assets. Check out who we are and how we work here.
At Carta we want to create an environment for Carta's owners - you - to do your best work, by offering competitive benefits and perks:
We are committed to WELLNESS:
Health, dental, vision, and life insurance
Competitive PTO and unlimited sick time
401k matching program
Commuter benefits
Catered lunch and unlimited snacks
Cell phone stipend
Unlimited reimbursement for work related books
Fast paced work environment geared towards professional growth
Carta is backed by many of the best investors in the world, including Social Capital (Slack, Intercom, Box), Union Square Ventures (Twitter, Twilio, Coinbase), Menlo Ventures (Uber, Warby Parker), Spark Capital (Oculus VR, Slack, Cruise Automation), Meritech Capital (GoFundMe, Looker, Snowflake), and Tribe Capital.
","http://www.indeed.com/viewjob?t=Senior+Data+Engineer&c=Carta&l=Seattle,+WA&jk=03886c626b0d7055&rtk=1d6u5i1k7b7pe800&from=rss"
JOB203883079785,Data Engineer,Data Engineer,"AWS, Docker, Kubernetes, Terraform, Vault","Design, implement, and maintain scalable data pipelines,Collaborate with domain experts and analysts to solve data challenges,Develop advanced data reporting and visualizations,Apply data modelling methodologies and contribute to a robust data platform,Master’s degree in Computer Science or equivalent,Experience with SQL and relational databases,Experience with one or more programming languages (Python or Java preferred),Strong understanding of data models (Data Vault and Kimball) and data warehouses in general,Fluent in English, Dutch not required,Python, Pentaho Data Integration (with custom components developed in Java),Snowflake, MongoDB, PostgreSQL, Tableau,Spark, Elastic MapReduce, Snowplow, Kinesis","
Job description
Picnic is an app-only supermarket. We rely on our Data Engineers to glean insights from large data sets and promote business intelligence. Working with next-generation technologies they write the future of in-app grocery ordering. We’re on a quest for new Data Engineers to join our all-star team.
🏦 Where you fit in
Picnic is data-driven. As one of our engineers, you play a critical role in each aspect of our business. From route planning, delivery of groceries, to analyzing supply chains. You ensure that each level of our operation is supported, adjusted, and predicted with data.
There are no two ways about it – you’re a Data Wizard or Witch. While manipulating data, you bring out detailed information and quirky insights. You find what others can’t and glean business opportunity from numbers. Collaborating with our analysts, you find practical solutions to persistent problems.
By working towards a reliable data pipeline, you allow the team to mine and crunch data. You analyse, experiment, and promote statistics that pique your interest. Do you think you've spotted how to ensure our large fleet of electric vehicles is used in the most efficient way? Test, evaluate, and evolve your ideas alongside our dedicated Distribution team.
More interested in customer behavior? That’s fine – work on in-app analytics to ensure our mobile store remains smooth, speedy, and robust. You have the opportunity to work on what you love while writing the future of in-app grocery shopping!
We’re using the Snowplow Framework to improve our store. If you want more motivation to apply, check out this case study here.
🔥 What challenges await you
Design, implement, and maintain scalable data pipelines
Collaborate with domain experts and analysts to solve data challenges
Develop advanced data reporting and visualizations
Apply data modelling methodologies and contribute to a robust data platform
👉🏼 Who you are
Master’s degree in Computer Science or equivalent
Experience with SQL and relational databases
Experience with one or more programming languages (Python or Java preferred)
Strong understanding of data models (Data Vault and Kimball) and data warehouses in general
Fluent in English, Dutch not required
👩‍💻 Technologies you'll use
Python, Pentaho Data Integration (with custom components developed in Java)
Snowflake, MongoDB, PostgreSQL, Tableau
Spark, Elastic MapReduce, Snowplow, Kinesis
AWS, Docker, Kubernetes, Terraform, Vault
Hungry for more? Check out https://stackshare.io/picnic-technologies for an overview of our tech stack.
",http://stackoverflow.com/jobs/166957/data-engineer-picnic
JOB204049934439,Senior Data Engineer,Senior Data Engineer,High quality swag,"Own technical design and project execution for the team, delegating work to other engineers on the team while also making individual engineering contributions,Lead technical development of distributed data infrastructure and search application in collaboration with ML+NLP collaborators,Push the boundaries of search with the latest technologies and methods,Scale our platform to billions of documents and drive millions of searches,Make hands-on engineering contributions to Grata with a focus on overcoming technical challenges and modeling practices that improve quality and velocity,Mentor engineers on the team through activities like pairing and code reviews to promote a culture of technical excellence,Collaborate with other teams across Grata to steward a coordinated strategy,8+ years of experience as a software engineer, developing web applications, large scale data pipelines, and scalable infrastructure,1+ years of experience in a team lead role,You know how to work with data-centric distributed systems, and are comfortable supporting microservice and serverless architectures,Experience collaborating with ML practitioners to build data and analytical systems,Experience with Python, Django, React, Postgres, NoSQL, Elasticsearch, AWS, Kubernetes, Spark, and other big data technologies,Experience planning projects and managing team-wide efforts to completion,Appreciate productivity and care deeply about helping teams collaborate more effectively and efficiently, including your own,Excited to be a part of an inclusive culture,Competitive salary,Meaningful equity,Fully paid healthcare, dental, and vision benefits,2 company trips / yr (starting back up at some point),Happy hours, team events and lunches","
Job description
Grata is building the go-to source for middle market company and SMB discovery. Our B2B search engine helps you expand your universe. Business development professionals across recruiting, private equity, and investment banking use Grata to find their next deal. We’re disrupting traditional databases that have rigid categories, outdated information, and limited coverage of private companies.
We’ve recently experienced significant growth and raised capital from top investors who built Google and transformed the finance industry.
We’re looking for an experienced team lead to help us build the next generation of company search.
About the Role:
Own technical design and project execution for the team, delegating work to other engineers on the team while also making individual engineering contributions
Lead technical development of distributed data infrastructure and search application in collaboration with ML+NLP collaborators
Push the boundaries of search with the latest technologies and methods
Scale our platform to billions of documents and drive millions of searches
Make hands-on engineering contributions to Grata with a focus on overcoming technical challenges and modeling practices that improve quality and velocity
Mentor engineers on the team through activities like pairing and code reviews to promote a culture of technical excellence
Collaborate with other teams across Grata to steward a coordinated strategy
About You:
8+ years of experience as a software engineer, developing web applications, large scale data pipelines, and scalable infrastructure
1+ years of experience in a team lead role
You know how to work with data-centric distributed systems, and are comfortable supporting microservice and serverless architectures
Experience collaborating with ML practitioners to build data and analytical systems
Experience with Python, Django, React, Postgres, NoSQL, Elasticsearch, AWS, Kubernetes, Spark, and other big data technologies
Experience planning projects and managing team-wide efforts to completion
Appreciate productivity and care deeply about helping teams collaborate more effectively and efficiently, including your own
Excited to be a part of an inclusive culture
Perks
Competitive salary
Meaningful equity
Fully paid healthcare, dental, and vision benefits
2 company trips / yr (starting back up at some point)
Happy hours, team events and lunches
High quality swag
Grata is an equal opportunity employer that is committed to inclusion and diversity. We take affirmative action to ensure equal opportunity for all applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, Veteran status, or other legally protected characteristics.
",http://stackoverflow.com/jobs/435900/senior-data-engineer-grata-inc
JOB204179794021,Lead Distributed Data Engineer (Remote) at Nomics,Lead Distributed Data Engineer (Remote) at Nomics,,,,https://remoteok.io/l/70367
JOB205587858478,Senior Data Engineer - BlackLocus,Senior Data Engineer - BlackLocus,,,"
Job Information
POSITION PURPOSE
The Sr Data Engineer will expand and optimize data, data flow, data collection for cross functional teams, and data pipeline architecture. The Sr Data Engineer will support and collaborate with the software engineering team, data analysts, and data scientist to ensure data delivery architecture is consistent throughout ongoing projects. Continuously improve or re-design data architecture to support the next generation of products and initiatives.
MAJOR TASKS, RESPONSIBILITES AND KEY ACCOUNTABILITIES
40% - Data Validation, ETL, Infrastructure Development: Coding validation and ETL to ensure successful data integration
30% - Data Infrastructure Maintenance: Backup and optimization activities to maintain performance; code, configure, test, etc data to ensure integrity
20% - Data Architecture Design and Analysis: Create and maintain optimal data pipeline architecture; Develop data architecture to meet business requirements
10% - Planning/Requirements Analysis: Collaborate with team leads and cross functional partners to assess business requirements and communicate opportunities
NATURE AND SCOPE
This position reports to the Technology Leader.
This position has 0 direct reports.
ENVIRONMENTAL JOB REQUIREMENTS
Environment:
Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.
Travel:
Typically requires overnight travel less than 10% of the time.
Additional Environmental Job Requirements: MINIMUM QUALIFICATIONS
Must be eighteen years of age or older.
Must be legally permitted to work in the United States.
Additional Minimum Qualifications:
Experience message queuing, stream processing, and scalable data stores
Experience managing projects and organizing data
Experience supporting and working with cross-functional teams
Experience with SQL, NoSQL databases, relational databases, and query authoring
Experience building and optimizing data pipelines, architectures, data sets and workflow management tools such as Azkaban, Luigi, Airflow, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C#, Scala, GoLang, etc.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
Education Required:
The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.
Years of Relevant Work Experience: 5 years
Physical Requirements:
Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.
Additional Qualifications:
Preferred Qualifications:
8+ years of previous related work experience
Ability to convey complex or technical ideas and processes in easy-to-understand terms to diverse audiences
Ability to negotiate, handle complaints, settle disputes, and resolve grievances with both internal and external customers
Excellent written and verbal communication skills
Knowledge, Skills, Abilities and Competencies:Collaborates - Building partnerships and working collaboratively with others to meet shared objectives
Communicates Effectively - Developing and delivering multi-mode communications that convey a clear understanding of the unique needs of different audiences
Cultivates Innovation - Creating new and better ways for the organization to be successful
Drives Engagement - Creating a climate where people are motivated to do their best to help the organization achieve its objectives
Instills Trust - Gaining the confidence and trust of others through honesty, integrity, and authenticity
Nimble Learning - Actively learning through experimentation when tackling new problems, using both successes and failures as learning fodder
Optimizes Work Processes - Knowing the most effective and efficient processes to get things done with a focus on continuous improvement
Plans and Aligns - Planning and prioritizing work to meet commitments aligned with organizational goals
Tech Savvy - Anticipating and adopting innovations in business-building digital and technology applications. We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
",https://militaryjobs.homedepot.com/EC8362E9CBF04CA89DDFB7AF819ED0FC25
JOB206644118559,Data Engineer Jobs in Texas,Data Engineer Jobs in Texas,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/data-engineer/jobs-in/texas/usa/jobs/?utm_medium=.JOBS%20Universe&utm_source=.JOBS%20RSS%20Feed-DE&utm_campaign=.JOBS%20RSS%20Feed&vs=25
JOB207220278298,"Data Engineer Jobs in Houston, TX","Data Engineer Jobs in Houston, TX",,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/data-engineer/jobs-in/houston/texas/usa/jobs/?utm_source=.JOBS%20RSS%20Feed-DE&utm_campaign=.JOBS%20RSS%20Feed&utm_medium=.JOBS%20Universe&vs=25
JOB210257193044,Data Engineer,Data Engineer,"Gleaming new 100,000 square foot headquarters complete with a 70-foot climbing wall, showers, lockers, and bike parking","Build, scale, and operate a streaming data pipeline.You’ll be on a team responsible for moving, processing, and analyzing about 20 terabytes of images each week.,Create a world-class research platform.You’ll work with Data Scientists and Biologists to create a platform that allows them to generate and access petabytes of data, gives them tools to quickly iterate on novel analysis and research, and deploys new deep learning models into the production data pipeline.,Provide visibility into operations.You’ll create tools, dashboards, and metrics that will help everyone keep track of the work they care about, and alert them when they need to take corrective actions.,Act as a mentor to peers. You will share your technical knowledge and experiences, resulting in an increase in their productivity and effectiveness.,Experimentation- We want Software Engineers who think critically and use data to measure results.Rigorous use of the scientific method allows our Software Engineers to quickly understand the critical aspects of the problems we’re trying to solve and whether or not we’re moving in the right direction.,Collaboration- We want Software Engineers who play well with others. The role will require close collaboration with our Biological, High Throughput Screening, and Data Science teams to help us achieve our mission to discover transformative new treatments.,Curiosity- We want Software Engineers who aren’t satisfied with the status quo. Our Software Engineers openly discuss the tradeoffs inherent in how we build software, and go beyond the traditional boundaries of engineering teams to enable us to get things done faster, cheaper, and more reliably than in traditional drug discovery.,An ability to be resourceful and collaborative in order to complete large projects. We don't have much in the way of project managers.,A track record of learning new technologies as needed to get things done. Our current tech stack uses Python and the pydata libraries, Clojure, Kafka, Kubernetes + Docker, PostgreSQL, Big Query, and other cloud services provided by Google Cloud Platform. Experience with Python or the JVM will be helpful.,An ability to get things done using various tools from the nooks and crannies of software engineering: composing command line tools such as kubectl, jq, and xargs; creating SQL triggers and managing migrations; and operational support.,An ability to write well tested and instrumented code that can be continuously deployed into a production environment with confidence.,An interest in learning from and teaching peers in areas of performance, scalability, and system architecture.,Biology background is not necessary, but intellectual curiosity is a must!,Coverage of health, vision, and dental insurance premiums (in most cases 100%),401(k) with generous matching (immediate vesting),Stock option grants,Two one-week paid company closures (summer and winter) in addition to flexible, generous vacation/sick leave,Commuter benefit and vehicle parking to ease your commute,Complimentary chef-prepared lunches and well-stocked snack bars,Generous paid parental leave for birth, non-birth and adoptive parents,Fully-paid gym membership to Metro Fitness, located just feet away from our new headquarters","
Job description
At Recursion we combine experimental biology, automation, and artificial intelligence to quickly and efficiently identify treatments for human diseases. We are transforming drug discovery into a data science problem and to do that we are building a platform for rapid biological experimentation, data generation, automated analysis, model training, and prediction.
THE PROBLEMS YOU’LL SOLVE
As a Software Engineer you’ll work closely with Biologists, Automation Scientists, and Data Scientists to build the infrastructure and applications needed to decode human biology and reinvent drug discovery. In this role, you will:
Build, scale, and operate a streaming data pipeline.You’ll be on a team responsible for moving, processing, and analyzing about 20 terabytes of images each week.
Create a world-class research platform.You’ll work with Data Scientists and Biologists to create a platform that allows them to generate and access petabytes of data, gives them tools to quickly iterate on novel analysis and research, and deploys new deep learning models into the production data pipeline.
Provide visibility into operations.You’ll create tools, dashboards, and metrics that will help everyone keep track of the work they care about, and alert them when they need to take corrective actions.
Act as a mentor to peers. You will share your technical knowledge and experiences, resulting in an increase in their productivity and effectiveness.
THE QUALITIES WE VALUE
Experimentation- We want Software Engineers who think critically and use data to measure results.Rigorous use of the scientific method allows our Software Engineers to quickly understand the critical aspects of the problems we’re trying to solve and whether or not we’re moving in the right direction.
Collaboration- We want Software Engineers who play well with others. The role will require close collaboration with our Biological, High Throughput Screening, and Data Science teams to help us achieve our mission to discover transformative new treatments.
Curiosity- We want Software Engineers who aren’t satisfied with the status quo. Our Software Engineers openly discuss the tradeoffs inherent in how we build software, and go beyond the traditional boundaries of engineering teams to enable us to get things done faster, cheaper, and more reliably than in traditional drug discovery.
THE EXPERIENCE YOU’LL NEED
We’re hiring a couple of Data Engineers and are interested in people with varying levels of experience.
An ability to be resourceful and collaborative in order to complete large projects. We don't have much in the way of project managers.
A track record of learning new technologies as needed to get things done. Our current tech stack uses Python and the pydata libraries, Clojure, Kafka, Kubernetes + Docker, PostgreSQL, Big Query, and other cloud services provided by Google Cloud Platform. Experience with Python or the JVM will be helpful.
An ability to get things done using various tools from the nooks and crannies of software engineering: composing command line tools such as kubectl, jq, and xargs; creating SQL triggers and managing migrations; and operational support.
An ability to write well tested and instrumented code that can be continuously deployed into a production environment with confidence.
An interest in learning from and teaching peers in areas of performance, scalability, and system architecture.
Biology background is not necessary, but intellectual curiosity is a must!
THE PERKS YOU’LL ENJOY
Coverage of health, vision, and dental insurance premiums (in most cases 100%)
401(k) with generous matching (immediate vesting)
Stock option grants
Two one-week paid company closures (summer and winter) in addition to flexible, generous vacation/sick leave
Commuter benefit and vehicle parking to ease your commute
Complimentary chef-prepared lunches and well-stocked snack bars
Generous paid parental leave for birth, non-birth and adoptive parents
Fully-paid gym membership to Metro Fitness, located just feet away from our new headquarters
Gleaming new 100,000 square foot headquarters complete with a 70-foot climbing wall, showers, lockers, and bike parking
Recursion is an equal opportunity employer and complies with all applicable federal, state, and local fair employment practices laws. Recursion strictly prohibits and does not tolerate discrimination against applicants because of race, color, religion, creed, national origin or ancestry, ethnicity, sex, pregnancy, gender (including gender nonconformity and status as a transgender individual), age, physical or mental disability, citizenship, past, current, or prospective service in the uniformed services, or any other characteristic protected under applicable federal, state, or local law.
",https://stackoverflow.com/jobs/202491/data-engineer-recursion
JOB210976670726,Senior Data Engineer - BlackLocus Jobs in United States,Senior Data Engineer - BlackLocus Jobs in United States,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/usa/jobs/?vs=25&utm_source=.JOBS%20RSS%20Feed-DE&utm_medium=.JOBS%20Universe&utm_campaign=.JOBS%20RSS%20Feed
JOB211096873061,Data Engineer,Data Engineer,"Proficient in English. You read and write proficiently, and speak at a conversational level in English.","Work closely with our Data Scientists, Data Analysts, and Performance Marketers to identify the data-related tooling and infrastructural needs of the company, and participate in defining the plan to fulfil them.,Help define the software architecture of new data tools or that of new features for existing tools, and then develop them. The work spans broadly from the most infrastructure- or backend-oriented to the implementation of data-science algorithms and the development of complex front-ends.,Constantly improve the quality of our tools and infrastructure by fixing bugs and refactoring the code base where necessary.,Expand our set of libraries as needed to make yourself as well as other engineers more efficient and effective.,Stay informed on new, relevant technologies and test the promising ones to make sure we don’t miss out on game-changing opportunities to boost our productivity and the enjoyment of our work.,Huge impact. Your software will help us store, retrieve, visualize, analyze, and ultimately make sense of enormous amounts of data and ultimately make a real difference on how well we serve our tens of millions of users and whether we win or we lose in the market.,Talented, knowledgeable colleagues. You’ll get the chance to learn (and teach to!) some of the brightest and most skilled people you’ll ever meet. Your talent is going to blossom here.,Cool tech stack. We strive to use the best, most modern tools and technologies, and when they fall short of our expectations we invent our own. It’s a geek’s paradise.,Own products. We don’t work for clients, but only develop our own apps. Freed from politics, we can move fast and be daring.,Fun, young environment. We have near-zero hierarchy and a very relaxed workplace. Also, we’re 28 years old on average and often hang out together, so you might actually end up making new friends!,Top-notch office. Our office is amazing! We designed it ourselves and it goes beyond excellent functionality by offering all sorts of amenities, such as foosball tables and gaming consoles.,International reach. Our audience is wildly international. Our company language is English. We’re a global reality.,Passion for the topic. You have a long-standing, proven passion for writing software. It’s a big plus if you have a demonstrated interest for data science, data analytics, or building tools.,Reasoning and depth of learning. You’re structured and creative enough to solve most challenging problems independently, given the necessary knowledge. You learn new concepts and skills rapidly, and look to understand stuff truly in depth.,Drive. You’re energetic, hard-working, and persevere through adversity until the job is done, and done well. You get turned on by getting results, and always aim for excellence in what you do.,Pragmatism. Far from being too academic or obsessive in your perfectionism, you understand that, when getting things done in a competitive world, speed is often as important as quality.,Curiosity and initiative. You love exploring and you’re entrepreneurial in seeking out new opportunities and testing new ideas of your own accord. You don’t just wait to be told what to do all the time.,Attention to detail. You care to get the small things right as well as the big ones. You’re meticulous in checking that your code will work exactly as expected.,Diligence, organization. You can blindly be entrusted with big responsibilities as well as small, more menial tasks.,Humbleness. You’re down to earth, eager to listen to people’s feedback and constructive criticism, and ready to get your hands dirty with whatever the team needs to succeed.","
Job description
Our apps are used by tens of millions of people every month and downloaded hundreds of thousands of times per day. This enormous traffic, coupled with our insatiable curiosity to know more and drive to optimize our performance, makes so that we end up storing and constantly retrieving, visualizing, and analyzing large amounts of data. Hence, we’re looking for a passionate, bright, and driven data engineer that’s eager to bring our data-related technologies to the next level.
A few examples of your responsibilities:
Work closely with our Data Scientists, Data Analysts, and Performance Marketers to identify the data-related tooling and infrastructural needs of the company, and participate in defining the plan to fulfil them.
Help define the software architecture of new data tools or that of new features for existing tools, and then develop them. The work spans broadly from the most infrastructure- or backend-oriented to the implementation of data-science algorithms and the development of complex front-ends.
Constantly improve the quality of our tools and infrastructure by fixing bugs and refactoring the code base where necessary.
Expand our set of libraries as needed to make yourself as well as other engineers more efficient and effective.
Stay informed on new, relevant technologies and test the promising ones to make sure we don’t miss out on game-changing opportunities to boost our productivity and the enjoyment of our work.
What we offer
Huge impact. Your software will help us store, retrieve, visualize, analyze, and ultimately make sense of enormous amounts of data and ultimately make a real difference on how well we serve our tens of millions of users and whether we win or we lose in the market.
Talented, knowledgeable colleagues. You’ll get the chance to learn (and teach to!) some of the brightest and most skilled people you’ll ever meet. Your talent is going to blossom here.
Cool tech stack. We strive to use the best, most modern tools and technologies, and when they fall short of our expectations we invent our own. It’s a geek’s paradise.
Own products. We don’t work for clients, but only develop our own apps. Freed from politics, we can move fast and be daring.
Fun, young environment. We have near-zero hierarchy and a very relaxed workplace. Also, we’re 28 years old on average and often hang out together, so you might actually end up making new friends!
Top-notch office. Our office is amazing! We designed it ourselves and it goes beyond excellent functionality by offering all sorts of amenities, such as foosball tables and gaming consoles.
International reach. Our audience is wildly international. Our company language is English. We’re a global reality.
What we look for
Passion for the topic. You have a long-standing, proven passion for writing software. It’s a big plus if you have a demonstrated interest for data science, data analytics, or building tools.
Reasoning and depth of learning. You’re structured and creative enough to solve most challenging problems independently, given the necessary knowledge. You learn new concepts and skills rapidly, and look to understand stuff truly in depth.
Drive. You’re energetic, hard-working, and persevere through adversity until the job is done, and done well. You get turned on by getting results, and always aim for excellence in what you do.
Pragmatism. Far from being too academic or obsessive in your perfectionism, you understand that, when getting things done in a competitive world, speed is often as important as quality.
Curiosity and initiative. You love exploring and you’re entrepreneurial in seeking out new opportunities and testing new ideas of your own accord. You don’t just wait to be told what to do all the time.
Attention to detail. You care to get the small things right as well as the big ones. You’re meticulous in checking that your code will work exactly as expected.
Diligence, organization. You can blindly be entrusted with big responsibilities as well as small, more menial tasks.
Humbleness. You’re down to earth, eager to listen to people’s feedback and constructive criticism, and ready to get your hands dirty with whatever the team needs to succeed.
Proficient in English. You read and write proficiently, and speak at a conversational level in English.
Commitment & contract
Full-time, permanent (tempo indeterminato).
Location
Milan, Corso Como 15. It’s fine if you prefer to work remotely sometimes. We offer substantial support for relocation, including finding an apartment in Milan and paying the rent for twelve weeks.
Compensation & benefits
Generous, top of market, and moreover can grow very rapidly and include stock options, depending on your performance. Breakfast, lunch, and snacks are paid-for, when you work from the office. You’ll receive the latest Mac, iPhone, and wireless noise-cancelling Bose headset.
Learn more about Bending Spoons and apply directly on our website.
About Bending Spoons
Bending Spoons is a fast-growing tech company focused on building and marketing mobile applications. Despite being such a young company, we've already achieved notable results, with tens of millions of downloads of our apps, and millions of users active every month. Our goal? Becoming the #1 app developer and publisher in the world. And our ambitions don't end there!
",https://stackoverflow.com/jobs/201171/data-engineer-bending-spoons
JOB211231573714,Data and Research - Hadoop Data Engineer,Data and Research - Hadoop Data Engineer,,"Accountable for supporting projects by preparing data for data exploration and research modeling.,Create visualizations of data for purposes of data discovery and data exploration,Provide subject matter expertise to claim's business intelligence data environment,Create and operationalize data products including transformation logic as well as business requirements and specifications.,Serve as data expert of significant projects with broad impact to business and enterprise performance.,Serve as a business intelligence data environment subject matter expert to support the claim research community and claim business partners,Understanding of data warehousing, information delivery, and use of big data,Develops and prepares data using Hive, Pig, SQL, and SAS.,Develops data pipelines utilizing appropriate technologies and frameworks (Java, Python, Scala, NiFi).,Capable of building data visualizations to help support data discovery and data exploration.,Create and operationalize data products. Incorporate core data management competencies - data governance, data security, data quality.,Builds, tests, and implements analytic processes into the business workstream, including pilots and proof of concept.,Provide subject matter expertise to claim's business intelligence data environment.","Reasons could include: the employer is not accepting applications, is not actively hiring, or is reviewing applications
Tweets by @TRV_Careers
Job Overview
Job Title:
Data and Research - Hadoop Data Engineer
Company:
Travelers Insurance
Pay:
Not Specified
Job Type:
Category:
Actuary
Location:
Hartford, Connecticut
About Travelers
The Travelers Companies, Inc. (NYSE: TRV) is a leading property casualty insurer selling primarily through independent agents and brokers. The company's diverse business lines offer its global customers a wide range of coverage in the auto, home and business settings. A component of the Dow Jones Industrial Average, Travelers has more than 30,000 employees and generated revenues of approximately $25 billion in 2010.
Data and Research - Hadoop Data Engineer
Company Information
Solid reputation, passionate people and endless opportunities. That's Travelers. Our superior financial strength and consistent record of strong operating returns mean security for our customers - and opportunities for our employees. You will find Travelers to be full of energy and a workplace in which you truly can make a difference.
Job Summary
Accountable for supporting projects by preparing data for data exploration and research modeling.
Create visualizations of data for purposes of data discovery and data exploration
Provide subject matter expertise to claim's business intelligence data environment
Create and operationalize data products including transformation logic as well as business requirements and specifications.
Serve as data expert of significant projects with broad impact to business and enterprise performance.
Serve as a business intelligence data environment subject matter expert to support the claim research community and claim business partners
Understanding of data warehousing, information delivery, and use of big data
Primary Job Duties & Responsibilities
Develops and prepares data using Hive, Pig, SQL, and SAS.
Develops data pipelines utilizing appropriate technologies and frameworks (Java, Python, Scala, NiFi).
Capable of building data visualizations to help support data discovery and data exploration.
Create and operationalize data products. Incorporate core data management competencies - data governance, data security, data quality.
Builds, tests, and implements analytic processes into the business workstream, including pilots and proof of concept.
Provide subject matter expertise to claim's business intelligence data environment.
Minimum Qualifications
Bachelors degree in MIS, Mathematics, Finance, Statistics, Electrical Engineering, Technology, Computer Science, or Computer Engineering or the equivalent education or 2 years experience in information delivery or related field required.
Education, Work Experience & Knowledge
Bachelors degree in STEM (Science, Technology, Engineering, Mathematics), or related field or equivalent experience preferred.
2+ years working with programming languages specific to function supported preferred.
2+ years working with analytic tools/models preferred.
2+ years working with Business Intelligence preferred.
Working knowledge of Information Delivery practices and processes.
Working Knowledge: Understands basic principles and terminology in order to understand and solve simple problems.
Job Specific & Technical Skills & Competencies
Experience with Hortonworks Hadoop stack (e.g., HDFS, NiFi, Hive, Pig, Hadoop streaming, Map Reduce, Ambari, etc.).
SAS/R Experience.
Programming skills in Java/Java EE, Scala, and/or Python.
Linux/Unix scripting experience.
Experience designing and developing data pipelines.
A solid understanding of emerging technology capabilities, and a keen interest in staying abreast of emerging technology trends and open source projects and tools.
RESTFul service design and development preferred.
Demonstrated intermediate analytic and diagnostic skills.
Demonstrated intermediate interpersonal skills.
Demonstrated intermediate communication and presentation skills.
Ability to work independently and as part of a team.
Demonstrated ability to influence others.
Intermediate project management skills.
Working understanding of the business functions, processes, and overall business strategies.
Demonstrated ability to see results to completion.
Intermediate problem solving and decision making skills.
Physical Requirements
Requires extended periods of computer use.
Requires extended periods of sitting.
Equal Employment Opportunity Statement
Travelers is an equal opportunity employer.
To apply for this position please CLICK HERE
",http://www.indeed.com/viewjob?jk=4467731d8e762ae6&qd=NGstvRTMEOvJmVpt7yc_yoTWPCm0QNPdIzzPht0ZasBpY5gwu7FCZnkMImjJUar7D0xbCEX8pxZEkbI23f4B94w2WFTZgoHbmjqtbTlwUTy_Z5i4Qk6_rCJbdisHdWXFruJraDvE4FO-ETfZ9aXbRg&indpubnum=7409121151176687&chnl=tdwi&atk=1b69nrcciah73dnk
JOB211995231268,"Senior Data Engineer - BlackLocus Jobs in Austin, TX","Senior Data Engineer - BlackLocus Jobs in Austin, TX",,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/austin/texas/usa/jobs/
JOB212217971759,Data Engineer,Data Engineer,,,"
POSITION PURPOSE
Congrats! You re learning about an exciting new role with The Home Depots Global Custom Commerce (GCC) team that will revitalize and invigorate the way we manage and view data. For this role, we are looking for some one who can develop, implement, test and maintain data pipelines (batch & streaming) and data structures within a cloud based column-oriented data store. This person will support the GCC BI and Data Science strategic initiatives to drive better customer experiences and more profitable outcomes
Why work here? Our entrepreneurial roots and maverick mentality, coupled with the resources and backing of the #1 home improvement retailer in the world, The Home Depot, is a unique opportunity for you to be a transformative retail disrupter. Plus, GCC is the world s largest online window covering company, and we ve got a demonstrably awesome 20-year track record. From our open-floor office to our open-door ethos, our culture is rooted in improving, evolving, and having fun (we re pretty serious about cake, cook-offs, ping pong, meaningful work and exciting projects). Most importantly, our team members are always inspired, engaged, and ready for growth. That means you ll have the resources and the runway to create truly magical, out-of-the-box work. Moreover, you will play an important role in leveraging our culture, people, systems, processes, and technology ultimately to provide incredible customer experiences, while growing business for GCC and The Home Depot. This is your chance to be part of something big, in a small start-up environment. We re ranked as one of The Top 5 Workplaces in Texas and have consistently won the following awards:The Best Place to Work in Houston (Houston Business Journal), Houston s Top Workplaces (Houston Chronicle) and Houston s Best and Brightest.
MAJOR TASKS, RESPONSIBILITES AND KEY ACCOUNTABILITIES
20%- Implement a real time streaming data ingestion and processing pipeline using Google Dataflow (Apache Beam)
20%- Interface with business intelligence analyts and others in IT (i.e. data engineers, architects, WebOps) in frequent whiteboard sessions to dicsucuss the design, implementation, and testing of data pipleines
20%- Maintain data architecture standards and ETL/ELT best practices consistent with a column oritented data store in an analytic use case
20%- Active and engaged particitpation in the Scrum delivery process
20%- Support solutions in production
NATURE AND SCOPE
This role reports to the Sr. Manager of EDW.
This role has no direct reports.
ENVIRONMENTAL JOB REQUIREMENTS
Environment:
Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.
Travel:
Typically requires overnight travel less than 10% of the time.MINIMUM QUALIFICATIONS
Must be eighteen years of age or older.
Must be legally permitted to work in the United States.
Education Required:
The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.
Years of Relevant Work Experience: 6 years
Physical Requirements:
Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.
Preferred Qualifications:
Familiarity with Agile methodologies
Experience with Spark dataframes, SparkSQL, Kafka, KSQL, real-time streaming, and message bus technologies
Experience with data science technologies such as SAS, R, Matlab, or similar
Experience with data warehousing and dimensional modeling
Knowledge, Skills, Abilities and Competencies:
Experience in building real time streaming data ingestion and processing pipeline using Apache Beam (running on either Google Datflow or Apache (Apex, Flink, or Spark) or Kafka in an analytics or data science use case
Experience with data processing tools (e.g. Hadoop, Spark, Dataflow, etc.)
Experience building ETL/ELT pipelines
Experience with column-oriented databases (e.g Redhift, BigQuery, Vertica)
Ability to go from whiteboard discussion to code
Ability to effectively communicate with technical and non-technical audiences
Strong programming ability
Success in a highly dynamic environment and ability to shift priorities with agility
Ability to act independently with minimal supervision
Willingness to explore and implement new ideas and technologies
Experience working directly with subject matter experts in both business and technology domains
Experience as a team lead We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
",https://militaryjobs.homedepot.com/houston-tx/data-engineer/4B642DC9C39B4857867CACB6FE730745/job/?utm_source=.JOBS%20RSS%20Feed-DE&utm_campaign=.JOBS%20RSS%20Feed&utm_medium=.JOBS%20Universe
JOB212343456108,"Data Engineer, Newsroom","Data Engineer, Newsroom",,"Experience running and supporting production of enterprise data platforms,Experience creating internal tools that combine content and audience data,Experience in building infrastructure required for optimal extraction, transformation and loading of data from various resources,Knowledge of JavaScript, Python, Bash and SQL,Build data pipelines with tools and cloud-based data services like Google’s BigQuery, AWS, Dataproc and Pub/Sub,2+ years of data engineering experience,Strong statistics skills,LI-JA1-WSJ","
Job Description:
The Wall Street Journal seeks a data engineer who will be responsible for developing tools to help the newsroom in its data science work. The Journal is expanding its use of data in both editorial and audience-related projects, and this engineer will be an important force in bolstering the newsroom’s data capacities.
The Journal is seeking a full-stack data engineer who will be responsible for (1) acquiring new datasets, (2) creating and maintaining data pipelines, (3) deploying data and insights to editors in the newsroom, and (4) building prototypes of tools for editors and newsroom staffers.
This role is responsible for making and maintaining a data pipeline for all the data sets we want, have and need. This is a function tied to the newsroom’s top-level strategy, working in collaboration with the Audience group, the R&D Lab and the broader newsroom. The engineer will collaborate with data scientists and work directly with a number of highly sophisticated audience and content data sets. The engineer will also help with rapid prototyping and testing of newsroom data tools as well as help maintain ones that are successful.
We are looking for someone with deep knowledge of audience behavior around common journalism types, like breaking news and enterprise journalism, as well as experience in newsroom tools and data dashboards. The data engineer should have strong background in A/B testing as well as managing data processes that inform content optimization. This role is suited for a talented engineer with a strong understanding of newsroom workflow and a passion for helping journalists connect with their audiences.
Skills:
Experience running and supporting production of enterprise data platforms
Experience creating internal tools that combine content and audience data
Experience in building infrastructure required for optimal extraction, transformation and loading of data from various resources
Knowledge of JavaScript, Python, Bash and SQL
Build data pipelines with tools and cloud-based data services like Google’s BigQuery, AWS, Dataproc and Pub/Sub
2+ years of data engineering experience
Strong statistics skills
This position reports to The Wall Street Journal’s Head of Data Solutions.
LI-JA1-WSJ
Dow Jones , Making Careers Newsworthy
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, protected veteran status, or disability status. EEO/AA/M/F/Disabled/Vets .
Dow Jones is committed to providing reasonable accommodation for qualified individuals with disabilities, in our job application and/or interview process. If you need assistance or accommodation in completing your application, due to a disability, please reach out to us at TalentResourceTeam@dowjones.com . Please put “Reasonable Accommodation"" in the subject line.
Business Area: NEWS/WSJ
Job Category: IT Development Group
About Us
The Wall Street Journal is a global news organization that provides leading news, information, commentary and analysis. The Wall Street Journal engages readers across print, digital, mobile, social, and video. Building on its heritage as the preeminent source of global business and financial news, the Journal includes coverage of U.S. and world news, politics, arts, culture, lifestyle, sports, and health. It holds 38 Pulitzer Prizes for outstanding journalism. The Wall Street Journal is published by Dow Jones, a division of News Corp (NASDAQ: NWS, NWSA; ASX: NWS, NWSLV).
If you are a current employee at Dow Jones, do not apply here. Please go to the Career section on your Workday homepage and view ""Find Jobs - Dow Jones."" Thank you.
Req ID: 14570
",https://www.mediabistro.com/jobs/description/382065/data-engineer-newsroom/
JOB212455326723,Senior Data Engineer - BlackLocus Jobs in United States,Senior Data Engineer - BlackLocus Jobs in United States,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/usa/jobs/?utm_medium=.JOBS%20Universe&utm_campaign=.JOBS%20RSS%20Feed&vs=25&utm_source=.JOBS%20RSS%20Feed-DE
JOB213194307127,"Senior Data Engineer, Cloud","Senior Data Engineer, Cloud",Gym membership compensation,"Drive design and implementation leveraging modern design patterns,Ability to partner effectively with UX, PM, DevOps, QE and other developers to design and implement meeting the spirit of requirements,Experience in modern front end frameworks,Technically curious to keep present on advances in technology,Experience with segregation of model, presentation, and business logic.,TDD experience and strong desire to build in test from the start.,Write code (Test or Product) to deliver against project timescales, quality and requirements in various languages including Java or other selected languages for Sophos Cloud products.,Provide guidance and mentorship to junior developers in daily Scrum meetings.,Possesses a passion for solving complex Big Data problems,Plan for, design and implement our next-generation cloud security products.,Be involved from inception through implementation in a real hands on fashion.,BS in Computer Science, Engineering, or equivalent with 7+ years of development and data modelling background,Building highly scalable SaaS solutions using Big Data technologies,Experience with CI/CD,Experience with Agile Software Development methodologies (scrum/ kanban),Excellent attention to detail,Excellent verbal and written communication skills,Experience with the following technologies (recommended) and strong desire to learn (required),Programming language -- Java (must)
Batch processing -- Hadoop ,MapReduce
Stream processing -- Kafka and Amazon Kinesis
NoSQL -S3 , MongoDB.
Columnar stores - HBASE, Amazon Redshift
Restful web services
Code/Build/Deployment -- git, hg, svn, maven, sbt, jenkins, bamboo, ...
Amazon Web Services
Data Warehousing/ built ETL,Programming language -- Java (must),Batch processing -- Hadoop ,MapReduce,Stream processing -- Kafka and Amazon Kinesis,NoSQL -S3 , MongoDB.,Columnar stores - HBASE, Amazon Redshift,Restful web services,Code/Build/Deployment -- git, hg, svn, maven, sbt, jenkins, bamboo, ...,Amazon Web Services,Data Warehousing/ built ETL,Medical insurance,Dental insurance,Vision insurance,Life insurance,Long-term disability insurance,401k plan,Vacation time","
At Sophos, we operate at the cutting edge of technology, protecting businesses worldwide against complex threats, viruses and spam. We build high quality software security products in a fast-paced, nimble environment and we've been doing it for over 20 years.
Join us to help our customers protect their business and meet compliance needs.
Role
To function as a senior data lead for product features or key technology choices and implementation. Collaborates as part of a team for the development of complex systems; including requirements analysis, concept development and design, implementation and testing, demonstrating flexibility of role as required
Main Duties
Drive design and implementation leveraging modern design patterns
Ability to partner effectively with UX, PM, DevOps, QE and other developers to design and implement meeting the spirit of requirements
Experience in modern front end frameworks
Technically curious to keep present on advances in technology
Experience with segregation of model, presentation, and business logic.
TDD experience and strong desire to build in test from the start.
Write code (Test or Product) to deliver against project timescales, quality and requirements in various languages including Java or other selected languages for Sophos Cloud products.
Provide guidance and mentorship to junior developers in daily Scrum meetings.
Possesses a passion for solving complex Big Data problems
Plan for, design and implement our next-generation cloud security products.
Be involved from inception through implementation in a real hands on fashion.
Experience And Skills
BS in Computer Science, Engineering, or equivalent with 7+ years of development and data modelling background
Building highly scalable SaaS solutions using Big Data technologies
Experience with CI/CD
Experience with Agile Software Development methodologies (scrum/ kanban)
Excellent attention to detail
Excellent verbal and written communication skills
Experience with the following technologies (recommended) and strong desire to learn (required)
Programming language -- Java (must)
Batch processing -- Hadoop ,MapReduce
Stream processing -- Kafka and Amazon Kinesis
NoSQL -S3 , MongoDB.
Columnar stores - HBASE, Amazon Redshift
Restful web services
Code/Build/Deployment -- git, hg, svn, maven, sbt, jenkins, bamboo, ...
Amazon Web Services
Data Warehousing/ built ETL
Benefits
In most cases, the compensation package includes:
Medical insurance
Dental insurance
Vision insurance
Life insurance
Long-term disability insurance
401k plan
Vacation time
Gym membership compensation
",https://www.sophos.com/zh-cn/about-us/careers/united-states/senior-data-engineer-cloud.aspx
JOB214347433014,Senior Data Engineer - BlackLocus,Senior Data Engineer - BlackLocus,,,"
Job Information
POSITION PURPOSE
The Sr Data Engineer will expand and optimize data, data flow, data collection for cross functional teams, and data pipeline architecture. The Sr Data Engineer will support and collaborate with the software engineering team, data analysts, and data scientist to ensure data delivery architecture is consistent throughout ongoing projects. Continuously improve or re-design data architecture to support the next generation of products and initiatives.
MAJOR TASKS, RESPONSIBILITES AND KEY ACCOUNTABILITIES
40% - Data Validation, ETL, Infrastructure Development: Coding validation and ETL to ensure successful data integration
30% - Data Infrastructure Maintenance: Backup and optimization activities to maintain performance; code, configure, test, etc data to ensure integrity
20% - Data Architecture Design and Analysis: Create and maintain optimal data pipeline architecture; Develop data architecture to meet business requirements
10% - Planning/Requirements Analysis: Collaborate with team leads and cross functional partners to assess business requirements and communicate opportunities
NATURE AND SCOPE
This position reports to the Technology Leader.
This position has 0 direct reports.
ENVIRONMENTAL JOB REQUIREMENTS
Environment:
Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.
Travel:
Typically requires overnight travel less than 10% of the time.
Additional Environmental Job Requirements:MINIMUM QUALIFICATIONS
Must be eighteen years of age or older.
Must be legally permitted to work in the United States.
Additional Minimum Qualifications:
Experience message queuing, stream processing, and scalable data stores
Experience managing projects and organizing data
Experience supporting and working with cross-functional teams
Experience with SQL, NoSQL databases, relational databases, and query authoring
Experience building and optimizing data pipelines, architectures, data sets and workflow management tools such as Azkaban, Luigi, Airflow, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C#, Scala, GoLang, etc.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
Education Required:
The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.
Years of Relevant Work Experience: 5 years
Physical Requirements:
Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.
Additional Qualifications:
Preferred Qualifications:
8+ years of previous related work experience
Ability to convey complex or technical ideas and processes in easy-to-understand terms to diverse audiences
Ability to negotiate, handle complaints, settle disputes, and resolve grievances with both internal and external customers
Excellent written and verbal communication skills
Knowledge, Skills, Abilities and Competencies:Collaborates - Building partnerships and working collaboratively with others to meet shared objectives
Communicates Effectively - Developing and delivering multi-mode communications that convey a clear understanding of the unique needs of different audiences
Cultivates Innovation - Creating new and better ways for the organization to be successful
Drives Engagement - Creating a climate where people are motivated to do their best to help the organization achieve its objectives
Instills Trust - Gaining the confidence and trust of others through honesty, integrity, and authenticity
Nimble Learning - Actively learning through experimentation when tackling new problems, using both successes and failures as learning fodder
Optimizes Work Processes - Knowing the most effective and efficient processes to get things done with a focus on continuous improvement
Plans and Aligns - Planning and prioritizing work to meet commitments aligned with organizational goals
Tech Savvy - Anticipating and adopting innovations in business-building digital and technology applications. We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
",https://militaryjobs.homedepot.com/austin-tx/senior-data-engineer-blacklocus/35068FD906174D91A159D54015CA5347/job/?utm_medium=.JOBS%20Universe&utm_source=.JOBS%20RSS%20Feed-DE&utm_campaign=.JOBS%20RSS%20Feed
JOB216334894080,"Senior Data Engineer - BlackLocus Jobs in Austin, TX","Senior Data Engineer - BlackLocus Jobs in Austin, TX",,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/austin/texas/usa/jobs/?utm_medium=.JOBS%20Universe&vs=25&utm_source=.JOBS%20RSS%20Feed-DE&utm_campaign=.JOBS%20RSS%20Feed
JOB218175210519,"Senior Data Engineer - BlackLocus Jobs in Austin, TX","Senior Data Engineer - BlackLocus Jobs in Austin, TX",,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/austin/texas/usa/jobs/?vs=25&utm_campaign=.JOBS%20RSS%20Feed&utm_source=.JOBS%20RSS%20Feed-DE&utm_medium=.JOBS%20Universe
JOB218696729637,"Senior Data Engineer - BlackLocus Jobs in Austin, TX","Senior Data Engineer - BlackLocus Jobs in Austin, TX",,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/austin/texas/usa/jobs/?utm_medium=.JOBS%20Universe&vs=25&utm_campaign=.JOBS%20RSS%20Feed&utm_source=.JOBS%20RSS%20Feed-DE
JOB219032610880,Senior Data Engineer (m/f),Senior Data Engineer (m/f),"Relocation is simplified — paid accommodation, as well as experienced “relocation buddies,” guide you through your visa application.","As Data Engineer, you will be responsible for fast, accurate, robust and scalable data-processing in our company,You develop and deploy new features in an agile, test-driven environment in tandem with our team of data engineers, data scientists, software developers, and operations managers,You build fault tolerant, self-healing, adaptive, and highly accurate data computational pipelines,You optimize data transfer processes at the code, memory and architecture level,You develop in an environment of micro-services and event-based architecture,You have either a bachelor's degree with 3+ years of work experience or a master’s degree and 2+ year of work experience,You have prior experience with a high-level programming language like Ruby, Scala or Go,You have the ability to quickly understand business requirements and transform them into data models,You are experienced with Big Data related technologies like HDFS, Hive, Pig and Spark,You have an aptitude to independently learn new technologies and you are passionate about data,Prior experience with online marketing is a plus, e.g. Google AdWords, BingAds, Social Media Advertising or Universal Analytics,We trust in data — data drive our business decisions and product development roadmap.,Our employees are our best investment — develop yourself through knowledge sharing sessions, workshops, and personalized training.,We keep innovating — stay close to users, challenge the status quo, dedicate 20% of your work time to new ideas.,We get great work done — we enjoy working face-to-face, but value results over office presence.,Our team is diverse — we unite smart and passionate people from over 30 nationalities.","
Job description
To strengthen our international team in Berlin, we are offering a full-time position as
Senior Data Engineer (m/f)
Retailers face unique challenges - we support them with technology-led solutions. Crealytics is a customer-centric organization: our data-driven, proprietary technology aids some of the world's biggest eCommerce players (including Foot Locker, ASOS, and Urban Outfitters). Crealytics’ Product & Technology specialists are key to this. From design and engineering to data science, they work closely with our Digital Marketing and Business Intelligence teams. We employ over 150 experts across our Berlin, London, New York City and Passau offices.
And we’re looking to expand. If you’re interested in sharpening your area of expertise while learning new skills, we’d love to hear from you.
// Your responsibilities
As Data Engineer, you will be responsible for fast, accurate, robust and scalable data-processing in our company
You develop and deploy new features in an agile, test-driven environment in tandem with our team of data engineers, data scientists, software developers, and operations managers
You build fault tolerant, self-healing, adaptive, and highly accurate data computational pipelines
You optimize data transfer processes at the code, memory and architecture level
You develop in an environment of micro-services and event-based architecture
// Your profile
You have either a bachelor's degree with 3+ years of work experience or a master’s degree and 2+ year of work experience
You have prior experience with a high-level programming language like Ruby, Scala or Go
You have the ability to quickly understand business requirements and transform them into data models
You are experienced with Big Data related technologies like HDFS, Hive, Pig and Spark
You have an aptitude to independently learn new technologies and you are passionate about data
Prior experience with online marketing is a plus, e.g. Google AdWords, BingAds, Social Media Advertising or Universal Analytics
// How we work
We trust in data — data drive our business decisions and product development roadmap.
Our employees are our best investment — develop yourself through knowledge sharing sessions, workshops, and personalized training.
We keep innovating — stay close to users, challenge the status quo, dedicate 20% of your work time to new ideas.
We get great work done — we enjoy working face-to-face, but value results over office presence.
Our team is diverse — we unite smart and passionate people from over 30 nationalities.
Relocation is simplified — paid accommodation, as well as experienced “relocation buddies,” guide you through your visa application.
Join our team and become part of our success story!
",https://stackoverflow.com/jobs/165041/senior-ruby-developer-m-f-crealytics-gmbh
JOB219606919240,Senior Data Engineer,Senior Data Engineer,Always improve: we value personal progress and want you to look back proudly on what you’ve done.,"Move smart: we are data driven, and employ tools and best practices to ship code quickly and safely (continuous integration, code review, automated testing, etc).,Distribute knowledge: we want to scale our engineering team to a point where our contributions do not stop at the company code base. We believe in the Open Source culture and communication with the outside world.,Leave code better than you found it: because we constantly raise the bar.,Unity makes strength: moving people from A to B is not as easy as it sounds but, we always keep calm and support each other.","
Job description
Our millions of rides create an incredibly rich dataset that needs to be transformed, exposed and analyzed in order to improve our multiple products.
By joining the Data Engineering team, you will be part of an early stage team who builds the data transport, collection and storage at Heetch. The team is quite new and you will have the opportunity to shape its direction while having a large impact.
You will own Heetch's data platform by architecting, building, and launching highly scalable infrastructure and reliable data pipelines that'll support our growing data processing and analytics needs. You will also create the tooling that allows users to be self sufficient, building their own pipelines and data processing.
Your efforts will allow accessibility to incredible rich insights enlightening Data Analysts, Data Scientists, Operations managers, Product Managers and many others.
WHAT YOU’LL DO
• Implement and be responsible for a scalable data processing infrastructure which will evolve to based on business and engineering needs
•Build large-scale batch data pipelines.
•Build large-scale real-time data pipelines.
•Be responsible for scaling up data processing flow to meet the rapid data growth at Heetch.
•Consistently improve and make evolve data model & data schema based on business and engineering needs. • Implement systems tracking data quality and consistency.
•Develop tools supporting self-service data pipeline management (ETL).
•Tune jobs to improve data processing performance.
•Implement data and machine learning algorithms (A/B testing, Sessionization,).
•Work with the business, product and engineering teams to create and implement a holistic data architecture.
REQUIREMENT
•At least 4+ years in Software Engineering with a focus on Data Engineering
•Extensive experience with Spark or other cluster-computing frameworks.
•Advanced SQL query competencies (queries, SQL Engine, advanced performance tuning).
•Strong skills in Python, Scala or Java
•Experience with workflow management tools (Airflow, Oozie, Azkaban, Luigi).
•Comfortable working directly with data analytics to bridge business requirements with data engineering.
•Inventive and self-started.
Bonus points
•Experience with Kafka.
•Experience designing and developing data warehouses
•Experience with data engineering in an AWS or cloud environment
•Performance tuning and administration of Spark, Kafka, Hive and Redshift
•Experience deploying and managing AWS infrastructure.
•Experience building data models for normalizing/standardizing varied datasets for machine learning/deep learning.
•Experience working on a remote team.
•Experience developing data engineering tools
PERKS
•Stocks.
•Paid conference attendance/travel.
•Heetch credits.
•A Spotify subscription.
•Medical care
•Code retreats and company retreats.
•Travel budget (visit your remote coworkers and our offices).
OUR ENGINEERING VALUES
Move smart: we are data driven, and employ tools and best practices to ship code quickly and safely (continuous integration, code review, automated testing, etc).
Distribute knowledge: we want to scale our engineering team to a point where our contributions do not stop at the company code base. We believe in the Open Source culture and communication with the outside world.
Leave code better than you found it: because we constantly raise the bar.
Unity makes strength: moving people from A to B is not as easy as it sounds but, we always keep calm and support each other.
Always improve: we value personal progress and want you to look back proudly on what you’ve done.
",https://stackoverflow.com/jobs/200909/senior-data-engineer-heetch?a=15ntwiguvaXC
JOB223390368779,"Data Engineer Jobs in Houston, TX","Data Engineer Jobs in Houston, TX",,"Houston, TX","
Data Engineer Jobs in Houston, TX
Current Search Criteria
More
",https://militaryjobs.homedepot.com/data-engineer/jobs-in/houston/texas/usa/jobs/?vs=25&utm_campaign=.JOBS%20RSS%20Feed&utm_source=.JOBS%20RSS%20Feed-DE&utm_medium=.JOBS%20Universe
JOB223434589200,"Senior Data Engineer - BlackLocus Jobs in Austin, TX","Senior Data Engineer - BlackLocus Jobs in Austin, TX",,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/austin/texas/usa/jobs/?vs=25&utm_medium=.JOBS%20Universe&utm_source=.JOBS%20RSS%20Feed-DE&utm_campaign=.JOBS%20RSS%20Feed
JOB226219370586,Data Engineer,Data Engineer,"Transparency – regular All-Team meetings, so you can stay in-the-know with what’s going on in all areas our business","Design and develop business-critical data pipelines and related back-end services,Identification of and participation in simplifying and addressing scalability issues for enterprise level data pipeline,Design and build big data infrastructure to support our data lake,2+ years of extensive experience with Hadoop (or similar) Ecosystem (MapReduce, Yarn, HDFS, Hive, Spark, Presto, HBase, Parquet),Experience with building, breaking, and fixing production data pipelines,Hands-on SQL skills and background in other data stores like SQL-Server, Postgres, and MongoDB,Experience with continuous delivery and automated deployments (Terraform),ETL experience,Able to identify and participate in addressing scalability issues for enterprise level data,Python programming experience,Experience with machine learning libraries like scikit-learn, Tensorflow, etc., or an interest in picking it up,Experience with R to mine structured and unstructured data and/or building statistical models,Experience with Elasticsearch,Experience with AWS services like Glue, S3, SQS, Lambda, Fargate, EC2, Athena, Kinesis, Step Functions, DynamoDB, CloudFormation and CloudWatch will be a huge plus,You can work remotely in the continental US with occasional travel to Bend, Oregon,You can be based at a shared office space in the heart of downtown Portland, Oregon,You can be based at our offices in Bend, Oregon (relocation assistance package available),An inclusive, fun, values-driven company culture – we’ve won awards for it,A growing tech company in Bend, Oregon,Work / Life balance - what a concept!,Excellent benefits package with a Medical Expense Reimbursement Program that helps keep our medical deductibles LOW for our Team Members,401(k) with generous matching component,Generous time off plus a VTO day to use working at your favorite charity,Competitive pay + annual bonus program,FREE TURKEYS (or pies) for every Team Member for Thanksgiving (hey, it's a tradition around here),Your work makes a difference here, and we make a huge impact to our clients’ profits","
Job description
NAVIS is excited to be hiring a Data Engineer for a remote, US-based position! Candidates based outside of the US are not being considered at this time. This is a NEW position due to growth in this area.
Be a critical element of what sets NAVIS apart from everyone else! Join the power behind the best-in-class Hospitality CRM software and services that unifies hotel reservations and marketing teams around their guest data to drive more bookings and revenue.
Our Guest Experience Platform team is seeking an experienced Data Engineer to play a lead role in the building and running of our modern big data and machine learning platform that powers our products and services. In this role, you will responsible for building the analytical data pipeline, data lake, and real-time data streaming services. You should be passionate about technology and complex big data business challenges.
You can have a huge impact on everything from the functionality we deliver for our clients, to the architecture of our systems, to the technologies that we are adopting.
You should be highly curious with a passion for building things!
Click here for a peek inside our Engineering Team
DUTIES & RESPONSIBILITIES:
Design and develop business-critical data pipelines and related back-end services
Identification of and participation in simplifying and addressing scalability issues for enterprise level data pipeline
Design and build big data infrastructure to support our data lake
QUALIFICATIONS:
2+ years of extensive experience with Hadoop (or similar) Ecosystem (MapReduce, Yarn, HDFS, Hive, Spark, Presto, HBase, Parquet)
Experience with building, breaking, and fixing production data pipelines
Hands-on SQL skills and background in other data stores like SQL-Server, Postgres, and MongoDB
Experience with continuous delivery and automated deployments (Terraform)
ETL experience
Able to identify and participate in addressing scalability issues for enterprise level data
Python programming experience
DESIRED, BUT NOT REQUIRED SKILLS:
Experience with machine learning libraries like scikit-learn, Tensorflow, etc., or an interest in picking it up
Experience with R to mine structured and unstructured data and/or building statistical models
Experience with Elasticsearch
Experience with AWS services like Glue, S3, SQS, Lambda, Fargate, EC2, Athena, Kinesis, Step Functions, DynamoDB, CloudFormation and CloudWatch will be a huge plus
POSITION LOCATION:
There are 3 options for the location of this position (candidates based outside the US are NOT being considered at this time):
You can work remotely in the continental US with occasional travel to Bend, Oregon
You can be based at a shared office space in the heart of downtown Portland, Oregon
You can be based at our offices in Bend, Oregon (relocation assistance package available)
Check out this video to learn more about the Tech scene in Bend, Oregon
NAVIS OFFERS:
An inclusive, fun, values-driven company culture – we’ve won awards for it
A growing tech company in Bend, Oregon
Work / Life balance - what a concept!
Excellent benefits package with a Medical Expense Reimbursement Program that helps keep our medical deductibles LOW for our Team Members
401(k) with generous matching component
Generous time off plus a VTO day to use working at your favorite charity
Competitive pay + annual bonus program
FREE TURKEYS (or pies) for every Team Member for Thanksgiving (hey, it's a tradition around here)
Your work makes a difference here, and we make a huge impact to our clients’ profits
Transparency – regular All-Team meetings, so you can stay in-the-know with what’s going on in all areas our business
",http://stackoverflow.com/jobs/362699/data-engineer-navis
JOB226299118645,"Senior Data Engineer - BlackLocus Jobs in Austin, TX","Senior Data Engineer - BlackLocus Jobs in Austin, TX",,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/austin/texas/usa/jobs/?vs=25&utm_medium=.JOBS%20Universe&utm_campaign=.JOBS%20RSS%20Feed&utm_source=.JOBS%20RSS%20Feed-DE
JOB226489926691,Senior Data Engineer - BlackLocus Jobs in United States,Senior Data Engineer - BlackLocus Jobs in United States,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/usa/jobs/?utm_medium=.JOBS%20Universe&utm_source=.JOBS%20RSS%20Feed-DE&utm_campaign=.JOBS%20RSS%20Feed&vs=25
JOB232719501018,"Staff Data Engineer, Monetization","Staff Data Engineer, Monetization","Bachelor's degree in Computer Science or a related field,Experience with relational databases, SQL, and map-reduce languages (Pig, Hive),Understanding of how different data storage engines work and what are the limitations (SQL, NoSQL, key-value stores),Knowledge of Java, C++, C and GO or Node.js,Experience with Druid or other time series based data storage solution,Deep knowledge building high-performance, high-availability, distributed systems,Experience with Kafka, Spark, Cassandra,Extensive experience working with big data and designing ETL pipelines from end to end,Expert with one RDMS, familiarity with PostgreSQL and Redshift,Knowledge of ad serving platforms and online advertising systems,Experience in game development","Build, scale, and maintain data pipelines to process billions of daily events into our data warehouses,Write and tune complex Java, MapReduce, Spark, and Hive jobs,Explore available technologies and design solutions to continuously improve our data quality, workflow reliability, scalability while reporting performance and capabilities,Troubleshoot data issues and build customized reports to investigate key business questions,Work closely with the Unity Engine, Ads, Analytics and Game Services teams worldwide,Drive key business initiatives with multiple teams and stakeholders across the organization,Mentor and help engineers grow,Work across teams to instill engineering best practices and patterns","Reasons could include: the employer is not accepting applications, is not actively hiring, or is reviewing applications
Unity powers over half of all the world's games and over two thirds of the world's VR and AR products. We put the most powerful creative tools in the hands of millions of developers and artists through our foundational principle of Democratization of Development. We are hard at work integrating revolutionary monetization systems deep into the core of Unity's engine. Combining data from over a billion players with advanced deep learning technology and in house proprietary analytics. The goal: to make our customers more successful and their consumers happier.
Unity is looking for a Staff Data Engineer, Monetization who will join a team focusing on building the next generation of Unity's monetization suite. As the leading development platform for online and mobile games, Unity is helping take developer's creations further and faster than ever before. Unity Monetization enables developers to build a business through advertising, in-app purchase and analytics. Our fast growing business requires a Staff Data Engineer, Monetization to care about system scalability, performance and processing big volumes of data. In addition, the system functional requirements also drive us towards use of rule engines and machine learning.
Responsibilities
Build, scale, and maintain data pipelines to process billions of daily events into our data warehouses
Write and tune complex Java, MapReduce, Spark, and Hive jobs
Explore available technologies and design solutions to continuously improve our data quality, workflow reliability, scalability while reporting performance and capabilities
Troubleshoot data issues and build customized reports to investigate key business questions
Work closely with the Unity Engine, Ads, Analytics and Game Services teams worldwide
Drive key business initiatives with multiple teams and stakeholders across the organization
Mentor and help engineers grow
Work across teams to instill engineering best practices and patterns
Requirements
Bachelor's degree in Computer Science or a related field
Experience with relational databases, SQL, and map-reduce languages (Pig, Hive)
Understanding of how different data storage engines work and what are the limitations (SQL, NoSQL, key-value stores)
Knowledge of Java, C++, C and GO or Node.js
Experience with Druid or other time series based data storage solution
Deep knowledge building high-performance, high-availability, distributed systems
Experience with Kafka, Spark, Cassandra
Extensive experience working with big data and designing ETL pipelines from end to end
Bonus points
Expert with one RDMS, familiarity with PostgreSQL and Redshift
Knowledge of ad serving platforms and online advertising systems
Experience in game development
Who we are
Unity is the creator of the world's most widely-used real-time 3D (RT3D) development platform, providing content creators around the world with the tools they need to build rich, interactive 2D, 3D, VR and AR experiences. In fact, apps made with Unity reach 2.7 billion devices worldwide, and were installed more than 24 billion times in the last 12 months.
The global engineering team keeps Unity at the forefront of technology and — working alongside partners like Magic Leap, Google, Facebook, Oculus and Microsoft — ensures optimized support for the latest technology and platforms. Unity is powering the real-time revolution, expanding beyond games and breaking into other industries including automotive, film, architecture, engineering, construction and more.
Unity is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. Therefore, we provide employment opportunities without regard to age, race, color, ancestry, national origin, religion, disability, sex, gender identity or expression, sexual orientation, or any other protected status in accordance with applicable law. If there are preparations we can make to help ensure you have a comfortable and positive interview experience, please let us know.
Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
Headhunters and recruitment agencies may not submit resumes/CVs through this Web site or directly to managers. Unity does not accept unsolicited headhunter and agency resumes. Unity will not pay fees to any third-party agency or company that does not have a signed agreement with Unity.
#LI-WP1 #SEN
","http://www.indeed.com/viewjob?t=Staff+Data+Engineer&c=Unity+Technologies&l=San+Francisco,+CA&jk=a20d70f8a75add1a&rtk=1d7geqhrmbmkm800&from=rss"
JOB237077939260,"Data Engineer Jobs in Houston, TX","Data Engineer Jobs in Houston, TX",,"Houston, TX","
Data Engineer Jobs in Houston, TX
Current Search Criteria
More
",https://militaryjobs.homedepot.com/data-engineer/jobs-in/houston/texas/usa/jobs/?utm_source=.JOBS%20RSS%20Feed-DE&utm_campaign=.JOBS%20RSS%20Feed&vs=25&utm_medium=.JOBS%20Universe
JOB238528970749,"Data Engineer, Commercial","Data Engineer, Commercial","Excellent medical, dental, and vision benefits","Ingesting 3rd party and internal data and creating clean data models to empower business and operational teams.,Developing standardized metrics to drive the behavior of our commercial organization and measure the outcome of that behavior.,Providing visibility to commercial leaders through the creation of dashboards and reports.,Analyzing the impact of commercial programs using our sales and field data.,This role offers tremendous upwards exposure towards senior business leaders and the chance to truly impact the decision-making at JUUL.,Excellent Python and SQL skills.,Experience with data visualization, dash-boarding and analytical report building.,World-class ability to extract and communicate insights from real-world datasets.,4+ years applicable experience or a relevant advanced degree.,Experience with Pandas, GCP/BigQuery, Tableau and Mode is valuable but not required.,You get excited about taking ownership of problems and solving them in a fast-paced and scrappy environment working cross-functionally with both technical and non-technical people,You are output focused and see data science as a powerful tool to get things done rather than as an end in itself.,You are a strong critical thinker with a passion for understanding complex issues and are comfortable working on ambiguous problems.,A place to grow your career. We’ll help you set big goals - and exceed them,People. Work with talented, committed and supportive teammates,Equity and performance bonuses. Every employee is a stakeholder in our success,Boundless snacks and drinks,Cell phone subsidy, commuter benefits, and discounts on JUUL products","Data Engineer, Commercial
THE COMPANY:
Juul Labs’ mission is to impact the lives of the world’s one billion adult smokers by eliminating combustible cigarettes. We have the opportunity to address one of the world’s most intractable challenges through a commitment to exceptional quality, research, design, and innovation. Backed by leading technology investors, we are committed to the same excellence when it comes to hiring great talent.
We are a diverse team that is united by this common purpose and we are hiring the world’s best engineers, scientists, designers, product managers, operations experts, and customer service and business professionals. If the opportunity to build your career at one of the fastest-growing companies is compelling, read on for more details.
ROLE AND RESPONSIBILITIES:
Data Engineering at JUUL means working with varied, messy data sets and applying analytical methods to help inform and drive business and product decisions. We are looking for output-focused problem solvers with a strong conceptual mindset and superb communication skills.
The team sees itself as analytics generalists - we choose the right technique for each problem, pride ourselves on building beautiful systems and data infrastructure while moving fast, and are ultimately driven by the value and insights data science can generate for the business and our customers.
Examples of projects we work on include
Ingesting 3rd party and internal data and creating clean data models to empower business and operational teams.
Developing standardized metrics to drive the behavior of our commercial organization and measure the outcome of that behavior.
Providing visibility to commercial leaders through the creation of dashboards and reports.
Analyzing the impact of commercial programs using our sales and field data.
This role offers tremendous upwards exposure towards senior business leaders and the chance to truly impact the decision-making at JUUL.
PERSONAL AND PROFESSIONAL QUALIFICATIONS:
Minimum qualifications:
Excellent Python and SQL skills.
Experience with data visualization, dash-boarding and analytical report building.
World-class ability to extract and communicate insights from real-world datasets.
4+ years applicable experience or a relevant advanced degree.
Experience with Pandas, GCP/BigQuery, Tableau and Mode is valuable but not required.
Preferred qualifications:
You get excited about taking ownership of problems and solving them in a fast-paced and scrappy environment working cross-functionally with both technical and non-technical people
You are output focused and see data science as a powerful tool to get things done rather than as an end in itself.
You are a strong critical thinker with a passion for understanding complex issues and are comfortable working on ambiguous problems.
EDUCATION:
Bachelor’s degree from a top university or equivalent, ideally in Mathematics, Economics, Physics, Computer Science or a similar discipline
JUUL LABS PERKS & BENEFITS:
A place to grow your career. We’ll help you set big goals - and exceed them
People. Work with talented, committed and supportive teammates
Equity and performance bonuses. Every employee is a stakeholder in our success
Boundless snacks and drinks
Cell phone subsidy, commuter benefits, and discounts on JUUL products
Excellent medical, dental, and vision benefits
JUUL Labs is proud to be an equal opportunity employer and is committed to creating a diverse and inclusive work environment for all employees and job applicants, without regard to race, color, religion, sex, sexual orientation, age, gender identity or gender expression, national origin, disability or veteran status. We will consider for employment qualified applicants with arrest and conviction records, pursuant to the San Francisco Fair Chance Ordinance. JUUL Labs also complies with the employment eligibility verification requirements of the Immigration and Nationality Act. All applicants must have authorization to work for JUUL Labs in the US
",https://www.sitepoint.com/jobs/juul-labs/data-engineer-commercial
JOB239073858570,Snowflake Data Engineer,Snowflake Data Engineer,"Total 2+ years in IT (preferably DW/ETL/BI projects),Experience with gathering end user requirements and writing technical documentation,Time management and multitasking skills to effectively meet deadlines,Basic understanding of data management concepts such as 3NF, Dimensional and their specific applications,SQL, PL/SQL experience in analyzing, transforming and integrating data (preferably in one of the database technologies such as Oracle, MSSQL, DB2, Teradata),Basic understanding of DWH-related terms such as for example procedures, functions, triggers, views, indexes etc.,Ability to analyze data from various sources to find meaningful insights as well as identify gaps and inconsistencies,Client facing and team player skills,Good command of written and spoken English,Willingness to develop competences in the area of data analytics,Availability and mobility to work on projects in Poland and across Europe,Previous experience with ETL tools (for example ODI, SAS DI, IBM DataStage, Informatica, MS SSIS),Experience in Agile development methodologies,Access to leading edge Cloud technologies,Career and competence support, including ongoing mentoring and financing of certificates in different technologies and tools.,Full work comfort: private healthcare, additionally life insurance, sport packages.,Opportunity to work with global top clients on innovative and large international projects on European level","Work in interdisciplinary teams that combine technical, business and data science competencies.,Design and implement solutions around data warehouse implementation ranging from architecture, ETL processes, multidimensional modelling, data marts implementation.,Integrate datasets and dataflows using a variety of best in class software as well as profile and analyze large and complex datasets from disparate sources.,Be involved in the full project lifecycle (gathering business requirements, system design, development, testing and deployment).,We are looking for both experienced specialists as well and non-experienced talents.","
Job Description
We are glad to invite you to become a part of an international team that will deliver Snowflake projects for world-class Consumer Goods companies at global scale. Work on the solution design and implementation, take part in subsequent phases of the project.
You will:
Work in interdisciplinary teams that combine technical, business and data science competencies.
Design and implement solutions around data warehouse implementation ranging from architecture, ETL processes, multidimensional modelling, data marts implementation.
Integrate datasets and dataflows using a variety of best in class software as well as profile and analyze large and complex datasets from disparate sources.
Be involved in the full project lifecycle (gathering business requirements, system design, development, testing and deployment).
We are looking for both experienced specialists as well and non-experienced talents.
Qualifications
What we expect from you:
Total 2+ years in IT (preferably DW/ETL/BI projects)
Experience with gathering end user requirements and writing technical documentation
Time management and multitasking skills to effectively meet deadlines
Basic understanding of data management concepts such as 3NF, Dimensional and their specific applications
SQL, PL/SQL experience in analyzing, transforming and integrating data (preferably in one of the database technologies such as Oracle, MSSQL, DB2, Teradata)
Basic understanding of DWH-related terms such as for example procedures, functions, triggers, views, indexes etc.
Ability to analyze data from various sources to find meaningful insights as well as identify gaps and inconsistencies
Client facing and team player skills
Good command of written and spoken English
Willingness to develop competences in the area of data analytics
Availability and mobility to work on projects in Poland and across Europe
Nice to have:
Previous experience with ETL tools (for example ODI, SAS DI, IBM DataStage, Informatica, MS SSIS)
Experience in Agile development methodologies
Our offer:
Access to leading edge Cloud technologies
Career and competence support, including ongoing mentoring and financing of certificates in different technologies and tools.
Full work comfort: private healthcare, additionally life insurance, sport packages.
Opportunity to work with global top clients on innovative and large international projects on European level
If this sounds like the ideal role, career and company for you, please apply online as soon as possible.
When applying please enclose the below statements:
I hereby consent to the processing of my personal data by Accenture sp. z o.o. with its registered seat in Warsaw (00-121), at ul. Sienna 39, NIP 526-00-15-900 (Data Controller), in accordance with the Act of May 10, 2018 on the Protection of Personal Data (Journal of Laws of 2018, item 1000) and the Regulation on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (Data Protection Directive), necessary to carry out the recruitment process by Accenture . At the same time, I declare that I provide my personal data completely voluntary. I also declare that I have been informed about my right to withdraw my consent or object to processing of data, request access to them, rectification, deletion, limitation of processing and their transfer, at any time and the right to lodge a complaint to the data protection supervisory authority.
I hereby also consent to the processing of my personal data for future recruitment proceedings held by Accenture sp. z o.o. with its registered seat in Warsaw (00-121), at ul. Sienna 39, NIP 526-00-15-900 (Data Controller), in accordance with the Act of May 10, 2018 on the Protection of Personal Data (Journal of Laws of 2018, item 1000) and the Regulation on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (Data Protection Directive). At the same time, I declare that I provide my personal data completely voluntary. I also declare that I have been informed about my right to withdraw my consent or object to processing of data, request access to them, rectification, deletion, limitation of processing and their transfer, at any time and the right to lodge a complaint to the data protection supervisory authority.
Accenture does not discriminate employment candidates on the basis of race, religion, color, sex, age, disability, national origin, political beliefs, trade union membership, ethnicity, denomination, sexual orientation or any other basis impermissible under Polish law.
",https://www.accenture.com/pl-pl/careers/jobdetails?id=00832496_pl&title=Snowflake+Data+Engineer
JOB239129576372,Data Engineer,Data Engineer,,"Gather requirements, assess gaps, and build roadmaps and architectures to help the analytics driven organization achieve its goals.,Work closely with Data Analysts to ensure data quality and availability for analytical modelling.,Explore suitable options and designs for specific analytical solutions.,Define extract, load, and transform (ELT) based on jointly defined requirements.,Prepare, clean, and massage data for use in modeling and prototypes,Identify gaps and implement solutions for data security, quality, and automation of processes.,Bachelor’s degree or four or more years of work experience.,Four or more years of experience as a data engineer,Four or more years of experience finding, cleaning, and preparing data for use by Data Scientists,Experience knitting disperate data sources together,Four or more years of experience building data pipelines,Experience using SQL (i.e., PL/SQL or T-SQL with RDBMSs like Teradata, MS SQL Server, Oracle, etc.),Experience in data engineering, databases, and data warehouses.,Strong experience with data engineering in Python.,Master’s degree in Computer Science, Engineering, Statistics, IT, or related field.,Experience with Scala, Julia, R, Python or other machine learning programming language,Experience on Big Data platforms (i.e., Hadoop, Map/Reduce, Spark, HBase, CouchDB, Hive, etc.),Strong analytical and problem-solving skills.,Experience working in a network operations center environment.","
When you join Verizon
You’ll have the power to go beyond – doing the work that’s transforming how people, businesses and things connect with each other. Not only do we provide the fastest and most reliable network for our customers, but we were first to 5G - a quantum leap in connectivity. Our connected solutions are making communities stronger and enabling energy efficiency. Here, you’ll have the ability to make an impact and create positive change. Whether you think in code, words, pictures or numbers, join our team of the best and brightest. We offer great pay, amazing benefits and opportunity to learn and grow in every role. Together we’ll go far.
Diversity and Inclusion at Verizon
At Verizon, we know that diversity makes us stronger. We are committed to a collaborative, inclusive environment that encourages authenticity and fosters a sense of belonging. We strive for everyone to feel valued, connected, and empowered to reach their potential and contribute their best. Check out our diversity and inclusion page to learn more.
What you’ll be doing...
We're adding a Data Engineer to work on a portfolio of innovative projects that will enable digital operational excellence within Verizon Business Group (VBG) Customer Operations. The program direction includes artificial intelligence, operations automation, and industry leading omnichannel technology to improve the efficiency and client experience of our services. You will critically analyze a global network operations environment to build data pipelines, transform data into actionable intelligence. As part of this effort, you will turn raw data into usable data pipelines and build data tools and products for effort automation and easy data accessibility. You will also diagnose the existing architecture, data maturity, and identify gaps. You will build data assets that enhance the quality of overall data structures feeding the data science program.
You should be highly analytical and have the ability to transform complex data into easily understood, actionable information. You should flourish in a fast-paced environment and quickly adapt to changing priorities. You should also be flexible, highly curious with a dependability to work well individually and as part of a team.
Gather requirements, assess gaps, and build roadmaps and architectures to help the analytics driven organization achieve its goals.
Work closely with Data Analysts to ensure data quality and availability for analytical modelling.
Explore suitable options and designs for specific analytical solutions.
Define extract, load, and transform (ELT) based on jointly defined requirements.
Prepare, clean, and massage data for use in modeling and prototypes
Identify gaps and implement solutions for data security, quality, and automation of processes.
Support maintenance, bug fixes and, performance analysis along data pipeline.
What we’re looking for...
You'll need to have:
Bachelor’s degree or four or more years of work experience.
Four or more years of experience as a data engineer
Four or more years of experience finding, cleaning, and preparing data for use by Data Scientists
Experience knitting disperate data sources together
Four or more years of experience building data pipelines
Experience using SQL (i.e., PL/SQL or T-SQL with RDBMSs like Teradata, MS SQL Server, Oracle, etc.)
Experience in data engineering, databases, and data warehouses.
Strong experience with data engineering in Python.
Ability to travel occasionally
Even better if you have:
Master’s degree in Computer Science, Engineering, Statistics, IT, or related field.
Experience with Scala, Julia, R, Python or other machine learning programming language
Experience on Big Data platforms (i.e., Hadoop, Map/Reduce, Spark, HBase, CouchDB, Hive, etc.)
Strong analytical and problem-solving skills.
Experience working in a network operations center environment.
Experience as an open source Ccntributor.
Equal Employment Opportunity
We're proud to be an equal opportunity employer - and celebrate our employees' differences, including race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, and Veteran status. Different makes us better.
",https://www.verizon.com/about/work/jobs/5875273-data-engineer
JOB240358048069,Data Analyst III - Data Engineer,Data Analyst III - Data Engineer,,,"
Cox Communications is the largest private telecom company in America, and we proudly serve six million homes and businesses across 18 states. At Cox, we are committed to creating meaningful moments of human connection, not only with our products and services, but also with our career opportunities. Come connect with us, and lets build a better future together.
Role Summary
Looking for a Senior Data Analyst to join an enterprise reporting and analytics team supporting Cox Communications Enterprise Finance and Accounting as well as our business partners. This person should be comfortable in a data engineering role building data pipelines and ETL processes, have enough business acumen to understand context and intent, and apply these concepts to data solutions. This role will assist in data strategy and design, and develop data-sets for the Finance BI ecosystem to support reporting, analysis & analytical modeling.
Recognized as a Subject Matter Expert (SME) and authority on issues related to Business Intelligence applications reporting, analysis, and metrics. This person will exercise an inquisitive mindset to transform business questions into actionable data exploration exercises and data sets using data analysis, modeling, automation, and optimization techniques. Operates with considerable latitude for independent judgment. Provides influence and expertise to cross-functional teams and other stakeholders on ideas and solutions that impact corporate results.
Primary Responsibilities and Essential Functions
• Supports and/or leads discussions with multidisciplinary teams to collect functional business requirements, scoping analytical projects, manage expectations and deadlines, and translate needs into technical specifications.
• Supports technical development of solutions to expedite delivery of new datasets, process automation, production of complex models and analyses, including gap assessments, and works to deliver strategies.
• Serves as an organizational consultant on matters relating to data and databases by providing expertise to assist users in meeting their needs.
• Initiates the identification of actionable insights and contribute to the development of business recommendations through effective presentations and communication of results.
• Develops processes and solutions to speed up / expedite the development of datasets, report automation, production of dashboards, complex models, and analyses.
• Extract and manipulate data from a variety of cloud and on-premise based systems for reporting and analytical purposes, including: Oracle databases, Essbase and data cubes, Tableau, SQL Server, and various data sources as needed.
• Report automation and self-service dashboard solutions using combination of tools such as SQL, Tableau, Prep, Alteryx, Informatica and Python.
• Develops automated processes that preserve data integrity by managing the alignment of data availability and integration processes.
• Expertise in creating and optimizing Tableau Datasets and Visualizations.
• Identifies, researches, and resolves discrepancies in an analytical procedure or cross-functional methods.
• Establish and maintain design and development best practices including keeping written procedures to document data processes and ensure best data governance practices are maintained.
• Liaises with CCI Technology/EDS partners for both data-sourcing needs and for “promotion” of data-sets into the enterprise BI layer when/as-needed.
• Leads data collection, cleansing, and validation.
• Conducts day-to-day activities with minimum supervision.
Qualifications:Skills and Qualifications
Minimum
• 5 or more years of experience required in related field (developing and implementing analytical solutions in Finance, Marketing, Sales or Operations). 3 or more years of experience required if candidate possesses a related advanced degree.
• Requires strong skills in SQL writing and query optimization.
• Requires experience building data workflows, manipulation of large data sets, or developing data pipelines in analytical tools such as Informatica, Alteryx, Tableau Prep, SQL, SSIS, etc.
• Requires strong skills and experience with reporting and data visualization in analytical tools such as Tableau, Prep, SQL, etc.
• Requires effective proficiency in teamwork, communication, presentation, and time management to work effectively with teams throughout organization, including strong verbal and written communication.
• Experience manipulating large datasets and the ability to extrapolate conclusions from the data.
• Demonstrated problem solving and analytical thinking skills.
• Excellent interpersonal, leadership, presentation, and collaborative skills to work effectively with teams throughout organization.
• BS/BA degree in related discipline
Preferred
• Master's degree in a related discipline preferred
• Working knowledge of Tableau and/or visual analytics software tools and best practices
• Working knowledge of Alteryx and/or data transformation tools and best practices
• 3 or more years using Tableau for analysis, visualization & dashboard development
• 3 or more years of experience in database administration and SQL, including SQL tuning/performance optimization
• 2 or more years of experience in Data Warehousing, ETL Development, Data Management tools such as SSIS, Informatica, Datastage, etc
• 1 or more years of experience using Oracle Essbase or integration with data cubes
• 2 or more years of experience using Alteryx for data preparation & modeling
• 1 or more years of experience in OBIEE report and RPD development
• 1 or more years of experience in Java, Python or other programming or scripting languages
• Knowledge of Big Data querying tools, such as Pig, Hive, and Impala
• Experience within telecom, consumer package goods, retail, financial services, or consulting industries
• Operational analytics including application for Call Center, Technical Support, Collections, and Customer Experience Analytics
#LI-355
About Cox Communications
Cox Communications is committed to creating meaningful moments of human connection through broadband applications and services. The largest private telecom company in America, we proudly serve six million homes and businesses across 18 states. We're dedicated to empowering others to build a better future and celebrate diverse products, people, suppliers, communities and the characteristics that makes each one unique. Cox Communications is the largest division of Cox Enterprises, a family-owned business founded in 1898 by Governor James M. Cox.
Cox is an Equal Employment Opportunity employer - All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.
Statement to ALL Third-Party Agencies and Similar Organizations: Cox accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Cox employees, Cox hiring manager, or send to any Cox facility. Cox is not responsible for any fees or charges associated with unsolicited resumes.
",https://www.mediabistro.com/jobs/description/404109/data-analyst-iii-data-engineer/
JOB242174952456,Data Engineer,Data Engineer,,,"
POSITION PURPOSE
Congrats! You re learning about an exciting new role with The Home Depots Global Custom Commerce (GCC) team that will revitalize and invigorate the way we manage and view data. For this role, we are looking for some one who can develop, implement, test and maintain data pipelines (batch & streaming) and data structures within a cloud based column-oriented data store. This person will support the GCC BI and Data Science strategic initiatives to drive better customer experiences and more profitable outcomes
Why work here? Our entrepreneurial roots and maverick mentality, coupled with the resources and backing of the #1 home improvement retailer in the world, The Home Depot, is a unique opportunity for you to be a transformative retail disrupter. Plus, GCC is the world s largest online window covering company, and we ve got a demonstrably awesome 20-year track record. From our open-floor office to our open-door ethos, our culture is rooted in improving, evolving, and having fun (we re pretty serious about cake, cook-offs, ping pong, meaningful work and exciting projects). Most importantly, our team members are always inspired, engaged, and ready for growth. That means you ll have the resources and the runway to create truly magical, out-of-the-box work. Moreover, you will play an important role in leveraging our culture, people, systems, processes, and technology ultimately to provide incredible customer experiences, while growing business for GCC and The Home Depot. This is your chance to be part of something big, in a small start-up environment. We re ranked as one of The Top 5 Workplaces in Texas and have consistently won the following awards:The Best Place to Work in Houston (Houston Business Journal), Houston s Top Workplaces (Houston Chronicle) and Houston s Best and Brightest.
MAJOR TASKS, RESPONSIBILITES AND KEY ACCOUNTABILITIES
20%- Implement a real time streaming data ingestion and processing pipeline using Google Dataflow (Apache Beam)
20%- Interface with business intelligence analyts and others in IT (i.e. data engineers, architects, WebOps) in frequent whiteboard sessions to dicsucuss the design, implementation, and testing of data pipleines
20%- Maintain data architecture standards and ETL/ELT best practices consistent with a column oritented data store in an analytic use case
20%- Active and engaged particitpation in the Scrum delivery process
20%- Support solutions in production
NATURE AND SCOPE
This role reports to the Sr. Manager of EDW.
This role has no direct reports.
ENVIRONMENTAL JOB REQUIREMENTS
Environment:
Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.
Travel:
Typically requires overnight travel less than 10% of the time.MINIMUM QUALIFICATIONS
Must be eighteen years of age or older.
Must be legally permitted to work in the United States.
Education Required:
The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.
Years of Relevant Work Experience: 6 years
Physical Requirements:
Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.
Preferred Qualifications:
Familiarity with Agile methodologies
Experience with Spark dataframes, SparkSQL, Kafka, KSQL, real-time streaming, and message bus technologies
Experience with data science technologies such as SAS, R, Matlab, or similar
Experience with data warehousing and dimensional modeling
Knowledge, Skills, Abilities and Competencies:
Experience in building real time streaming data ingestion and processing pipeline using Apache Beam (running on either Google Datflow or Apache (Apex, Flink, or Spark) or Kafka in an analytics or data science use case
Experience with data processing tools (e.g. Hadoop, Spark, Dataflow, etc.)
Experience building ETL/ELT pipelines
Experience with column-oriented databases (e.g Redhift, BigQuery, Vertica)
Ability to go from whiteboard discussion to code
Ability to effectively communicate with technical and non-technical audiences
Strong programming ability
Success in a highly dynamic environment and ability to shift priorities with agility
Ability to act independently with minimal supervision
Willingness to explore and implement new ideas and technologies
Experience working directly with subject matter experts in both business and technology domains
Experience as a team lead We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
",https://militaryjobs.homedepot.com/houston-tx/data-engineer/4B642DC9C39B4857867CACB6FE730745/job/?utm_medium=.JOBS%20Universe&utm_source=.JOBS%20RSS%20Feed-DE&utm_campaign=.JOBS%20RSS%20Feed
JOB243176450157,Data Engineer,Data Engineer,"Knowledge and experience of financial markets, banking or exchanges","Design, build, and launch efficient and reliable data pipelines into production,Design and implement warehousing solutions to scale with the needs of the business,Develop new systems and tools to enable the team to consume and understand data more intuitively,Partner with engineers, project managers, and analysts to deliver insights to the business,4+ years experience in data engineering with data warehouse technology,4+ years experience in custom ETL design, implementation and maintenance,4+ years experience with schema design and dimensional data modeling,Strong SQL skills on multiple platform,Skilled in programming languages Python, R, and/or Java,Strong computer science fundamentals including data structures and algorithms,Strong software engineering skills in any server side language, preferable Python,Kafka, Cloud computing, machine learning, text analysis, NLP & Web development experience is a plus,NoSQL experience a plus,Experience with Continuous integration and deployment,Experienced in working collaboratively across different teams and departments","
Job description
As a member of our data engineering team, you’ll shape the way we approach data at Gemini by using your engineering, analytical and communication skills to work with teams across the business. You know how to ask the right questions and are passionate about using data to support and drive informed business decisions. You’ll guide our internal teams to use data to improve the product and achieve KPIs. Communicating your insights with leaders across the organization is paramount to success.
RESPONSIBILITIES:
Design, build, and launch efficient and reliable data pipelines into production
Design and implement warehousing solutions to scale with the needs of the business
Develop new systems and tools to enable the team to consume and understand data more intuitively
Partner with engineers, project managers, and analysts to deliver insights to the business
MINIMUM QUALIFICATIONS:
4+ years experience in data engineering with data warehouse technology
4+ years experience in custom ETL design, implementation and maintenance
4+ years experience with schema design and dimensional data modeling
Strong SQL skills on multiple platform
Skilled in programming languages Python, R, and/or Java
Strong computer science fundamentals including data structures and algorithms
Strong software engineering skills in any server side language, preferable Python
PREFERRED QUALIFICATIONS:
Kafka, Cloud computing, machine learning, text analysis, NLP & Web development experience is a plus
NoSQL experience a plus
Experience with Continuous integration and deployment
Experienced in working collaboratively across different teams and departments
Knowledge and experience of financial markets, banking or exchanges
",https://stackoverflow.com/jobs/208438/data-engineer-gemini
JOB244533757667,Geospatial Data Engineer,Geospatial Data Engineer,,"Working in an interdisciplinary field, together with computer scientists, business specs, and telecom network engineers, and will require excellent interpersonal and communication skills.,Integrating multiple data sources, models, and software tools with business line specific decision support and data analysis.,Developing new automation methods to analyze and evaluate business strategies across various business geographies, technologies, drivers and scales.,Modeling complex systems by integrating large varied datasets of economic, demographic and telecom related information.,Creating and walking through executive presentations that explain the complex data and algorithms used in simple easy-to-understand visually striking layman terms that leave a residual impact on an executive audience.,Solving complex geospatial problems utilizing robust and repeatable solutions.,Challenging existing constructs and business paradigms and creatively solving problems that result in a business transformation of a process or a program or a current approach.,Bachelor’s degree or four or more years of work experience.,Masters of Science in Geographic Information Systems.,Experience in one or more programming languages (e.g., Python, JavaScript).,Experience in analysis of large spatial and non-spatial datasets.,Experience with a multitude of databases in general (Oracle, Postgres).,Knowledge of R, SPSS, or SAS for statistical analysis is preferred.,Experience with large-scale parallel computing in distributed environments and familiarity with GIS and spatial databases (e.g., Postgres / PostGIS, Oracle/ESRI sde).,Experience using Python in automation of analytics tasks.,Demonstrated use of / development of spatially enabled Web Front Ends (ArcGIS JavaScript API, React, etc.),Experience managing data in SQL and/or NoSQL databases (Postgres, Oracle, Teradata, Hadoop, Casandra, MongoDB).,Knowledge in application of technical procedures, principles, theories and concepts in the Telecommunications field. General knowledge of other related disciplines.,Experience with leading one or more areas of team, task or project lead responsibilities.,Demonstrated experience managing short and long term projects from start to finish.,Experience in Telco, Cable or other network related field (Electric, Wastewater, Gas/Oil, Urban planning).,Interpersonal and communication skills.,Ability to convey complex information to upper level execs.","Reasons could include: the employer is not accepting applications, is not actively hiring, or is reviewing applications
What you’ll be doing...
The Engineering Program Office Data Science Team has an immediate opening for a talented and experienced Geospatial Data Engineer with hands on expertise in creation and automation of complex spatial and data algorithms using Python Automation and Web Front End visualization using modern JavaScript frameworks experience. Besides a strong interest in understanding the Telecom business model in particular and a passion for data in general. You must perform cross-disciplinary analysis and visualization of traditional and spatial data to help solve complex business problems. You will help to develop analysis automation scripts as well as build web front ends and visualization frameworks to model business driven problems.
Working in an interdisciplinary field, together with computer scientists, business specs, and telecom network engineers, and will require excellent interpersonal and communication skills.
Integrating multiple data sources, models, and software tools with business line specific decision support and data analysis.
Developing new automation methods to analyze and evaluate business strategies across various business geographies, technologies, drivers and scales.
Modeling complex systems by integrating large varied datasets of economic, demographic and telecom related information.
Creating and walking through executive presentations that explain the complex data and algorithms used in simple easy-to-understand visually striking layman terms that leave a residual impact on an executive audience.
Solving complex geospatial problems utilizing robust and repeatable solutions.
Challenging existing constructs and business paradigms and creatively solving problems that result in a business transformation of a process or a program or a current approach.
Challenging existing thought processes and actively work in cross disciplinary groups and make a case using rich data and presentation.
What we’re looking for...
You’ll need to have:
Bachelor’s degree or four or more years of work experience.
Six or more years of relevant work experience.
Even better if you have:
Masters of Science in Geographic Information Systems.
Experience in one or more programming languages (e.g., Python, JavaScript).
Experience in analysis of large spatial and non-spatial datasets.
Experience with a multitude of databases in general (Oracle, Postgres).
Knowledge of R, SPSS, or SAS for statistical analysis is preferred.
Experience with large-scale parallel computing in distributed environments and familiarity with GIS and spatial databases (e.g., Postgres / PostGIS, Oracle/ESRI sde).
Experience using Python in automation of analytics tasks.
Demonstrated use of / development of spatially enabled Web Front Ends (ArcGIS JavaScript API, React, etc.)
Experience managing data in SQL and/or NoSQL databases (Postgres, Oracle, Teradata, Hadoop, Casandra, MongoDB).
Knowledge in application of technical procedures, principles, theories and concepts in the Telecommunications field. General knowledge of other related disciplines.
Experience with leading one or more areas of team, task or project lead responsibilities.
Demonstrated experience managing short and long term projects from start to finish.
Experience in Telco, Cable or other network related field (Electric, Wastewater, Gas/Oil, Urban planning).
Interpersonal and communication skills.
Ability to convey complex information to upper level execs.
Ability to adapt to quickly changing business environment and requests that come in related to upper level executive requests.
When you join Verizon...
You’ll have the power to go beyond – doing the work that’s transforming how people, businesses and things connect with each other. Not only do we provide the fastest and most reliable network for our customers, but we were first to 5G - a quantum leap in connectivity. Our connected solutions are making communities stronger and enabling energy efficiency. Here, you’ll have the ability to make an impact and create positive change. Whether you think in code, words, pictures or numbers, join our team of the best and brightest. We offer great pay, amazing benefits and opportunity to learn and grow in every role. Together we’ll go far.
Equal Employment Opportunity
We're proud to be an equal opportunity employer - and celebrate our employees' differences, including race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, and Veteran status. Different makes us better.
",https://www.indeed.com/viewjob?jk=b2e32aeb5603cb8f&qd=a08hzet0leru2ueorxyai80k_t6cg0ezcrqotjaiweabpqv2l9sactzbzibmnvaj3kpsboodki_pbkjsanz7qx6nojn63azumly1372szmy&indpubnum=3522232380844066&chnl=marketgrabberdemo&atk=1dp51cpf4o23f800
JOB245410038832,"Data Engineer Jobs in Houston, TX","Data Engineer Jobs in Houston, TX",,"Houston, TX","
Data Engineer Jobs in Houston, TX
Current Search Criteria
More
",https://militaryjobs.homedepot.com/data-engineer/jobs-in/houston/texas/usa/jobs/?vs=25&utm_campaign=.JOBS%20RSS%20Feed&utm_medium=.JOBS%20Universe&utm_source=.JOBS%20RSS%20Feed-DE
JOB245531461365,Sr Data Engineer - Product,Sr Data Engineer - Product,http://www.showtimeanytime.com/,"Develop understanding of key business, product and user questions.,Collaborate with other Product Engineering team members to develop, test and support data-related initiatives. Work with other departments to understand their data needs.,Evolve data-driven feature prototypes into production features that scale,Streamline feature engineering, so that the underlying data is efficiently extracted.,Build flexible data pipelines that we can rapidly evolve as our needs change and capabilities grow.,Develop and enhance our data warehouse in AWS S3.,You have at least 3 years of relevant experience in a comparable data engineering role,You have expert-level knowledge of SQL/Spark SQL,You have experience in pursuing and launching data-backed decisions, such as recommendations, to make end-user-facing products better,You like to dive-deep on data questions to come up with effective solutions,You believe in writing code that is easy to understand, test and maintain,You thrive in a workplace that values autonomy, applauds ideas and a enjoys a sense of humor,http://www.showtime.com/","REF#: 34702
CBS BUSINESS UNIT: Showtime
JOB TYPE: Full-Time Staff
JOB SCHEDULE: Full-Time
JOB LOCATION: New York, NY
DESCRIPTION:
The Showtime Product team is looking for an experienced, curious and creative Sr. Data Engineer to help us pursue answers to our increasingly interesting and complex business questions and empower our team to incorporate data-driven features and machine learning into our products, which include our standalone service SHOWTIME and our TV Everywhere service, Showtime Anytime.
In this role, you will be an integral part of our data engineering team and collaborate with our dedicated Product Analytics team, the Showtime Research and Data Strategy teams, the CRM team, and our in-house backend and front-end engineering groups. You will work with the rest of the data team to architect solutions and develop technologies, systems and workflows that enable our analysts and data scientists to focus on algorithms and analyses rather than on the associated engineering.
Ideal candidates will be innovative, self-motivated, a quick study, and willing to develop new skills while constantly improving existing abilities.
Key Technologies: Java, Scala, Groovy, Spark, AWS, AWS/EMR, Spring, Mongo, Git, Redis, Bamboo, JIRA, etc
Responsibilities:
Develop understanding of key business, product and user questions.
Collaborate with other Product Engineering team members to develop, test and support data-related initiatives. Work with other departments to understand their data needs.
Evolve data-driven feature prototypes into production features that scale
Streamline feature engineering, so that the underlying data is efficiently extracted.
Build flexible data pipelines that we can rapidly evolve as our needs change and capabilities grow.
Develop and enhance our data warehouse in AWS S3.
QUALIFICATIONS:
You have at least 3 years of relevant experience in a comparable data engineering role
You have expert-level knowledge of SQL/Spark SQL
You have experience in pursuing and launching data-backed decisions, such as recommendations, to make end-user-facing products better
You like to dive-deep on data questions to come up with effective solutions
You believe in writing code that is easy to understand, test and maintain
You thrive in a workplace that values autonomy, applauds ideas and a enjoys a sense of humor
ABOUT US:
SHOWTIME continues to make its mark across the cultural landscape with one of the most successful programming lineups in television. The SHOWTIME programming slate features original series including Emmy® nominated limited series ESCAPE AT DANNEMORA, BILLIONS, HOMELAND, SHAMELESS, THE CHI, RAY DONOVAN, THE AFFAIR, KIDDING, BLACK MONDAY, THE LOUDEST VOICE, CITY ON A HILL, THE L WORD: GENERATION Q, BACK TO LIFE, WORK IN PROGRESS and ON BECOMING A GOD IN CENTRAL FLORIDA. The network’s eclectic, brand-defining programming is further distinguished by the captivating offerings of SHOWTIME Documentary Films, including docuseries THE CIRCUS: INSIDE THE WILDEST POLITICAL SHOW ON EARTH, Emmy-nominated WU-TANG CLAN: OF MICS AND MEN and THE FOURTH ESTATE and documentary films THE KINGMAKER and READY FOR WAR. SHOWTIME Sports continues to dominate with its flagship franchise SHOWTIME CHAMPIONSHIP BOXING® and the Emmy Award-winning series INSIDE THE NFL. SHOWTIME is currently available to subscribers via cable, DBS and telco providers, and as a stand-alone streaming service through Amazon, Apple®, Google, LG Smart TVs, Oculus Go, Roku®, Samsung and Xbox One. Consumers can also subscribe to SHOWTIME via Amazon’s Prime Video Channels, DirecTV Now, FuboTV, Hulu, Sling TV and YouTube TV. The network’s authentication service, SHOWTIME ANYTIME, is available at no additional cost to SHOWTIME customers who subscribe to the network through participating providers. Subscribers can also watch on their computers at [1] www.showtime.com and [2] www.showtimeanytime.com.
References
Visible links
http://www.showtime.com/
http://www.showtimeanytime.com/
EEO STATEMENT:
Equal Opportunity Employer Minorities/Women/Veterans/Disabled
","http://www.indeed.com/viewjob?t=Senior+Data+Engineer&c=CBS&l=New+York,+NY&jk=92991024886978cb&rtk=1dgi5044dnove800&from=rss"
JOB245705107437,Data Engineer - Wix Marketing,Data Engineer - Wix Marketing,,"Design, implement and support robust, scalable solutions to enhance business analysis capabilities, identify gaps and design processes to fill them.,Work with analysts to understand business priorities and translate requirements into data models.,Collaborate with various stakeholders across the company like data developers, analysts, data science, finance, etc, in order to deliver team tasks.,Build complex multi-cloud ETL pipelines in Apache Airflow.,Build Python API integrations with 3rd party vendors.","We are:
Wix’s Marketing Data Engineering team. We’re responsible for all marketing data pipelines including 3rd party integrations, internal ETL procedures, cloud and on premises DWH management and modeling. We operate in a data environment with 200M users and an enormous amount of data events. We communicate with multiple stakeholders both internally and externally and fully responsible for all data related developments.
You are:
An independent, self-learner who understands business processes and can translate business needs into data models. You have at least 1 year of data engineering experience including API integrations. You can quickly learn new technologies and have a good level of Python including familiarity with modern CI/CD approach and mainstream libraries.
You’re highly proficient in SQL, including performance tuning, and you’re familiar with database modeling in both relational and data warehouse environments. You have experience in cloud environments (GCP/AWS/Azure) and modern data warehouse solutions (BigQuery, Snowflake, Redshift, Presto, etc).
Bonus points if you have a working knowledge of Apache Airflow.
As Data Engineer, you will:
Design, implement and support robust, scalable solutions to enhance business analysis capabilities, identify gaps and design processes to fill them.
Work with analysts to understand business priorities and translate requirements into data models.
Collaborate with various stakeholders across the company like data developers, analysts, data science, finance, etc, in order to deliver team tasks.
Build complex multi-cloud ETL pipelines in Apache Airflow.
Build Python API integrations with 3rd party vendors.
Implement new tools and development approaches.
",https://www.wix.com/jobs/locations/tel-aviv/positions/3884
JOB248666605292,Sr. Data Engineer - Product,Sr. Data Engineer - Product,http://www.showtimeanytime.com/,http://www.showtime.com/,"REF#: 33447
CBS BUSINESS UNIT: Showtime
JOB TYPE: Full-Time Staff
JOB SCHEDULE: Full-Time
JOB LOCATION: New York, NY
DESCRIPTION:
The Showtime Product team is looking for an experienced, curious and creative Sr. Data Engineer to help us pursue answers to our increasingly interesting and complex business questions and empower our team to incorporate data-driven features and machine learning into our products, which include our standalone service SHOWTIME and our TV Everywhere service, Showtime Anytime.
In this role, you will be an integral part of our data engineering team and collaborate with our dedicated Product Analytics team, the Showtime Research and Data Strategy teams, the CRM team, and our in-house backend and front-end engineering groups. You will work with the rest of the data team to architect solutions and develop technologies, systems and workflows that enable our analysts and data scientists to focus on algorithms and analyses rather than on the associated engineering.
Ideal candidates will be innovative, self-motivated, a quick study, and willing to develop new skills while constantly improving existing abilities.
Key Technologies: Java, Scala, Groovy, Spark, AWS, AWS/EMR, Spring, Mongo, Git, Redis, Bamboo, JIRA, etc
Responsibilities:
Develop understanding of key business, product and user questions.
Collaborate with other Product Engineering team members to develop, test and support data-related initiatives. Work with other departments to understand their data needs.
Evolve data-driven feature prototypes into production features that scale
Streamline feature engineering, so that the underlying data is efficiently extracted.
Build flexible data pipelines that we can rapidly evolve as our needs change and capabilities grow.
Develop and enhance our data warehouse in AWS S3.
QUALIFICATIONS:
You have at least 2 years of relevant experience in a comparable data engineering role
You have expert-level knowledge of SQL/Spark SQL
You have experience in pursuing and launching data-backed decisions, such as recommendations, to make end-user-facing products better
You like to dive-deep on data questions to come up with effective solutions
You believe in writing code that is easy to understand, test and maintain
You thrive in a workplace that values autonomy, applauds ideas and enjoys a sense of humor
ABOUT US:
SHOWTIME and its critically-acclaimed, award-winning original series continue to make their mark on the cultural landscape, with one of the most successful programming slates in all of television. With an impressive line-up of new and returning original series, the SHOWTIME hit dramas and comedies include HOMELAND, SHAMELESS, BILLIONS, RAY DONOVAN, THE AFFAIR, SMILF, THE CHI, KIDDING, ESCAPE AT DANNEMORA and BLACK MONDAY. Original series play a key part in the SHOWTIME programming mix, along with box office hits, comedy and music specials, provocative documentaries, and hard-hitting sports programming, including the flagship franchise SHOWTIME CHAMPIONSHIP BOXING® and the Emmy Award-winning veteran series INSIDE THE NFL. SHOWTIME is currently available to subscribers via cable, DBS and telco providers, and as a stand-alone streaming service through Amazon, Apple®, Google, LG Smart TVs, Oculus Go, Roku®, Samsung and Xbox One. Consumers can also subscribe to SHOWTIME via Amazon’s Prime Video Channels, DirecTV Now, FuboTV, Hulu, Sling TV, Sony PlayStation™ Vue, and YouTube TV. The network’s authentication service, SHOWTIME ANYTIME, is available at no additional cost to SHOWTIME customers who subscribe to the network through participating providers. Subscribers can also watch on their computers at [1] www.showtime.com and [2] www.showtimeanytime.com.
References
Visible links
http://www.showtime.com/
http://www.showtimeanytime.com/
EEO STATEMENT:
Equal Opportunity Employer Minorities/Women/Veterans/Disabled
","http://www.indeed.com/viewjob?t=Senior+Data+Engineer&c=Showtime&l=New+York,+NY&jk=763142a24863d48f&rtk=1d84366td2008000&from=rss"
JOB249047382196,"EmployeeChannel, Inc. — NLP Data Engineer","EmployeeChannel, Inc. — NLP Data Engineer",,,"
Title:
NLP Data Engineer
Type:
Job
Brief Description:
English; Computational Linguistics: Programmer
Company:
EmployeeChannel, Inc.
Location:
CA, USA
Posted On:
Feb 02, 2017
Application Deadline:
Apr 15, 2017
More Information:
University or Organization: EmployeeChannel, Inc.
Job Location: California, USA
Job Title: NLP Data Engineer
Job Rank: Programmer

Specialty Areas: Computational Linguistics

Required Language(s): English (eng)

Description:

Data Engineer with a focus on Natural Language Processing

EmployeeChannel, Inc. is looking for a highly motivated Natural Language
Processing data engineer with a strong background in software development and
language technologies including text mining, information retrieval, speech
processing and language modeling. This position gives you an opportunity to
apply your problem solving skills to challenging problems in natural language
processing for enterprise-scale customers. The data engineer will utilize
their experience leveraging machine learning techniques and language data to
develop a new generation of human resources-oriented customer support
products. The ideal candidate is an accomplished software engineer who will
work with fellow engineers and data scientists to combine unstructured data
analysis with traditional data mining and machine learning techniques in a new
domain. Among other projects, you will build a scalable and distributed search
system including content acquisition, indexing, and query interfaces.

The data engineer will:

report to the senior natural language processing architect and work on an NLP
and analytics-focused team to improve search in the product and create a more
intuitive and personalized conversation within the question-answering
interface.

Required Technical and Professional Expertise:

- Strong Python, JavaScript, and SQL programming skills.
- Knowledge of, or experience building production quality and large scale
deployments of applications related to natural language processing and machine
learning.
- Knowledge of machine learning techniques and algorithms and the ability to
apply them in concert with data driven natural language processing methods.
- Experience using many of the following:
Information retrieval/search (Word2vec, Lucene, and Elasticsearch)
Text similarity measures (tf–idf, n-grams, and Jaccard similarity)
Experience with scikit-learn / NLTK / Stanford core
Linguistic dictionaries, ontologies, taxonomies, and other NLP
resources.
- Ability to quickly prototype ideas and solutions.
- Experience performing data analysis and creatively solving complex problems.
- Excellent communication skills and experience developing solutions in
coordination with a high-performing team in an agile environment.
- Knowledge of R or comparable statistical modeling and graphics
packages.

Nice to Have Technical and Professional Experience

- MS in Computer Science, Computational Linguistics, Cognitive Science, Data
Science, Semiotics, Information Systems, Experimental Psychology, or similar.
- Experience developing software for highly contextual or domain- specific
search, chat-bots, intelligent assistants, or AI agents.
- Experience building solutions to with Natural Languages Understanding (NLU),
Natural Language Generation (NLG), and semantics-based problems.
- Experience improving search recall and precision with enterprise data.
- Human-in-the-loop and human computation experience including setting up and
analyzing the results of language annotation tasks on crowdsourcing platforms.
- Big data infrastructure, data mining, or data management.

About Us:

EmployeeChannel, Inc. is a leading provider of cloud-based apps for real-time
employee communications, delivering the knowledge and performance of a
company’s HR professionals and their partners at employees’ fingertips.



Application Deadline: 15-Apr-2017 (Open until filled)

Email Address for Applications: sarah@employeechannelinc.com
Contact Information
        Sarah
        Email: sarah@employeechannelinc.com
Notes:
Log in with administrative privileges to enable editing ",https://cldb.ling.washington.edu/jobdetail.php?JobID=1109
JOB250210436157,Senior Data Engineer - BlackLocus,Senior Data Engineer - BlackLocus,,,"
Job Information
POSITION PURPOSE
The Sr Data Engineer will expand and optimize data, data flow, data collection for cross functional teams, and data pipeline architecture. The Sr Data Engineer will support and collaborate with the software engineering team, data analysts, and data scientist to ensure data delivery architecture is consistent throughout ongoing projects. Continuously improve or re-design data architecture to support the next generation of products and initiatives.
MAJOR TASKS, RESPONSIBILITES AND KEY ACCOUNTABILITIES
40% - Data Validation, ETL, Infrastructure Development: Coding validation and ETL to ensure successful data integration
30% - Data Infrastructure Maintenance: Backup and optimization activities to maintain performance; code, configure, test, etc data to ensure integrity
20% - Data Architecture Design and Analysis: Create and maintain optimal data pipeline architecture; Develop data architecture to meet business requirements
10% - Planning/Requirements Analysis: Collaborate with team leads and cross functional partners to assess business requirements and communicate opportunities
NATURE AND SCOPE
This position reports to the Technology Leader.
This position has 0 direct reports.
ENVIRONMENTAL JOB REQUIREMENTS
Environment:
Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.
Travel:
Typically requires overnight travel less than 10% of the time.
Additional Environmental Job Requirements: MINIMUM QUALIFICATIONS
Must be eighteen years of age or older.
Must be legally permitted to work in the United States.
Additional Minimum Qualifications:
Experience message queuing, stream processing, and scalable data stores
Experience managing projects and organizing data
Experience supporting and working with cross-functional teams
Experience with SQL, NoSQL databases, relational databases, and query authoring
Experience building and optimizing data pipelines, architectures, data sets and workflow management tools such as Azkaban, Luigi, Airflow, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C#, Scala, GoLang, etc.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
Education Required:
The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.
Years of Relevant Work Experience: 5 years
Physical Requirements:
Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.
Additional Qualifications:
Preferred Qualifications:
8+ years of previous related work experience
Ability to convey complex or technical ideas and processes in easy-to-understand terms to diverse audiences
Ability to negotiate, handle complaints, settle disputes, and resolve grievances with both internal and external customers
Excellent written and verbal communication skills
Knowledge, Skills, Abilities and Competencies:Collaborates - Building partnerships and working collaboratively with others to meet shared objectives
Communicates Effectively - Developing and delivering multi-mode communications that convey a clear understanding of the unique needs of different audiences
Cultivates Innovation - Creating new and better ways for the organization to be successful
Drives Engagement - Creating a climate where people are motivated to do their best to help the organization achieve its objectives
Instills Trust - Gaining the confidence and trust of others through honesty, integrity, and authenticity
Nimble Learning - Actively learning through experimentation when tackling new problems, using both successes and failures as learning fodder
Optimizes Work Processes - Knowing the most effective and efficient processes to get things done with a focus on continuous improvement
Plans and Aligns - Planning and prioritizing work to meet commitments aligned with organizational goals
Tech Savvy - Anticipating and adopting innovations in business-building digital and technology applications. We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
",https://militaryjobs.homedepot.com/austin-tx/senior-data-engineer-blacklocus/EC8362E9CBF04CA89DDFB7AF819ED0FC/job/?utm_campaign=.JOBS%20RSS%20Feed&utm_medium=.JOBS%20Universe&utm_source=.JOBS%20RSS%20Feed-DE
JOB250578118761,Data Engineer - Lead Level,Data Engineer - Lead Level,Exceptionally detail-oriented,"Leads and influences technical direction for large scale, highly complex technical initiatives and/or projects requiring integration of cross-functional systems.,Provides technical guidance in evaluating applications systems or evaluating requests for proposals.,Collaborates with the business to prioritize key business/technical initiatives.,Utilizes expert knowledge of the customers business to recommend solutions, and ensures business and technology objectives are met and maintained.,Understands user and process requirements and ensures those requirements can be achieved through high quality deliverables.,Creates system documentation/play book(s) and serves as a lead technical reviewer and contributor in requirements, design and code reviews.,Typically serves as a resource to the business and/or as a technical resource to cross functional third party and internal team members on highly complex design/code reviews.,May troubleshoot complex problems and recommend solutions or practices relative to root cause analyses and identification of solutions for improving system performance and availability.,On behalf of the manager; manages the consistent delegation of work packages to cross functional and third-party team members for execution through the full development life cycle.,Appropriately advises management of issues.,Assists team leads and management with delegation of technical work packages to cross functional and third-party team members for execution through the full development life cycle.,Keeps management appropriately informed of progress and issues.,Performs design and analysis, coding and unit/integration testing of highly complex system functionality and/or defect correction across multiple platforms.,Displays advanced knowledge and understanding of functional and technical domains of specific products and appropriately evaluates the impact of changes or additions.,Develops accurate estimates on work packages.,Analyzes and designs specifications for less experienced internal and third-party team members to execute.,Actively mentors and contributes to the technical and soft skills development of internal and third-party teams.,Actively participates in cross departmental staffing and/or technical decisions.,Bachelor's degree or 4 additional years of related experience beyond the minimum required may be substituted in lieu of a degree,8 or more years of software development experience demonstrating depth of technical and functional understanding within specific I/T discipline(s)/technology(s) i.e., Business Intelligence, Mobile, Web, Java, etc,8+ years experience developing, deploying and supporting high-quality, fault-tolerant data pipelines (leveraging distributed, big data movement technologies and approaches, including but not limited to ETL and streaming ingestion and processing),8+ years experience in a software engineer role, leveraging Java, Python, Scala or C++,4+ years advanced distributed schema and SQL development skills including partitioning for performance of ingestion and consumption patterns,4+ years experience with distributed NoSQL databases and event brokers (Apache Cassandra, Kafka, Graph databases, Document Store databases),Curious and excited by new ideas,Energized by a fast-paced environment,Able to understand and translate business needs into leading-edge technology,Comfortable working as part of a connected team, but self-motivated,Community-focused, dependable and committee","
We are currently seeking talented Data Engineer - Lead Level for our San Antonio, TX facility.
Data Engineers are engaged in all phases of the software development lifecycle which include; gathering and analyzing user/business system requirements, responding to outages and creating application system models. Data Engineers primary functions are to design, develop, document, test and debug new and existing software systems and/or applications for internal use, perform defect corrections (analysis, design, code). In addition, Data Engineers participate in design meetings and consult with business clients to refine, test, and debug programs to meet business needs. This role is occupied by those who display expertise within their respective areas of specialization that enable them to lead and influence technical direction with an appropriate awareness of decisions and resulting impacts on business and technical objectives. Incumbents effectively evaluate and analyze situations or problems and are expected to exercise judgment in the selection of methodologies, techniques, and evaluation criteria for achieving objectives and results. In addition; Incumbents have productive and solid working relationships with internal and third-party team members and, on behalf of management, delegate technical work packages.
Skills & requirements
ABOUT USAA
USAA knows what it means to serve. We facilitate the financial security of millions of U.S. military members and their families. This singular mission requires a dedication to innovative thinking at every level.
In each of the past five years, we've been a top-40 Fortune 100 Best Companies to Work For®, and we've ranked among Victory Media's Top 10 Military Friendly® Employers primar13 years straight. We embrace a robust veteran workforce and encourage veterans and veteran spouses to apply.
ABOUT USAA IT
Our most important qualification isn't technical, it's human. Here, we don't just sit in front of a screen. We stand behind our 11 million members who rely on us every day.
We are over 3,000 employees strong, a passionately supportive and collaborative team built on Agile principles. We've been a top-two Computerworld 100 Best Places to Work in IT five years in a row and were recently named a Top 50 Employer for Minority Engineers & IT by Workforce Diversity Magazine.
See what it's like to work for a company where your passion meets our purpose:
USAA Information Technology: A Realistic Preview
PRIMARY RESPONSIBILITIES
Leads and influences technical direction for large scale, highly complex technical initiatives and/or projects requiring integration of cross-functional systems.
Provides technical guidance in evaluating applications systems or evaluating requests for proposals.
Collaborates with the business to prioritize key business/technical initiatives.
Utilizes expert knowledge of the customers business to recommend solutions, and ensures business and technology objectives are met and maintained.
Understands user and process requirements and ensures those requirements can be achieved through high quality deliverables.
Creates system documentation/play book(s) and serves as a lead technical reviewer and contributor in requirements, design and code reviews.
Typically serves as a resource to the business and/or as a technical resource to cross functional third party and internal team members on highly complex design/code reviews.
May troubleshoot complex problems and recommend solutions or practices relative to root cause analyses and identification of solutions for improving system performance and availability.
On behalf of the manager; manages the consistent delegation of work packages to cross functional and third-party team members for execution through the full development life cycle.
Appropriately advises management of issues.
Assists team leads and management with delegation of technical work packages to cross functional and third-party team members for execution through the full development life cycle.
Keeps management appropriately informed of progress and issues.
Performs design and analysis, coding and unit/integration testing of highly complex system functionality and/or defect correction across multiple platforms.
Displays advanced knowledge and understanding of functional and technical domains of specific products and appropriately evaluates the impact of changes or additions.
Develops accurate estimates on work packages.
Analyzes and designs specifications for less experienced internal and third-party team members to execute.
Actively mentors and contributes to the technical and soft skills development of internal and third-party teams.
Actively participates in cross departmental staffing and/or technical decisions.
Typically anticipates opportunities and proactively and consistently champions innovative solutions cross functionally and across the Enterprise.
MINIMUM REQUIREMENTS
Bachelor's degree or 4 additional years of related experience beyond the minimum required may be substituted in lieu of a degree
8 or more years of software development experience demonstrating depth of technical and functional understanding within specific I/T discipline(s)/technology(s) i.e., Business Intelligence, Mobile, Web, Java, etc
Experience leading software development teams (internal and/or third party) is required
PREFERRED
8+ years experience developing, deploying and supporting high-quality, fault-tolerant data pipelines (leveraging distributed, big data movement technologies and approaches, including but not limited to ETL and streaming ingestion and processing)
8+ years experience in a software engineer role, leveraging Java, Python, Scala or C++
4+ years advanced distributed schema and SQL development skills including partitioning for performance of ingestion and consumption patterns
4+ years experience with distributed NoSQL databases and event brokers (Apache Cassandra, Kafka, Graph databases, Document Store databases)
3+ years experience with cloud-based data offerings (Amazon AWS, Google GCP, Microsoft Azure)
DESIRED CHARACTERISTICS
USAA Data Engineers create innovative solutions that impact our members. Collectively, we are:
Curious and excited by new ideas
Energized by a fast-paced environment
Able to understand and translate business needs into leading-edge technology
Comfortable working as part of a connected team, but self-motivated
Community-focused, dependable and committee
Exceptionally detail-oriented
BENEFITS
USAA's most valuable resource is our 28,000 employees. We promote a culture of diversity and inclusion, encouraging varied perspectives and ideas.
Our team enjoys world-class benefits, pay and highly competitive reward opportunities, including comprehensive healthcare, wellness and wealth building programs, employee resource groups, 401K matching dollar-for-dollar up to 8% of pay, career planning and continuing education.
We promote a strong work-life balance with a variety of on-site services and conveniences depending on location, including a daycare, health center and pharmacy, multiple dining options, company stores, covered parking and free fitness centers. USAA is a casual dress environment.
The above description reflects the details considered necessary to describe the principal functions of the job and should not be construed as a detailed description of all the work requirements that may be performed in the job.
At USAA our employees enjoy one of the best benefits packages in the business, including a flexible business casual or casual dress environment, comprehensive medical, dental and vision plans, along with wellness and wealth building programs. Additionally, our career path planning and continuing education will assist you with your professional goals.
USAA also offers a variety of on-site services and conveniences to help you manage your work and personal life, including seven cafeterias, two company stores and three fitness centers.
Relocation assistance is available for this position.
",https://stackoverflow.com/jobs/196549/data-engineer-lead-level-usaa
JOB250741988716,"Senior Manager, Data Engineer","Senior Manager, Data Engineer",,"Data munging with emphasis on ability to deal with imperfections in data.,Developing, refining and scaling data management and analytics procedures, systems, workflows, best practices and other issues.,Developing of data-driven products.,Visualizing and communicating data clearly for use both internally and externally.,Building data pipelines that clean, transform and aggregate data from many different sources.,Developing models that can be used to make predictions.,Building complex functions that answer questions for the business.,Modeling data at rest and enable powerful data analysis.,Providing solutions that help share data with the enterprise.,Bachelor’s degree in Mathematics, Statistics, Engineering, Computer Science or related discipline and 3+ years of experience in analytics or business intelligence.,Proficiency in languages such as Java and/or Scala.,Experience with web technologies such HTML, JavaScript, XPath, JSON, or Drupal,Exposure to Linux operating systems. Some exposure to Unix is helpful but not required.,Experience in working with big data technologies Spark, Hadoop, MapReduce, MySQL, NoSQL databases,Experience with AWS Data Tools such as S3, Redshift, RDS and Kenesis,Experience producing and consuming event driven data,Experience with scraping social media, using social media APIs,Basic understanding of statistics","
No child should grow up hungry in America. Since 1984, Share Our Strength® has led the fight against hunger and poverty by inspiring and organizing individuals and businesses to share their strengths. Share Our Strength, a national nonprofit, is ending childhood hunger in America by ensuring all children get the healthy food they need. By connecting kids in need with nutritious food and teaching their families how to cook healthy, affordable meals, the No Kid Hungry Campaign surrounds children in this nation with healthy food where they live, learn and play.
Share Our Strength, long known as an innovative leader in the fight against childhood hunger in the US, is looking for a data engineer to help launch several new and exciting technology initiatives.
The ideal candidate will have demonstrable experience creating interactive data visualizations, working with unstructured data and building data workflows and will be highly adaptable with an eagerness to learn and apply new skills. The exceptional candidate will have an entrepreneurial spirit as well as passion for solving difficult challenges through innovation and creativity, with a strong focus on results. This person should have highly polished interpersonal skills, as they will be working across multiple departments to execute a new data management strategy.
Near term projects could include assisting in the selection and implementation of a new Customer Relationship Management (CRM) solution, designing and implementing data visualization solutions for both internal and external audiences, and developing the underlying data feeds to support dynamic, web-based dashboards for a variety of internal and external stakeholders.
Data munging with emphasis on ability to deal with imperfections in data.
Developing, refining and scaling data management and analytics procedures, systems, workflows, best practices and other issues.
Developing of data-driven products.
Visualizing and communicating data clearly for use both internally and externally.
Building data pipelines that clean, transform and aggregate data from many different sources.
Developing models that can be used to make predictions.
Building complex functions that answer questions for the business.
Modeling data at rest and enable powerful data analysis.
Providing solutions that help share data with the enterprise.
Serving as an advocate for best practices and continued learning.
Required Skills:
Bachelor’s degree in Mathematics, Statistics, Engineering, Computer Science or related discipline and 3+ years of experience in analytics or business intelligence.
Proficiency in languages such as Java and/or Scala.
Experience with web technologies such HTML, JavaScript, XPath, JSON, or Drupal
Exposure to Linux operating systems. Some exposure to Unix is helpful but not required.
Helpful Extras:
Experience in working with big data technologies Spark, Hadoop, MapReduce, MySQL, NoSQL databases
Experience with AWS Data Tools such as S3, Redshift, RDS and Kenesis
Experience producing and consuming event driven data
Experience with scraping social media, using social media APIs
Basic understanding of statistics
Previous experience with a major CRM implementation.
None specified
No requirement
",https://www.idealist.org/en/nonprofit-job/826aa049ffc94f70b733a9bc8e01af0d-senior-manager-data-engineer-share-our-strength-washington
JOB250793453637,(Senior) Data Engineer - Data Science Team,(Senior) Data Engineer - Data Science Team,"A deep understanding of distributed computing frameworks such as Spark (particularly SparkML, SparkSQL, tune/optimize and debug Spark jobs), Hadoop and/or Flink,Experience with big data at AWS, in particular using EMR and S3,Experience with Docker and container orchestration like Kubernetes, Swarm or similar,Experience with pipeline management tools like Airflow, Luigi or NiFi,Experience with programming languages such as Python, Go and/or Scala,Good knowledge of SQL/RDBMS,Experience with the command line, shell scripting and version control (Git),Excellent communication skills in English, both oral and written; German is nice to have,Preferably experience with automatic configuration management like Terraform and Puppet,Preferably experience with modern agile software development practices like microservices, test-driven development, pair programming, CI/CD etc.,Training opportunities for your individual management or specialist career,The provision of all necessary equipment that you need to deliver top performances,Employees are self-reliant and free to schedule their own work day,Onboarding program including Welcome Day, Trainings and individual incorporation,The chance to work together on our goals, while also working to create something new,700 motivated colleagues and a cool office loft in the trendy district of Kreuzberg","You will be part of the data science team and work closely with our data scientists to operationalize machine learning pipelines,You will develop and implement effective data processing architectures,You will also collaborate a lot with the data warehouse and data platform team,You will participate at meetups, conferences and the research community and apply what you’ve learned back at your daily work","
Job description
The position provides the opportunity to work on a wide range of interesting topics from operationalizing deep learning models to training recommender systems on petabytes of data. As part of the data science team, you will be also given a lot of responsibilities to shape the direction of the team. If you would like to become part of this success story, please send your application.
About your new role
You will be part of the data science team and work closely with our data scientists to operationalize machine learning pipelines
You will develop and implement effective data processing architectures
You will also collaborate a lot with the data warehouse and data platform team
You will participate at meetups, conferences and the research community and apply what you’ve learned back at your daily work
Skills & Requirements
A deep understanding of distributed computing frameworks such as Spark (particularly SparkML, SparkSQL, tune/optimize and debug Spark jobs), Hadoop and/or Flink
Experience with big data at AWS, in particular using EMR and S3
Experience with Docker and container orchestration like Kubernetes, Swarm or similar
Experience with pipeline management tools like Airflow, Luigi or NiFi
Experience with programming languages such as Python, Go and/or Scala
Good knowledge of SQL/RDBMS
Experience with the command line, shell scripting and version control (Git)
Excellent communication skills in English, both oral and written; German is nice to have
Preferably experience with automatic configuration management like Terraform and Puppet
Preferably experience with modern agile software development practices like microservices, test-driven development, pair programming, CI/CD etc.
At idealo you can expect:
Training opportunities for your individual management or specialist career
The provision of all necessary equipment that you need to deliver top performances
Employees are self-reliant and free to schedule their own work day
Onboarding program including Welcome Day, Trainings and individual incorporation
The chance to work together on our goals, while also working to create something new
700 motivated colleagues and a cool office loft in the trendy district of Kreuzberg
",https://stackoverflow.com/jobs/207508/senior-data-engineer-data-science-team-idealo-internet-gmbh
JOB251740088411,Data Engineer - Mid Level,Data Engineer - Mid Level,,"Independently installs, customizes and integrates commercial software packages.,Facilitates root cause analysis of system issues.,Works with experienced team members to conduct root cause analysis of issues, review new and existing code and/or perform unit testing.,Learns to create system documentation/play books and attends requirements, design and code reviews.,Receives work packages from manager and/or delegates.,Identifies ideas to improve system performance and impact availability.,Resolves complex technical design issues.,Creates system documentation/play book(s) and participates as a reviewer and contributor in requirements, design and code reviews.,May serve as the subject matter expert on development techniques.,Partners with experienced team members to develop accurate work estimates on work packages.,May serve as a mentor on procedural matters to less experienced internal and third-party team members.,Bachelor’s degree OR 4 additional years of related experience beyond the minimum required may be substituted in lieu of a degree,3+ years of operational experience in Linux environments (configuration, health checks, monitoring, etc.),3+ years of coding/scripting experience (Bash, Python, Perl, etc.),3+ years of experience working with relational databases. Advanced SQL knowledge, strong understanding of key database management concepts. Familiarity with a variety of databases (Oracle, UDB, DB2, SQL Server, etc.),3+ years of experience working with APIs to collect and/or ingest data.,3+ years of infrastructure automation and orchestration experience.,Proven ability to design, build, and operate a technology stack.,Strong analytic and troubleshooting skills.","
We are currently seeking a talented Data Engineer - Mid Level for our Phoenix, AZ facility.
Data Engineers are engaged in all phases of the software development lifecycle which include; gathering and analyzing user/business system requirements, responding to outages and creating application system models. Data Engineers primary functions are to design, develop, document, test and debug new and existing software systems and/or applications for internal use, perform defect corrections (analysis, design, code). In addition, Data Engineers participate in design meetings and consult with business clients to refine, test, and debug programs to meet business needs, and interact and sometimes direct third-party partners in the achievement of business and technology initiatives. This role is a solid, career-level role where functional and technical proficiency has been obtained, and incumbents display a depth of technical understanding within their respective areas of specialization allowing them to operate independently. Incumbents also display a proficiency that allows them to begin to mentor others (third party and internal resources) on procedural matters.
Skills & requirements
ABOUT USAA
USAA knows what it means to serve. We facilitate the financial security of millions of U.S. military members and their families. This singular mission requires a dedication to innovative thinking at every level.
In each of the past five years, we've been a top-40 Fortune 100 Best Companies to Work For®, and we've ranked among Victory Media's Top 10 Military Friendly® Employers 13 years straight. We embrace a robust veteran workforce and encourage veterans and veteran spouses to apply.
ABOUT USAA IT
Our most important qualification isn't technical, it's human. Here, we don't just sit in front of a screen. We stand behind our 11 million members who rely on us every day.
We are over 3,000 employees strong, a passionately supportive and collaborative team built on Agile principles. We've been a top-two Computerworld 100 Best Places to Work in IT five years in a row and were recently named a Top 50 Employer for Minority Engineers & IT by Workforce Diversity Magazine.
See what it's like to work for a company where your passion meets our purpose:
USAA Information Technology: We’re Hiring Phoenix
PRIMARY RESPONSIBILITIES
Independently installs, customizes and integrates commercial software packages.
Facilitates root cause analysis of system issues.
Works with experienced team members to conduct root cause analysis of issues, review new and existing code and/or perform unit testing.
Learns to create system documentation/play books and attends requirements, design and code reviews.
Receives work packages from manager and/or delegates.
Identifies ideas to improve system performance and impact availability.
Resolves complex technical design issues.
Creates system documentation/play book(s) and participates as a reviewer and contributor in requirements, design and code reviews.
May serve as the subject matter expert on development techniques.
Partners with experienced team members to develop accurate work estimates on work packages.
May serve as a mentor on procedural matters to less experienced internal and third-party team members.
May assist experienced team members with the delegation of work packages.
MINIMUM REQUIREMENTS
Bachelor’s degree OR 4 additional years of related experience beyond the minimum required may be substituted in lieu of a degree
4 or more years of software development experience demonstrating depth of technical understanding within Business Intelligence, ETL, or Data engineering
PREFERRED
3+ years of operational experience in Linux environments (configuration, health checks, monitoring, etc.)
3+ years of coding/scripting experience (Bash, Python, Perl, etc.)
3+ years of experience working with relational databases. Advanced SQL knowledge, strong understanding of key database management concepts. Familiarity with a variety of databases (Oracle, UDB, DB2, SQL Server, etc.)
3+ years of experience working with APIs to collect and/or ingest data.
3+ years of infrastructure automation and orchestration experience.
Proven ability to design, build, and operate a technology stack.
Strong analytic and troubleshooting skills.
Working experience of IBM Optim or IBM Atlas
The above description reflects the details considered necessary to describe the principal functions of the job and should not be construed as a detailed description of all the work requirements that may be performed in the job.
At USAA our employees enjoy one of the best benefits packages in the business, including a flexible business casual or casual dress environment, comprehensive medical, dental and vision plans, along with wellness and wealth building programs. Additionally, our career path planning and continuing education will assist you with your professional goals.
Relocation assistance is not available for this position.
",https://stackoverflow.com/jobs/199559/data-engineer-mid-level-usaa
JOB252598355686,Data Engineer Intern,Data Engineer Intern,,"Create electrical and optical data visualization tool for various projects.,Develop web based tool to generate and present report for production.,Pursuing a degree in computer science, electrical engineering or a related technical field.,Strong in Python, SQL and web based programming.,Strong in statistical analysis is a plus.,Able to work well in a team environment.","Job Description:
Reporting to Sr. Test & Support Engineer, candidate will work cross functionally with testing, reliability, and IT teams, to create data input, management and visualization tools for engineer to analyze data and for management to oversee company’s test data.
Required Experience:
Create electrical and optical data visualization tool for various projects.
Develop web based tool to generate and present report for production.
Develop other data input, management tools
Experience and Skills
Pursuing a degree in computer science, electrical engineering or a related technical field.
Strong in Python, SQL and web based programming.
Strong in statistical analysis is a plus.
Able to work well in a team environment.
Have strong problem analysis and solving capability
From: SLD Laser
",http://www.indeed.com/viewjob?jk=9de5ca1b31ad93b6&qd=AfqoRVvJB5tfYzqmHPywUU3Yaacz5fjG655vtZ4V-4kmr624OToBYiQZCBqA2Fw72niKAHn0qjOQDypllVLKQDjRf1GoyahbLXjpxiIJpuU&indpubnum=8784826545310241&chnl=QJ&atk=1d95co283f0b7800
JOB254546045029,Data Engineer (Scala / Java),Data Engineer (Scala / Java),,,"
Job description
Who we are
The future of transportation is Green. Here at FlixMobility Tech, the R&D group, we develop software with the brightest minds from around the world to engineer new experiences for our millions of customers across our apps and websites. Every day we solve challenging problems, like how to scale rapidly around the world and how to make an experience that delights our customers. We have a culture of sharing ideas, contributing to open source projects and being an active member in our technical communities.
To support our ambitious growth, we are now looking for a Data Engineer (m/f/x) for our Data Platform Team in Berlin starting as soon as possible.
About the team:
We are responsible for building the data platform. We are highly focused on simplicity and ease of use by all data-oriented users. We are a strong enabler of our data-strategy: make the right data easy available to everybody for high-quality decisions
Our tech stack: Scala, Java, everything with Kafka (Streams, Connect, KSQL,…), Akka, Spark, Flink, Docker, K8s, Play, Slick, AWS Services (eg. EMR,S3), NewRelic, JUnit, ScalaTest, ScalaSpec
Your tasks - Paint the world green
Your purpose
• You will work in our data science incubation team and help us to develop a decentralized data organization that implants quantitative decision making into our company's DNA
• You will work alongside our product development and business unit analytics teams of individuals with diverse backgrounds and skills in analytics and data science
• You will have the opportunity to directly influence strategic decisions by leading organizational level initiatives that drive scale, efficiency, and insight across our organization
• You will collaborate with business and technology stakeholders to evaluate data sources, techniques, and tools to support our decentralized data science community
Your value
• You will discover and verify new opportunities to grow our business, scale and optimize operations and to tap into new markets via innovative data products
• You will evolve FlixBus into a data driven company by providing leadership and governance to a decentralized, company wide data organization
• You will support on all organizational levels to derive decisions utilizing data and analytical skills
• You will help to structure work, planning new analyses, translating business questions into analytical projects
• You will consult and mentor data scientists, data engineers and data analysts to drive excellence in value generation
• You will strive to represent FlixBus as a technology organization by presenting at conferences, contributing to patents and writing white papers
Your Profile - Ready to hop on board
Your expertise:
• Proven track record of at least 7+ years of applying data science methods to business problems in an industry context, preferably in e-commerce
• Lateral team leadership, mentoring and cross team project management skills
• Extensive and deep experience with designing, developing, validating, and deploying advanced data products and delivering actionable insights from data analysis
• Experience leading or collaborating with a team of data scientists in developing and delivering machine learning models that work in production
PhD or MsC in Computer Science, Computational and Applied Statistics, Operations Research, Machine Learning, Mathematics or comparable field
• Experience in projects involving large scale multidimensional databases, complex business infrastructure, and cross-functional teams
Your technical skills
• Strong verbal/written communication and presentation skills, including an ability to effectively communicate with both business and technical teams
• Solid programming experience in mainstream programming languages like Python, R, Scala, or Java
• Experience visualizing and communicating data
• Hands-on experience applying machine learning techniques (especially feature engineering) using standard off the shelf packages
• Good understanding of sourcing data using various data management solution (relational as well as non-relational databases)
• Experience working with large data streaming technologies like Spark, Flink
Perks - More than just a job
• Drive change. With innovation and smart technology, we are changing the way people travel, and you too can have an impact on this ride. Everyone is equally important and works together on uncharted challenges alongside inspiring colleagues from all over the world.
• Trust-based working. We don't punch the clock – organize your own schedule. We trust in what you do!
• Fun at work and beyond. Discover the world with your free FlixBus rides and join our regular team events – there's always something to celebrate!
• Feel at home. We provide you with a comfortable working space, free drinks, casual dress code, diverse employee discounts and more.
",https://stackoverflow.com/jobs/196437/data-engineer-scala-java-flixbus
JOB254897947682,Data Engineer Jobs in United States,Data Engineer Jobs in United States,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/data-engineer/jobs-in/usa/jobs/?vs=25&utm_source=.JOBS%20RSS%20Feed-DE&utm_medium=.JOBS%20Universe&utm_campaign=.JOBS%20RSS%20Feed
JOB256864331858,Data Engineer - Data Platform (m/f/d),Data Engineer - Data Platform (m/f/d),,,"
Job description
About the team:
We are responsible for building the data platform. We are highly focused on simplicity and ease of use by all data-oriented users. We are a strong enabler of our data-strategy: make the right data easily available to everybody for high-quality decisions.
Our tech stack: Scala, Java, everything with Kafka (Streams, Connect, KSQL,…), Akka, Spark, Flink, Docker, K8s, Play, Slick, AWS Services (eg. EMR,S3), NewRelic, JUnit, ScalaTest, ScalaSpec
To support our ambitious growth, we are now looking for a Data Engineer (m/f/d) to join our team in Berlin, Germany starting as soon as possible.
Your tasks - Paint the world green
Your purpose
• You will work in our data science incubation team and help us to develop a decentralized data organization that implants quantitative decision making into our company's DNA
• You will work alongside our product development and business unit analytics teams of individuals with diverse backgrounds and skills in analytics and data science
• You will have the opportunity to directly influence strategic decisions by leading organizational level initiatives that drive scale, efficiency, and insight across our organization
• You will collaborate with business and technology stakeholders to evaluate data sources, techniques, and tools to support our decentralized data science community
Your value
• You will discover and verify new opportunities to grow our business, scale and optimize operations and to tap into new markets via innovative data products
• You will evolve FlixBus into a data driven company by providing leadership and governance to a decentralized, company wide data organization
• You will support on all organizational levels to derive decisions utilizing data and analytical skills
• You will help to structure work, planning new analyses, translating business questions into analytical projects
• You will consult and mentor data scientists, data engineers and data analysts to drive excellence in value generation
• You will strive to represent FlixBus as a technology organization by presenting at conferences, contributing to patents and writing white papers
Your Profile - Ready to hop on board
Your expertise:
• Proven track record of at least 7+ years of applying data science methods to business problems in an industry context, preferably in e-commerce
• Lateral team leadership, mentoring and cross team project management skills
• Extensive and deep experience with designing, developing, validating, and deploying advanced data products and delivering actionable insights from data analysis
• Experience leading or collaborating with a team of data scientists in developing and delivering machine learning models that work in production
PhD or MsC in Computer Science, Computational and Applied Statistics, Operations Research, Machine Learning, Mathematics or comparable field
• Experience in projects involving large scale multidimensional databases, complex business infrastructure, and cross-functional teams
Your technical skills
• Strong verbal/written communication and presentation skills, including an ability to effectively communicate with both business and technical teams
• Solid programming experience in mainstream programming languages like Python, R, Scala, or Java
• Experience visualizing and communicating data
• Hands-on experience applying machine learning techniques (especially feature engineering) using standard off the shelf packages
• Good understanding of sourcing data using various data management solution (relational as well as non-relational databases)
• Experience working with large data streaming technologies like Spark, Flink
",https://stackoverflow.com/jobs/196437/data-engineer-data-platform-m-f-x-flixbus
JOB258012922921,Data Engineer,Data Engineer,,,"
POSITION PURPOSE
Congrats! You re learning about an exciting new role with The Home Depots Global Custom Commerce (GCC) team that will revitalize and invigorate the way we manage and view data. For this role, we are looking for some one who can develop, implement, test and maintain data pipelines (batch & streaming) and data structures within a cloud based column-oriented data store. This person will support the GCC BI and Data Science strategic initiatives to drive better customer experiences and more profitable outcomes
Why work here? Our entrepreneurial roots and maverick mentality, coupled with the resources and backing of the #1 home improvement retailer in the world, The Home Depot, is a unique opportunity for you to be a transformative retail disrupter. Plus, GCC is the world s largest online window covering company, and we ve got a demonstrably awesome 20-year track record. From our open-floor office to our open-door ethos, our culture is rooted in improving, evolving, and having fun (we re pretty serious about cake, cook-offs, ping pong, meaningful work and exciting projects). Most importantly, our team members are always inspired, engaged, and ready for growth. That means you ll have the resources and the runway to create truly magical, out-of-the-box work. Moreover, you will play an important role in leveraging our culture, people, systems, processes, and technology ultimately to provide incredible customer experiences, while growing business for GCC and The Home Depot. This is your chance to be part of something big, in a small start-up environment. We re ranked as one of The Top 5 Workplaces in Texas and have consistently won the following awards:The Best Place to Work in Houston (Houston Business Journal), Houston s Top Workplaces (Houston Chronicle) and Houston s Best and Brightest.
MAJOR TASKS, RESPONSIBILITES AND KEY ACCOUNTABILITIES
20%- Implement a real time streaming data ingestion and processing pipeline using Google Dataflow (Apache Beam)
20%- Interface with business intelligence analyts and others in IT (i.e. data engineers, architects, WebOps) in frequent whiteboard sessions to dicsucuss the design, implementation, and testing of data pipleines
20%- Maintain data architecture standards and ETL/ELT best practices consistent with a column oritented data store in an analytic use case
20%- Active and engaged particitpation in the Scrum delivery process
20%- Support solutions in production
NATURE AND SCOPE
This role reports to the Sr. Manager of EDW.
This role has no direct reports.
ENVIRONMENTAL JOB REQUIREMENTS
Environment:
Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.
Travel:
Typically requires overnight travel less than 10% of the time.MINIMUM QUALIFICATIONS
Must be eighteen years of age or older.
Must be legally permitted to work in the United States.
Education Required:
The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.
Years of Relevant Work Experience: 6 years
Physical Requirements:
Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.
Preferred Qualifications:
Familiarity with Agile methodologies
Experience with Spark dataframes, SparkSQL, Kafka, KSQL, real-time streaming, and message bus technologies
Experience with data science technologies such as SAS, R, Matlab, or similar
Experience with data warehousing and dimensional modeling
Knowledge, Skills, Abilities and Competencies:
Experience in building real time streaming data ingestion and processing pipeline using Apache Beam (running on either Google Datflow or Apache (Apex, Flink, or Spark) or Kafka in an analytics or data science use case
Experience with data processing tools (e.g. Hadoop, Spark, Dataflow, etc.)
Experience building ETL/ELT pipelines
Experience with column-oriented databases (e.g Redhift, BigQuery, Vertica)
Ability to go from whiteboard discussion to code
Ability to effectively communicate with technical and non-technical audiences
Strong programming ability
Success in a highly dynamic environment and ability to shift priorities with agility
Ability to act independently with minimal supervision
Willingness to explore and implement new ideas and technologies
Experience working directly with subject matter experts in both business and technology domains
Experience as a team lead We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
",https://militaryjobs.homedepot.com/houston-tx/data-engineer/4B642DC9C39B4857867CACB6FE730745/job/?utm_campaign=.JOBS%20RSS%20Feed&utm_source=.JOBS%20RSS%20Feed-DE&utm_medium=.JOBS%20Universe
JOB258173729080,Data Engineer / Scientist,Data Engineer / Scientist,"Strong programming skills in C++, Java, Scala, or Python,Deep understanding of basic data structures and algorithms,Experience with scaling data platforms to hundreds of terabytes or petabytes using Spark or Hadoop,Familiarity with modern machine learning techniques,Creative, collaborative, & product focused",,"We are looking for excellent software engineers with experience in big data engineering. You will have the opportunity to engage with exciting new-product teams around Apple, and use your data science, systems, machine learning and artificial intelligence skills to tackle challenging technical problems in our next generation products that will delight millions of people.
We are hiring in Cupertino, Seattle, and Pittsburgh.
Strong programming skills in C++, Java, Scala, or Python
Deep understanding of basic data structures and algorithms
Experience with scaling data platforms to hundreds of terabytes or petabytes using Spark or Hadoop
Familiarity with modern machine learning techniques
Creative, collaborative, & product focused
Curious about new technologies and passionate about exploring new use cases
At Apple, you will design, develop and deploy large scale services and platforms. You will also collaborate with teams across Apple, who are building the newest, most compelling intelligent applications in the world. You will have strong engineering and communication skills, as well as a belief that data driven processes lead to great products.
B.S., M.S., or PhD in Computer Science, Computer Engineering, Statistics, Bioinformatics, Applied Mathematics, or equivalent practical experience
","https://www.glassdoor.com/job-listing/data-engineer-scientist-apple-JV_IC1147439_KO0,23_KE24,29.htm?jl=3199282045"
JOB259165169757,"Lead Data Engineer - Python, Azure","Lead Data Engineer - Python, Azure",,"Design, develop, and support our Data infrastructure utilizing various technologies to process terabytes of data, including SQL, Python, Microsoft Azure, and AWS.,Create solutions to enable diagnostic and predictive analytics capabilities.,Partner with the Analytics, Marketing, and Finance organizations to get feedback and iterate upon the Data Ecosystem development.,Develop components and distributed ETL systems for our suite of large data platforms,Be curious about trends and emerging technologies in the Data space, participate in user communities, and share what you learn with your teammates,Familiarity with developing data processing solutions and data applications using technologies like Python, C#, Java, SQL, Spark, or No SQL DB,Experience working with all kinds of data-- clean, dirty, unstructured, semi-structured and relational,Problem solving and multi-tasking in a fast-paced, globally distributed environment,Strong communication skills, good interpersonal skills,Collaborate with business partners to understand and refine requirements,Experience with developing end-to-end data pipelines in large cloud-compute infrastructure solutions such as Azure, AWS or Google is a plus,Five years working directly on Big Data technologies preferred","
Job description
About Our Team:
The Data Engineering Team's mission is to enable our internal business partners with the information to make better decisions for our customers. All of our team members collaboratively work together to design, build, and sustain our Data Ecosystem, which includes technologies like our Data Warehouse, Data Lake, and proprietary predictive analytics tools. We build the right thing, the right way through positive relationships with Marketing, Analytics, and Finance.
When you join our team, you will have a fantastic opportunity to advance your career by working in cutting-edge technology and growing your business expertise.
What You Will Do:
As a Lead Data Engineer, you will help us scale our Data infrastructure to expand our proprietary predictive analytics and Big Data capabilities. You will work with our vast Data Ecosystem, including our Data Warehouse and Data Lake, to build out our platform and provide tooling to empower our internal customers. Your technical experience and business insight will directly drive real business results. Your ability to seek complex challenges and collaborate in a team environment will mean you have an immediate impact.
Essential Functions Include:
Design, develop, and support our Data infrastructure utilizing various technologies to process terabytes of data, including SQL, Python, Microsoft Azure, and AWS.
Create solutions to enable diagnostic and predictive analytics capabilities.
Partner with the Analytics, Marketing, and Finance organizations to get feedback and iterate upon the Data Ecosystem development.
Develop components and distributed ETL systems for our suite of large data platforms
Be curious about trends and emerging technologies in the Data space, participate in user communities, and share what you learn with your teammates
You Have:
Familiarity with developing data processing solutions and data applications using technologies like Python, C#, Java, SQL, Spark, or No SQL DB
Experience working with all kinds of data-- clean, dirty, unstructured, semi-structured and relational
Problem solving and multi-tasking in a fast-paced, globally distributed environment
Strong communication skills, good interpersonal skills
Collaborate with business partners to understand and refine requirements
Experience with developing end-to-end data pipelines in large cloud-compute infrastructure solutions such as Azure, AWS or Google is a plus
Five years working directly on Big Data technologies preferred
Life at Vistaprint
Vistaprint is a place for people who don't settle, who challenge the status quo and never stop asking how to do things better. Technology and design are always evolving and we're continually finding ways to redefine the way they work together. We love that we haven't had to sacrifice our start-up feel, even as we grow. By giving our team full autonomy to explore smarter solutions and allowing them to make an immediate impact, we're all the better for it. Here, you have a voice and we want to hear it.
Benefits
",http://stackoverflow.com/jobs/282403/lead-data-engineer-python-azure-vistaprint
JOB260487195948,Data Engineer,Data Engineer,,,"
As a Data Engineer for the CIA, you will focus on the design, implementation, and operation of data management systems to meet the CIA's business needs. This includes designing how the data will be stored, consumed, integrated, and managed by different data entities and digital systems. Data Engineers work together with data consumers to determine, create, and populate optimal data architectures, structures, and systems.
Data Engineers must also plan, design, and optimize for data throughput and query performance issues. This requires constantly updating expertise in areas such as platform, network and storage technologies, bandwidth management, data bus implications, and design.
Additionally, you will play a key role in the selection of backend database technologies (SQL, NoSQL, HPC, etc), their configuration and utilization, and the optimization of the full data pipeline infrastructure to support the actual content, volume, ETL, and periodicity of data to support the intended kinds of queries and analysis to match expected responsiveness.
The Directorate of Digital Innovation (DDI) is at the forefront of defining the future of digital expertise within the CIA. DDI focuses on developing the workforce with cutting-edge skills, investing in IT infrastructure, and modernizing the way the Agency does business. DDI officers help accelerate the integration of innovative methods and tools to enhance the CIA's cyber and digital capabilities on a global scale and ultimately help safeguard our nation. Learn more about the Directorate of Digital Innovation.
See our work in action:
In addition to a comprehensive benefits package, the CIA offers exciting career opportunities and a dynamic environment. We're on the forefront of world-altering events – as they happen. So working here isn't just a job, it's a mindset and a lifestyle.
",https://www.cia.gov/careers/opportunities/science-technology/data-engineer.html
JOB260893918228,Senior Data Engineer - BlackLocus,Senior Data Engineer - BlackLocus,,,"
Job Information
POSITION PURPOSE
The Sr Data Engineer will expand and optimize data, data flow, data collection for cross functional teams, and data pipeline architecture. The Sr Data Engineer will support and collaborate with the software engineering team, data analysts, and data scientist to ensure data delivery architecture is consistent throughout ongoing projects. Continuously improve or re-design data architecture to support the next generation of products and initiatives.
MAJOR TASKS, RESPONSIBILITES AND KEY ACCOUNTABILITIES
40% - Data Validation, ETL, Infrastructure Development: Coding validation and ETL to ensure successful data integration
30% - Data Infrastructure Maintenance: Backup and optimization activities to maintain performance; code, configure, test, etc data to ensure integrity
20% - Data Architecture Design and Analysis: Create and maintain optimal data pipeline architecture; Develop data architecture to meet business requirements
10% - Planning/Requirements Analysis: Collaborate with team leads and cross functional partners to assess business requirements and communicate opportunities
NATURE AND SCOPE
This position reports to the Technology Leader.
This position has 0 direct reports.
ENVIRONMENTAL JOB REQUIREMENTS
Environment:
Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.
Travel:
Typically requires overnight travel less than 10% of the time.
Additional Environmental Job Requirements: MINIMUM QUALIFICATIONS
Must be eighteen years of age or older.
Must be legally permitted to work in the United States.
Additional Minimum Qualifications:
Experience message queuing, stream processing, and scalable data stores
Experience managing projects and organizing data
Experience supporting and working with cross-functional teams
Experience with SQL, NoSQL databases, relational databases, and query authoring
Experience building and optimizing data pipelines, architectures, data sets and workflow management tools such as Azkaban, Luigi, Airflow, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C#, Scala, GoLang, etc.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
Education Required:
The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.
Years of Relevant Work Experience: 5 years
Physical Requirements:
Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.
Additional Qualifications:
Preferred Qualifications:
8+ years of previous related work experience
Ability to convey complex or technical ideas and processes in easy-to-understand terms to diverse audiences
Ability to negotiate, handle complaints, settle disputes, and resolve grievances with both internal and external customers
Excellent written and verbal communication skills
Knowledge, Skills, Abilities and Competencies:Collaborates - Building partnerships and working collaboratively with others to meet shared objectives
Communicates Effectively - Developing and delivering multi-mode communications that convey a clear understanding of the unique needs of different audiences
Cultivates Innovation - Creating new and better ways for the organization to be successful
Drives Engagement - Creating a climate where people are motivated to do their best to help the organization achieve its objectives
Instills Trust - Gaining the confidence and trust of others through honesty, integrity, and authenticity
Nimble Learning - Actively learning through experimentation when tackling new problems, using both successes and failures as learning fodder
Optimizes Work Processes - Knowing the most effective and efficient processes to get things done with a focus on continuous improvement
Plans and Aligns - Planning and prioritizing work to meet commitments aligned with organizational goals
Tech Savvy - Anticipating and adopting innovations in business-building digital and technology applications. We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
",https://militaryjobs.homedepot.com/austin-tx/senior-data-engineer-blacklocus/EC8362E9CBF04CA89DDFB7AF819ED0FC/job/?utm_medium=.JOBS%20Universe&utm_campaign=.JOBS%20RSS%20Feed&utm_source=.JOBS%20RSS%20Feed-DE
JOB261170391106,ETL Big Data Engineer,ETL Big Data Engineer,,,"
Job description
As a member of our Software Engineering Group we look first and foremost for people who are passionate around solving business problems through innovation & engineering practices. You will be required to apply your depth of knowledge and expertise to all aspects of the software development lifecycle, as well as partner continuously with your many stakeholders on a daily basis to stay focused on common goals. We embrace a culture of experimentation and constantly strive for improvement and learning. You'll work in a collaborative, trusting, thought-provoking environment-one that encourages diversity of thought and creative solutions that are in the best interests of our customers globally.
Qualifications:
You should be able to demonstrate the ability to work in a modern SDLC environment to build durable, stable and efficient software solutions geared towards solving the key business requirements of the organization. Understand business requirements and collaborate with the architecture team to translate them into technical design. You are required to have basic understanding of a data model and its core principles along with data integration architecture.
This role requires a wide variety of strengths and capabilities, including:
• BS/BA degree or equivalent experience.
• Proficiency in one or more modern programming languages AbInitio, BigData ecosystem in Spark, hdfs architechture, Linux OS and scripting, Control-M, Oracle DB).
• Understanding of software skills such as business analysis, development, maintenance and software improvement.
• In depth grasp of the various components of the Ab Initio ETL toolset.
• Creation of ETL pipelines to validate, enrich and persist data.
• Operational knowledge of operating systems such as Linux/AIX.
• Demonstrable ability to use UNIX shell scripting.
• Ability to work in an Agile development environment.
• Must have hands on experience with ETL using Ab Initio of at least 5+ years.
• Must have 1+ years of hands on Spark development experience using Scala and/or Java.
• Advanced knowledge of application, data and infrastructure architecture disciplines.
• Understanding of architecture and design across all systems.
• Working proficiency in developmental toolsets.
• Knowledge of industry wide technology trends and best practices.
• Ability to work in large, collaborative teams to achieve organizational goals, and passionate about building an innovative culture.JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.
We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs.
Equal Opportunity Employer/Disability/Veterans
",http://stackoverflow.com/jobs/434079/etl-big-data-engineer-jpmorgan-chase-bank-na
JOB262415270801,Senior Big Data Engineer,Senior Big Data Engineer,,"Build analytical solutions to enable Data Scientist by manipulating large data sets and integrating diverse data sources.,Work closely with the data scientists, and database and systems administrators to create data solutions.,Bachelor’s degree or four or more years of work experience.,Experience of designing, building, and deploying production-level data pipelines using tools from Hadoop stack (HDFS, Hive, Spark, HBase, Kafka, NiFi, Oozie, Splunk etc.).","
When you join Verizon
You’ll have the power to go beyond – doing the work that’s transforming how people, businesses and things connect with each other. Not only do we provide the fastest and most reliable network for our customers, but we were first to 5G - a quantum leap in connectivity. Our connected solutions are making communities stronger and enabling energy efficiency. Here, you’ll have the ability to make an impact and create positive change. Whether you think in code, words, pictures or numbers, join our team of the best and brightest. We offer great pay, amazing benefits and opportunity to learn and grow in every role. Together we’ll go far.
What you’ll be doing...
The Visible Engineering team is seeking a Senior Data Engineer to work with a small team responsible for building, deploying, and supporting a Big Data solution that will enable operations for a large enterprise environment. You will design, build and maintain Enterprise Level Data Pipe-Lines utilizing the tools available within the Big Data Eco-System. As a Senior Big Data Engineer - You will work on Advanced Analytics using Big Data technologies such as Hadoop and Data Warehousing.
Build analytical solutions to enable Data Scientist by manipulating large data sets and integrating diverse data sources.
Perform ad-hoc analysis and develop reproducible analytical approaches to meet business requirements.
Perform exploratory and targeted data analyses using descriptive statistics and other methods.
Use complex algorithms to develop systems & applications that deliver business functions or architectural components.
Work closely with the data scientists, and database and systems administrators to create data solutions.
Follow best practices on design and implementation to aid in company-wide data governance.
Improve existing data pipelines by simplifying and increasing performance.
Design, build, and deploy new data pipelines within Big Data Eco-Systems.
Documents new/existing pipelines, Data Sets and Data Sets.
Abides by department development standards and SOP's.
Attends all department meetings.
Keeps updated on latest technologies relevant to position’s duties.
Keeps management updated on projects and assigned work.
What we’re looking for...
You’ll need to have:
Bachelor’s degree or four or more years of work experience.
Six or more years of relevant work experience.
Even better if you have:
Experience of designing, building, and deploying production-level data pipelines using tools from Hadoop stack (HDFS, Hive, Spark, HBase, Kafka, NiFi, Oozie, Splunk etc.).
Experience with various noSQL databases (Hive, MongoDB, Couchbase, Cassandra, Neo4j).
Experience with analytic or feature engineer programming (python or scala or java).
Experience implementing open source frameworks & exposure to various open source & package software architectures (AngularJS, ReactJS, Node, Elasticsearch, Spark, Scala, Splunk, Apigee, and Jenkins etc.).
Experience troubleshooting JVM-related issues.
Experience with SQL databases and Change Data Capture.
Experience and strategies to deal with mutable data in Hadoop.
Experience with Stream sets.
Experience of Agile and DevOps methodologies.
Experience in full development life cycle and significant experience in delivering applications and architecture services.
Experience in data visualization tools like Kibana, Grafana, Tableau and associated architectures.
Experience evaluating and implementing cutting-edge digital technologies.
Experience with Cloud technologies (AWS, GCP, PCF, Docker, Kubernetes and application migration.
Equal Employment Opportunity
We're proud to be an equal opportunity employer - and celebrate our employees' differences, including race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, and Veteran status. Different makes us better.
",https://www.verizon.com/about/work/jobs/5417977-senior-big-data-engineer
JOB263822006617,Data Engineer,Data Engineer,"Minimum of 2 years development experience.,Experience in data analytics, business intelligence, or data science,Proficient in SQL,Strong programming skills,Experience with designing and building RESTful API services,Strong experience with ETL, must be able to interact with various data sources and connecting them to a data warehouse,Must be technically proficient and able to problem solve how data should be extracted, transformed and loaded into a warehouse.,This role will work collaboratively with the business departments it supports and must be able to understand the requirements of the data analytics group, and how their requirements can be technologically executed.,Bachelor's degree in a related field of study.,Experience with Amazon AWS , Azure, and PowerBI preferred, not required,Big Data Tools – MapReduce, Hadoop, Spark,Communication protocols JSON, XML,Amazon Redshift or SnowflakeBottom of Form","Working with a variety of different data formats and platforms, including SQL and NoSQL databases, Big Data (MapReduce/Hadoop, Spark, etc.), JSON, XML, and cloud data warehouse technology such as Amazon Redshift or Snowflake.,Working with Business Analytics and IT team members to clarify and refine functional data requirement specifications.,Working with our Business Analytics team on normalizing and aggregating large data sets based on business needs and requirements,Developing processes and techniques for practicing good “data hygiene” and to ensure data is always up-to-date, accurate, and stored efficiently,Testing new technologies and architectures to help find the best ways to work with unique data sets,Being able to benchmark and troubleshoot data-related issues, analyze system bottlenecks and propose solutions to eliminate them,Designing ETL, ELT processes and data warehouse structures to enhance existing on-premise architectures,Utilizing cloud solutions and cloud data warehouse technologies.,Interacting with various on-premise and cloud data sources as well as RESTful APIs to achieve optimal data footprint.,Following Agile principles to prioritize design/architecture/POC backlog using Agile principles,Writing and optimizing scripts to transform, aggregate and optimize data"," Apply Now
Job Description
H. Belo currently has a job opening for a Data Engineer. The Data Engineer will join our Information Technology group in support of a growing Business Intelligence team and will be responsible for the development and testing of various data solutions. This role will work closely with other data engineers and data scientists to move, manipulate, and extract value from our data across distributed systems.
Responsibilities include:
Working with a variety of different data formats and platforms, including SQL and NoSQL databases, Big Data (MapReduce/Hadoop, Spark, etc.), JSON, XML, and cloud data warehouse technology such as Amazon Redshift or Snowflake.
Working with Business Analytics and IT team members to clarify and refine functional data requirement specifications.
Working with our Business Analytics team on normalizing and aggregating large data sets based on business needs and requirements
Developing processes and techniques for practicing good “data hygiene” and to ensure data is always up-to-date, accurate, and stored efficiently
Testing new technologies and architectures to help find the best ways to work with unique data sets
Being able to benchmark and troubleshoot data-related issues, analyze system bottlenecks and propose solutions to eliminate them
Designing ETL, ELT processes and data warehouse structures to enhance existing on-premise architectures
Utilizing cloud solutions and cloud data warehouse technologies.
Interacting with various on-premise and cloud data sources as well as RESTful APIs to achieve optimal data footprint.
Following Agile principles to prioritize design/architecture/POC backlog using Agile principles
Writing and optimizing scripts to transform, aggregate and optimize data
We regret that we are unable to consider candidates who require visa sponsorship for this role, now or in the future.
Job Requirements
The ideal candidate will have 2 – 3 years of experience in data, data engineering or programming roles in a data warehousing environment. Strong candidates will have proven ability to design, develop, and maintain data warehousing and ETL work flows for large data sets.
Minimum of 2 years development experience.
Experience in data analytics, business intelligence, or data science
Proficient in SQL
Strong programming skills
Experience with designing and building RESTful API services
Strong experience with ETL, must be able to interact with various data sources and connecting them to a data warehouse
Must be technically proficient and able to problem solve how data should be extracted, transformed and loaded into a warehouse.
This role will work collaboratively with the business departments it supports and must be able to understand the requirements of the data analytics group, and how their requirements can be technologically executed.
Bachelor's degree in a related field of study.
Preferred:
Experience with Amazon AWS , Azure, and PowerBI preferred, not required
Big Data Tools – MapReduce, Hadoop, Spark
Communication protocols JSON, XML
Amazon Redshift or SnowflakeBottom of Form
",https://dfwishiring.dallasnews.com/company/dallas-morning-news-29940/job/data-engineer-in-dallas-tx-rnz2pv3icfu3vgfb4esfjvag2vl0v8/
JOB265012930641,Data Engineer,Data Engineer,Little to no travel,"We helped the second largest personal lines insurer in the United States design and build a “Virtual Assistant” to speed up the productivity of new customer contact center employees by utilizing a Cognitive Computing/Artificial Intelligence system.,The world’s largest brewer was experiencing too much downtime during production. We identified 140 causal factors across seven different dimensions and 43 categories — a pool of more than $100 million in potential cost savings.,When our client, the second-largest cable operator in the United States, acquired another organization, we took the lead, assessing product catalogues for both organizations and providing recommendations on how to transition to a single product catalogue for current customers and the additional 1.4 million subscribers our client gained from the acquisition.,Proven experience analyzing existing tools and databases and providing software solution recommendations.,Ability to translate business requirements into non-technical, lay terms.,High-level experience in methodologies and processes for managing large scale databases.,Demonstrated experience handling large data sets and relational databases.,Understanding of addressing and metadata standards.,Ability to work with stakeholders to assess potential risks.,Unlimited Training & Career Growth, and we mean it: Pluralsight, Safari Library, Conferences, Certifications, Lunch & Learns, etc.,Weekly Coding Challenges,Sponsored Hackathons,Full time Employment - not only do we support our clients, but we grow our company.,Excellent health, dental, vision, maternity and paternity leave,Revenue sharing and a 401(k) retirement savings,Life, disability and long-term care","
Job description
At Daugherty, we understand the challenge that a number of our clients face: they have mounds of data, but no way to make any sense of it. That’s where you come in. We are looking for an experience Data & Analytics Engineer to join our team. You will work with some of the biggest companies in the world, transforming information into easy to understand, actionable insights. Your fine eye for detail and deep understanding of what data truly matters will give you the power to have an immediate impact.
Don’t believe us? Check it out.
We helped the second largest personal lines insurer in the United States design and build a “Virtual Assistant” to speed up the productivity of new customer contact center employees by utilizing a Cognitive Computing/Artificial Intelligence system.
The world’s largest brewer was experiencing too much downtime during production. We identified 140 causal factors across seven different dimensions and 43 categories — a pool of more than $100 million in potential cost savings.
When our client, the second-largest cable operator in the United States, acquired another organization, we took the lead, assessing product catalogues for both organizations and providing recommendations on how to transition to a single product catalogue for current customers and the additional 1.4 million subscribers our client gained from the acquisition.
Are you ready to make a difference? Here’s what we're looking for:
Proven experience analyzing existing tools and databases and providing software solution recommendations.
Ability to translate business requirements into non-technical, lay terms.
High-level experience in methodologies and processes for managing large scale databases.
Demonstrated experience handling large data sets and relational databases.
Understanding of addressing and metadata standards.
Ability to work with stakeholders to assess potential risks.
Our awesome benefits include:
Unlimited Training & Career Growth, and we mean it: Pluralsight, Safari Library, Conferences, Certifications, Lunch & Learns, etc.
Weekly Coding Challenges
Sponsored Hackathons
Full time Employment - not only do we support our clients, but we grow our company.
Excellent health, dental, vision, maternity and paternity leave
Revenue sharing and a 401(k) retirement savings
Life, disability and long-term care
Little to no travel
The recruiting process at Daugherty is different for every candidate. We want you to feel excited to join our team. We want you to be eager to take on a new challenge. We are always 100% honest about what to expect, because we don’t want Daugherty to be just another job. We want Daugherty to be your dream job.
",https://stackoverflow.com/jobs/203474/data-engineer-daugherty-business-solutions
JOB265651710077,Senior Data Engineer,Senior Data Engineer,"We are offering an annual salary in the range of $120,000 - $140,000 USD.","We work in small teams, fast-paced, we all get a lot done by everyone wearing many hats.,We are serious about optimizing our time and staying focused on the most important goals and outcomes.,We are a remote team and are completely on board with 100% remote work, meaning we focus on overcommunication to ensure we can stay in sync despite our physical distance.,We coordinate using a kanban board, hold a daily standup, and mostly communicate via ad hoc video calls and Slack.,We’re building lots of new things, but also maintaining a significant business. We are mindful of the balance and need to monitor and pay down tech debt and also innovate with exciting greenfield projects.,GrowFlow’s data pipelines consume data from all of our products (4+ and counting) into a central data warehouse in BigQuery.,We process & transform the data with DBT, visualize it with PowerBI and Amplitude.,Segment.com is our central product analytics customer data platform, collecting behavior/event data from all our sources and sending it to both our warehouse and various partner destinations.,Ensure the availability and timely delivery of data, analytics & reporting, company-wide.,Ingest and aggregate structured & unstructured data from internal and external data sources to our data warehouse.,Model new data sets Build, maintain & improve performant, efficient & reliable ELT workflows and data pipelines,Document new & existing data models, ELT workflows, pipelines, data dictionaries and tracking events.,Build, deploy and monitor robust data tests to monitor & validate production pipelines.,Improve data-driven decisions by providing guidance & assistance to internal business stakeholders (Customer Experience, Sales, Marketing, Growth, etc) who need to unlock insights about our markets, customers and business processes.,Work w/ Product & Engineering to evolve and expand GrowFlow’s Insights product, our customer-facing business intelligence tool.,Work with business data analysts to develop, extend & support data-driven A/B experiments.,7+ years total engineering experience,3+ years experience dealing with “data”, including things like SQL databases, No-SQL databases, columnar databases and data pipelines.,Familiarity with Embedded Reporting tools/platforms (PowerBI, Domo, Looker, Sisense etc.),Bonuses:,Experience with Google Big Query, DBT (getdbt.com) or PowerBI,Experience working with data using Python (e.g. Pandas, Apache Beam, scikit, tensorflow, etc),Experience using ETL tools (SAS, Informatica, Talend, MSSQL SSIS, etc),Ability to acutely focus on company objectives and mission at hand.,Ability to pass a background check; have appropriate work authorization,Be Customer Obsessed: As a support engineer, our ideal candidate should have a heartbeat on customer satisfaction, and strive to make sure customer issues are resolved quickly and effectively.,Over Communicate: As a 100% remote company, over communication is key to delivering continued productivity across all teams. Our ideal candidate goes above and beyond to ensure important messages are received by the correct party.,Challenge Respectfully: GrowFlow is far more likely to succeed by examining problems and situations through several lenses. Our ideal candidate should be able to engage and work with both the support team and the engineering team to ensure we are delivering the best solution for our customers.,Extreme Ownership: At GrowFlow, we pride ourselves on each member practicing extreme ownership and accountability. Our ideal candidate should be able and willing to take ownership of customer reported issues and see them all the way to their resolution.,Stay Curious, Stay Scrappy: Most of us dork out over non-work related topics at a ridiculous level of detail, because that’s how we’re wired. We’re naturally inquisitive, ask tough questions and aren’t afraid to ruffle feathers to find better answers. Our Ideal candidate should be intuitive and eager to learn new things.,Do Less Better: At GrowFlow, we believe that the path to becoming the market leader looks like focusing on doing fewer things, but doing them better than anyone else in the industry. Our Ideal candidate is able to create a “path of least resistance” when resolving customer reported issues.,Results Get Rewarded: At GrowFlow, we recognize that the quickest path to becoming the top company in the industry is by forming the top team in the industry. Our ideal candidate should have a heartbeat on KPIs related to the T2 support engineer position and should be focused on measuring and improving metrics related to his or her position.,We are a fully remote company and this position will be remote.,We are looking for someone who is ready to join us full-time after a brief trial period (all our employees do this).,We offer health benefits, 401k, unlimited time off, charity matching, and other cool perks.","
Job description
We are looking for an engineer with a “find a way or make a way” attitude who has a passion for ensuring products “just work” for customers. The mission of the Data Engineer is to power the data engine at GrowFlow. That means your job is to ensure we’re surfacing insightful data to both external and internal stakeholders at just the right time and empowering both to make intelligent and data-informed decisions about their business.
The ideal candidate will be someone with a keen sense for organization, an itch to look at things from different perspectives and a collaborative mindset that enables our data team to work with and empower both our customers and internal stakeholders.
Data Engineering at Growflow encompasses both traditional BI analytics as well as empowering internal usage data (i.e. customer product usage via segment.com)
Our environment is typical of a start-up:
We work in small teams, fast-paced, we all get a lot done by everyone wearing many hats.
We are serious about optimizing our time and staying focused on the most important goals and outcomes.
We are a remote team and are completely on board with 100% remote work, meaning we focus on overcommunication to ensure we can stay in sync despite our physical distance.
We coordinate using a kanban board, hold a daily standup, and mostly communicate via ad hoc video calls and Slack.
We’re building lots of new things, but also maintaining a significant business. We are mindful of the balance and need to monitor and pay down tech debt and also innovate with exciting greenfield projects.
Our Data Stack
GrowFlow’s data pipelines consume data from all of our products (4+ and counting) into a central data warehouse in BigQuery.
We process & transform the data with DBT, visualize it with PowerBI and Amplitude.
Segment.com is our central product analytics customer data platform, collecting behavior/event data from all our sources and sending it to both our warehouse and various partner destinations.
Your Mission & Responsibilities:
As a part of the GrowFlow Data, Analytics & Reporting Team you will...
Ensure the availability and timely delivery of data, analytics & reporting, company-wide.
Ingest and aggregate structured & unstructured data from internal and external data sources to our data warehouse.
Model new data sets Build, maintain & improve performant, efficient & reliable ELT workflows and data pipelines
Document new & existing data models, ELT workflows, pipelines, data dictionaries and tracking events.
Build, deploy and monitor robust data tests to monitor & validate production pipelines.
Improve data-driven decisions by providing guidance & assistance to internal business stakeholders (Customer Experience, Sales, Marketing, Growth, etc) who need to unlock insights about our markets, customers and business processes.
Work w/ Product & Engineering to evolve and expand GrowFlow’s Insights product, our customer-facing business intelligence tool.
Work with business data analysts to develop, extend & support data-driven A/B experiments.
Be able to communicate effectively both within and outside of engineering, working with product, sales and customers to understand needs and discover ways to deliver insights.
See if you fit our requirements.
For this role, we are looking for someone with the following characteristics:
7+ years total engineering experience
3+ years experience dealing with “data”, including things like SQL databases, No-SQL databases, columnar databases and data pipelines.
Familiarity with Embedded Reporting tools/platforms (PowerBI, Domo, Looker, Sisense etc.)
Bonuses:
Experience with Google Big Query, DBT (getdbt.com) or PowerBI
Experience working with data using Python (e.g. Pandas, Apache Beam, scikit, tensorflow, etc)
Experience using ETL tools (SAS, Informatica, Talend, MSSQL SSIS, etc)
Ability to acutely focus on company objectives and mission at hand.
Ability to pass a background check; have appropriate work authorization
To achieve our mission, we always look for high-caliber people who share our core values:
Be Customer Obsessed: As a support engineer, our ideal candidate should have a heartbeat on customer satisfaction, and strive to make sure customer issues are resolved quickly and effectively.
Over Communicate: As a 100% remote company, over communication is key to delivering continued productivity across all teams. Our ideal candidate goes above and beyond to ensure important messages are received by the correct party.
Challenge Respectfully: GrowFlow is far more likely to succeed by examining problems and situations through several lenses. Our ideal candidate should be able to engage and work with both the support team and the engineering team to ensure we are delivering the best solution for our customers.
Extreme Ownership: At GrowFlow, we pride ourselves on each member practicing extreme ownership and accountability. Our ideal candidate should be able and willing to take ownership of customer reported issues and see them all the way to their resolution.
Stay Curious, Stay Scrappy: Most of us dork out over non-work related topics at a ridiculous level of detail, because that’s how we’re wired. We’re naturally inquisitive, ask tough questions and aren’t afraid to ruffle feathers to find better answers. Our Ideal candidate should be intuitive and eager to learn new things.
Do Less Better: At GrowFlow, we believe that the path to becoming the market leader looks like focusing on doing fewer things, but doing them better than anyone else in the industry. Our Ideal candidate is able to create a “path of least resistance” when resolving customer reported issues.
Results Get Rewarded: At GrowFlow, we recognize that the quickest path to becoming the top company in the industry is by forming the top team in the industry. Our ideal candidate should have a heartbeat on KPIs related to the T2 support engineer position and should be focused on measuring and improving metrics related to his or her position.
Other Details.
We are a fully remote company and this position will be remote.
We are looking for someone who is ready to join us full-time after a brief trial period (all our employees do this).
We offer health benefits, 401k, unlimited time off, charity matching, and other cool perks.
We are offering an annual salary in the range of $120,000 - $140,000 USD.
",http://stackoverflow.com/jobs/462177/senior-data-engineer-growflow
JOB266038772782,"Data Engineer Jobs in Houston, TX","Data Engineer Jobs in Houston, TX",,"Houston, TX","
Data Engineer Jobs in Houston, TX
Current Search Criteria
More
",https://militaryjobs.homedepot.com/data-engineer/jobs-in/houston/texas/usa/jobs/?utm_medium=.JOBS%20Universe&utm_source=.JOBS%20RSS%20Feed-DE&utm_campaign=.JOBS%20RSS%20Feed&vs=25
JOB266622190603,Senior Data Engineer - BlackLocus Jobs in United States,Senior Data Engineer - BlackLocus Jobs in United States,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/usa/jobs/?utm_source=.JOBS%20RSS%20Feed-DE&utm_medium=.JOBS%20Universe&vs=25&utm_campaign=.JOBS%20RSS%20Feed
JOB267201414204,Senior Data Engineer - BlackLocus Jobs in United States,Senior Data Engineer - BlackLocus Jobs in United States,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/usa/jobs/?vs=25&utm_campaign=.JOBS%20RSS%20Feed&utm_medium=.JOBS%20Universe&utm_source=.JOBS%20RSS%20Feed-DE
JOB267706582749,Senior+ Data Engineer,Senior+ Data Engineer,"Roughly 5 (or more!) years of Industry experience on a data or machine learning team,Proficiency with modern programming languages (Go, Python, Java, Scala, etc.) and SQL,Some practical experience with probability, statistical modeling, or machine learning,Backend developer experience optimizing the data access layer in mature web applications,Experience building and working with real-time compute and streaming infrastructures (Kafka, Kinesis, Flink, Storm, Beam, etc.),Experience writing and debugging ETL jobs using a distributed data framework.,A deep and abiding appreciation for agile software processes, data-driven development, reliability, and responsible experimentation,A collaborative attitude and a helpful personality,Health, dental, vision, and life insurance,401k matching program,Commuter benefits,Catered lunch and unlimited snacks,Unlimited reimbursement for work related books","Enable data scientists to train and deploy machine learning algorithms at scale, in fault-tolerant, highly-available systems,Use best practices in continuous integration and delivery with Docker and Kubernetes.,Work closely with application engineers to build data products that power Carta’s core applications,Create data pipelines using batch and streaming tools like Airflow, Spark, Kafka, and Google Pub/Sub,Uphold our engineering standards and bring consistency to the many codebases and processes you will encounter","Reasons could include: the employer is not accepting applications, is not actively hiring, or is reviewing applications
Carta is hiring experienced data engineers at the Senior, Staff, Senior Staff, and Principal levels in San Francisco, Palo Alto, Seattle, and New York City to build products and services powered by the ownership graph: the central registry of asset ownership across the globe.
As a data engineer at Carta, you’ll play a foundational role on Carta’s fast-growing Data & Machine Learning organization, working on one of the world’s most valuable data sets. You’ll spend two thirds of your time working on data engineering and backend software projects, and split the remaining third between DevOps, data science, and machine learning.
Candidates must have strong technical skills, be excited by “zero to one” projects, and enjoy working closely with stakeholders across engineering, product, business, and marketing.
Enable data scientists to train and deploy machine learning algorithms at scale, in fault-tolerant, highly-available systems
Use best practices in continuous integration and delivery with Docker and Kubernetes.
Work closely with application engineers to build data products that power Carta’s core applications
Create data pipelines using batch and streaming tools like Airflow, Spark, Kafka, and Google Pub/Sub
Uphold our engineering standards and bring consistency to the many codebases and processes you will encounter
Roughly 5 (or more!) years of Industry experience on a data or machine learning team
Proficiency with modern programming languages (Go, Python, Java, Scala, etc.) and SQL
Some practical experience with probability, statistical modeling, or machine learning
Backend developer experience optimizing the data access layer in mature web applications
Experience building and working with real-time compute and streaming infrastructures (Kafka, Kinesis, Flink, Storm, Beam, etc.)
Experience writing and debugging ETL jobs using a distributed data framework.
A deep and abiding appreciation for agile software processes, data-driven development, reliability, and responsible experimentation
A collaborative attitude and a helpful personality
Carta is creating the ownership network that maps the world's assets. Check out who we are and how we work here.
At Carta we want to create an environment for Carta's owners - you - to do your best work, by offering competitive benefits and perks:
We are committed to WELLNESS:
Health, dental, vision, and life insurance
Competitive PTO and unlimited sick time
401k matching program
Commuter benefits
Catered lunch and unlimited snacks
Cell phone stipend
Unlimited reimbursement for work related books
Fast paced work environment geared towards professional growth
Carta is backed by many of the best investors in the world, including Social Capital (Slack, Intercom, Box), Union Square Ventures (Twitter, Twilio, Coinbase), Menlo Ventures (Uber, Warby Parker), Spark Capital (Oculus VR, Slack, Cruise Automation), Meritech Capital (GoFundMe, Looker, Snowflake), and Tribe Capital.
","http://www.indeed.com/viewjob?t=Senior+Data+Engineer&c=Carta&l=New+York,+NY&jk=11d6dabfc68bedc9&rtk=1d6u5hvhtbm1n800&from=rss"
JOB268093883423,Data Engineer Jobs in United States,Data Engineer Jobs in United States,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/data-engineer/jobs-in/usa/jobs/?vs=25&utm_campaign=.JOBS%20RSS%20Feed&utm_medium=.JOBS%20Universe&utm_source=.JOBS%20RSS%20Feed-DE
JOB268269126668,Data Engineer,Data Engineer,,,"
POSITION PURPOSE
Congrats! You re learning about an exciting new role with The Home Depots Global Custom Commerce (GCC) team that will revitalize and invigorate the way we manage and view data. For this role, we are looking for some one who can develop, implement, test and maintain data pipelines (batch & streaming) and data structures within a cloud based column-oriented data store. This person will support the GCC BI and Data Science strategic initiatives to drive better customer experiences and more profitable outcomes
Why work here? Our entrepreneurial roots and maverick mentality, coupled with the resources and backing of the #1 home improvement retailer in the world, The Home Depot, is a unique opportunity for you to be a transformative retail disrupter. Plus, GCC is the world s largest online window covering company, and we ve got a demonstrably awesome 20-year track record. From our open-floor office to our open-door ethos, our culture is rooted in improving, evolving, and having fun (we re pretty serious about cake, cook-offs, ping pong, meaningful work and exciting projects). Most importantly, our team members are always inspired, engaged, and ready for growth. That means you ll have the resources and the runway to create truly magical, out-of-the-box work. Moreover, you will play an important role in leveraging our culture, people, systems, processes, and technology ultimately to provide incredible customer experiences, while growing business for GCC and The Home Depot. This is your chance to be part of something big, in a small start-up environment. We re ranked as one of The Top 5 Workplaces in Texas and have consistently won the following awards:The Best Place to Work in Houston (Houston Business Journal), Houston s Top Workplaces (Houston Chronicle) and Houston s Best and Brightest.
MAJOR TASKS, RESPONSIBILITES AND KEY ACCOUNTABILITIES
20%- Implement a real time streaming data ingestion and processing pipeline using Google Dataflow (Apache Beam)
20%- Interface with business intelligence analyts and others in IT (i.e. data engineers, architects, WebOps) in frequent whiteboard sessions to dicsucuss the design, implementation, and testing of data pipleines
20%- Maintain data architecture standards and ETL/ELT best practices consistent with a column oritented data store in an analytic use case
20%- Active and engaged particitpation in the Scrum delivery process
20%- Support solutions in production
NATURE AND SCOPE
This role reports to the Sr. Manager of EDW.
This role has no direct reports.
ENVIRONMENTAL JOB REQUIREMENTS
Environment:
Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.
Travel:
Typically requires overnight travel less than 10% of the time.MINIMUM QUALIFICATIONS
Must be eighteen years of age or older.
Must be legally permitted to work in the United States.
Education Required:
The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.
Years of Relevant Work Experience: 6 years
Physical Requirements:
Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.
Preferred Qualifications:
Familiarity with Agile methodologies
Experience with Spark dataframes, SparkSQL, Kafka, KSQL, real-time streaming, and message bus technologies
Experience with data science technologies such as SAS, R, Matlab, or similar
Experience with data warehousing and dimensional modeling
Knowledge, Skills, Abilities and Competencies:
Experience in building real time streaming data ingestion and processing pipeline using Apache Beam (running on either Google Datflow or Apache (Apex, Flink, or Spark) or Kafka in an analytics or data science use case
Experience with data processing tools (e.g. Hadoop, Spark, Dataflow, etc.)
Experience building ETL/ELT pipelines
Experience with column-oriented databases (e.g Redhift, BigQuery, Vertica)
Ability to go from whiteboard discussion to code
Ability to effectively communicate with technical and non-technical audiences
Strong programming ability
Success in a highly dynamic environment and ability to shift priorities with agility
Ability to act independently with minimal supervision
Willingness to explore and implement new ideas and technologies
Experience working directly with subject matter experts in both business and technology domains
Experience as a team lead We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
",https://militaryjobs.homedepot.com/houston-tx/data-engineer/4B642DC9C39B4857867CACB6FE730745/job/?utm_campaign=.JOBS%20RSS%20Feed&utm_medium=.JOBS%20Universe&utm_source=.JOBS%20RSS%20Feed-DE
JOB268651620465,Data Engineer for the Dutch vanguard of creativity and craftsmanship,Data Engineer for the Dutch vanguard of creativity and craftsmanship,Experience with micro-services and kubernetes,"Experience with any framework for data processing workflows,Experience visualizing and documenting architectures, e.g. a flow diagram describing how data flows from an input to ETL pipelines to a data warehouse,Experience with Google Dataflow or other cloud data processing services (e.g. on AWS),3+ years experience with SQL and Python (or Java or Node.js),Experience with unit and behavioral testing,Great understanding of CI/CD flows, containerization, and related best practices,Understanding of horizontal scalability and throughput of databases,Proactive and “can-do” mentality,Expereince with Node.js,Experience with BI visualization tools such as Superset","
Job description
As a Data engineer you are in a unique position of enabling the entire company to make insightful, data-driven decisions. Thanks to your ETL infrastructure, pipelines that write data from any input to a centralized data warehouse can easily be developed and maintained. This data is then used to create analysis by your fellow colleagues in the business intelligence team. Next to that you would be responsible for identifying, designing, and implementing internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
We support our software developers, data analysts and data scientists on data initiatives aiming to ensure consistent optimal data delivery architecture throughout bloomon's ongoing projects. We are a team of self-directed data lovers and are proud of being able to support the data needs of multiple teams, systems and products within all five countries bloomon operates. Our team constantly looks into opportunities for optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives. Best part of it for you - joining us would mean that you will be playing the main role into deciding on the data architecture.
What do we expect from you?
Experience with any framework for data processing workflows
Experience visualizing and documenting architectures, e.g. a flow diagram describing how data flows from an input to ETL pipelines to a data warehouse
Experience with Google Dataflow or other cloud data processing services (e.g. on AWS)
3+ years experience with SQL and Python (or Java or Node.js)
Experience with unit and behavioral testing
Great understanding of CI/CD flows, containerization, and related best practices
Understanding of horizontal scalability and throughput of databases
Proactive and “can-do” mentality
Bonuses but not required:
Expereince with Node.js
Experience with BI visualization tools such as Superset
Experience with micro-services and kubernetes
About Bloomon
At bloomon we assemble our bouquets with unique flowers from all over the world. We believe that diversity creates uniqueness. This is what we translate in our tech team as well. We offer you the opportunity to join a team of unique international developers who are helping us turning the industry on its head. We all love what we do – so challenge yourself, use new technologies, step out of your comfort zone, and take initiative! bloomon is the place where EVERYTHING you do matters!
Anything in our product is based on tech and data. Behind every bunch of flowers there are tons of algorithms, lines of codes, and you may even come across a bug or two.
",https://stackoverflow.com/jobs/148470/data-engineer-for-the-dutch-vanguard-of-bloomon
JOB269193979984,Back End Data Engineer,Back End Data Engineer,Strong Clevertech Community,"Experience using LookML (Looker),Hands-on coding experience and expertise in back end related technologies, like Node or Python,B.S. in Computer Science or equivalent experience followed by 5+ years work experience in using SQL and databases in a business environment,Expertise in Data Visualization,Deep experience in the latest libraries and programming techniques,Familiar with SQL/NoSQL databases like MongoDB and their declarative query languages,Knowledge in using BI Analytics and related technologies,You have accomplishments that showcase your capabilities by their success and technical depth.,You own new features from idea to completion.,Work well with a core team to design and execute major new features.,Enjoy contributing to a fast moving exciting project,Strong communicator and fluent in English with excellent written and verbal communication skills.,Thrive and excel in our diverse, distributed and agile team environment,Competitive Vacation Package,Annual Financial Allowance for YOUR development,Flexible Family Leave,Clevertech Gives Back Program,Clevertech U (Leadership Program, Habit Building, New Skills Training),Clevertech Swag","
Job description
REQUIREMENTS:
Experience using LookML (Looker)
Hands-on coding experience and expertise in back end related technologies, like Node or Python
B.S. in Computer Science or equivalent experience followed by 5+ years work experience in using SQL and databases in a business environment
Expertise in Data Visualization
Deep experience in the latest libraries and programming techniques
Familiar with SQL/NoSQL databases like MongoDB and their declarative query languages
Knowledge in using BI Analytics and related technologies
WHO YOU ARE:
You have accomplishments that showcase your capabilities by their success and technical depth.
You own new features from idea to completion.
Work well with a core team to design and execute major new features.
Enjoy contributing to a fast moving exciting project
Strong communicator and fluent in English with excellent written and verbal communication skills.
Thrive and excel in our diverse, distributed and agile team environment
Who We Are
Clevertech is a leading consultancy that is on a mission to build transformational digital solutions for the world’s most innovative organizations. Enterprise companies turn to Clevertech to help them launch innovative digital products that interact with hundreds of millions of customers, transactions and data points. By partnering with Clevertech these companies are propelling forward and changing their industries, business models and more.
Based in New York City with fully remote development teams, Clevertech has built core product offerings for clients whose value was revealed in transactions valued in excess of $100 million.
The problems we solve everyday are real and require creativity, grit and determination. We are building a culture that challenges norms while fostering experimentation and personal growth. We are hiring team members who are passionate and energized by the vision of empowering our customers in a complex industry through technology, data and a deep understanding of client concerns. In order to grasp the scale of problems we face, ideally you have some exposure to Logistics, FinTech, Transportation, Insurance, Media or other complex multifactor industries.
Our Benefits
We know that people do their best work when they’re taken care of. So we make sure to offer great benefits that promote personal and professional growth!
Competitive Vacation Package
Annual Financial Allowance for YOUR development
Flexible Family Leave
Clevertech Gives Back Program
Clevertech U (Leadership Program, Habit Building, New Skills Training)
Clevertech Swag
Strong Clevertech Community
How We Work
Why do people join Clevertech? To make an impact. To grow themselves. To be surrounded by developers who they can learn from. We are truly excited to be creating waves in an industry under transformation.
True innovation comes from an exchange of knowledge across all of our teams. To put people on the path for success, we nurture a culture built on trust, collaboration, and personal growth. You will work in small feature-based cross-functional teams and be empowered to take ownership.
We make a point of constantly evolving our experience and skills. We value diverse perspectives and fostering personal growth by challenging everyone to push beyond our comfort level and try something new.
The result? We produce meaningful work
Getting Hired
We hire people from a variety of backgrounds who are respectful, collaborative, and introspective. Members of the tech team, for example, come from diverse backgrounds having worked as copy editors, graphic designers, and photographers prior to joining Clevertech.
Our hiring process focuses not only on your skills but also on your professional and personal ambitions. We want to get to know you. We put a lot of thought into the interview process in order to get a holistic understanding of you while being mindful of your time. You will solve problems derived from the work we do on a daily basis followed by thoughtful discussions around potential fit. Whatever the outcome, we want you to have a great candidate experience.
Want to learn more about Clevertech and the team? Check out clevertech.careers.
",https://stackoverflow.com/jobs/260001/back-end-data-engineer-clevertech
JOB270642222141,Big Data Engineer Consultant,Big Data Engineer Consultant,,"On-premise and cloud-based deployment patterns,Streaming, micro-batching and right-time use cases,Provide innovative data engineering design and deployment approaches that leverage innovations in in-memory processing, agile delivery, automation, storage architectures etc. to design modern data pipelines at speed and scale,Working closely with technology partners, Accenture Technology Labs and Accenture Innovation centres to incubate emerging technologies and build prototypes/demos to enhance our data engineering codebases and frameworks,Mentor and upskill other data engineers","
- Job description
Role: Big Data Engineer Consultant
The digital revolution is changing everything. It’s everywhere – transforming how we work and play. Are you reacting to the disruption each day or are you leading the way as a digital disrupter? Accenture Digital is driving these exciting changes and bringing them to life across 40 industries in more than 120 countries. At the forefront of digital, you’ll create it, own it and make it a reality for our clients. Join us and become an integral part of our experienced digital team with the credibility, expertise and insight our clients depend on.
Accenture Digital is powered by three practices – Analytics, Interactive, and Mobility. As part of our Analytics practice, you’ll help businesses deliver insight-driven outcomes in entirely new ways.
Accenture Analytics supports clients to turn information into action by driving technology-enabled business insights, creating a ""decision making environment"" embracing social media, cloud, mobility, big data and legacy environments. We deliver and run the information strategy, architecture and governance that enable a ""single source of the truth"", empowering our clients to analyse that data for smarter decision making, actions and outcomes.
What responsibilities will you have?
Work with client teams to design and implement modern, scalable data pipelines and architectures leveraging Hadoop, NoSQL, Apache open source and emerging technologies, covering:
On-premise and cloud-based deployment patterns
Streaming, micro-batching and right-time use cases
Agile and DevOps techniques and implementation approaches
Provide innovative data engineering design and deployment approaches that leverage innovations in in-memory processing, agile delivery, automation, storage architectures etc. to design modern data pipelines at speed and scale
Working closely with technology partners, Accenture Technology Labs and Accenture Innovation centres to incubate emerging technologies and build prototypes/demos to enhance our data engineering codebases and frameworks
Mentor and upskill other data engineers
+ Basic qualifications
",https://www.accenture.com/gb-en/careers/jobdetails?id=00653072_en-GB&title=Big+Data+Engineer+Consultant
JOB270683695197,Data Engineer,Data Engineer,Experience with streaming data,"Working with the Senior Data Engineer in designing, building, future-proofing and operating a scalable data infrastructure,Working with the Senior Data Engineer in delivering data platform infrastructure, tooling and reporting on a regular basis,Working with the Senior Data Engineer in understanding the needs of our product teams and delivering valued data models,Enabling better testing and development workflows,Supporting the creation of data products that promote customer self-serve,Work with engineering to ensure the collection of high-quality data,Previous software engineering experience working in environments dealing with large datasets,Understanding of modern code-driven data engineering frameworks like Airflow,Understanding of functional data engineering principles,Familiarity with testing data pipelines,An understanding of distributed data processing methodologies, frameworks, and best practices,Solid understanding of databases and a working knowledge of SQL,Experience working with Python,Experience working with cloud products (e.g. S3, Kinesis, SQS, SNS),Experience working with Agile methodologies and a cross-functional environment,Experience with machine learning libraries","
Job description
Airtasker is a fast-growing online and mobile marketplace for local services and temporary labour. We are revolutionising the way people and businesses get more done by connecting real-time labour requirements with one of the world's most under-utilised assets - people power. Airtasker has big ambitions and recently raised $33M worth of funding as we go international, with the UK being the first country to plant our flag! We are building a talented team with opportunities to make a real impact in a hyper-growth and solutions-oriented start-up workplace. We are looking for a Data Engineer to join our small but talented Data team. This role will be foundational and critical in setting up core and scalable data infrastructure at Airtasker.
You will be responsible for:
Working with the Senior Data Engineer in designing, building, future-proofing and operating a scalable data infrastructure
Working with the Senior Data Engineer in delivering data platform infrastructure, tooling and reporting on a regular basis
Working with the Senior Data Engineer in understanding the needs of our product teams and delivering valued data models
Enabling better testing and development workflows
Supporting the creation of data products that promote customer self-serve
Work with engineering to ensure the collection of high-quality data
Key attributes we are looking for:
Essential:
Previous software engineering experience working in environments dealing with large datasets
Understanding of modern code-driven data engineering frameworks like Airflow
Understanding of functional data engineering principles
Familiarity with testing data pipelines
An understanding of distributed data processing methodologies, frameworks, and best practices
Solid understanding of databases and a working knowledge of SQL
Experience working with Python
Experience working with cloud products (e.g. S3, Kinesis, SQS, SNS)
Experience working with Agile methodologies and a cross-functional environment
Desirable:
Experience with machine learning libraries
Experience with streaming data
",https://stackoverflow.com/jobs/204023/data-engineer-airtasker
JOB270893139707,Data Engineer jobs,Data Engineer jobs,"Provide report predicting the future data, based on existing information.,U-SQL is the new big data query language of the Azure Data Lake Analytics service.,Experience providing technical leadership and mentor other engineers for the best practices on the data engineering space.,Able to use data to frame out and solve problems.,Be comfortable with algorithms and data structures, such as dynamic array, linked list, stack, queue, binary…,Experience with ingesting external data sources into an existing platform.,Create error reporting, install metrics, add data quality measures.,Follow best practices and security standards for all data, including personally identifiable data.,The Data Engineer I builds robust, fault-tolerant data…,Advanced knowledge of application, data, and infrastructure architecture disciplines.,BS/BA degree or equivalent experience.,The data engineer designs and builds platforms, tools, and solutions that help the bank manage, secure, and generate value from its data., Designs data solutions for data distributions and.,Verification, data modeling, and data mining.,Automation of data, data platforms, and tools.,Improve data usability and data quality in our data warehouse.,Experience with dimensional data modeling and schema design in a database or data warehouse.,Around 4 years of experience working as data engineer / data warhousing projects managing petabytes of data.,Data engineering: 3 years (Preferred).,Data Vault 2.0 data architecture.,Identify anomalies or inconsistencies in data.,Large scale data flows (Kafka).,Strong written and verbal communication skills.,Location: DE (the position that would be remote to start and then sit onsite in Delaware post-pandemic).,Experience building and optimizing 'big data' data pipelines, architectures and data sets.,Optimize and maintain data pipelines and architecture for the data…,Work with data engineers and data scientists to drive efficient solutions from the platform.,Help define the data story and enable data-driven solutions at…","Analyzes processes and data by extracting data from various data warehouse environments.,Performs data mapping for systems integration, data provisioning, and…","
Analyzes processes and data by extracting data from various data warehouse environments.
Performs data mapping for systems integration, data provisioning, and…
Provide report predicting the future data, based on existing information.
U-SQL is the new big data query language of the Azure Data Lake Analytics service.
Experience providing technical leadership and mentor other engineers for the best practices on the data engineering space.
Able to use data to frame out and solve problems.
Be comfortable with algorithms and data structures, such as dynamic array, linked list, stack, queue, binary…
Experience with ingesting external data sources into an existing platform.
Create error reporting, install metrics, add data quality measures.
Follow best practices and security standards for all data, including personally identifiable data.
The Data Engineer I builds robust, fault-tolerant data…
Advanced knowledge of application, data, and infrastructure architecture disciplines.
BS/BA degree or equivalent experience.
The data engineer designs and builds platforms, tools, and solutions that help the bank manage, secure, and generate value from its data.
 Designs data solutions for data distributions and.
Verification, data modeling, and data mining.
Automation of data, data platforms, and tools.
Improve data usability and data quality in our data warehouse.
Experience with dimensional data modeling and schema design in a database or data warehouse.
Around 4 years of experience working as data engineer / data warhousing projects managing petabytes of data.
Data engineering: 3 years (Preferred).
Data Vault 2.0 data architecture.
Identify anomalies or inconsistencies in data.
Large scale data flows (Kafka).
Strong written and verbal communication skills.
Location: DE (the position that would be remote to start and then sit onsite in Delaware post-pandemic).
Experience building and optimizing 'big data' data pipelines, architectures and data sets.
Optimize and maintain data pipelines and architecture for the data…
Work with data engineers and data scientists to drive efficient solutions from the platform.
Help define the data story and enable data-driven solutions at…
People also searched:
",https://www.indeed.com/jobs?q=Data+Engineer&l=
JOB270969865256,"Data Engineer Jobs in Houston, TX","Data Engineer Jobs in Houston, TX",,"Houston, TX","
Data Engineer Jobs in Houston, TX
Current Search Criteria
More
",https://militaryjobs.homedepot.com/data-engineer/jobs-in/houston/texas/usa/jobs/?utm_source=.JOBS%20RSS%20Feed-DE&utm_medium=.JOBS%20Universe&vs=25&utm_campaign=.JOBS%20RSS%20Feed
JOB271009691148,"Senior Data Engineer, Cloud","Senior Data Engineer, Cloud",Gym membership compensation,"Drive design and implementation leveraging modern design patterns,Ability to partner effectively with UX, PM, DevOps, QE and other developers to design and implement meeting the spirit of requirements,Experience in modern front end frameworks,Technically curious to keep present on advances in technology,Experience with segregation of model, presentation, and business logic.,TDD experience and strong desire to build in test from the start.,Write code (Test or Product) to deliver against project timescales, quality and requirements in various languages including Java or other selected languages for Sophos Cloud products.,Provide guidance and mentorship to junior developers in daily Scrum meetings.,Possesses a passion for solving complex Big Data problems,Plan for, design and implement our next-generation cloud security products.,Be involved from inception through implementation in a real hands on fashion.,BS in Computer Science, Engineering, or equivalent with 7+ years of development and data modelling background,Building highly scalable SaaS solutions using Big Data technologies,Experience with CI/CD,Experience with Agile Software Development methodologies (scrum/ kanban),Excellent attention to detail,Excellent verbal and written communication skills,Experience with the following technologies (recommended) and strong desire to learn (required),Programming language -- Java (must)
Batch processing -- Hadoop ,MapReduce
Stream processing -- Kafka and Amazon Kinesis
NoSQL -S3 , MongoDB.
Columnar stores - HBASE, Amazon Redshift
Restful web services
Code/Build/Deployment -- git, hg, svn, maven, sbt, jenkins, bamboo, ...
Amazon Web Services
Data Warehousing/ built ETL,Programming language -- Java (must),Batch processing -- Hadoop ,MapReduce,Stream processing -- Kafka and Amazon Kinesis,NoSQL -S3 , MongoDB.,Columnar stores - HBASE, Amazon Redshift,Restful web services,Code/Build/Deployment -- git, hg, svn, maven, sbt, jenkins, bamboo, ...,Amazon Web Services,Data Warehousing/ built ETL,Medical insurance,Dental insurance,Vision insurance,Life insurance,Long-term disability insurance,401k plan,Vacation time","
At Sophos, we operate at the cutting edge of technology, protecting businesses worldwide against complex threats, viruses and spam. We build high quality software security products in a fast-paced, nimble environment and we've been doing it for over 20 years.
Join us to help our customers protect their business and meet compliance needs.
Role
To function as a senior data lead for product features or key technology choices and implementation. Collaborates as part of a team for the development of complex systems; including requirements analysis, concept development and design, implementation and testing, demonstrating flexibility of role as required
Main Duties
Drive design and implementation leveraging modern design patterns
Ability to partner effectively with UX, PM, DevOps, QE and other developers to design and implement meeting the spirit of requirements
Experience in modern front end frameworks
Technically curious to keep present on advances in technology
Experience with segregation of model, presentation, and business logic.
TDD experience and strong desire to build in test from the start.
Write code (Test or Product) to deliver against project timescales, quality and requirements in various languages including Java or other selected languages for Sophos Cloud products.
Provide guidance and mentorship to junior developers in daily Scrum meetings.
Possesses a passion for solving complex Big Data problems
Plan for, design and implement our next-generation cloud security products.
Be involved from inception through implementation in a real hands on fashion.
Experience And Skills
BS in Computer Science, Engineering, or equivalent with 7+ years of development and data modelling background
Building highly scalable SaaS solutions using Big Data technologies
Experience with CI/CD
Experience with Agile Software Development methodologies (scrum/ kanban)
Excellent attention to detail
Excellent verbal and written communication skills
Experience with the following technologies (recommended) and strong desire to learn (required)
Programming language -- Java (must)
Batch processing -- Hadoop ,MapReduce
Stream processing -- Kafka and Amazon Kinesis
NoSQL -S3 , MongoDB.
Columnar stores - HBASE, Amazon Redshift
Restful web services
Code/Build/Deployment -- git, hg, svn, maven, sbt, jenkins, bamboo, ...
Amazon Web Services
Data Warehousing/ built ETL
Benefits
In most cases, the compensation package includes:
Medical insurance
Dental insurance
Vision insurance
Life insurance
Long-term disability insurance
401k plan
Vacation time
Gym membership compensation
",https://www.sophos.com/it-it/about-us/careers/united-states/senior-data-engineer-cloud.aspx
JOB271264564974,"How do we estimate Data Engineer salaries in Newport, RI?","How do we estimate Data Engineer salaries in Newport, RI?",,,"United States Arizona Phoenix Tempe California Belmont Berkeley Beverly Hills Burlingame Carlsbad Costa Mesa Culver City Cupertino El Segundo Fremont Gardena Irvine Livermore Los Angeles Los Gatos Manhattan Beach Marina del Rey Menlo Park Modesto Mountain View Newport Beach Oakland Palo Alto Playa Vista Pleasanton Redwood City Redwood Shores San Bruno San Carlos San Diego San Francisco San Jose San Juan Capistrano San Mateo San Ramon Santa Clara Santa Monica Sunnyvale West Hollywood Colorado Boulder Denver Connecticut Hartford Delaware Wilmington District of Columbia Washington Florida Boca Raton Doral Fort Lauderdale Miami Oldsmar Orlando Saint Petersburg Tampa Winter Park Georgia Atlanta Duluth Lawrenceville Idaho Boise Illinois Chicago Lake Forest Lombard Northlake Oakbrook Terrace Riverwoods Schaumburg Indiana Indianapolis Maryland Baltimore Massachusetts Andover Boston Brookline Burlington Cambridge North Reading Somerville Southborough Westborough Michigan Ann Arbor Detroit Minnesota Eden Prairie Minneapolis Missouri St. Louis Nebraska Lincoln Omaha Nevada Las Vegas New Hampshire Dover New Portsmouth New Jersey East Rutherford Jersey City Morristown Mount Laurel New Brunswick Piscataway Princeton Raritan Rutherford Wayne New York State Brooklyn Manhattan New York North Carolina Cary Durham Raleigh Ohio Cincinnati Oregon Beaverton Bend Portland Pennsylvania Canonsburg Philadelphia Pittsburgh Plymouth Meeting West Lawn Rhode Island Newport Tennessee Knoxville Memphis Texas Arlington Austin Dallas Fort Worth Frisco Houston Irving Midland Plano Richardson San Antonio Sugar Land Utah American Fork Draper Ogden South Jordan Virginia Alexandria Arlington Charlottesville Chesapeake Herndon McLean Reston Richmond Vienna Washington State Bellevue Kirkland Seattle Vancouver Wisconsin Antigo
18% Below national average
How do we estimate Data Engineer salaries in Newport, RI?
Salary estimates are based on information gathered from past employees, Indeed members, salaries reported for the same role in other locations and today's market trends.
Please note that all salary figures are approximations based upon third party submissions to Indeed. These figures are given to the Indeed users for the purpose of generalized comparison only. Minimum wage may differ by jurisdiction and you should consult the employer for actual salary figures.
","https://www.indeed.com/salaries/Data-Engineer-Salaries,-Newport-RI"
JOB271502394424,Senior Data Engineer - BlackLocus Jobs in United States,Senior Data Engineer - BlackLocus Jobs in United States,,"The specific accommodation requested to complete the employment application.,The name of the organization being represented,The location of the organization","
The Home Depot is committed to being an equal employment employer offering opportunities to all job seekers including individuals with disabilities. If you believe you need reasonable accommodations in order to search for a job opening or to apply for a position please contact us by sending an email to myTHDHR@homedepot.com. This email box is designed to assist job seekers who require reasonable accommodation to the application process. A response to your request may take up to two business days.
In your email please include the following:
The specific accommodation requested to complete the employment application.
The Home Depot store location(s) (city, state) to which you would like to apply
If you are a third-party organization supporting individuals with disabilities, please send an email to myTHDHR@homedepot.com
In your email please include the following
The name of the organization being represented
The location of the organization
A brief description of your need
Please Note:
Emails sent for non-disability related issues such as following up on an application will not receive a response.
Thank you
",https://militaryjobs.homedepot.com/senior-data-engineer-blacklocus/jobs-in/usa/jobs/?vs=25&utm_medium=.JOBS%20Universe&utm_campaign=.JOBS%20RSS%20Feed&utm_source=.JOBS%20RSS%20Feed-DE
JOB271951341633,Data Engineer - Build our First Data Eng Team!,Data Engineer - Build our First Data Eng Team!,"Company events: happy hours, bowling, bocce league, etc.","Optimize and execute on requests to pull, analyze, interpret and visualize data,Partner with team leaders across the organization to build out and iterate on team, and individual performance metrics,Optimize our data release processes, and partner with team leads to iterate on and improve existing data pipelines.,Design and develop systems that ingest and transform our data streams using the latest tools.,Design, build, and integrate new cutting edge databases and data warehouses, develop new data schemas and figure out new innovative ways of storing and representing our data.,Research, architect, build, and test robust, highly available and massively scalable systems, software, and services.,5+ years of data engineering experience,Robust experience with Python, Spark, and Airflow,Experience writing and executing complex SQL queries,Experience building data pipelines and ETL design (implementation and maintenance),Experience with AWS or other IAAS or PAAS provider,Scrum/Agile software development process.,Real estate experience,Experience with Periscope, Looker, Tableau and other BI tools,Experience with building data pipelines,Experience with machine learning,Medical, vision, dental, and paternity/maternity benefits.,401(k),Commuter benefits,Flexible time off policy,Catered lunches and snacks,Corporate gym membership","
Job description
We are on a mission to empower people to make smarter decisions during one of life’s most important moments: buying or selling their home. By analyzing 30 million+ real estate transactions from 2 million agents across the country, we are able to take an unbiased, data-driven approach to match our clients with top performing real estate agents to meet each of their specific needs. Our algorithm and marketplace solutions guide our clients through every step of the home buying or selling experience. Join us and build our first Data Engineering team and the # destination for home sellers! Learn more about our engineering team!
What You'll Do Here:
We are building our Data Engineering team to tackle HomeLight's diverse, data challenges. This position is an excellent opportunity for an engineer that wants to own the development, optimization, and operation of our data pipeline, which collects, processes, and distributes data to a suite of HomeLight products and teams. You will provide mission-critical data to both our algorithms and internal users, refining our product and identifying new markets. Some projects you will work on:
Optimize and execute on requests to pull, analyze, interpret and visualize data
Partner with team leaders across the organization to build out and iterate on team, and individual performance metrics
Optimize our data release processes, and partner with team leads to iterate on and improve existing data pipelines.
Design and develop systems that ingest and transform our data streams using the latest tools.
Design, build, and integrate new cutting edge databases and data warehouses, develop new data schemas and figure out new innovative ways of storing and representing our data.
Research, architect, build, and test robust, highly available and massively scalable systems, software, and services.
You Have
5+ years of data engineering experience
Robust experience with Python, Spark, and Airflow
Experience writing and executing complex SQL queries
Experience building data pipelines and ETL design (implementation and maintenance)
Experience with AWS or other IAAS or PAAS provider
Scrum/Agile software development process.
Bonus points for:
Real estate experience
Experience with Periscope, Looker, Tableau and other BI tools
Experience with building data pipelines
Experience with machine learning
The Perks
Medical, vision, dental, and paternity/maternity benefits.
401(k)
Commuter benefits
Flexible time off policy
Catered lunches and snacks
Corporate gym membership
Company events: happy hours, bowling, bocce league, etc.
To make sure we hire the most qualified people, we have a multi-step interview process which may include interviews, a homework assignment, and a reference check. We’re excited to get to know you and hope you’re ready to give this opportunity everything you’ve got!
",https://stackoverflow.com/jobs/197120/data-engineer-homelight
JOB122638841,"5 jobs with job title Data Engineer - Austin, Texas, United States","5 jobs with job title Data Engineer - Austin, Texas, United States",,,"
Browse for Data Engineer Jobs in Austin, Texas, United States. Find the job of your dreams on CareerCast.com today!
Search for Similar Listings
",https://www.careercast.com/jobs/data-engineer-austin-texas-334613576-b
JOB3310353755,Senior Big Data Engineer,Senior Big Data Engineer,"Developing and delivering AWS cloud solutions in areas such as AIML, advanced analytics, microservices, serverless, etc.,Building highly scalable, cloud-native applications on AWS platform using services like API Gateway, Lambda, SQS, DynamoDB and ECS.,Build and operationalize large scale enterprise data solutions and applications using one or more of AWS data and analytics services in combination with RedShift, DynamoDB, Glue, Athena, EMR, Spark etc.,,Design and build a utomation of end to end data pipeline with metadata, data quality checks, and audit,Following security guidelines to develop secure and compliant Cloud services by working with Risk and Security team,Be a graduate in Computer Science/Software Engineering/Mathematics, or related field with a minimum of 10+ years of experience in information technology,Have 4+ years' experience in big data, database and data warehouse architecture and delivery,3+ years of hands-on experience implementing data analytics solutions using AWS services: VPC, EC2, S3, AutoScaling, CloudFormation, LakeFormation, DMS, Kinesis, Kafka, CDC processing Redshift, RDS, DynamoDB, Cloudtrail, CloudWatch, Docker, Lambda, Spark, Glue, Sage Maker, AI/ML, API GW, etc.,3+ years for experience in most-used programming languages in data analytics solutions (like Python, Spark, PySpark, Unix shell/Perl scripting),Experience in event-driven, microservices and serverless implementations,Familiarity with the Technology stack available in the industry for data management, data ingestion, capture, processing and curation: Kafka, HVR, Talend, Hadoop, Hive, Spark, etc.,AWS Big data or AI/ML Specialty or any other AWS certifications are a plus,Have professional profiency in English,Working flexible hours - flexing the times when you work in the day to help you fit everything in and work when you are the most productive,Contemporary work-life balance policies and wellbeing activities,Comprehensive private medical care options,Safety net of life insurance and disability programs,Additional elected or voluntary benefits",,"
Company: Baker Hughes
Skills: IT - Analysis & Management
Experience: 10 + Years
Education: Tech/Vocational Cert/Apprenticeship
Location: Budapest, Hungary
Would you like to shape our strategy for Data and Analytics?
Would you like to shape the future of energy technology using data?
Join our Digital Technology Team!
Our Digital Technology business provides intelligent, connected technologies to monitor and control our energy extraction assets. We provide customers with the peace of mind needed to reliably and efficiently improve their operations. Our team oversees the operational excellence and performance of our Data and Analytics platform and EcoSystem.
Partner with the best
As Lead Big Data Engineer you will deliver projects to innovate and create a next-generation of Cloud-based solutions for our Data and Analytics platform. You'll have ownership of development and support of our cloud strategy. You will collaborate with internal cross-functional teams to ensure successful service delivery of quality products.
As Big Data & AI/ML Engineer, you will be responsible for:
Developing and delivering AWS cloud solutions in areas such as AIML, advanced analytics, microservices, serverless, etc.
Building highly scalable, cloud-native applications on AWS platform using services like API Gateway, Lambda, SQS, DynamoDB and ECS.
Build and operationalize large scale enterprise data solutions and applications using one or more of AWS data and analytics services in combination with RedShift, DynamoDB, Glue, Athena, EMR, Spark etc.,
Design and build a utomation of end to end data pipeline with metadata, data quality checks, and audit
Following security guidelines to develop secure and compliant Cloud services by working with Risk and Security team
Fuel your passion
To be successful in this role you should:
Be a graduate in Computer Science/Software Engineering/Mathematics, or related field with a minimum of 10+ years of experience in information technology
Have 4+ years' experience in big data, database and data warehouse architecture and delivery
3+ years of hands-on experience implementing data analytics solutions using AWS services: VPC, EC2, S3, AutoScaling, CloudFormation, LakeFormation, DMS, Kinesis, Kafka, CDC processing Redshift, RDS, DynamoDB, Cloudtrail, CloudWatch, Docker, Lambda, Spark, Glue, Sage Maker, AI/ML, API GW, etc.
3+ years for experience in most-used programming languages in data analytics solutions (like Python, Spark, PySpark, Unix shell/Perl scripting)
Experience in event-driven, microservices and serverless implementations
Familiarity with the Technology stack available in the industry for data management, data ingestion, capture, processing and curation: Kafka, HVR, Talend, Hadoop, Hive, Spark, etc.
AWS Big data or AI/ML Specialty or any other AWS certifications are a plus
Have professional profiency in English
Work in a way that works for you
We recognize that everyone is different and that the way in which people want to work and deliver at their best is different for everyone too. In this role, we can offer the following flexible working patterns:
Working flexible hours - flexing the times when you work in the day to help you fit everything in and work when you are the most productive
Working with us
Our people are at the heart of what we do at Baker Hughes. We know we are better when all of our people are developed, engaged and able to bring their whole authentic selves to work. We invest in the health and well-being of our workforce, train and reward talent and develop leaders at all levels to bring out the best in each other.
Working for you
Our inventions have revolutionized energy for over a century. But to keep going forward tomorrow, we know we have to push the boundaries today. We prioritize rewarding those who embrace change with a package that reflects how much we value their input. Join us, and you can expect:
Contemporary work-life balance policies and wellbeing activities
Comprehensive private medical care options
Safety net of life insurance and disability programs
Additional elected or voluntary benefits
About Us:
With operations in over 120 countries, we provide better solutions for our customers and richer opportunities for our people. As a leading partner to the energy industry, we're committed to achieving net-zero carbon emissions by 2050 and we're always looking for the right people to help us get there. People who are as passionate as we are about making energy safer, cleaner and more efficient.
Join Us:
Are you seeking an opportunity to make a real difference in a company that values innovation and progress? Join us and become part of a team of people who will challenge and inspire you! Let's come together and take energy forward.
Baker Hughes Company is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national or ethnic origin, sex, sexual orientation, gender identity or expression, age, disability, protected veteran status or other characteristics protected by law.
",https://www.rigzone.com/oil/jobs/postings/1104150_senior_big_data_engineer/
JOB3384117176,Associate Data Engineer,Associate Data Engineer,"BS/MS degree in Computer Science, Engineering or related field,Experience building processes that extract, process and add value to data sets from multiple source systems.,Experiencing with data modeling and tuning of relational as well as NoSQL datastores (Oracle, Red-shift, Impala, HDFS/Hive, Athena, etc.),Experience working with distributed computing tools (Spark, Hive, etc.),Experience with AWS cloud services: EC2, EMR, RDS, Redshift, S3, Lambda,Experience with data pipeline and workflow management tools: Airflow, etc.,Experience with one or more general purpose programming languages, including but not limited to: Java, Scala, C, C++, C#, Swift/Objective C, Python, or JavaScript.,Experience working with agile development methodologies such as Sprint and Scrum","Collaborate with Data Engineers and Business SME's to develop data products and services.,Build data products and service processes which perform data transformation, metadata extraction, workload management and error processing management.,Implement standardized, automated operational and quality control processes to deliver accurate and timely data and reporting to meet or exceed SLAs.,Work in product teams in support of operations data platform backlog"," Amgen is seeking Associate Data Engineers to help realize Amgen's Operations Data Strategy. This program will produce business insights through data science solutions. You will build upon our awarded Enterprise Data Lake to develop value added data products that span the Operations Domain (Process Development, Supply Chain, Quality, Engineering, Manufacturing). There is no more challenging data environment than Life Sciences due to the integration of scientific research, manufacturing, logistics of pharmaceutical products. Expect to make a difference in providing patients with products that meet their medical needs in a competitive landscape.
Successful candidates will have the requisite technical skills; the ability to absorb the nuances of the Bio-Tech operations value chain, including supply chain, logistics, and manufacturing source systems; high personal standards of productivity and quality; and the ability to contribute in a collaborative environment.
Key Activities for the Associate Data Engineer include:
Collaborate with Data Engineers and Business SME's to develop data products and services.
Build data products and service processes which perform data transformation, metadata extraction, workload management and error processing management.
Implement standardized, automated operational and quality control processes to deliver accurate and timely data and reporting to meet or exceed SLAs.
Work in product teams in support of operations data platform backlog
Provide Run/DevOps support
Basic Qualifications:
Bachelor's degree
OR
Associate degree and 4 years of Information Systems experience
OR
High school diploma / GED and 6 years of Information Systems experience
Preferred Qualifications:
BS/MS degree in Computer Science, Engineering or related field
Experience building processes that extract, process and add value to data sets from multiple source systems.
Experiencing with data modeling and tuning of relational as well as NoSQL datastores (Oracle, Red-shift, Impala, HDFS/Hive, Athena, etc.)
Experience working with distributed computing tools (Spark, Hive, etc.)
Experience with AWS cloud services: EC2, EMR, RDS, Redshift, S3, Lambda
Experience with data pipeline and workflow management tools: Airflow, etc.
Experience with one or more general purpose programming languages, including but not limited to: Java, Scala, C, C++, C#, Swift/Objective C, Python, or JavaScript.
Experience working with agile development methodologies such as Sprint and Scrum
Experience with Software engineering best-practices, including but not limited to version control (Git, TFS, Subversion, etc.), CI/CD (Jenkins, Maven, Gradle, etc.), automated unit testing, Dev Ops.
Amgen is committed to unlocking the potential of biology for patients suffering from serious illnesses by discovering, developing, manufacturing and delivering innovative human therapeutics. This approach begins by using tools like advanced human genetics to unravel the complexities of disease and understand the fundamentals of human biology.
Amgen focuses on areas of high unmet medical need and leverages its expertise to strive for solutions that improve health outcomes and dramatically improve people's lives. A biotechnology pioneer since 1980, Amgen has grown to be one of the world's leading independent biotechnology companies, has reached millions of patients around the world and is developing a pipeline of medicines with breakaway potential.
Amgen is committed to unlocking the potential of biology for patients suffering from serious illnesses by discovering, developing, manufacturing and delivering innovative human therapeutics. This approach begins by using tools like advanced human genetics to unravel the complexities of disease and understand the fundamentals of human biology.
Amgen focuses on areas of high unmet medical need and leverages its expertise to strive for solutions that improve health outcomes and dramatically improve people's lives. A biotechnology pioneer since 1980, Amgen has grown to be one of the world's leading independent biotechnology companies, has reached millions of patients around the world and is developing a pipeline of medicines with breakaway potential.
Join Us
If you're seeking a career where you can truly make a difference in the lives of others, a career where you can work at the absolute forefront of biotechnology with the top minds in the field, you'll find it at Amgen.
As an organization dedicated to improving the quality of life for people around the world, Amgen fosters an inclusive environment of diverse, ethical, committed and highly accomplished people who respect each other but compete intensely to win. Together, we live the Amgen values as we continue advancing science to serve patients.
Amgen is an Equal Opportunity employer and will consider all qualified applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.
",https://www.biospace.com/job/1980400/associate-data-engineer/
JOB5025787389,Senior Data Engineer,Senior Data Engineer,,"Scaling our existing data processes, focusing on quality every step of the way,Provide guidance on technology, library and tooling choices to the team,Wary of things like scope creep, over-engineering and ‘skipping unit tests for now’,learning our business domain,good software engineering principles and practice,solving business problems whilst avoiding technical complexity,5 years or more of software development experience,,Working together, be that pairing, or wider team collaboration,A belief in the agile principles, not just a single ""Agile Process"",Willingness to use the appropriate tool for the job, not just the latest ""hot"" technology,Sharing your knowledge and experience with others,Good (current) knowledge of SQL and at least two other programming languages,Experience in collaborative design of software systems including contracts, integration points and database schemas,Google Cloud Platform,PostgreSQL,Bash,Python,Flyway,Oracle,Groovy,Build and design large scale real-time and batch data pipelines.,Distributed microservice based applications at scale,Docker and Kubernetes to run your amazing code,Wearing a Scrum Master hat from time to time","
Senior Data Engineer
Country
United Kingdom
Job Family
Technology
For over 80 years, GfK has been a reliable and trusted insight partner for the world’s biggest companies and leading brands who make a difference in every consumer’s life - and we will continue to build on this. We connect data, science and innovative digital research solutions to provide answers for key business questions around consumers, markets, brands and media. With our headquarters in Germany and a presence in around 60 countries worldwide, you benefit from our global company with a diverse community of ~9,000 employees.
Harnessing the power of our workforce, the greatest asset we have is our people. As part of GfK, you can take your future into your own hands. We value talent, skills and responsibility and support your development within our international teams. We are proud of our heritage and our future: Currently we are in the latter stages of a transformational journey from a traditional market research company to a trusted provider of prescriptive data analytics powered by innovative technology. This is only possible with extraordinary people and this is why we are looking for YOU to help create our future. For our employees as well as for our clients we pursue one goal: Growth from Knowledge!
Job Description
Job Description
We are looking for you, a Senior Data Engineer to help us build the world’s premier market intelligence platform and it’s all about data. Helping us design, implement and scale our data within the client platform, understanding challenges, coming up with the data architecture to help us scale into the future achieving 10x growth and beyond. You will also work closely with our Backend and Frontend teams to support them with linking our data API’s into the back and frontend of our systems. You will be analytical and data driven in your role, working as part of a cross functional data engineering team of around 6 indivduals to help drive your finished product.
As a Senior Data Engineer, you will have following key accountabilities:
Scaling our existing data processes, focusing on quality every step of the way
Provide guidance on technology, library and tooling choices to the team
Wary of things like scope creep, over-engineering and ‘skipping unit tests for now’
learning our business domain
good software engineering principles and practice
solving business problems whilst avoiding technical complexity
collaborating with our teams consisting of data scientists and machine learning engineers, UX specialists, product specialists, and SREs
Now that we've introduced you to the Senior Data Engineering position, what skills, qualifications and experience should you have?
5 years or more of software development experience,
Working together, be that pairing, or wider team collaboration
A belief in the agile principles, not just a single ""Agile Process""
Willingness to use the appropriate tool for the job, not just the latest ""hot"" technology
Sharing your knowledge and experience with others
Good (current) knowledge of SQL and at least two other programming languages
Experience in collaborative design of software systems including contracts, integration points and database schemas
The ability to Test-Drive software with automated tests
Our current ""Tech Stack"" includes, but is not limited to:
Google Cloud Platform
PostgreSQL
Bash
Python
Flyway
Oracle
Groovy
Spock Framework for testing
If you don't match exactly, don't worry, a good engineering mind will get you a long way!
Besides the things we really expect you to have, there are some things which would be amazing if you have experience with them as well:
Build and design large scale real-time and batch data pipelines.
Distributed microservice based applications at scale
Docker and Kubernetes to run your amazing code
Wearing a Scrum Master hat from time to time
Experience with cloud technologies such as GCP, AWS
We offer an exciting work environment that brings people together. We encourage an entrepreneurial and innovative spirit. We make use of the latest digital technologies. We are looking for self-starters, who accept challenges and create solutions.
Can there be a better place to take centre stage in the digital revolution? We are excited to get to know you!
We offer an exciting work environment that brings people together. We encourage an entrepreneurial and innovative spirit. We make use of the latest digital technologies. We are looking for self-starters, who accept challenges and create solutions.
Can there be a better place to take center stage in the digital revolution? We are excited to getting to know you!
Posted: 18 days ago
City: London
Job Time: Full Time
Requisition ID: R00006129
",https://www.gfk.com/ja/careers/search-for-jobs/Senior-Data-Engineer_R00006129
JOB6028816401,Senior Data Engineer,Senior Data Engineer,"Expert level SQL skills,7-10 years experience in database technologies (i.e., Postgres, MySQL, SQL Server, Oracle, RedShift etc.),Minimum 5 years of experience in Data Warehousing,Working knowledge of dimensional modeling techniques,Working knowledge of data quality approaches and techniques,Experience with Redshift is highly desired,Experience with AWS tools (S3/Redshift/DynamoDB/IAM) is highly desired,Experience working with a standard ETL tool (i.e., Informatica, SSIS, Talend, Pentaho, etc.),Architectural insight on where to store data and modeling experience to recommend how it should be structured to make it accessible, performant, and resilient to change,An entrepreneurial spirit, a drive to ship quickly, and familiarity with agile software development practices,The ability to deal with ambiguity, communicate well with partner teams – both technical and non-technical, and a strong empathy for the customer experience,Experience working with Linux is a plus,Programming language experience (Python, Java, etc) is a plus,API development experience is a plus,Working with the Agile/Scrum development process is a plus","Design data warehouse solutions using dimensional methodologies to support ETL processes and data analytics applications,Develop, implement and tune ETL processes,Write and tune SQL including database queries, ddl and dml, stored procedures, triggers, user defined functions, analytic functions, etc.,Create code that meets design specifications, follows standards, and is easy to maintain,Own features that you develop end to end. Work with end users on requirements gathering, develop and test your code, implement new processes in production, then maintain and support them over time,Drive our data platform and help evolve our technology stack and development best practices
Develop and unit test assigned features to meet product requirements,Work with Analytics and Digital Marketing teams to provide them the data they need to make efficient decisions,Work with Quality Assurance team to ensure that the processes are fully tested,Support and maintain dev/test/prod environments to meet business delivery specifications and needs,Assist with adhoc report generation and data analysis for customers,Be part of monthly on call rotation","
Overview
Redfin is combining technology and customer service to reinvent the end to end experience for buying and selling a home in the consumer’s favor. The opportunity is huge, with $75 billion spent every year on real estate commissions and the industry is ripe for change. So far, we’ve helped over 20,000 people buy and sell homes, saving them over $100M in fees, and doing it all with a 97% customer satisfaction score.
As a Senior Data Engineer for the Data Engineering Team, your job is to integrate, sanitize, and productize our massive store of market and user data to turn it into a competitive weapon. You will have ownership of Redfin’s Data Warehouse platform, overall architecture, data integration and operational excellence. You will also be working closely with marketing team to provide key business KPIs and enable marketing automation.
Job Responsibilities
Design data warehouse solutions using dimensional methodologies to support ETL processes and data analytics applications
Develop, implement and tune ETL processes
Write and tune SQL including database queries, ddl and dml, stored procedures, triggers, user defined functions, analytic functions, etc.
Create code that meets design specifications, follows standards, and is easy to maintain
Own features that you develop end to end. Work with end users on requirements gathering, develop and test your code, implement new processes in production, then maintain and support them over time
Drive our data platform and help evolve our technology stack and development best practices
Develop and unit test assigned features to meet product requirements
Work with Analytics and Digital Marketing teams to provide them the data they need to make efficient decisions
Work with Quality Assurance team to ensure that the processes are fully tested
Support and maintain dev/test/prod environments to meet business delivery specifications and needs
Assist with adhoc report generation and data analysis for customers
Be part of monthly on call rotation
Job Requirements
Expert level SQL skills
7-10 years experience in database technologies (i.e., Postgres, MySQL, SQL Server, Oracle, RedShift etc.)
Minimum 5 years of experience in Data Warehousing
Working knowledge of dimensional modeling techniques
Working knowledge of data quality approaches and techniques
Experience with Redshift is highly desired
Experience with AWS tools (S3/Redshift/DynamoDB/IAM) is highly desired
Experience working with a standard ETL tool (i.e., Informatica, SSIS, Talend, Pentaho, etc.)
Architectural insight on where to store data and modeling experience to recommend how it should be structured to make it accessible, performant, and resilient to change
An entrepreneurial spirit, a drive to ship quickly, and familiarity with agile software development practices
The ability to deal with ambiguity, communicate well with partner teams – both technical and non-technical, and a strong empathy for the customer experience
Experience working with Linux is a plus
Programming language experience (Python, Java, etc) is a plus
API development experience is a plus
Working with the Agile/Scrum development process is a plus
",https://www.geekwire.com/jobs/job/redfin-seattle-2-senior-data-engineer/
JOB6145254247,Distinguished Data Engineer - Director,Distinguished Data Engineer - Director,"Masters' Degree,4+ years of experience with AWS","Deep technical experts and thought leaders that help accelerate adoption of the very best engineering practices, while maintaining knowledge on industry innovations, trends and practices,Design and develop cutting-edge solutions, using existing and emerging technology platforms","Job Description
1750 Tysons (12023), United States of America, McLean, Virginia
Distinguished Data Engineer - Director
At Capital One, we believe in the values of excellence and doing the right thing. We are a technology-oriented company delivering financial products to market through modern technology and constant innovation at a massive scale.
Distinguished Engineers are...
Deep technical experts and thought leaders that help accelerate adoption of the very best engineering practices, while maintaining knowledge on industry innovations, trends and practices
Visionaries, collaborating on Capital One's toughest issues, to deliver on business needs that directly impact the lives of our customers and associates
Role models and mentors, helping to coach and strengthen the technical expertise and know-how of our engineering and product community
Evangelists, both internally and externally, helping to elevate the DistinguishedEngineering community and establish themselves as a go-to resource on given technologies and technology-enabled capabilities
Leaders who gain the trust and confidence of those around them, from hands on engineers to executives
Whether a member of our engineering or architecture teams, Distinguished Engineers are individual contributors expected to solve problems in a fast-paced, collaborative, and iterative delivery environment. In order to meet these demands, candidates should be influential engineering leaders with deep technology expertise, and a collaborative style that brings others into the decision-making process. Distinguished Engineers will significantly impact the Tech agenda within their organization and devise clear roadmaps to deliver next generation technology solutions across organizational boundaries.
Responsibilities:
Design and develop cutting-edge solutions, using existing and emerging technology platforms
Leverage sound judgment and problem solving to tackle some of Capital One's most critical problems and connect the dots to broader implications of the work
Provide technical vision, technical solutions and directions to build complex and sustainable data ecosystem / platform
Lead, manage and grow our data ingestion, data refinement and data consumption teams.
Design, develop, deploy and manage a highly reliable and scalable data pipeline.
Build/Modernize our data refinement/ETL processes
Oversee the implementation of solutions for tracking data quality, data consistency and lineage..
Embrace and incubate emerging technology and open source products across all platforms
Collaborate with enterprise teams on developing and adhering to the company standards in terms of validation rules, nomenclature, design and deployments.
Collaborate with internal teams to find areas of opportunities for automation and machine learning.
Steamline the entire data ecosystem from end to end to ensure the most efficient , standard, privacy compliant processes possible.
Lead the way in creating next-generation talent for Tech, mentoring internal talent and actively recruiting external talent to bolster Capital One's Tech talent
Basic Qualifications:
At least 8 years of experience in database management and data warehousing
At least 5 years of experience developing in Spark, Python, SQL, Java, or Scala
At least 2 years of experience working with Cloud technologies
Preferred Qualifications:
Masters' Degree
10+ years experience architecting and delivering software systems or platforms
10+ years of data governance and security controls
8+ years of experience with Python
4+ years of experience with AWS
4+ years of experience with Go
4+ years experience working with Docker
2+ years of experience building and managing Kubernetes
Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.
",https://www.snagajob.com/search/q-distinguished+data+engineer
JOB7072641033,Data Engineer,Data Engineer,,,"
Overview
About the Services Engineering Team
The Services Engineering Team contributes to the mission of Highspot Customer Services by developing internal tools and platforms that support our customer services organization as they work with customers including helping them to continually refine practices and assess/improve customer health and value, analyzing data to generate unique business insights for customers, and providing insights to other teams in the company.
This role requires a blend of technical know-how and creative problem-solving skills, while maintaining unwavering focus on delivering great experiences to our customers. A successful candidate should have an entrepreneurial spirit with a continuous learning attitude. Most of all, the candidate should get their gratification from building tools and data platforms that enhance and optimize the way we support customers.
What You’ll Do
Support customer-facing teams in delivering value to customers
Create and maintain optimal data pipeline architecture
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Support internal stakeholders to assist with data-related technical issues and support their data infrastructure needs.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
Your Background
Bachelor’s degree or equivalent experience
3+ years of programming experience using SQL, computing data analytics, and developing business insights
Experience with data visualization tools and software libraries
Working SQL knowledge and experience working with relational databases, query authoring (SQL)
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
Experience supporting and working with cross-functional teams in a dynamic environment
PostgreSQL and Snowflake experience are a plus
Tableau experience is a plus
Benefits
Comprehensive medical, dental, and vision benefits
401(k) Matching
Paid parental leave
Flexible work and vacation schedules
Discounted ClassPass membership
2 volunteer days per year
Transportation benefits
Competitive compensation and stock options
Fully-stocked kitchen
Annual company-wide events
Meaningfully contribute to a compelling vision!
Equal Opportunity Statement
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of age, ancestry, citizenship, color, ethnicity, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or invisible disability status, political affiliation, veteran status, race, religion, or sexual orientation.
",https://www.geekwire.com/jobs/job/data-engineer/
JOB7278269748,Data Engineer - Cloud Technology,Data Engineer - Cloud Technology,"Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.,Bachelor’s Degree in STEM related field or equivalent,Six years of related experience,Proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and an understanding of software engineering practices.,Practical experience in the deployment of Cloud Technology with a preference on AWS Cloud,Working knowledge of Jenkins, Git repositories and terraform 12 or higher preferred,Knowledge of infrastructure as code automation strategies,The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions.,Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on.,Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems.,Strong verbal and written communication skills with the ability to interact with team members and business partners.,Leadership - Intermediate leadership skills with a proven track record of self-motivation in identifying personal growth opportunities.,Strong understanding of foundational IT and Cloud Infrastructure.,Understanding of Infrastructure as Code and/or Config Management Systems.,Strong understanding of AWS Cloud,Familiar with allied cloud platforms such as Databricks and Snowflake,Familiar with Cloud upgrade and resiliency strategies,Understanding (preferably hands on experience) of Python and Spark platforms.","Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.,Design data solutions.,Analyze sources to determine value and recommend data to include in analytical processes.,Incorporate core data management competencies including data governance, data security and data quality.,Collaborate within and across teams to support delivery and educate end users on data products/analytic environment.,Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate.","
The Travelers Companies, Inc.
Data Engineer - Cloud Technology
Company Summary
Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.
Target Openings
3
Job Description Summary
Travelers is seeking a Data Engineer - Cloud Technology to join our Business Insurance Technology Shared Value Stream – Technical Foundation & Operations organization as we grow and transform our technology landscape and move to the AWS cloud. The Cloud Technology Data Engineer may complete end-to-end engineering and development tasks for specific system assignments including designing, developing, analyzing, configuring, testing, debugging, troubleshooting, documenting, health monitoring/alerting and implementation.
The Cloud Technology Data Engineer may consult with users to determine hardware, software or system functional specifications, managing interaction between the systems and other technical support areas and defining technical requirements and coordinating team resources to solve problems.
The key areas of accountability include to the following:
1. Support the build out of new and existing services as well as assist our customers with migrating application to the cloud, leveraging their knowledge of application development.
2. Serve as our primary technical service concierge by providing design consulting and bridging any gap that may exist for our internal customers in leveraging our primary cloud platforms.
3. Assist in designing and engineering solutions and aiding developers to have a strong understanding of our business’ cloud strategy and application portfolio.
4. Drive migrations of internal applications within Shared Value Stream portfolio to cloud.
Travelers offers a hybrid work location model that is designed to support flexibility.
Primary Job Duties & Responsibilities
Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.
Design data solutions.
Analyze sources to determine value and recommend data to include in analytical processes.
Incorporate core data management competencies including data governance, data security and data quality.
Collaborate within and across teams to support delivery and educate end users on data products/analytic environment.
Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate.
Test data movement, transformation code, and data components.
Minimum Qualifications
Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
Four years of data engineering or equivalent experience.
Education, Work Experience, & Knowledge
Bachelor’s Degree in STEM related field or equivalent
Six years of related experience
Proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and an understanding of software engineering practices.
Practical experience in the deployment of Cloud Technology with a preference on AWS Cloud
Working knowledge of Jenkins, Git repositories and terraform 12 or higher preferred
Knowledge of infrastructure as code automation strategies
Knowledge of Cloud data and platform security concepts with a preference on AWS Cloud
Job Specific Technical Skills & Competencies
The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions.
Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on.
Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems.
Strong verbal and written communication skills with the ability to interact with team members and business partners.
Leadership - Intermediate leadership skills with a proven track record of self-motivation in identifying personal growth opportunities.
Strong understanding of foundational IT and Cloud Infrastructure.
Understanding of Infrastructure as Code and/or Config Management Systems.
Strong understanding of AWS Cloud
Familiar with allied cloud platforms such as Databricks and Snowflake
Familiar with Cloud upgrade and resiliency strategies
Understanding (preferably hands on experience) of Python and Spark platforms.
Familiar with Agile methodologies
Employment Practices
Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences.
If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.
Travelers reserves the right to fill this position at a level above or below the level included in this posting.
To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.
More From The Travelers Companies, Inc.
Related Job Listings
",https://www.insurancejournal.com/jobs/637019-data-engineer-cloud-technology
JOB9044563221,"Data Engineer (SQL, Data Analysis)","Data Engineer (SQL, Data Analysis)","Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.,Bachelor’s Degree in STEM related field or equivalent,6 years of programming/development experience preferred.,Strong problem solver, value deadlines and complete work on time,Strong collaboration and communication,Substantial experience with SSMS, T-SQL (developing, maintaining and troubleshooting complex stored procedures and processes),Thorough knowledge of database schemas, tables, relationships, and constraints,Microsoft SQL Server Reporting Services (SSRS), QlikView, ETL etc. is a plus,The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions.,Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on.,Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems.,Strong verbal and written communication skills with the ability to interact with team members and business partners.","Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.,Design data solutions.,Analyze sources to determine value and recommend data to include in analytical processes.,Incorporate core data management competencies including data governance, data security and data quality.,Collaborate within and across teams to support delivery and educate end users on data products/analytic environment.,Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate.","
The Travelers Companies, Inc.
Data Engineer (SQL, Data Analysis)
Company Summary
Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.
Target Openings
1
Job Description Summary
Travelers is looking for a Data Engineer to work with data from operational systems that will be transformed into business consumption marts. This role will include analyzing / profiling data and determining the right source of truth. Data will be transformed for consumption utilizing a new Metadata Driven-Ingestion Framework. Looking for a self-starter to drive business solutions in an Agile / Collaborative environment.
This position may be based 100% remotely or in one of our offices.
Primary Job Duties & Responsibilities
Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.
Design data solutions.
Analyze sources to determine value and recommend data to include in analytical processes.
Incorporate core data management competencies including data governance, data security and data quality.
Collaborate within and across teams to support delivery and educate end users on data products/analytic environment.
Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate.
Test data movement, transformation code, and data components.
Minimum Qualifications
Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
Four years of data engineering or equivalent experience.
Education, Work Experience, & Knowledge
Bachelor’s Degree in STEM related field or equivalent
6 years of programming/development experience preferred.
Strong problem solver, value deadlines and complete work on time
Strong collaboration and communication
Substantial experience with SSMS, T-SQL (developing, maintaining and troubleshooting complex stored procedures and processes)
Thorough knowledge of database schemas, tables, relationships, and constraints
Microsoft SQL Server Reporting Services (SSRS), QlikView, ETL etc. is a plus
Knowledge of data warehousing and CDC concept
Job Specific Technical Skills & Competencies
The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions.
Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on.
Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems.
Strong verbal and written communication skills with the ability to interact with team members and business partners.
Leadership - Intermediate leadership skills with a proven track record of self-motivation in identifying personal growth opportunities.
Employment Practices
Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences.
If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.
Travelers reserves the right to fill this position at a level above or below the level included in this posting.
To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.
More From The Travelers Companies, Inc.
Related Job Listings
",https://www.insurancejournal.com/jobs/634496-data-engineer-sql-data-analysis
JOB11394475849,Data Engineer,Data Engineer,Work with awesome companies around the world. We partner with great software companies all over the world and you'll constantly get to interact with people from these great companies,"You have experience in SQL: You’ve used written complex SQL queries that join across data from multiple systems, matching them up even when there was not a straightforward way to join the tables. You've designed tables with an eye towards ease of use and high performance. You've documented schemas and created data dictionaries.,You are a skilled written communicator. Zapier is a 100% remote team and writing is our primary means of communication.,You appreciate our team’s values of eagerness to collaborate with teammates from any function of the organization or with any level of data knowledge, iterating over your deliverables, and being curious.,You understand that the perfect is the enemy of the good and default to action by shipping MVP code and iterating as needed to get towards better solutions.,You have experience with APIs: You've ingested large quantities of data from RESTful APIs.,You have experience and a comfort level with programming. You can read and write code in Python, Go, Rust, Java, or C#. You're familiar with distributed source control using Git.,You have experience running infrastructure needed to orchestrate data pipelines, store data with different retention and performance requirements, and perform compute for multiple loads. Experience with tools like Ansible, Terraform, and/or Vagrant is a plus.,You understand columnar-store file formats like Orc or Parquet and are also familiar with Avro and Avro schemas.,Develop ETL to ingest and transform data from upstream databases and APIs into a data warehouse. The tools used include AWS Redshift, NiFi, Kafka, Matillion ETL, and custom Python.,Build, deploy, and continuously improve the infrastructure used by our data scientists and data and business analysts. The tools we have been using here include Docker, Terraform, Ansible, Kubernetes, and AWS EC2.,As a part of Zapier's all-hands philosophy, help customers via support to ensure they have the best experience possible.,Competitive salary (we pay based on the norms of your country),Great healthcare + dental + vision coverage*,Retirement plan with 4% company match*,Profit-sharing,2-3 annual company retreats to awesome places,14 weeks paid leave for new parents of biological or adopted children,Pick your own equipment. We'll set you up with whatever Apple laptop + monitor combo you want plus any software you need.,Unlimited vacation policy. Plus we require you to take at least 2 weeks off each year. We see most employees take 4-5 weeks off per year. This isn't a vague policy where unlimited vacation means no vacation.","
Data Engineer
Hi there!
We're looking for a Data Engineer to join the data team at Zapier. Interested in helping grow a product that helps the world automate their work so they can get back to living? Then read on…
We know applying for and taking on a new job at any company requires a leap of faith. We want you to feel comfortable and excited to apply at Zapier. To help share a bit more about life at Zapier, here are a few resources in addition to the job description that can give you an inside look at what life is like at Zapier. We hope you'll take the leap and apply.
Zapier is proud to be an equal opportunity workplace dedicated to pursuing and hiring a diverse workforce.
About You
You have experience in SQL: You’ve used written complex SQL queries that join across data from multiple systems, matching them up even when there was not a straightforward way to join the tables. You've designed tables with an eye towards ease of use and high performance. You've documented schemas and created data dictionaries.
You are a skilled written communicator. Zapier is a 100% remote team and writing is our primary means of communication.
You appreciate our team’s values of eagerness to collaborate with teammates from any function of the organization or with any level of data knowledge, iterating over your deliverables, and being curious.
You understand that the perfect is the enemy of the good and default to action by shipping MVP code and iterating as needed to get towards better solutions.
We're looking for somebody who would make a successful Data Engineer...
You have experience with APIs: You've ingested large quantities of data from RESTful APIs.
You have experience and a comfort level with programming. You can read and write code in Python, Go, Rust, Java, or C#. You're familiar with distributed source control using Git.
You have experience running infrastructure needed to orchestrate data pipelines, store data with different retention and performance requirements, and perform compute for multiple loads. Experience with tools like Ansible, Terraform, and/or Vagrant is a plus.
You understand columnar-store file formats like Orc or Parquet and are also familiar with Avro and Avro schemas.
Things You Might Do
Zapier is a startup, so you'll likely get experience on many different projects across the organization. Here are some things you'll get a taste of:
Develop ETL to ingest and transform data from upstream databases and APIs into a data warehouse. The tools used include AWS Redshift, NiFi, Kafka, Matillion ETL, and custom Python.
Build, deploy, and continuously improve the infrastructure used by our data scientists and data and business analysts. The tools we have been using here include Docker, Terraform, Ansible, Kubernetes, and AWS EC2.
As a part of Zapier's all-hands philosophy, help customers via support to ensure they have the best experience possible.
About Data at Zapier
Zapier relies on dozens of systems that emit data about Zapier and our potential and current users and partners. This data is useful for us to make a better product, better decisions, and understand our weaknesses and opportunities. The data team at Zapier pulls this data from DBs, APIs, and event streams, collocates it and then processes it through all the disparate systems to bring them together in a reliable, timely, performant, and easy to understand way for the employees and systems that need it.
Within the data team, we're made up of several subteams: Data Ops focusing on data infrastructure and storage, compute, ingest, and dimensional modeling; Data Products focusing on building statistical and ML tools and models; and Data Governance.
Our stack is best summed up by: AWS Redshift (and the related AWS products AWS Glue, Redshift Spectrum, AWS S3), Looker, Airflow, Matillion ETL, Kafka, Python, and NiFi. But we're pragmatic -- for example, we have some Java for ingesting data from Kafka, and we use Clojure for inferring schema and other information about data sets.
How To Apply
We have a non-standard application process. To jump-start the process we ask a few questions we normally would ask at the start of an interview. This helps speed up the process and lets us get to know you a bit better right out of the gate. Please make sure to answer each question.
After you apply, you are going to hear back from us, even if we don't seem like a good fit. In fact, throughout the process, we strive to make sure you never go more than seven days without hearing from us.
About Zapier
Since 2011, Zapier has been helping people across the world automate the boring and tedious parts of their job. We do that by helping everyone connect the web applications they already use and love.
We believe that there are jobs a computer is best at doing and that there are jobs a human is best at doing. We want to empower businesses to create processes and systems that let computers do what they are best at doing and let humans do what they are best at doing.
We believe that with the right tools, you can have big impact with less hassle.
We believe in small teams. Small teams are fast and nimble. Small teams mean less bureaucracy and less management and more getting things done.
We believe in a safe, welcoming, and inclusive environment. All teammates at Zapier agree to a code of conduct.
The Whole Package
Location: Planet Earth.
Our team of 300+ is distributed because it lets us work with the best people. You don't have to be located in the USA either. Some team members live in the United Kingdom, Thailand, India, Nigeria, Taiwan, Guatemala, New Zealand, Australia, and more! You just need the skills and drive to succeed in this role and the ability to work from anywhere.
Compensation:
Competitive salary (we pay based on the norms of your country)
Great healthcare + dental + vision coverage*
Retirement plan with 4% company match*
Profit-sharing
2-3 annual company retreats to awesome places
14 weeks paid leave for new parents of biological or adopted children
Pick your own equipment. We'll set you up with whatever Apple laptop + monitor combo you want plus any software you need.
Unlimited vacation policy. Plus we require you to take at least 2 weeks off each year. We see most employees take 4-5 weeks off per year. This isn't a vague policy where unlimited vacation means no vacation.
Work with awesome companies around the world. We partner with great software companies all over the world and you'll constantly get to interact with people from these great companies
*While we take care of our international folks as best we can, currently, healthcare and retirement plans are only available to US-, Canada- and UK-based employees. Optional: Share anonymously some demographic information about yourself to help us better track trends related to the backgrounds of candidates interested in working at Zapier in order for us to build a team that represents the users at Zapier and the broader world population.
Zapier is an equal opportunity employer. We're excited to work with talented and empathetic people no matter their race, color, gender, sexual orientation, religion, national origin, physical or mental disability, or age. Our code of conduct provides a beacon for the kind of company we strive to be, and we celebrate our differences because those differences are what allow us to make a product that serves a global user base.
",https://zapier.com/jobs/4692036002/data-engineer/
JOB11992431016,Data Engineer,Data Engineer,,"Collaborate with engineers to extract, transform, and load (ETL) data from a wide variety of in-house and 3rd party data sources,Ensure we have data consistency on both production and analytical databases. You will own the integrity of our data from end-to-end and the company will make high impact decisions based on this data.,Build a data warehouse to provide timely data to multiple third party applications (Salesforce, Marketo, etc),Design and build tools that make our data pipelines and surfacing more reliable and easier to use,Work closely with backend engineers to roll out new tools and features,Triage, identify, and fix scaling challenges,Collaborate with internal data customers to gather requirements,You have at least 2 years of experience with at least one relational database—MySQL, Postgres, Oracle or other.,You have experience with SQL and Data Warehousing using a relational database.,You are experienced with large-scale data pipelines and ETL tooling.,You have previous coding experience. Our ETL process is in Ruby and we use Python for some data analysis.,You are experienced with EDA (Exploratory Data Analysis) and Data Visualization (we use Tableau).,You have used Amazon Redshift.,You can manipulate data using Python (pandas, numpy, scikit-learn, etc).","
If you love clean data, we want to hear from you. We are looking for a Data Engineer who will help take the company’s data reporting and infrastructure to the next level. You will work with the Executive, Product, Marketing, Sales, Sales Engineering, Finance and Customer Success teams every day—in short, your work will have an impact on the whole company. You will be our second Data Engineer and will be critical in shaping our data foundation.
You will contribute to a variety of projects that range from designing robust and fully automated ETL processes to building tools for improving company-wide productivity with data. You have a passion for designing, implementing and operating stable, scalable and efficient solutions to flow data from production systems into the data warehouse.
We know new analytics technologies are emerging every single day and we are excited about the impact they will have – we hope you share our enthusiasm!
What You'll Do
Collaborate with engineers to extract, transform, and load (ETL) data from a wide variety of in-house and 3rd party data sources
Ensure we have data consistency on both production and analytical databases. You will own the integrity of our data from end-to-end and the company will make high impact decisions based on this data.
Build a data warehouse to provide timely data to multiple third party applications (Salesforce, Marketo, etc)
Design and build tools that make our data pipelines and surfacing more reliable and easier to use
Work closely with backend engineers to roll out new tools and features
Triage, identify, and fix scaling challenges
Collaborate with internal data customers to gather requirements
Help develop our data engineering function in areas of data architecture, business intuition and insight.
Who You Are
You have at least 2 years of experience with at least one relational database—MySQL, Postgres, Oracle or other.
You have experience with SQL and Data Warehousing using a relational database.
You are experienced with large-scale data pipelines and ETL tooling.
You have previous coding experience. Our ETL process is in Ruby and we use Python for some data analysis.
You can maintain confidentiality of sensitive customer data.
Bonus Points
You are experienced with EDA (Exploratory Data Analysis) and Data Visualization (we use Tableau).
You have used Amazon Redshift.
You can manipulate data using Python (pandas, numpy, scikit-learn, etc).
You have previously worked in Business Intelligence, Analytics or Finance.
We believe that the way business gets done today is broken. That’s why we’re dedicated to simplifying work for everyone - from small startups to large enterprise companies. Millions of individuals and over 80,000 companies world-wide trust the HelloSign platform – which includes eSignature, digital workflow and eFax solutions – to automate and manage their most important business transactions.
With a sharp focus on user experience and a lust for innovation, HelloSign is on a mission to Simplify Work.
We are centrally located in downtown San Francisco near BART, the Transbay Terminal, and the Ferry Building. Just over 100 employees, we are growing the company deliberately, with a keen eye towards maintaining a culture that values lifestyle, fun and continuous improvement. We were awarded the Hirepalooza Culture Award for Lifestyle in 2015 and the Healthy Mothers Workplace Bronze Award in 2016 and 2017. This year, we won SF Business Times' Best Places to Work Award for Small Employers. We continue to maintain an overwhelmingly positive presence on Glassdoor and The Muse.
We have raving fans who love what we make • We're user-focused and product-driven • We're always evolving with an eye towards improvement • We're committed to building a product people want • We thrive on collaboration and learning from each other • We have a supportive, familial atmosphere • We work in an open, airy, creative space • We laugh a lot • We love dogs • And we'll never forget your birthday!
HelloSign is an equal opportunity employer committed to hiring a diverse team of qualified individuals • HelloSign conducts background checks; pursuant to the San Francisco Fair Chance Ordinance, HelloSign will consider for employment qualified applicants with arrest and conviction records • HelloSign participates in E-Verify.
",https://www.themuse.com/jobs/hellosign/data-engineer
JOB18090949970,Amazon Web Services (AWS) Big Data Engineer,Amazon Web Services (AWS) Big Data Engineer,"Building and supporting reusable frameworks to ingest, integrate and provision data,Automating of end to end data pipeline with metadata, data quality checks, and audit,Building and supporting a big data platform on the cloud,Building and supporting data pipelines for data extraction, transformation, and loading processes using cloud native services or custom scripting using python, pyspark, etc.,,Be a Graduate in Computer Science/Software Engineering/Mathematics, or related field with a minimum of 4 yrs of experience in information technology,Have 3+ yrs' experience in data warehouse/data lake technical architecture,Have minimum of 2 yrs of Big Data and Big Data tools like Redshift, S3, Glue, Athena, DynamoDB, Python, Pyspark etc.,Have experience in Kafka, Spark, Hadoop is preferred,Have 3+ yrs of experience working in cloud data platforms or tools,Have familiarity with batch processing and workflow tools like AirFlow,Working flexible hours - flexing the times when you work in the day to help you fit everything in and work when you are the most productive,Contemporary work-life balance policies and wellbeing activities,Comprehensive private medical care options,Safety net of life insurance and disability programs,Tailored financial programs",,"
Company: Baker Hughes
Skills: IT - Analysis & Management, IT - Software Development
Experience: 3 + Years
Education: Bachelors/3-5 yr Degree
Location: Bengaluru, Karnataka, India
Big Data Engineer
Are you passionate about being part of a successful team?
Do you enjoy hands-on technical work and working with data?
Join our Digital Technology - Data Analytics Team
Our team is responsible for Data platform architecture and operations. You will be part of the team implementing next gen data platform. Partner with CTO team to align on Enterprise standards, continue to position D&A technology to support the growing demands across BH.
Partner with the best
You will design, build, and implement production data pipelines from ingestion to consumption within a big data architecture. Using AWS native or custom programming and partners with data engineering, architecture, and cloud team members.
As a Data Engineer, you will be responsible for:
Building and supporting reusable frameworks to ingest, integrate and provision data
Automating of end to end data pipeline with metadata, data quality checks, and audit
Building and supporting a big data platform on the cloud
Building and supporting data pipelines for data extraction, transformation, and loading processes using cloud native services or custom scripting using python, pyspark, etc.,
Developing, and operationalizing large-scale enterprise data solutions and/or reporting platforms
Fuel your passion
To be successful in this role you will:
Be a Graduate in Computer Science/Software Engineering/Mathematics, or related field with a minimum of 4 yrs of experience in information technology
Have 3+ yrs' experience in data warehouse/data lake technical architecture
Have minimum of 2 yrs of Big Data and Big Data tools like Redshift, S3, Glue, Athena, DynamoDB, Python, Pyspark etc.
Have experience in Kafka, Spark, Hadoop is preferred
Have 3+ yrs of experience working in cloud data platforms or tools
Have familiarity with batch processing and workflow tools like AirFlow
Having AWS certifications will be a plus
Work in a way that works for you
We recognize that everyone is different and that the way in which people want to work and deliver at their best is different for everyone too. In this role, we can offer the following flexible working patterns:
Working flexible hours - flexing the times when you work in the day to help you fit everything in and work when you are the most productive
Working with us
Our people are at the heart of what we do at Baker Hughes. We know we are better when all of our people are developed, engaged and able to bring their whole authentic selves to work. We invest in the health and well-being of our workforce, train and reward talent and develop leaders at all levels to bring out the best in each other.
Working for you
Our inventions have revolutionized energy for over a century. But to keep going forward tomorrow, we know we have to push the boundaries today. We prioritize rewarding those who embrace change with a package that reflects how much we value their input. Join us, and you can expect:
Contemporary work-life balance policies and wellbeing activities
Comprehensive private medical care options
Safety net of life insurance and disability programs
Tailored financial programs
Additional elected or voluntary benefits
About Us
With operations in over 120 countries, we provide better solutions for our customers and richer opportunities for our people. As a leading partner to the energy industry, we're committed to achieving net-zero carbon emissions by 2050 and we're always looking for the right people to help us get there. People who are as passionate as we are about making energy safer, cleaner and more efficient.
Join Us
Are you seeking an opportunity to make a real difference in a company with a global reach and exciting services and clients? Come join us and grow with a team of people who will energize and inspire you!
About Us:
With operations in over 120 countries, we provide better solutions for our customers and richer opportunities for our people. As a leading partner to the energy industry, we're committed to achieving net-zero carbon emissions by 2050 and we're always looking for the right people to help us get there. People who are as passionate as we are about making energy safer, cleaner and more efficient.
Join Us:
Are you seeking an opportunity to make a real difference in a company that values innovation and progress? Join us and become part of a team of people who will challenge and inspire you! Let's come together and take energy forward.
Baker Hughes Company is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national or ethnic origin, sex, sexual orientation, gender identity or expression, age, disability, protected veteran status or other characteristics protected by law.
",https://www.rigzone.com/oil/jobs/postings/1106033_big_data_engineer/
JOB18695734788,Informatics Engineer III (Data Engineer),Informatics Engineer III (Data Engineer),,"Design and develop scientific databases, create methods to process and analyze omics data or other biological information.,Lead application development efforts and establish data engineering platforms to enable the storage, organization, dissemination, and analytics of dynamic data generated from innovative research, exploratory and clinical studies.,Contribute to strategic planning and implementation of our data engineering platforms for multiple functions to ensure data accessibility, quality, and integrity.,Bachelor’s with 7+ years relevant experience; or Master’s/PhD with 4+ years relevant experience; or equivalent experience. Degree in computer sciences, bioinformatics or related field.,Track record of successfully delivering large scale informatics solutions to address complex scientific data challenges, and applying modern software engineering practices to deliver applications and/or scientific data analyses.,Experience with omics data analysis and method development,Familiarity with relational and non- relational databases. Working knowledge of scientific applications development cycles, data management techniques and infrastructure requirements.,Working knowledge of scripting languages, Python and R strongly preferred,Demonstrated adherence to best practices in software engineering, particularly iterative development, version control, testing and modular design.,Experience in operating on large data, such as data stored in relational and non-relational databases, HDF5 files or parquet files.","
South San Francisco
California, United States of America
The Position
Major Responsibilities
Development Sciences Informatics is seeking a talented and experienced informatics engineer to develop scientific software tools, software engineering, bioinformatics algorithm design, pipeline development and implementation. You will provide engineering leadership in collaboration with scientists and other engineers to facilitate deep exploration of multidimensional preclinical and clinical omics data. You should have a flexible and learning mindset, be able to work in a fluid and dynamic environment, be comfortable leading globally distributed development teams and have a strong desire to pursue creative solutions to challenging problems.
Design and develop scientific databases, create methods to process and analyze omics data or other biological information.
Lead application development efforts and establish data engineering platforms to enable the storage, organization, dissemination, and analytics of dynamic data generated from innovative research, exploratory and clinical studies.
Contribute to strategic planning and implementation of our data engineering platforms for multiple functions to ensure data accessibility, quality, and integrity.
Lead local and off-shore engineering teams to delivery informatics solutions and meet business needs.
Who You Are
Bachelor’s with 7+ years relevant experience; or Master’s/PhD with 4+ years relevant experience; or equivalent experience. Degree in computer sciences, bioinformatics or related field.
Track record of successfully delivering large scale informatics solutions to address complex scientific data challenges, and applying modern software engineering practices to deliver applications and/or scientific data analyses.
Experience with omics data analysis and method development
Familiarity with relational and non- relational databases. Working knowledge of scientific applications development cycles, data management techniques and infrastructure requirements.
Working knowledge of scripting languages, Python and R strongly preferred
Demonstrated adherence to best practices in software engineering, particularly iterative development, version control, testing and modular design.
Experience in operating on large data, such as data stored in relational and non-relational databases, HDF5 files or parquet files.
Excellent analytical, and written/verbal communication skills. Self-motivated, proactive and a team player.
#DevSciInformatics
#DevSci
Who We Are
A member of the Roche Group, Genentech has been at the forefront of the biotechnology industry for more than 40 years, using human genetic information to develop novel medicines for serious and life-threatening diseases. Genentech has multiple therapies on the market for cancer & other serious illnesses. Please take this opportunity to learn about Genentech where we believe that our employees are our most important asset & are dedicated to remaining a great place to work.
The next step is yours. To apply today, click on the ""Apply online"" button.
Genentech is an equal opportunity employer & prohibits unlawful discrimination based on race, color, religion, gender, sexual orientation, gender identity/expression, national origin/ancestry, age, disability, marital & veteran status. For more information about equal employment opportunity, visit our Genentech Careers page.
Join our Talent Community. By joining our Talent Community, your resume will be available to our recruitment team, Join today!
",https://www.gene.com/careers/detail/202008-121399/Informatics-Engineer-III-Data-Engineer
JOB20950723775,Limited Duration Senior Enterprise Data Engineer,Limited Duration Senior Enterprise Data Engineer,"Working-knowledge of data integration, data movement, global database administration, traffic shadowing, test driven development, and software development life cycle.,Big data dimensional design leveraging star or snowflake schema.,SQL Server Integration Services (SSIS), SQL Server Reporting Services (SSRS), and SQL Server Analysis Services (SSAS) or other reporting services.,Python, R, Tableau, or other programming languages and analysis tools preferred but not required.,Knowledge of Agile methodology and frameworks like Scrum, Kanban, XP,Build and execute Big Data strategies, systems, and platforms addressing the capture of data, data storage, data analysis, search, sharing, transfer, visualization, querying, updating, information privacy, and data source.,Cluster enterprise relational and document-oriented databases with RESTful services and traffic mirroring.,Integrate database strategies with data larger than 1TB using relational databases, especially MS SQL Server.,Database Administrator 1,Database Administrator 2","Trust & confidence – Making our intent and actions be transparent and honest while fostering healthy, inclusive relationships, actively listening and maintaining open communications, delivering on our promises, investing in other's success, and engaging each other and the community,Creative work environment – Exploring meaningful new ideas and relationships to foster innovation and encourage collaboration and creativity. Challenging the standard method of doing business in a positive environment.,Now & later perspective – Looking beyond day to day challenges to better anticipate the future and adjust to change.,Respectful & inclusive work environment – Seeking out a wide range of voices and making each other feel respected and included.,Self-awareness & emotional intelligence – Learning to recognize and understand our own emotions and the emotions of others and recognizing our individual strengths and weakness to raise self-awareness so we can perform better.,Wellbeing - We take care of ourselves and each other.,Excellent communication skills & a drive to understand customers,The ability to bring an understanding of Data Governance; Shows an understanding and adherence to established industry standard policies (such as DGI) and related experience,Performance optimization of databases in a multi-tier architectural environment,Obsessive attention to detail with a strong interest in automating any duplicate systems,The ability to provide direct support for the integration of data from, and interfaces and data flows between and among multiple applications from multiple sources, both in-house and vendor-provided.,Oversee all aspects of database security, business continuity, database usage standards and practices, database infrastructure design, implementation, integration, troubleshooting, and administration.,Support database architecture strategy, data modeling, and database design,Provide Tier-2 and Tier-3 support to development teams and business users with database operations, including the development of complex SQL, tuning of DML and the creation of stored procedures.,Develop, install, maintain and monitor globally-distributed hybrid-cloud corporate databases in a high performance/high availability environment supporting existing and new enterprise products,Manage backups and synchronization of multiple databases between data centers.,Support design and development of SQL code and SSRS reports or other reporting platforms,Transact-SQL experience and SQL Server clustering/failover qualifications required,Performs other technical tasks relative to the administration of City databases.","
General Statement of Duties
**This is a Limited Duration position. Please see information under ""Supplemental Information"" for details about limited duration assignments.
This posting is for a Limited Duration position. The position is projected to last 24 months.
The City of Eugene Information Services Division (ISD) builds and maintains the City of Eugene's technologies to meet the evolving needs of the community.
We are looking for dedicated and innovative people who share a love of working with technology to solve problems. Join our fun, friendly, and diverse Application Team. We develop and support city-wide applications for an organization with extensive opportunities to learn, grow, and make a difference in a community that cares about you.
Work Schedule:
Part-time, grant funded position - 20 hours/week, Monday - Friday with additional or flexible hours to meet business needs.
Location:
Information Services, 100 W. 10th Avenue, Suite 450, Eugene
Salary:
Database Administrator 1:$33.64 - $43.52/hour
Database Administrator 2: $36.60 - $48.32/hour
THIS POSITION IS OPEN UNTIL FILLED
The next review of applications will take place:
Wednesday, April 8, 2020 at 5:00 pm PST
ONLINE APPLICATIONS ONLY
--------------------------------------------------------------------------
Calling Eugene Home
Eugene is located at the southern end of the agriculturally rich Willamette Valley. From here, it is a short jaunt east to the Cascade Mountains, west to the stunning Pacific Ocean coastline, or north to Portland. We're a small city with unlimited things to do: Downtown Eugene is revitalizing; the Oregon Bach Festival and Eugene Symphony call the Hult Center for the Performing Arts home; you can float the Willamette River and hook a salmon after work in the shadow of downtown; a booming food and beverage economy, including topnotch local craft breweries and wineries in the surrounding countryside, is the foundation of a local restaurant scene; the University of Oregon brings arts, culture, and educational opportunities, as well as championship athletics (Go Ducks!); a nationally-recognized transit system helps you move around the city; and our Gold rating as a Walk- and Bicycle-Friendly Community ensures that safe travel options abound! Known as Track Town USA, the community annually plays host to numerous track and field events at historic Hayward Field, including the IAAF World Championships in 2021! The impact of track and field can be seen beyond the track, with abundant trails coursing through the south hills, along the Willamette River, and through hundreds of acres of city parks. To learn more about Eugene, visit Eugene Cascades and Coast.
-------------------------------------------------------------------------------------------
The Organization
The City of Eugene has a Council-Manager form of government. In this form of government, the city council develops legislation and policies to direct the City. The city manager, hired by the city council, provides administrative direction to the organization, oversees City of Eugene personnel and operations, and carries out the city council's direction. The City of Eugene has over 1,500 employees and a $722 million total budget. The City of Eugene is a service-oriented and welcoming organization that provides services through six departments: Central Services, Fire and Emergency Medical Services, Police, Public Works, Planning and Development, and Library, Recreation and Cultural Services. The State of the City video shows how the city is meeting new challenges, learning from one another, building connections, and celebrating our city.
As an organization we are focusing on six Core Competencies for employees:
Trust & confidence – Making our intent and actions be transparent and honest while fostering healthy, inclusive relationships, actively listening and maintaining open communications, delivering on our promises, investing in other's success, and engaging each other and the community
Creative work environment – Exploring meaningful new ideas and relationships to foster innovation and encourage collaboration and creativity. Challenging the standard method of doing business in a positive environment.
Now & later perspective – Looking beyond day to day challenges to better anticipate the future and adjust to change.
Respectful & inclusive work environment – Seeking out a wide range of voices and making each other feel respected and included.
Self-awareness & emotional intelligence – Learning to recognize and understand our own emotions and the emotions of others and recognizing our individual strengths and weakness to raise self-awareness so we can perform better.
Wellbeing - We take care of ourselves and each other.
Examples of Duties Performed - Duties may include but are not limited to the following
The successful Senior Enterprise Engineer candidate for our team will demonstrate:
Excellent communication skills & a drive to understand customers
The ability to bring an understanding of Data Governance; Shows an understanding and adherence to established industry standard policies (such as DGI) and related experience
Performance optimization of databases in a multi-tier architectural environment
Obsessive attention to detail with a strong interest in automating any duplicate systems
The ability to provide direct support for the integration of data from, and interfaces and data flows between and among multiple applications from multiple sources, both in-house and vendor-provided.
The scope of the position includes:
Oversee all aspects of database security, business continuity, database usage standards and practices, database infrastructure design, implementation, integration, troubleshooting, and administration.
Support database architecture strategy, data modeling, and database design
Provide Tier-2 and Tier-3 support to development teams and business users with database operations, including the development of complex SQL, tuning of DML and the creation of stored procedures.
Develop, install, maintain and monitor globally-distributed hybrid-cloud corporate databases in a high performance/high availability environment supporting existing and new enterprise products
Manage backups and synchronization of multiple databases between data centers.
Support design and development of SQL code and SSRS reports or other reporting platforms
Transact-SQL experience and SQL Server clustering/failover qualifications required
Performs other technical tasks relative to the administration of City databases.
Performs related and other duties as assigned.
Qualifications
Any equivalent combination of education and experience which provides the applicant with the knowledge, skills and abilities required to perform the job. A typical way to obtain the knowledge and abilities would be:
Knowledge of:
Working-knowledge of data integration, data movement, global database administration, traffic shadowing, test driven development, and software development life cycle.
Big data dimensional design leveraging star or snowflake schema.
SQL Server Integration Services (SSIS), SQL Server Reporting Services (SSRS), and SQL Server Analysis Services (SSAS) or other reporting services.
Python, R, Tableau, or other programming languages and analysis tools preferred but not required.
Knowledge of Agile methodology and frameworks like Scrum, Kanban, XP
Ability to:
Build and execute Big Data strategies, systems, and platforms addressing the capture of data, data storage, data analysis, search, sharing, transfer, visualization, querying, updating, information privacy, and data source.
Cluster enterprise relational and document-oriented databases with RESTful services and traffic mirroring.
Integrate database strategies with data larger than 1TB using relational databases, especially MS SQL Server.
Minimum Requirements
Education
Equivalent to a Bachelor's degree from an accredited college or university in computer science or a closely related field.
Experience
Four years of increasingly responsible experience in system and database administration in client-server environments. Experience with Microsoft SQL Server required.
Education
Equivalent to a bachelor's degree from an accredited college or university in computer science or a closely related field.
Experience
Six years of increasingly responsible experience in system and database administration in client-server environments. Experience with Microsoft SQL Server required.
Supplemental Information
Limited Duration Employees
Limited Duration Employees are those hired for the limited time period specified in this posting. Limited Duration employees are at-will employees and they do not have a probationary period. Limited duration employees have many of the same benefits as regular employees, although there are a few exceptions due to the limited length of employment. Non-Represented limited duration employees will receive City health plan coverage.
Selection Process
Applicants are screened based upon their relevant knowledge, abilities, skills, experience, and training. The selection process varies according to the position and can include such things as screening of supplemental questionnaires, written or skill tests, ability or fitness tests, interviews, and assessment processes. In addition, background investigations and records checks may be required. Some positions also require applicants to have a psychological evaluation and/or physical examination and a drug test prior to employment.
DUE TO THE VOLUME OF APPLICATIONS RECEIVED BY THE CITY, GENERALLY, ONLY APPLICANTS SELECTED FOR FURTHER CONSIDERATION (TESTING, INTERVIEWS) WILL BE CONTACTED.
Current information about the status of a job posting is available by going to www.eugene-or.gov/jobs and selecting ""Job Posting Status.""
The City of Eugene complies with the Americans with Disabilities Act of 1990. Any applicant with a qualified disability under the Americans with Disabilities Act may request accommodation by contacting an employment coordinator at (541) 682-5061.
In compliance with the Immigration Reform and Control Act of 1986, the City of Eugene will request all eligible candidates who accept employment with the City to provide documentation to prove they are eligible for employment in the United States.
The City of Eugene is committed to a work environment which values the cultural, educational, and life experiences of each employee. We believe that a diverse workforce enables us to deliver culturally competent service to all members of our community. As part of our commitment to diversity, the City continues to be an affirmative action/equal opportunity employer. Women, people with disabilities, and persons of color are strongly encouraged to apply.
",https://www.governmentjobs.com/jobs/2716633-0/limited-duration-senior-enterprise-data-engineer
JOB22605527715,Intern Data Analytics Data Engineer,Intern Data Analytics Data Engineer,,,"Description
Intern: Data Analytics (Data Engineer) Iowa City, IA, USA Student The University of Iowa Center for Advancement (UICA) is currently recruiting University of Iowa students for our paid summer internship program.By introducing students to the important work we do at UICA, we aim to (1) promote life-long engagement with theuniversityby fostering an appreciation of the impact of engagement and philanthropyand (2) encourageexploration of careers and volunteer roles in nonprofit and foundation settings by exposing students to the array of work available and the inner workings of a successful nonprofit. FOCUS OF THIS SPECIFIC INTERNSHIP OPENING Data Analytics (Data Engineer) The intern will assist with building systems to enable advanced analytics and data-driven business decisions. Specifically, the intern will help build data pipelines and analytics in Microsoft Azure and will explore the possibility of cloud computing and infrastructure to perform big data analytics. Software expertise or specific UI majors required: Computer Science/Business Analytics/Engineering major preferred. Expected time commitment (32-40 hours per week) and schedule requirements beyond the typical workday: At least 32 hours, can be flexible. Ways in which the intern will add value and help you achieve individual, unit, and/or organizational goals: The objective of this project is to explore Azure capability to store, retrieve useful information from unstructured data in Azure data lakes. We will be building systems to enable advanced analytics and data-driven business decisions. Usage of Cloud platforms such as Amazon Web Services and Microsoft Azure allow tremendous agility and speed to market for implementation of our systems and services which will improve the overall organizations productivity. Projects/deliverables that the intern will be expected to produce by the end of the internship: * Locate, evaluate, and acquire internal and external datasets. * Preprocess by cleaning, profiling, condensing, normalizing, and transforming raw data into usable formats for downstream analysis. * Load prepared data into temporary or operational ready data structures. * Present the impact and value added by web scraping and utilizing the publicly available data. * Potential opportunities to enhance the existing models built by the data scientists. * Demo the possibilities and proof of concepts. Intern responsibilities (incl. both challenging and routine activities) in addition to the deliverables described above: * Research new promising tools and technologies, and ways to more elegantly/ efficiently solve problems. * Clean and manipulate unstructured dataset into structured useable dataset in Azure. * Produces and maintains documentation on installations, incidents and procedures. * Build and maintain a ldquo;lessons learnedrdquo; knowledge base. Additional opportunities for learning or skill development not yet discussed: * The intern will have an opportunity to learn cloud computing, advanced data analytics techniques, visualization and Machine learning algorithms. * The intern will gain experience with a variety of platforms and software including: Azure and some cloud computing tools plus R, Python and SQL. SCHEDULE amp; COMPONENTS The internship program will run for 10 weeks, June 1 - August 7. Interns will earn $12/hour and are expected to work 32-40 hours per week, according to a schedule determined by the intern and supervisor. Outside commitments such as summer courses may be accommodated on a case-by-case basis. Five days of (unpaid) vacation are permitted during the course of the internship. In addition to project work with their supervisor/team, interns will benefit from several additional program components including extensive orientation, a day of service, opportunities to accompany UICA fundraisers on donor meetings, and educational programming related to leadership, fundraising, and careers. The internship will conclude with a reception at which interns share key accomplishments. GENERAL QUALIFICATIONS Must be a current University of Iowa student. Preference will be given to current sophomores, juniors, and first-semester seniors; May 2020 graduates may also be considered. APPLICATION INSTRUCTIONS Submit a resume, cover letter, and names and contact information of two references through the UICA careers page, www.foriowa.org/careers. If you are interested in an internship in more than one area please apply separately to each opportunity and describe your relative preferences in your cover letter. Any anticipated summer courses or outside commitments should also be described in the cover letter. APPLICATION DEADLINE: FEBRUARY 14 The University of Iowa Center for Advancement (UICA) is an independent nonprofit located on the north edge of campus, formed by joining the UI Alumni Association and the UI Foundation. Our mission is to advance the University of Iowa through engagement and philanthropy, and we are committed to engaging everyone who loves the University of Iowamdash;alumni, fans, patients, art lovers, students, parents, and friendsmdash;through programming, events, and opportunities to give back. (Learn more at www.foriowa.org.)
",https://www.internships.com/posting/bug_38695946016
JOB22615238334,Corios: Data Engineer,Corios: Data Engineer,"2+ years field experience implementing ETL/data integration in an enterprise IT environment.,Bachelor's Degree (or above) in computer science, data sciences, information sciences, software engineering, or a similar field is required,Commitment: Full time, 40-50 hours/week.,Travel: the basic expectation for travel within North America is approx. 25%.,Candidates are required to pass a background screen including a criminal history, reference check, bankruptcy and drug screen.","Carry out data acquisition activities ensuring the accuracy and integrity of data through data analysis, coding, and documentation of ETL processes,Develop, test, and implement ETL program logic using a variety of SQL dialects and the SAS programming language,Analyze and translate business requirements and functional specifications into technical specifications as part of the development process,Collaborate with IT in client organizations to design and test the data acquisition and ETL processes,Perform unit testing, system integration testing, and user acceptance testing and fix defects found by testing,Provide expert guidance and assistance to colleagues in other functional areas,Advanced SQL programming with Oracle, DB2, Teradata, and/or other RDBMS,SAS programming skills, including SAS PROC SQL, SAS Data Step, and SAS Macro programming skills,Understanding and usage of SAS Enterprise Guide and SAS Stored Processes,Ability to convey to management and the client what has been built and why,Ability to contribute in a highly collaborative team environment,Ability to complete analytical tasks independently with minimal guidance,Ability to take initiative,An intrinsic dedication to quality,Proficiency in Microsoft Office (Excel, Access),UNIX shell/Perl/Python scripting,Working knowledge of SAS BI Web Services,Experience programming with .NET or Java,Experience working with Informatica,Experience data modeling in ERwin,Experience with data in financial services, insurance, retail, and energy business,Experience with Hadoop/No-SQL data stores","
Company: Corios
Location: Portland, OR
Web: www.coriosgroup.com/
Position: Data Engineer
_Contact_:
This job is closed.
About Corios LLC
We're a Portland, Oregon-based management analytics consultancy looking to hire bright, inquisitive data engineers who enjoy solving challenging analytics problems, to fill positions in both our HQ and Durham NC offices.
At Corios, we tell the stories the numbers can't; we believe business decisions are influenced not only by the measurement of behavior, but by synthesizing data-driven insights along with our past experience in order to deliver the most relevant interpretation and client recommendations possible.
Our clients are leading financial services, energy and retailing companies in North America and around the world. Corios helps our clients make important decisions about customer acquisition, lifecycle marketing, utilization, retention, pricing, delinquency, debt recovery, capacity planning, and financial crime detection and prevention. To meet those objectives, we leverage deep expertise in predictive analytics, statistics, econometrics, forecasting, experimental design and mathematical optimization, and the business processes that leverage those analytical disciplines.
About the Data Engineer role
Data engineers at Corios are responsible for implementing data extraction, transformation, and load for clients in regulated industries such as financial services, insurance, retail, and energy sectors.
Responsibilities
Qualified candidates should possess most of the following skills, knowledge and experience:
Carry out data acquisition activities ensuring the accuracy and integrity of data through data analysis, coding, and documentation of ETL processes
Develop, test, and implement ETL program logic using a variety of SQL dialects and the SAS programming language
Analyze and translate business requirements and functional specifications into technical specifications as part of the development process
Collaborate with IT in client organizations to design and test the data acquisition and ETL processes
Perform unit testing, system integration testing, and user acceptance testing and fix defects found by testing
Provide expert guidance and assistance to colleagues in other functional areas
Skills Required
Advanced SQL programming with Oracle, DB2, Teradata, and/or other RDBMS
SAS programming skills, including SAS PROC SQL, SAS Data Step, and SAS Macro programming skills
Understanding and usage of SAS Enterprise Guide and SAS Stored Processes
Ability to convey to management and the client what has been built and why
Ability to contribute in a highly collaborative team environment
Ability to complete analytical tasks independently with minimal guidance
Ability to take initiative
An intrinsic dedication to quality
Skills Desired
Proficiency in Microsoft Office (Excel, Access)
UNIX shell/Perl/Python scripting
Working knowledge of SAS BI Web Services
Experience programming with .NET or Java
Experience working with Informatica
Experience data modeling in ERwin
Experience with data in financial services, insurance, retail, and energy business
Experience with Hadoop/No-SQL data stores
Qualifications
2+ years field experience implementing ETL/data integration in an enterprise IT environment.
Bachelor's Degree (or above) in computer science, data sciences, information sciences, software engineering, or a similar field is required
Commitment: Full time, 40-50 hours/week.
Travel: the basic expectation for travel within North America is approx. 25%.
Candidates are required to pass a background screen including a criminal history, reference check, bankruptcy and drug screen.
Corios LLC is a drug-free employer.
Compensation & benefits
Compensation will be commensurate with the candidate's experience and expected contribution to company performance.
",http://www.kdnuggets.com/jobs/16/04-18-corios-data-engineer.html
JOB25654744358,"Director, Data Engineer II","Director, Data Engineer II","Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.,Bachelor’s Degree in STEM related field or equivalent,Eight years of related experience,The ability to deliver work at a steady, predictable pace to achieve commitments, deliver complete solutions but release them in small batches, and identify and negotiate important tradeoffs.,Demonstrated track record of domain expertise including understanding technical concepts necessary and industry trends, and possess in-depth knowledge of immediate systems worked on and some knowledge of adjacent systems.,Strong problem solver who ensures systems are built with longevity and creates innovate ways to resolve issues.,Strong written and verbal communication skills with the ability to work collaborate well with team members and business partners.","Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions.,Design complex data solutions,Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes.,Incorporate core data management competencies including data governance, data security and data quality.,Collaborate within and across teams to support delivery and educate end users on complex data products/analytic environment.,Perform data and system analysis, assessment and resolution for complex defects and incidents and correct as appropriate.","
The Travelers Companies, Inc.
Director, Data Engineer II
Company Summary
Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.
Target Openings
1
Job Description Summary
Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape. In addition to your strong analytical mind, you will bring your inquisitive attitude and ability to translate stories found in data by leveraging a variety of data programming techniques. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights.
Primary Job Duties & Responsibilities
Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions.
Design complex data solutions
Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes.
Incorporate core data management competencies including data governance, data security and data quality.
Collaborate within and across teams to support delivery and educate end users on complex data products/analytic environment.
Perform data and system analysis, assessment and resolution for complex defects and incidents and correct as appropriate.
Test data movement, transformation code, and data components.
Minimum Qualifications
Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
Four years of data engineering or equivalent experience.
Education, Work Experience, & Knowledge
Bachelor’s Degree in STEM related field or equivalent
Eight years of related experience
Highly proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and a full understanding of modern software engineering practices.
Job Specific Technical Skills & Competencies
The ability to deliver work at a steady, predictable pace to achieve commitments, deliver complete solutions but release them in small batches, and identify and negotiate important tradeoffs.
Demonstrated track record of domain expertise including understanding technical concepts necessary and industry trends, and possess in-depth knowledge of immediate systems worked on and some knowledge of adjacent systems.
Strong problem solver who ensures systems are built with longevity and creates innovate ways to resolve issues.
Strong written and verbal communication skills with the ability to work collaborate well with team members and business partners.
Ability to lead team members and help create a safe environment for others to learn and grow as engineers. and a proven track record of self-motivation in identifying opportunities and tracking team efforts.
Employment Practices
Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences.
If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.
Travelers reserves the right to fill this position at a level above or below the level included in this posting.
To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.
More From The Travelers Companies, Inc.
Related Job Listings
",https://www.insurancejournal.com/jobs/636747-director-data-engineer-ii
JOB26225280944,"Consultant - Data Engineer SSA8, SC8","Consultant - Data Engineer SSA8, SC8","Independent worker able to manage project timelines and priorities;,Advanced analytical thinking and problem-solving skills;,Strong communication skills with the ability to compile and present information;,Good interpersonal skills and demonstrated ability to work within a team environment,Experience working in an international organisation or multicultural environment will be an added advantage.,Understanding of WFP’s Core mission and values.,Language skills: Fluent English (spoken and written).","Develop data warehouse/data lake (following defined architecture and only as applicable for M&E data) for ease of use, organization, accessibility, security, compliance, performance, scalability, monitoring, and availability;,Under M&E guidance, clean, transform, aggregate and integrate M&E data into data warehouse;,Develop ETL system and data pipelines (following defined standards) that move data from a variety of sources into warehouse, monitor data quality, check for errors and conform data to standards; use the WFP corporate ETL/data-lineage tools;,Build Database objects (tables, views, stored procedures, functions, etc.) and data services that provide data in format most useful for analysis;,Maintain data pipelines, architecture and schemas to maximize the (re-)usability, accuracy, robustness, performance, and scalability;,Collaborate with KECO and IT HQ teams to ensure standards are maintained,Document technical specifications and work in appropriate tools.,Build the Data Lake for M&E Data based on the RMT defined Architecture and using the WFP Corporate ETL/data lineage tools.,Migrate data from old M&E database to Data Lake.,Migrate data from ONA (online M to Data Lake,Develop API (where required) to facilitate an easier process to maintain.,Manage project deliverables and timeline,B.S. in CS, Engineering or other relevant field with additional years of related work experience or trainings/course. Advanced university degree in Computer Science, Engineering,2+ years of ETL/data engineering work (e.g. ETL (Extract Transform Load (ETL), data lakes, data marts, data warehousing),4+ years of professional software engineering,Knowledge and experience working with Hadoop stack (Horton Works),Experience working with/constructing Relational and noSQL/MongoDB databases,Experience working with engineers and business analysts to solve data needs,Experience working with/building a data pipeline,Experience building flexible data APIs,Experience working with Tableau,Ability to perform testing and regression testing and ensure high quality product work (e.g. ETL/ELT to the Data Lake, using the Data Lake for data analysis),Skilled at documenting data warehouses and hierarchies, process flows,Experience in metadata management and data quality processes and tools,Knowledge of Hadoop tools (e.g. Hive, Impala, Pig, Sqoop, Hue, Kafka, etc.","
Job Closed!
Company:
World Food Programme
Category:
Open
Job Type:
Contract
Salary:
Ksh. Not mentioned
Location:
Nairobi
Job details
JOB PURPOSE
This position will report to the Business Transformation Officer in Nairobi.
KEY ACCOUNTABILITIES (not all-inclusive)
Main Activities:
Develop data warehouse/data lake (following defined architecture and only as applicable for M&E data) for ease of use, organization, accessibility, security, compliance, performance, scalability, monitoring, and availability;
Under M&E guidance, clean, transform, aggregate and integrate M&E data into data warehouse;
Develop ETL system and data pipelines (following defined standards) that move data from a variety of sources into warehouse, monitor data quality, check for errors and conform data to standards; use the WFP corporate ETL/data-lineage tools;
Build Database objects (tables, views, stored procedures, functions, etc.) and data services that provide data in format most useful for analysis;
Maintain data pipelines, architecture and schemas to maximize the (re-)usability, accuracy, robustness, performance, and scalability;
Collaborate with KECO and IT HQ teams to ensure standards are maintained
Document technical specifications and work in appropriate tools.
Main Responsibilities:
Build the Data Lake for M&E Data based on the RMT defined Architecture and using the WFP Corporate ETL/data lineage tools.
Migrate data from old M&E database to Data Lake.
Migrate data from ONA (online M to Data Lake
Develop API (where required) to facilitate an easier process to maintain.
Manage project deliverables and timeline
STANDARD MINIMUM QUALIFICATIONS
Education: Advanced university degree in Computer Science, engineering or other relevant field, or First University degree with additional years of related work experience or trainings/course.
B.S. in CS, Engineering or other relevant field with additional years of related work experience or trainings/course. Advanced university degree in Computer Science, Engineering
2+ years of ETL/data engineering work (e.g. ETL (Extract Transform Load (ETL), data lakes, data marts, data warehousing)
4+ years of professional software engineering
Knowledge and experience working with Hadoop stack (Horton Works)
Experience working with/constructing Relational and noSQL/MongoDB databases
Experience working with engineers and business analysts to solve data needs
Experience working with/building a data pipeline
Experience building flexible data APIs
Experience working with Tableau
Desirable:
Ability to perform testing and regression testing and ensure high quality product work (e.g. ETL/ELT to the Data Lake, using the Data Lake for data analysis)
Skilled at documenting data warehouses and hierarchies, process flows
Experience in metadata management and data quality processes and tools
Knowledge of Hadoop tools (e.g. Hive, Impala, Pig, Sqoop, Hue, Kafka, etc.
FUNCTIONAL CAPABILITIES
Capability Name
Description of the behaviour expected for the proficiency level
Governance, Strategy and Architecture
Shares knowledge of IT governance process and system architecture development with team and analyses current designs for improvements and enhancements while ensuring compliance with legislation and specifies any required changes.
Change Implementation, Project Management, Planning and Optimization
Utilises working knowledge of project and change management approaches to collect and analyse relevant data from multiple stakeholders to develop evidence-based business case for change.
Technical Expertise
Continuously updates one’s own knowledge about new technologies and product modifications; Is sought out for advice/expertise and recognized internally as an important technical reference.
Requirement Definition & Management
Exhibits thorough understanding of business areas and processes to define, prioritize and customize IT infrastructure solutions to requirements.
Strategic Account Management
Facilitates open communication and discussion with clients to assess and promote understanding of need for future changes in services, products and systems, resulting in overall client satisfaction.
Business Analysis
Has in-depth understanding of operational requirements, business issues and opportunities to conduct stakeholder and benefit analysis of options to identify effective and optimal automated/ non-automated solutions that meet business needs
DESIRED EXPERIENCES FOR ENTRY INTO THE ROLE
Skills and Competencies:
Independent worker able to manage project timelines and priorities;
Advanced analytical thinking and problem-solving skills;
Strong communication skills with the ability to compile and present information;
Good interpersonal skills and demonstrated ability to work within a team environment
Experience working in an international organisation or multicultural environment will be an added advantage.
Understanding of WFP’s Core mission and values.
Language skills: Fluent English (spoken and written).
For more information, visit; https://career5.successfactors.eu/career?career_ns=job_listing&company=C0000168410P&navBarLevel=JOB_SEARCH&rcm_site_locale=en_GB&career_job_req_id=78462
Open World Food Programme 1 year ago
",https://www.standardmedia.co.ke/jobs/details/2582/consultant-data-engineer-ssa8-sc8
JOB27137201438,Data Engineer I,Data Engineer I,"Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.,Four years of data engineering or equivalent experience.,Bachelor’s Degree in STEM related field or equivalent,Good Analytical skills,Good experience with SQL,Proven experience as a strong collaborator.,Excellent organization skills and experience managing timelines.,Six years of related experience,Proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and an understanding of software engineering practices.,The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions.,Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on.,Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems.,Strong verbal and written communication skills with the ability to interact with team members and business partners.,Leadership - Intermediate leadership skills with a proven track record of self-motivation in identifying personal growth opportunities.","Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.,Design data solutions.,Analyze sources to determine value and recommend data to include in analytical processes.,Incorporate core data management competencies including data governance, data security and data quality.,Collaborate within and across teams to support delivery and educate end users on data products/analytic environment.,Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate.,Test data movement, transformation code, and data components.","
The Travelers Companies, Inc.
Data Engineer I
Company Summary
Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.
Target Openings
1
Job Description Summary
Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape. In addition to your strong analytical mind, you will bring your inquisitive attitude and ability to translate the stories found in data. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights.
This position may be based 100% remotely or in one of our offices.
Primary Job Duties & Responsibilities
Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.
Design data solutions.
Analyze sources to determine value and recommend data to include in analytical processes.
Incorporate core data management competencies including data governance, data security and data quality.
Collaborate within and across teams to support delivery and educate end users on data products/analytic environment.
Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate.
Test data movement, transformation code, and data components.
Minimum Qualifications
Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
Four years of data engineering or equivalent experience.
Education, Work Experience, & Knowledge
Bachelor’s Degree in STEM related field or equivalent
Good Analytical skills
Good experience with SQL
Proven experience as a strong collaborator.
Excellent organization skills and experience managing timelines.
Six years of related experience
Proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and an understanding of software engineering practices.
Job Specific Technical Skills & Competencies
The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions.
Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on.
Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems.
Strong verbal and written communication skills with the ability to interact with team members and business partners.
Leadership - Intermediate leadership skills with a proven track record of self-motivation in identifying personal growth opportunities.
Employment Practices
Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences.
If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.
Travelers reserves the right to fill this position at a level above or below the level included in this posting.
To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.
More From The Travelers Companies, Inc.
Related Job Listings
",https://www.insurancejournal.com/jobs/634919-data-engineer-i
JOB29386652060,Data Engineer,Data Engineer,"Bachelor's degree in Computer Science, Software Engineering, MIS or equivalent combination of education and experience,Development experience building ETL graphs using the Ab Initio GDE, EME and Co-Operating system,Strong SQL development skills,Development experience with at least two different programming languages (Python, Java, Scala, etc.),Development experience with Unix tools and shell scripts,Development experience with at least two different database platforms (Teradata, Oracle, MySQL, MS SQL, etc.),Minimum of 4-5 years experience designing, developing, and testing software aligned with defined requirements,Experience tuning SQL queries to ensure performance and reliability,Competitive salary with performance-based bonus opportunities,Single and Family Health Insurance plans, including Dental coverage,Short-Term and Long-Term disability,Matching 401(k),Competitive Paid Time Off,Training and Certification opportunities eligible for expense reimbursement,Team building and social activities","Design, develop, document, and test advanced data systems that bring together data from disparate sources, making it available to data scientists, analysts, and other users using scripting and/or programming languages (Python, Java, Scala, etc),Evaluate structured and unstructured datasets utilizing statistics, data mining, and predictive analytics to gain additional business insights,Design, develop, and implement data processing pipelines at scale,Present programming documentation and design to team members and convey complex information in a clear and concise manner.,Extract data from multiple sources, integrate disparate data into a common data model, and integrate data into a target database, application, or file using efficient programming processes.,Write and refine code to ensure performance and reliability of data extraction and processing.,Communicate with all levels of stakeholders as appropriate, including executives, data modelers, application developers, business users, and customers,Participate in requirements gathering sessions with business and technical staff to distill technical requirements from business requests.,Partner with clients to fully understand business philosophy and IT Strategy; recommend process improvements to increase efficiency and reliability in ETL development.,Collaborate with Quality Assurance resources to debug code and ensure the timely delivery of products.","
Company Description
CapTech is a team of master builders, creators, and problem solvers who help clients grow efficient, successful businesses. We unite diverse skills and perspectives to transform how data, systems, and ingenuity enable each client to advance what’s possible in a changing world.
As perceptive partners, our U.S-based consultants find inspiration in the unknown and enjoy getting our hands dirty solving our clients’ myriad of challenges. Across industries and business goals, we fuse technical depth and analytical prowess with creative savvy to move clients forward. This drive helps each organization use technology, management, and insight to turn ideas into action. Together, we create outcomes that exceed the expected — which is one of the reasons we’ve been on the Inc. 500/5000 list for over a decade.
Job Description
The Data Engineer, Analytics role falls into the Data Management & Business Intelligence practice area at CapTech, through which our consultants provide a broad spectrum of services to help our clients define and implement a strategy to deliver lasting and mission-critical information capabilities. Our Data Integration consultants bridge the gap between the business and IT side of companies. By partnering with clients to fully understand both their business philosophy and IT strategy, CapTech consultants maintain the vision that data integration should be built to help the organization make better decisions by providing the right data at the right time.
Specific responsibilities for the Data Engineer, Analytics position include:
Design, develop, document, and test advanced data systems that bring together data from disparate sources, making it available to data scientists, analysts, and other users using scripting and/or programming languages (Python, Java, Scala, etc)
Evaluate structured and unstructured datasets utilizing statistics, data mining, and predictive analytics to gain additional business insights
Design, develop, and implement data processing pipelines at scale
Present programming documentation and design to team members and convey complex information in a clear and concise manner.
Extract data from multiple sources, integrate disparate data into a common data model, and integrate data into a target database, application, or file using efficient programming processes.
Write and refine code to ensure performance and reliability of data extraction and processing.
Communicate with all levels of stakeholders as appropriate, including executives, data modelers, application developers, business users, and customers
Participate in requirements gathering sessions with business and technical staff to distill technical requirements from business requests.
Partner with clients to fully understand business philosophy and IT Strategy; recommend process improvements to increase efficiency and reliability in ETL development.
Collaborate with Quality Assurance resources to debug code and ensure the timely delivery of products.
Some of our technologies might include: Python, Cassandra, Spark, Java, Scala, Informatica, SQL Server, SSIS, Oracle, Kafka.
Qualifications
Specific qualifications for the Data Engineer, Analytics position include:
Bachelor's degree in Computer Science, Software Engineering, MIS or equivalent combination of education and experience
Development experience building ETL graphs using the Ab Initio GDE, EME and Co-Operating system
Strong SQL development skills
Development experience with at least two different programming languages (Python, Java, Scala, etc.)
Development experience with Unix tools and shell scripts
Development experience with at least two different database platforms (Teradata, Oracle, MySQL, MS SQL, etc.)
Minimum of 4-5 years experience designing, developing, and testing software aligned with defined requirements
Experience tuning SQL queries to ensure performance and reliability
Software engineering best-practices, including version control (Git, TFS, JIRA, etc.) and test-driven development
Additional Information
We offer challenging and impactful jobs with professional career paths. All CapTechers can keep their hands-on technology no matter what position they hold. Our employees find their work exciting and rewarding in a culture filled with opportunities to have fun along the way.
At CapTech we offer a competitive and comprehensive benefits package including, but not limited to:
Competitive salary with performance-based bonus opportunities
Single and Family Health Insurance plans, including Dental coverage
Short-Term and Long-Term disability
Matching 401(k)
Competitive Paid Time Off
Training and Certification opportunities eligible for expense reimbursement
Team building and social activities
Mentor program to help you develop your career
CapTech supports Equal Pay for all. In addition, in the State of Colorado, we are committed to Equal Pay for ALL in accordance with the Colorado Equal Pay for Equal Work Act. The base pay range for this role is: $75,000 - $160,000.
CapTech is an equal opportunity employer committed to fostering a culture of equality, inclusion and fairness — each foundational to our core values. We strive to create a diverse environment where each employee is encouraged to bring their unique ideas, backgrounds and experiences to the workplace.
Candidates must be eligible to work in the U.S. for any employer directly (we are not open to contract or “corp to corp” agreements). At this time, CapTech cannot transfer nor sponsor a work visa for this position. Applicants must be authorized to work directly for any employer in the United States without visa sponsorship.
CapTech is a Drug-Free work place.
Candidates must have the ability to work at CapTech’s client locations.
All positions include the possibility of travel.
CapTech has not contracted/does not contract with any outside vendors in its recruitment process. If you are interested in this position, please apply to CapTech directly.
#LI-AB1
",https://www.themuse.com/jobs/captech/data-engineer-5cc664
JOB29510020215,"Data Engineer, Insight Operations","Data Engineer, Insight Operations",,"Analytic & systematic.,Service minded problem solver,You have a bachelor/master in IT/Computer Science/Mathematics/Statistics,Working experience as a Data Engineer/ETL developer for 3+ years,You have developed solid SQL and database skills,Good understanding of DWH development concepts and data processing principles,Experience with visual ETL tools like Informatica PowerCenter, Pentaho or similar,Experience with programming/scripting and/or interest to learn python/pyspark","
Are you our new Data Engineer within Insight Operations? I am Maria Palmer and I lead the Insight Operations team at Telia Norway. Right now, I am looking for a person with solid data processing skills to join our growing team in Oslo. We are diverse and passionate contributors with wide range of skills and lots of passion to learn. I am eager to meet you who can contribute to my team!
Your next challenge?
As a member of Insight Operations you´ll be in charge of keeping our DWH and ETL jobs up and running, ensure stability of our data platform, monitor and maintain scheduled jobs and processes and resolve ETL related incidents and problems. You will also be responsible for maintaining our data and coding quality standards and building trust between IT Analytics department and its stakeholders, maintaining both quality and speed of our deliveries.
As a Telian you will also be offered to join in on our trainings for personal development and equip you with the tools you need to achieve your best performance. We have plenty of platforms where we meet up to share knowledge and network. We invite and promote each others successes and learnings, and have a strong and open culture for feedback.
We are looking forward moving to Økern Portal - the smartest office in the Nordics - in January 2021.
Who are you?
Like every other technology company, we have a fast-paced working environment and we find our new colleague adaptive and forward thinking next to being a positive and friendly colleague. You share our core values dare, care & simplify and live them by caring for your team, customers and society, having a curious approach to your tasks and challenge our way of working. You are always interested with learning new skills and technologies!
Your personality:
Analytic & systematic.
Service minded problem solver
Excellent communication skills
Your Experience:
You have a bachelor/master in IT/Computer Science/Mathematics/Statistics
Working experience as a Data Engineer/ETL developer for 3+ years
You have developed solid SQL and database skills
Good understanding of DWH development concepts and data processing principles
Experience with visual ETL tools like Informatica PowerCenter, Pentaho or similar
Experience with programming/scripting and/or interest to learn python/pyspark
You´ve heard of Agile, DevOps/DataOps and CI/CD (or you´ve spent time googling this)
Can't tick off all the boxes but still believe you can be our new colleague? Go ahead and apply anyway and let us get to know you better in the application letter. I look forward to read your application! Do you need to know more, call me at +47 96 62 69 78 or connect with me on LinkedIn. Selection is ongoing, so do not hesitate to get in touch.
Welcome to Telia – Home to your next big opportunity!
",https://www.finn.no/job/fulltime/ad.html?finnkode=170281419
JOB29844000071,Data engineer,Data engineer,,"An analytical, quantitative or IT orientated degree at BSc or MSc level [HBO/WO],3+ years of work experience in commercial environment,Strong analytic SQL skills,Java backend experience,Knowledge of Database architectures,Good social and communication skills,Experience with big data solutions,Knowledge of cloud solutions,Common with data visualization tools,Flexible work mentality,Familiar with Oracle, JSON/REST API and/or Python etc.,Competitive compensation package,Annual company performance-based bonuses,A non-hierarchical workplace,Young and highly motivated teammates,High responsibility","
Are you the Data Engineer that will shape the energy transition? Do you want to work in a dynamic and continuously evolving environment? Are you the Data Engineer that builds the foundations of the technology for the traders of Northpool?
The key to success of a winning trade can be found in the fluid processing of the latest relevant data. As Data Engineer your first focus will be designing, building and operating our database systems. You will be responsible for expending and optimizing our data and data pipeline architecture as well as optimizing the data flow and data collection. The design, architecture and configuration needs to meet the high performance requirements of the business.
You will work closely with the data analysts to translate questions from the traders into visualization tools. Together with the software engineers you’ll streamline data flows and develop trading algorithms that beat the markets.
As Data Engineer you have extensive experience in SQL and database architectures. You have experience with Java and are familiar with JSON/REST API’s. Knowledge of big data and cloud solutions as well as visualization possibilities is nice to have as it will enable you in building a data architecture foundation ready for the future.
Functie-eisen
We ask:
An analytical, quantitative or IT orientated degree at BSc or MSc level [HBO/WO]
3+ years of work experience in commercial environment
Strong analytic SQL skills
Java backend experience
Knowledge of Database architectures
Good social and communication skills
Natural drive to deliver solutions
We like:
Experience with big data solutions
Knowledge of cloud solutions
Common with data visualization tools
Flexible work mentality
Familiar with Oracle, JSON/REST API and/or Python etc.
We offer:
Competitive compensation package
Annual company performance-based bonuses
A non-hierarchical workplace
Young and highly motivated teammates
High responsibility
An office that’s fun to work in
Bedrijfsprofiel
Northpool is a commodity trading company with a strong focus on energy products. Northpool’s core business is trading European power and gas combined with expertise and knowledge of a broader range of energy products such as oil, coal and emissions as all energy related products.
Do you like to see the trading in real practice or directly want to apply for a job? Submit your resume, motivation and grade list or contact us at +31(0)88 2400 300. We will respond to your application as soon as possible.
Vacature kenmerken
",https://tweakers.net/carriere/it-banen/154/data-engineer-leiden-northpool
JOB31731979582,Senior Big Data Engineer,Senior Big Data Engineer,"5-10 years of technologies experience (Tech Lead experience a plus),Bachelor in Computer Science or related field, or equivalent experience,3-5 years experience with Spark, Scala, Java (Python is a plus),3-5 years experience working with Hadoop, SQL, no-SQL platforms (MongoDB a plus),3-5 years experience with various data types (AVRO, JSON, PARQUET a plus),Experience with development, management, and manipulation of large, complex datasets,Demonstrated knowledge of data management competencies and implementation","Executes complex functional work tracks for the team.,Partners with ATSV teams on Big Data efforts.,Partners closely with team members on Big Data solutions for our data science community and analytic users.,Leverages and uses Big Data best practices / lessons learned to develop technical solutions used for descriptive analytics, ETL, predictive modeling, and prescriptive “real time decisions” analytics,Influence within the team on the effectiveness of Big Data systems to solve their business problems.,Participates in the development of complex technical solutions using Big Data techniques in data & analytics processes.,Supports Innovation; regularly provides new ideas to help people, process, and technology that interact with analytic ecosystem.,Participates in the development of complex prototypes and department applications that integrate Big Data and advanced analytics to make business decisions.,Uses new areas of Big Data technologies, (ingestion, processing, distribution) and research delivery methods that can solve business problems.,Understands the Big Data related problems and requirements to identify the correct technical approach.,Works with key team members to ensure efforts within owned tracks of work will meet their needs.,Drives multiple tracks of work within the research group.,Identifies and develops Big Data sources & techniques to solve business problems.,Co-mingles data sources to lead work on data and problems across departments to drive improved business & technical results through designing, building, and partnering to implement models.,Manages various Big Data analytic tool development projects with midsize teams.,Executes on Big Data requests to improve the accuracy, quality, completeness, speed of data, and decisions made from Big Data analysis.,Uses, learns, teaches, and supports a wide variety of Big Data and Data Science tools to achieve results (i.e. Hadoop, SQL, no-SQL [MongoDB] and others).,Uses, learns, teaches, and supports a wide variety of programming languages on Big Data and Data Science work (i.e. Java, Python, and Perl).","
Where good people build rewarding careers.
Think that working in the insurance field can’t be exciting, rewarding and challenging? Think again. You’ll help us reinvent protection and retirement to improve customers’ lives. We’ll help you make an impact with our training and mentoring offerings. Here, you’ll have the opportunity to expand and apply your skills in ways you never thought possible. And you’ll have fun doing it. Join a company of individuals with hopes, plans and passions, all using and developing our talents for good, at work and in life.
Job Description
The Big Data Engineer - is accountable for leading a technical team of developers on the Master Data Management (MDM) team. This is both a hands-on devleopment and a tech leadership role charged with building a data platform and services to provide a single-source of truth for policy and quotes data. Engage with strategic partners to optimize the data quality function and identify strategic capabilities to keep up with data and insurance industry trends.
This role is responsible for driving multiple complex tracks of work to deliver Big Data solutions enabling advanced data science and analytics. This includes working with the team on new Big Data systems for analyzing data; the coding & development of advanced analytics solutions to make/optimize business decisions and processes; integrating new tools to improve descriptive, predictive, and prescriptive analytics; and discovery of new technical challenges that can be solved with existing and emerging Big Data hardware and software solutions.
This role contributes to the structured and unstructured Big Data / Data Science tools of Allstate from traditional to emerging analytics technologies and methods. The role is responsible for assisting in the selection and development of other team members.
Job Description
Executes complex functional work tracks for the team.
Partners with ATSV teams on Big Data efforts.
Partners closely with team members on Big Data solutions for our data science community and analytic users.
Leverages and uses Big Data best practices / lessons learned to develop technical solutions used for descriptive analytics, ETL, predictive modeling, and prescriptive “real time decisions” analytics
Influence within the team on the effectiveness of Big Data systems to solve their business problems.
Participates in the development of complex technical solutions using Big Data techniques in data & analytics processes.
Supports Innovation; regularly provides new ideas to help people, process, and technology that interact with analytic ecosystem.
Participates in the development of complex prototypes and department applications that integrate Big Data and advanced analytics to make business decisions.
Uses new areas of Big Data technologies, (ingestion, processing, distribution) and research delivery methods that can solve business problems.
Understands the Big Data related problems and requirements to identify the correct technical approach.
Works with key team members to ensure efforts within owned tracks of work will meet their needs.
Drives multiple tracks of work within the research group.
Identifies and develops Big Data sources & techniques to solve business problems.
Co-mingles data sources to lead work on data and problems across departments to drive improved business & technical results through designing, building, and partnering to implement models.
Manages various Big Data analytic tool development projects with midsize teams.
Executes on Big Data requests to improve the accuracy, quality, completeness, speed of data, and decisions made from Big Data analysis.
Uses, learns, teaches, and supports a wide variety of Big Data and Data Science tools to achieve results (i.e. Hadoop, SQL, no-SQL [MongoDB] and others).
Uses, learns, teaches, and supports a wide variety of programming languages on Big Data and Data Science work (i.e. Java, Python, and Perl).
Trains more junior engineers.
Job Qualifications
5-10 years of technologies experience (Tech Lead experience a plus)
Bachelor in Computer Science or related field, or equivalent experience
3-5 years experience with Spark, Scala, Java (Python is a plus)
3-5 years experience working with Hadoop, SQL, no-SQL platforms (MongoDB a plus)
3-5 years experience with various data types (AVRO, JSON, PARQUET a plus)
Experience with development, management, and manipulation of large, complex datasets
Demonstrated knowledge of data management competencies and implementation
Ability to operate and learn in a rapidly changing, high-visibility environment
The candidate(s) offered this position will be required to submit to a background investigation, which includes a drug screen.
Good Work. Good Life. Good Hands®.
As a Fortune 100 company and industry leader, we provide a competitive salary – but that’s just the beginning. Our Total Rewards package also offers benefits like tuition assistance, medical and dental insurance, as well as a robust pension and 401(k). Plus, you’ll have access to a wide variety of programs to help you balance your work and personal life -- including a generous paid time off policy.
Learn more about life at Allstate. Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video.
Allstate generally does not sponsor individuals for employment-based visas for this position.
Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.
For jobs in San Francisco, please click “here” for information regarding the San Francisco Fair Chance Ordinance.
For jobs in Los Angeles, please click “here” for information regarding the Los Angeles Fair Chance Initiative for Hiring Ordinance.
To view the “EEO is the Law” poster click “here”. This poster provides information concerning the laws and procedures for filing complaints of violations of the laws with the Office of Federal Contract Compliance Programs
To view the FMLA poster, click “here”. This poster summarizing the major provisions of the Family and Medical Leave Act (FMLA) and telling employees how to file a complaint.
It is the Company’s policy to employ the best qualified individuals available for all jobs. Therefore, any discriminatory action taken on account of an employee’s ancestry, age, color, disability, genetic information, gender, gender identity, gender expression, sexual and reproductive health decision, marital status, medical condition, military or veteran status, national origin, race (include traits historically associated with race, including, but not limited to, hair texture and protective hairstyles), religion (including religious dress), sex, or sexual orientation that adversely affects an employee's terms or conditions of employment is prohibited. This policy applies to all aspects of the employment relationship, including, but not limited to, hiring, training, salary administration, promotion, job assignment, benefits, discipline, and separation of employment.
",https://www.insurancejournal.com/jobs/583543-senior-big-data-engineer
JOB33181012727,Data Engineer - Big Data (JVM/Hadoop),Data Engineer - Big Data (JVM/Hadoop),,,"
Minimum Required Skills:
JVM Languages, Database Internals, Data Structures, Algorithms, Indexing/Hash Tables/Aggregation, SQL Databases, NO SQL, Hadoop ecosystems
We are a growth mode startup backed by Andreessen Horowitz and several top venture capitalists. We focus on big data products and solutions for our clients enabling them to more efficiently discover, consume and analyze data at a mass scale through interactive charting and data visualization. Our entire company is getting behind data as a core asset and the industry is in a battle for the data that will propel insights of the future. Due to this competitive landscapes and the challenges to come. We are looking for a motivated, team player that is interested in getting on-board with a mission driven team looking to take a data science approach to engineering. If this sounds like position you've been waiting for, we're excited to have found you and look forward to hearing from you!
What You Will Be Doing
- You'll be responsible for the infrastructure that provides insighst from raw data and consumes diverse sources of data without missing a beat.
- Learn new technologies. You don't believe in one-size-fits-all solutions. You should be able to adapt easily to meet the changing needs of our massive growth and rapidly evolving business environment.
- JVM development
- Optimize data structures and algorithms
- Work within the Hadoop ecosystem
- Change the way people use their data and make your impact felt on a small team
- Proof-of-concepts and Rapid Prototyping
What You Need for this Position
- Bachelor's in Computer Science or related discipline
- 3+ years of hands on data engineering experiencein a professional setting
- Experience with at least one of the JVM Languages (Java, Scala, Closure)
- C++
- Database Internals (query processing and general queries)
- Data Structures and Algorithms (Indexing/Hash Tables/Aggregation)
- SQL Databases
- Hadoop ecosystem (Spark, Hadoop, MapReduce, HBase, Hive, Pig, Flume, etc.)
Bonus Points:
- NoSQL
- Link to your GitHub page
- Publications and research in databases, information integration or data processing at scale
- Open source contributions to data oriented software projects and components
- Experience with streaming data
What's In It for You
- Base salary between 130k-150k
- Medical: 100% covered
- Dental: 100% covered
- Vision: 100% covered
- StockSo, if you are a Senior Software Engineer with experience, please apply today!
Applicants must be authorized to work in the U.S.Please apply directly to by clicking 'Click Here to Apply' with your Word resume!
Looking forward to receiving your resume and going over the position in more detail with you.
- Not a fit for this position? Click the link at the bottom of this email to search all of our open positions.
Looking forward to receiving your resume!
CyberCoders
CyberCoders, Inc is proud to be an Equal Opportunity Employer
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.
Your Right to Work - In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.
Copyright © 1999 - 2017 . CyberCoders, Inc. All rights reserved.
",https://www.google.com/url?rct=j&sa=t&url=https://www.dice.com/jobs/detail/Data-Engineer-%2526%252345-Big-Data-%2528JVM%2526%252347Hadoop%2529-CyberCoders-Menlo-Park-CA-94025/cybercod/AC-Data-Menlo1&ct=ga&cd=CAIyGTk5YWFjYjJkNzIyNDM5Njk6Y2E6ZW46Q0E&usg=AFQjCNFD071uo8XGgN_9YITGnIIiY-zsDQ
JOB34374781632,Data Engineer for Data Warehouse,Data Engineer for Data Warehouse,Be a fan of working in agile scrum environments,"You will be responsible for maintaining and evolving our existing data warehouse, develop data models and ETL and ensuring data consistency;,You will be working closely with the Business Intelligence and Big Data teams in the delivery of application and expanding our platform (using Big Data technology) to support the data requirements of the different departments and brands;,You will be involved, in data Integration which includes internal data, 3rd parties, and migrations;,Involved with Data Modelling, OLAP Cube Development and verifying data consistency and accuracy;,Keeping up to date on research and development of new technologies and techniques to enhance our data platform;,Collaborating with the Data DevOps, Business Intelligence, Big Data and Analytics teams.,You are an enthusiastic developer with experience in Data Warehousing and Business Intelligence;,You will ideally have a Bachelor or Master's degree in a relevant technical area;,Possess excellent English communication skills and enjoy working in a large team;,Think of SQL while having breakfast;,Have an advanced understanding of data warehouse and ETL concepts;,Have strong knowledge of data modelling and database architecture;,Have strong analytical and problem-solving skills;,Have the ability to effectively prioritize and handle multiple tasks and projects;,Have development experience in a Microsoft environment (SQL Server, SSIS, SSAS);,Have experience with data Integration tools (preferably SSIS), Data Warehouse modelling (Kimball);,Be familiar with at least one Object Oriented Language (.NET, Java, Python);,Be experienced and knowledgeable in core database development tuning techniques;,Be experienced with or have an understanding of big data technologies (Hadoop, HBase, Hive, Pig etc.);","
A leading iGaming client is looking for an individual to join their Data Warehouse team that wants to succeed in a high-performance environment.
RESPONSIBILITIES
Includes but not limited to:
You will be responsible for maintaining and evolving our existing data warehouse, develop data models and ETL and ensuring data consistency;
You will be working closely with the Business Intelligence and Big Data teams in the delivery of application and expanding our platform (using Big Data technology) to support the data requirements of the different departments and brands;
You will be involved, in data Integration which includes internal data, 3rd parties, and migrations;
Involved with Data Modelling, OLAP Cube Development and verifying data consistency and accuracy;
Keeping up to date on research and development of new technologies and techniques to enhance our data platform;
Collaborating with the Data DevOps, Business Intelligence, Big Data and Analytics teams.
REQUIREMENTS
You are an enthusiastic developer with experience in Data Warehousing and Business Intelligence;
You will ideally have a Bachelor or Master's degree in a relevant technical area;
Possess excellent English communication skills and enjoy working in a large team;
Moreover, you would:
Think of SQL while having breakfast;
Have an advanced understanding of data warehouse and ETL concepts;
Have strong knowledge of data modelling and database architecture;
Have strong analytical and problem-solving skills;
Have the ability to effectively prioritize and handle multiple tasks and projects;
Have development experience in a Microsoft environment (SQL Server, SSIS, SSAS);
Have experience with data Integration tools (preferably SSIS), Data Warehouse modelling (Kimball);
Be familiar with at least one Object Oriented Language (.NET, Java, Python);
Be experienced and knowledgeable in core database development tuning techniques;
Be experienced with or have an understanding of big data technologies (Hadoop, HBase, Hive, Pig etc.);
Be a fan of working in agile scrum environments
",https://www.timesofmalta.com/careers/view/19700101-castille-data-engineer-for-data-warehouse
JOB34506367838,77 Data Engineer Jobs,77 Data Engineer Jobs,"BS/MS degree with 6+ experience or Ph.D. degree with 3+ years of experience in a drug development setting.,4+ years of biologics downstream process development experience using a FPLC system (e.g. AKTA),Expertise in method/protocol development and scale-up for biologics purification, including, but not limited to affinity, cation exchange (CEX), anion exchange (AEX), viral filtration, and tangential flow filtration (TFF) is required.,Familiarity with HPLC based analytical methods (SEC, RP-HPLC, ion-exchange, hydrophobic interaction chromatography, etc),Prior experience with IND regulatory requirements, GMP environments, and quality documentation is highly desired.,Demonstrated ability to work independently with minimal supervision.,Familiarity with Design of Experiment (DOE) and comfortable working with analytical tools to create high-quality unbiased analyses.,Prior experience with a successful technology and process transfers to third party vendors (CRO/CDMO/CMO) is highly desired.,Experience mentoring, coaching, and training junior staff members are preferred.,Excellent interpersonal skills, including clear, succinct, and timely communication and proven ability to foster strong relationships with other team members and stakeholders.,Highly self-motivated and detail-oriented, with proven ability to work in a dynamic, fast-moving team.,Comfortable working with a data-driven team and collaborating with research scientists, data scientists, and platform engineers.,Familiarity or experience with scripting and statistical analysis of your data.","Lead downstream purification process development for exosome therapeutic development programs, currently in the preclinical stage.,Develop FPLC-based scalable column chromatographic methods for the purification and isolation of high-quality exosome products, including, but not limited to, preparatory scale affinity purification, ion exchange (IEX) chromatography, multimodal, hydrophobic interaction, and size exclusion (SEC) chromatography.,Execute and improve current Tangential Flow Filtration (TFF) procedure for isolation and formulation of exosome products.,As a subject matter expert, maintain knowledge and implement state-of-the-art technologies and processes for exosome purification and isolation.,Author process descriptions, SOPs, protocols, and tech transfer documents necessary for seamless process transfer to internal or external collaborators.,Meticulously maintain complete and accurate records of all work performed in LIMS and/or electronic lab notebook (ELN).,Play a central role in selection and interaction with contract manufacturers/research organizations, key suppliers, and other external vendors. Prior experience working with and managing CMO/CDMO/CRO desired.,Manage the downstream process development function, including operational considerations, lab buildout and equipment purchases, team recruitment, and training, setting key metrics and objectives, and providing guidance and mentorship to junior staff.,Coordinate tasks across multiple projects, demonstrating prioritization and planning. We are a start-up and are looking for applicants who are ready and willing to 'roll their sleeves up' and be the Key Driver to meet project timelines and milestones.","Job Description
Position Overview
We're looking for an excellent Downstream and Purification Process Development Scientist to join our client's dynamic team in South San Francisco. This role is an exciting opportunity to lead the development of formulations for building novel exosome therapeutics.
Responsibilities
Lead downstream purification process development for exosome therapeutic development programs, currently in the preclinical stage.
Develop FPLC-based scalable column chromatographic methods for the purification and isolation of high-quality exosome products, including, but not limited to, preparatory scale affinity purification, ion exchange (IEX) chromatography, multimodal, hydrophobic interaction, and size exclusion (SEC) chromatography.
Execute and improve current Tangential Flow Filtration (TFF) procedure for isolation and formulation of exosome products.
As a subject matter expert, maintain knowledge and implement state-of-the-art technologies and processes for exosome purification and isolation.
Author process descriptions, SOPs, protocols, and tech transfer documents necessary for seamless process transfer to internal or external collaborators.
Meticulously maintain complete and accurate records of all work performed in LIMS and/or electronic lab notebook (ELN).
Play a central role in selection and interaction with contract manufacturers/research organizations, key suppliers, and other external vendors. Prior experience working with and managing CMO/CDMO/CRO desired.
Manage the downstream process development function, including operational considerations, lab buildout and equipment purchases, team recruitment, and training, setting key metrics and objectives, and providing guidance and mentorship to junior staff.
Coordinate tasks across multiple projects, demonstrating prioritization and planning. We are a start-up and are looking for applicants who are ready and willing to 'roll their sleeves up' and be the Key Driver to meet project timelines and milestones.
Qualification and Skills
BS/MS degree with 6+ experience or Ph.D. degree with 3+ years of experience in a drug development setting.
4+ years of biologics downstream process development experience using a FPLC system (e.g. AKTA)
Expertise in method/protocol development and scale-up for biologics purification, including, but not limited to affinity, cation exchange (CEX), anion exchange (AEX), viral filtration, and tangential flow filtration (TFF) is required.
Familiarity with HPLC based analytical methods (SEC, RP-HPLC, ion-exchange, hydrophobic interaction chromatography, etc)
Prior experience with IND regulatory requirements, GMP environments, and quality documentation is highly desired.
Demonstrated ability to work independently with minimal supervision.
Familiarity with Design of Experiment (DOE) and comfortable working with analytical tools to create high-quality unbiased analyses.
Prior experience with a successful technology and process transfers to third party vendors (CRO/CDMO/CMO) is highly desired.
Experience mentoring, coaching, and training junior staff members are preferred.
Excellent interpersonal skills, including clear, succinct, and timely communication and proven ability to foster strong relationships with other team members and stakeholders.
Highly self-motivated and detail-oriented, with proven ability to work in a dynamic, fast-moving team.
Comfortable working with a data-driven team and collaborating with research scientists, data scientists, and platform engineers.
Familiarity or experience with scripting and statistical analysis of your data.
Experience collaborating with computational scientists while analyzing your data.
",https://www.snagajob.com/search/q-data+engineer
JOB36041639624,SQL Data Engineer,SQL Data Engineer,,"Managing the investigation of corporate data requirements, documenting them according to the required standards utilising the prescribed methods and tools,Implementing data flows to connect operational systems, data for analytics and BI systems. Re-engineer manual data flows to enable scaling and repeatable use,Working closely with data architects (to determine what data management systems are appropriate) and data scientists (to determine what data is needed for analysis).,Tackling problems associated with database integration and unstructured data sets,Ensuring that those using the data structures and associated components have a good understanding and that any queries are dealt with promptly and efficiently,Strong technical process understanding regardless of technology,Wide range of strong technical skills (i.e. Azure Devops, Azure Data Factory, Data Bricks, SQL, python),Core SQL Competencies – SSMS, SSIS, T-SQL, Stored Procedures,ADF Pipelines to build and populate SQL databases,Background in migrating traditional MS products to Azure,Ability to create efficient DW or DL structures to minimise cost of orchestration / processing and ingestion of data,Very high attention to detail,Strong communication skills,Efficient in building ETL and ELT processes for enterprise solutions,Strong software delivery methods and knowledge,Digital delivery – has a track record of working on DevOps delivery,Exposure in Climate Change data legislation, practices and stakeholders,Experience in Environmental related industries i.e Water, Energy, Forestry related,Presentation skills,Understanding of architecting solutions taking into account wider considerations","
SQL Data Engineer
Job purpose and background
Are you a capable SQL Data Engineer who is passionate about the power of data to solve environmental issues? CDP are looking for an SQL Data Engineer to shape delivery by collaborating with data architects and modellers to contribute to the acquisition of corporate data requirements, documenting them according to the required standards utilising the prescribed methods and Azure data tools, in order to build our centralised data platform.
This is a permanent role, with responsibility for developing, constructing, testing and maintaining architectures such as data pipelines and large-scale data processing warehouses. The post-holder will leverage industry best practice while delivering changes, such as agile backlogs, code repositories, automated builds, testing and releases. They will be responsible for ensuring data scientists can pull relevant data sets for their analyses, implement data pipelines to connect operational systems, data for analytics and BI systems. The role includes re-engineering manual data flows to enable automation, scaling and repeatable use and developing data set processes for data modelling, mining and production.
The post-holder will work closely with data architects (to determine what data management systems are appropriate) and data scientists (to determine which data are needed for analysis). They will provide clean, usable data to the business through the data platform in accordance with governance, and analyse, design, plan, execute and evaluate data requirements to support business activities and projects. The post-holder will be central in ensuring the delivery of world-class digital products and changing the delivery culture in CDP.
About CDP's data engineering team:
The Data Engineering Team’s primary remit is to improve the usability of the climate change, water, forests and cities data disclosed to CDP through robust and transparent methods. The team will create sustainable data pipelines for data quality monitoring, data cleaning, reporting and data science modelling. Harmonised data collected from external sources will enrich the data assets’ value and enhance accessibility for CDP’s stakeholders. The team will produce value-adding insight delivering it through data products that help internal and external stakeholders to better understand the quantitative and qualitative results of their actions. This in turn helps stakeholders to make data-led decisions and optimise for all constraints. Through every stage the data assets are governed by the industry practice standards in a robust and transparent manner.
Key responsibilities include:
Managing the investigation of corporate data requirements, documenting them according to the required standards utilising the prescribed methods and tools
Implementing data flows to connect operational systems, data for analytics and BI systems. Re-engineer manual data flows to enable scaling and repeatable use
Working closely with data architects (to determine what data management systems are appropriate) and data scientists (to determine what data is needed for analysis).
Tackling problems associated with database integration and unstructured data sets
Ensuring that those using the data structures and associated components have a good understanding and that any queries are dealt with promptly and efficiently
In liaison with the information management or IT management functions, contributing to the development and maintenance of corporate data standards
Required skills and experience:
Strong technical process understanding regardless of technology
Wide range of strong technical skills (i.e. Azure Devops, Azure Data Factory, Data Bricks, SQL, python)
Core SQL Competencies – SSMS, SSIS, T-SQL, Stored Procedures
ADF Pipelines to build and populate SQL databases
Background in migrating traditional MS products to Azure
Ability to create efficient DW or DL structures to minimise cost of orchestration / processing and ingestion of data
Very high attention to detail
Strong communication skills
Efficient in building ETL and ELT processes for enterprise solutions
Strong software delivery methods and knowledge
Strong performance-tuning skills.
Desired skills and experience
Digital delivery – has a track record of working on DevOps delivery
Exposure in Climate Change data legislation, practices and stakeholders
Experience in Environmental related industries i.e Water, Energy, Forestry related
Presentation skills
Understanding of architecting solutions taking into account wider considerations
Structured problem solving techniques.
This is a permanent full-time role, reporting to the Head of Data Engineering, which will be delivered remotely to start with. The post holder will be required to travel to CDP’s London office from time to time when it reopens.
Salary and benefits: Between £45,000 - £48,500 per annum dependent on experience, 30 days holiday excluding bank holidays, flexible working opportunities and others benefits.
Interested applicants must be eligible to work legally in the United Kingdom.
Before you apply
We’ll only use the information you provide to process your application. For more details on how we use your information, see our applicants privacy notice. By emailing us your CV and covering letter, you are permitting CDP to use the information you have provided for recruitment purposes.
To apply please email your CV and a covering letter setting out how you meet the required skills and experience or key responsibilities, which should be no more than two pages, to recruitment@cdp.net with ‘DI-SQL Data Engineer, Firstname Surname’ in the subject. Applications will be reviewed on a rolling basis, so early applications are strongly encouraged. The deadline is 8.00 am on 19 October 2020.
Are you interested in a career at CDP working in one of our global offices?
Explore our current job vacancies
",https://www.cdp.net/pt/info/careers/sql-data-engineer-2
JOB36857068921,Lead Data Engineer,Lead Data Engineer,"Bachelor's Degree in Computer Science or other STEM field (Science, Technology, Engineering, Math) from an accredited university,Strong competency with Linux and bash, familiarity with Ubuntu,Proficient with Python, common IDEs, Jupyter notebooks,Expertise with containers (e.g. Docker),Expertise with Data Virtualization tools (e.g. Dremio),Experience working with cloud platforms and provisioning infrastructure (AWS, Azure, GCP),Windows System Admin experience,Comfortable working with highly varied data, including structured and unstructured data sources,Experience in Energy or Oil & Gas Industry applications desirable.,Experience in computer firmware/software development and implementation through full scale commercialization of a product desirable.,Strong communication and presentation skills - well versed with MS Office suite",,"
Company: Baker Hughes
Skills: IT - Programming & Database, IT - Software Development
Education: Bachelors/3-5 yr Degree
Location: Queretaro, Mexico
Lead Data Engineer
Would you like to help the team to solve customer challenges in the energy industry?
Are you passionate in improve the capabilities, efficiency, and performance of sensors and industrial control systems?
Join our Digital Solutions-Engineering & Technology Team!!!
We operate at the heart of the digital transformation of our business. From Digital Engineering to enabling employee success, the Digital solution team is driven to provide the best products and service. We collaborate with teams to solve complex technical challenges and design future innovations.
Partner with the best
As Lead Data Engineer you will contribute on projects related to Data Engineering. Your Key focus areas will be development, deployment, and support of data pipelines from Enterprise Source Systems and IoT devices. You will work closely with various teams of Data Scientists, Functional subject matter experts, and IT project managers in defining, developing, and supporting data engineering solutions for Baker Hughes Additive Technology Centers.
As a Lead Data Engineer, you will be responsible for:
• Collection, evaluation, and documentation of business data requirements; defining data standards and guidelines for business
• Develop and manage connections to enterprise systems, edge devices and cloud systems (using existing API or creating new ones)
• Building algorithms and programs to automate data collection, aggregation & segregation, & transformation
• Prepare data for prescriptive and predictive modelling to help support development of analytics tools and programs
• Managing IT/OT network jump hosts for facilitate operational data transfer to enterprise systems or vice-versa
• Communication and presentation of project value and work progress to stakeholders and senior leadership.
Fuel your passion
To be successful in this role you should have:
Bachelor's Degree in Computer Science or other STEM field (Science, Technology, Engineering, Math) from an accredited university
Strong competency with Linux and bash, familiarity with Ubuntu
Proficient with Python, common IDEs, Jupyter notebooks
Expertise with containers (e.g. Docker)
Expertise with Data Virtualization tools (e.g. Dremio)
Experience working with cloud platforms and provisioning infrastructure (AWS, Azure, GCP)
Windows System Admin experience
Comfortable working with highly varied data, including structured and unstructured data sources
Experience in Energy or Oil & Gas Industry applications desirable.
Experience in computer firmware/software development and implementation through full scale commercialization of a product desirable.
Strong communication and presentation skills - well versed with MS Office suite
English fluent
.
Work in a way that works for you
We recognize that everyone is different and that the way in which people want to work and deliver at their best is different for everyone too. In this role, we can offer the following flexible working patterns:
• Standard working schedule supporting the clients' needs
Working with us
Our people are at the heart of what we do at Baker Hughes. We know we are better when all of our people are developed, engaged and able to bring their whole authentic selves to work. We invest in the health and well-being of our workforce, train and reward talent and develop leaders at all levels to bring out the best in each other.
Working for you
Our inventions have revolutionized energy for over a century. But to keep going forward tomorrow, we know we have to push the boundaries today. We prioritize rewarding those who embrace change with a package that reflects how much we value their input. Join us, and you can expect:
• Contemporary work-life balance policies and wellbeing activities
• Comprehensive private medical care options
• Safety net of life insurance and disability programs
• Tailored financial programs
Additional elected or voluntary benefits
About Us
With operations in over 120 countries, we provide better solutions for our customers and richer opportunities for our people. As a leading partner to the energy industry, we're committed to achieving net-zero carbon emissions by 2050 and we're always looking for the right people to help us get there. People who are as passionate as we are about making energy safer, cleaner and more efficient.
Join Us
Are you seeking an opportunity to make a real difference in a company with a global reach and exciting services and clients? Come join us and grow with a team of people who will energize and inspire you!
About Us:
With operations in over 120 countries, we provide better solutions for our customers and richer opportunities for our people. As a leading partner to the energy industry, we're committed to achieving net-zero carbon emissions by 2050 and we're always looking for the right people to help us get there. People who are as passionate as we are about making energy safer, cleaner and more efficient.
Join Us:
Are you seeking an opportunity to make a real difference in a company that values innovation and progress? Join us and become part of a team of people who will challenge and inspire you! Let's come together and take energy forward.
Baker Hughes Company is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national or ethnic origin, sex, sexual orientation, gender identity or expression, age, disability, protected veteran status or other characteristics protected by law.
",https://www.rigzone.com/oil/jobs/postings/1104687_lead_data_engineer/
JOB37023399267,Field Specialist (Mud Logging/ Data Engineer),Field Specialist (Mud Logging/ Data Engineer),"Ensure all operator and BH HS&E policies and procedures are understood and followed.,Understand and monitor all well site operations.,Ensure that all equipment and services are functioning properly and accurately recording data to the database.,Perform regular and frequent calibration checks of instruments and routine maintenance is performed as required on all equipment.,Notify well site personnel of any anticipated or observed drilling problems related to geology, detection of a kick, or lost circulation.,Monitor Pits, Well flow rates in or out in order to detect fluid gains or losses.,Collect, analyze, and log all geological samples.,Creating and editing all logs and reports for daily deliverables.,Monitor parameters and trends according to the operation: drilling, circulating, tripping, etc.,Manage the database and ensure the quality and integrity of the well data; ensure that the real time data transmitting is reliable and meets requirements.,Establish accurate and comprehensive Logs as per client's format. Update all logs, include standard SLS set, time logs prints and plots requested by Client daily and as required.,Ensure all daily reports are accurate and submitted on time.,Rig-Up unit and all equipment as required, conforming to scope of work. Ensure all installations are performed in a safe manner.,Submit a detailed report of any equipment or software malfunctions to the base and report the action(s) taken to repair or solve the problems.,Assist well site personnel to understand and use data interpretations provided by Baker Hughes Surface Logging. .,Bachelor's Degree with proven years' experience mud logging experience or High School Diploma with proven years offshore mud logging experience,Must have the flexibility to work any schedule offshore based on business needs,Experience customer/client interfacing,Experience with Microsoft Office products (Word, Excel, Powerpoint, etc),Working flexible hours - flexing the times when you work in the day to help you fit everything in and work when you are the most productive,Contemporary work-life balance policies and wellbeing activities,Comprehensive private medical care options,Safety net of life insurance and disability programs,Tailored financial programs",,"
Company: Baker Hughes
Skills: Field Service Tech
Education: Bachelors/3-5 yr Degree
Location: Aberdeen, Scotland, United Kingdom
Partner with the best
The Field Specialist will work an adhoc offshore rotation. The specialist will be in charge of all data collection, geological analysis, well monitoring and reporting as well as all wellsite communication during their tour. They will also be responsible for maintaining equipment readiness and supply levels during their time offshore. All task in the roles and responsibilities apply for this position as well as any additional task required for job safety and success.
As a Field Specialist (Mud Logging / Data Engineer), you will be responsible for:
Ensure all operator and BH HS&E policies and procedures are understood and followed.
Understand and monitor all well site operations.
Ensure that all equipment and services are functioning properly and accurately recording data to the database.
Perform regular and frequent calibration checks of instruments and routine maintenance is performed as required on all equipment.
Notify well site personnel of any anticipated or observed drilling problems related to geology, detection of a kick, or lost circulation.
Monitor Pits, Well flow rates in or out in order to detect fluid gains or losses.
Collect, analyze, and log all geological samples.
Creating and editing all logs and reports for daily deliverables.
Monitor parameters and trends according to the operation: drilling, circulating, tripping, etc.
Manage the database and ensure the quality and integrity of the well data; ensure that the real time data transmitting is reliable and meets requirements.
Establish accurate and comprehensive Logs as per client's format. Update all logs, include standard SLS set, time logs prints and plots requested by Client daily and as required.
Ensure all daily reports are accurate and submitted on time.
Rig-Up unit and all equipment as required, conforming to scope of work. Ensure all installations are performed in a safe manner.
Submit a detailed report of any equipment or software malfunctions to the base and report the action(s) taken to repair or solve the problems.
Assist well site personnel to understand and use data interpretations provided by Baker Hughes Surface Logging. .
Ensure all advanced equipment and services are running and accurately collecting data to the database.
Fuel your passion
To be successful in this role you will have:
Bachelor's Degree with proven years' experience mud logging experience or High School Diploma with proven years offshore mud logging experience
Must have the flexibility to work any schedule offshore based on business needs
Experience customer/client interfacing
Experience with Microsoft Office products (Word, Excel, Powerpoint, etc)
Prior M/LWD experience / knowledge would be desirable as this role could also be a cross trained field specialist to ARTE engineer
Work in a way that works for you
We recognize that everyone is different and that the way in which people want to work and deliver at their best is different for everyone too. In this role, we can offer the following flexible working patterns:
Working flexible hours - flexing the times when you work in the day to help you fit everything in and work when you are the most productive
Working with us
Our people are at the heart of what we do at Baker Hughes. We know we are better when all of our people are developed, engaged and able to bring their whole authentic selves to work. We invest in the health and well-being of our workforce, train and reward talent and develop leaders at all levels to bring out the best in each other.
Working for you
Our inventions have revolutionized energy for over a century. But to keep going forward tomorrow, we know we have to push the boundaries today. We prioritize rewarding those who embrace change with a package that reflects how much we value their input. Join us, and you can expect:
Contemporary work-life balance policies and wellbeing activities
Comprehensive private medical care options
Safety net of life insurance and disability programs
Tailored financial programs
Additional elected or voluntary benefits
About Us
With operations in over 120 countries, we provide better solutions for our customers and richer opportunities for our people. As a leading partner to the energy industry, we're committed to achieving net-zero carbon emissions by 2050 and we're always looking for the right people to help us get there. People who are as passionate as we are about making energy safer, cleaner and more efficient.
Join Us
Are you seeking an opportunity to make a real difference in a company with a global reach and exciting services and clients? Come join us and grow with a team of people who will energize and inspire you
About Us:
With operations in over 120 countries, we provide better solutions for our customers and richer opportunities for our people. As a leading partner to the energy industry, we're committed to achieving net-zero carbon emissions by 2050 and we're always looking for the right people to help us get there. People who are as passionate as we are about making energy safer, cleaner and more efficient.
Join Us:
Are you seeking an opportunity to make a real difference in a company that values innovation and progress? Join us and become part of a team of people who will challenge and inspire you! Let's come together and take energy forward.
Baker Hughes Company is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national or ethnic origin, sex, sexual orientation, gender identity or expression, age, disability, protected veteran status or other characteristics protected by law.
",https://www.rigzone.com/oil/jobs/postings/1110207_Field_Specialist_Mud_Logging_Data_Engineer/
JOB39399824294,Big Data Engineer/Admin,Big Data Engineer/Admin,,,"
Company: Allstate Insurance Company
Sorry, this position has been filled.
",https://careers.allstate.com/job/Tempe-Big-Data-EngineerAdmin-Ariz/495874300/
JOB40085253213,Data Engineer at Hinge,Data Engineer at Hinge,,,"
Hinge recently re-launched as The Relationship App: a subscription dating service for those looking to escape the games and find something real. We are taking on the exciting challenge of building the next generation’s ‘Match.com’, and we need a sharp data engineering wiz to help us provide right BI and analytics tools for our Growth, Member Experience and Leadership teams to support business decisions. As Data Engineer you’ll be an integral member of our engineering team and report to the VP of Engineering.
Mission
Enable member experience, growth and the overall business to meet their respective objectives through providing business intelligence, analytics and data insights.
Responsibilities
*With the support of the Growth and Members Experience teams, analyze results and draw actionable insights from the user’s behavioural data.
*Implementing ETL processes from DynamoDB, MongoDB, Mixpanel, Leanplum and other sources to Amazon Redshift in order to be consumed by Looker.
*Defining and owning data retention and archiving policies.
*Selecting and integrating any Big Data tools and frameworks required to provide requested data capabilities.
*Collaborate with our VP of Member Experience (Product) and our VP Growth
Requirements:
*MS or PhD in CS, Math, Statistics, or related discipline; or a BS with extensive experience in the field
*Background in consumer tech
*Proficient in Python or Golang and Unix/bash, or other similar scripting language
*Hands on Experience with ETL tooling.
*Expert-level SQL skills
*Ability to work with big datasets with minimal support
*Strong desire to make real impact
*Actively looking for ways to contribute, and knows how to get things done
*Track record of setting the bar high and hitting your goals
*Comfortable in a fluid start-up environment and will bring an energetic, fun and creative approach to their work
*Comfortable with AWS, Posgres, Redis, DynamoBD, Mixpanel, Looker
The Hinge Culture
*Candid: You are the first person to come to someone directly with an issue, or a compliment. The team can trust you to always be honest, even when it’s not the easy thing to do. You make all of us stronger by sharing your unique perspective and caring enough to make your feedback known.
*Open: You are open to change, feedback, and help - in fact you seek all of these things out. When someone challenges your ideas, you are able use their feedback as fuel to attack the problem from a different direction, and as an opportunity to challenge your own assumptions.
*Empowered: “The authority or power to do something.” See something, say something, change it. You are empowered to not only speak candidly about what you want to change, but you are actually the person who acts to change it. Be a co-creator and innovator, not a commentator.
*Rigorous: You approach your work with hustle and a critical eye. You’re smart. You can cut through a lot of data and noise to arrive at the right answer. You’re not afraid to explore a direction that may be wrong, because you know it will ultimately lead to further insights.
*Positive: You’re a problem solver who believes there’s a solution. Even when you cannot see the outcome, you encourage others with your energy and attitude to continue without roadblocks or fear of failure.
",https://angel.co/hinge/jobs/244671-data-engineer
JOB45037671716,"Data Engineer ( Ab Initio, Talend )","Data Engineer ( Ab Initio, Talend )","Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.,Experience with Ab Initio and/or Talend required,Bachelor’s Degree in STEM related field or equivalent,Six years of related experience,The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions.,Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on.,Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems.,Strong verbal and written communication skills with the ability to interact with team members and business partners.","Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.,Design data solutions.,Analyze sources to determine value and recommend data to include in analytical processes.,Incorporate core data management competencies including data governance, data security and data quality.,Collaborate within and across teams to support delivery and educate end users on data products/analytic environment.,Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate.","
The Travelers Companies, Inc.
Data Engineer ( Ab Initio, Talend )
Company Summary
Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.
Target Openings
3
Job Description Summary
Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape. In addition to your strong analytical mind, you will bring your inquisitive attitude and ability to translate the stories found in data. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights.
This position may be based 100% remotely or in one of our offices.
Primary Job Duties & Responsibilities
Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.
Design data solutions.
Analyze sources to determine value and recommend data to include in analytical processes.
Incorporate core data management competencies including data governance, data security and data quality.
Collaborate within and across teams to support delivery and educate end users on data products/analytic environment.
Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate.
Test data movement, transformation code, and data components.
Minimum Qualifications
Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
Four years of data engineering or equivalent experience.
Education, Work Experience, & Knowledge
Experience with Ab Initio and/or Talend required
Bachelor’s Degree in STEM related field or equivalent
Six years of related experience
Proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and an understanding of software engineering practices.
Job Specific Technical Skills & Competencies
The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions.
Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on.
Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems.
Strong verbal and written communication skills with the ability to interact with team members and business partners.
Leadership - Intermediate leadership skills with a proven track record of self-motivation in identifying personal growth opportunities.
Employment Practices
Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences.
If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.
Travelers reserves the right to fill this position at a level above or below the level included in this posting.
To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.
More From The Travelers Companies, Inc.
Related Job Listings
",https://www.insurancejournal.com/jobs/639207-data-engineer-ab-initio-talend
JOB48127834242,Data Engineer,Data Engineer,,"Full access to our jobs board, including over 1,000 exclusive jobs,Your Devex profile highlighted in recruiter search results,Connections to recruiters and industry experts through online and live Devex events","
See the full details of this exclusive job - and all of the other big development opportunities hand picked by our team. These positions are only available with a Career Account. Upgrade now to keep your job search moving.
Starting at $9.50, a Devex Career Account provides you:
Full access to our jobs board, including over 1,000 exclusive jobs
Your Devex profile highlighted in recruiter search results
Connections to recruiters and industry experts through online and live Devex events
",https://www.devex.com/jobs/data-engineer-580669
JOB48938243341,Sr. Associate Data Engineer,Sr. Associate Data Engineer,"Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.,Bachelor’s Degree in STEM related field or equivalent,Five years of related experience","Build and operationalize data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.,Participate in the design of data solutions.,Analyze sources to determine value and recommend data to include in analytical processes.,Incorporate core data management competencies including data governance, data security and data quality.,Partner and collaborate with team and business users to support delivery and educate end users on data products/analytic environment.,Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate.","
The Travelers Companies, Inc.
Sr. Associate Data Engineer
Company Summary
Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.
Target Openings
1
Job Description Summary
Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Senior Associate Data Engineer you will help guide growth and transformation of our analytics landscape. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights.
Primary Job Duties & Responsibilities
Build and operationalize data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.
Participate in the design of data solutions.
Analyze sources to determine value and recommend data to include in analytical processes.
Incorporate core data management competencies including data governance, data security and data quality.
Partner and collaborate with team and business users to support delivery and educate end users on data products/analytic environment.
Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate.
Test data movement, transformation code, and data components.
Minimum Qualifications
Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
Two years of data engineering or equivalent experience.
Education, Work Experience, & Knowledge
Bachelor’s Degree in STEM related field or equivalent
Five years of related experience
Developing knowledge of tools, techniques, and manipulation including Cloud platforms, programming languages and software engineering practices.
Employment Practices
Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences.
If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.
Travelers reserves the right to fill this position at a level above or below the level included in this posting.
To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.
More From The Travelers Companies, Inc.
Related Job Listings
",https://www.insurancejournal.com/jobs/639483-sr-associate-data-engineer
JOB51459491752,Data Engineer,Data Engineer,"Bachelor's or Master's degree in Life Sciences, Computer Science or Engineering,Experience in Software Engineering and Development,Strong learning agility, ability to pick up new technologies used to support Commercialization data analysis needs,Experience in Planisware,Strong experience working with agile methodology & DevOps (Jenkins, JIRA, Github) frameworks with successful experience working in a collaborative team environment,Experience working with container technologies (e.g., Docker) and developing microservices,Proficiency in software development languages including but not limited to Java and C#,Experience in Cloud (AWS, databricks platforms) & HPC (high performance computing) environments,Experience in developing and supporting web applications including familiarity with web technologies and frameworks (EXTJS, D3 JS, React.js),Data analysis and reporting experience by using analytics, visualization and database technologies (Oracle, PL SQL, Spotfire, Tableau, Python - NumPy, SciPy, Pandas),Expert in R scripting and R development in R Shiny;,Experience processing and analyzing large NGS data;,Expertise with translating business requirements to technical requirements and recommend solutions,Working with leading agile development methodologies such as Sprint and Scrum,Knowledge of or experience in Life, Physical or Computational Sciences,Strong written and oral communication skills","Create and improve systems to enable end to end solutions and products in support of Commercialization activities,Build data micro services which perform data transformation, metadata extraction, workload management and error processing management,Query, manipulate, and visualize data using R, JavaScript / CSS, and Tableau,Evaluate and utilize state of the art technologies in the industry to meet business needs,Contribute to maturing the Planisware system capabilities,Contribute to continuous development of the data analytics and insights strategy for Commercialization,Integrate the operations data platform with analytical tools such as Tableau, the Data Scientist Workbench, the Data Marketplace, etc.,Develop data processing pipelines for large datasets in the cloud (AWS); integrate with other data sources where applicable;,Collaborate with the other engineering team members to ensure all services are reliable, maintainable, and well-integrated into existing platforms,Adhere to best practices for testing and designing reusable code,Ensure effective communication between key partners, including business clients, technical staff and vendors to analyze scientific needs and implement informatics solutions in data acquisition, integration and analysis,Own and run product backlog delivery","
Data Engineer
Commercialization Information Systems
Amgen, Tampa
Amgen is seeking a Data Engineer to help realize Amgen's Commercialization analytics transformation strategy by developing a state-of-the-art analytical platform that will enable generation of cross-capability business insights. The Data engineer will help build leading edge scientific applications with modern technology stacks that will be used by our Commercialization partners to advance Amgen's pipeline. The extraordinary candidate will join our Commercialization Information Systems team to deliver solutions and products using best practices in Agile and DevOps. This Data Engineer position will report to the Senior Manager Commercialization Information Systems. The position will be based in Amgen's Tampa campus.
The Commercialization Information Systems team supports the critical business process in developing innovative product strategies, managing Amgen's pipeline portfolio, and making effective portfolio decisions to accelerate and grow Amgen's pipeline. Our success in analytics and deep insights is driven by our commitment to our patients, to our business clients, and to leverage superlative technologies that deliver critical business value.
Responsibilities:
Create and improve systems to enable end to end solutions and products in support of Commercialization activities
Build data micro services which perform data transformation, metadata extraction, workload management and error processing management
Query, manipulate, and visualize data using R, JavaScript / CSS, and Tableau
Evaluate and utilize state of the art technologies in the industry to meet business needs
Contribute to maturing the Planisware system capabilities
Contribute to continuous development of the data analytics and insights strategy for Commercialization
Integrate the operations data platform with analytical tools such as Tableau, the Data Scientist Workbench, the Data Marketplace, etc.
Develop data processing pipelines for large datasets in the cloud (AWS); integrate with other data sources where applicable;
Collaborate with the other engineering team members to ensure all services are reliable, maintainable, and well-integrated into existing platforms
Adhere to best practices for testing and designing reusable code
Ensure effective communication between key partners, including business clients, technical staff and vendors to analyze scientific needs and implement informatics solutions in data acquisition, integration and analysis
Own and run product backlog delivery
Basic Qualifications:
Master's degree in computer science or closely relevant degree program and 2 years of software engineering experience
OR
Bachelor's degree and 3 years of software engineering experience
OR
Associate degree and 6 years of software engineering experience
OR
High school diploma / GED and 8 years of software engineering experience
Preferred Qualifications:
Bachelor's or Master's degree in Life Sciences, Computer Science or Engineering
Experience in Software Engineering and Development
Strong learning agility, ability to pick up new technologies used to support Commercialization data analysis needs
Experience in Planisware
Strong experience working with agile methodology & DevOps (Jenkins, JIRA, Github) frameworks with successful experience working in a collaborative team environment
Experience working with container technologies (e.g., Docker) and developing microservices
Proficiency in software development languages including but not limited to Java and C#
Experience in Cloud (AWS, databricks platforms) & HPC (high performance computing) environments
Experience in developing and supporting web applications including familiarity with web technologies and frameworks (EXTJS, D3 JS, React.js)
Data analysis and reporting experience by using analytics, visualization and database technologies (Oracle, PL SQL, Spotfire, Tableau, Python - NumPy, SciPy, Pandas)
Expert in R scripting and R development in R Shiny;
Experience processing and analyzing large NGS data;
Expertise with translating business requirements to technical requirements and recommend solutions
Working with leading agile development methodologies such as Sprint and Scrum
Knowledge of or experience in Life, Physical or Computational Sciences
Strong written and oral communication skills
Amgen is committed to unlocking the potential of biology for patients suffering from serious illnesses by discovering, developing, manufacturing and delivering innovative human therapeutics. This approach begins by using tools like advanced human genetics to unravel the complexities of disease and understand the fundamentals of human biology.
Our culture is what makes Amgen a special place to work. We have a powerful shared purpose around our mission - to serve patients. We respect one another, recognize contributions, and have embedded collaboration, trust, empowerment and inclusion in all that we do.
We equip all our staff members to live well-rounded, healthy lives. Most recently, Amgen added benefits for transgender employees and continues to pride itself on industry-leading, family-friendly offerings for families of all compositions.
Amgen focuses on areas of high unmet medical need and uses its expertise to strive for solutions that improve health outcomes and dramatically improve people's lives. A biotechnology pioneer since 1980, Amgen has grown to be one of the world's leading independent biotechnology companies, has reached millions of patients around the world and is developing a pipeline of medicines with breakaway potential.
Amgen is an Equal Opportunity employer and will consider you without regard to your race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.
",https://www.biospace.com/job/1983680/data-engineer/
JOB52334220580,Senior Data Engineer,Senior Data Engineer,"Bachelor's Degree is required,At least 2 years of employment as a data engineer in a professional setting, or other relevant development experience,Expert in python,Expert working with cloud platforms (AWS, Google Cloud, etc),Experience with Airflow or other workflow management software,Ability to define data model and data storage strategies, including knowledge of distributed data systems,Ability to manage multiple/competing priorities and make the right tradeoffs and timely delivery of features,Experience or familiarity with geography, geometry and GIS systems,Experience working with satellite/remote imagery,Relevant education (Coding Bootcamp, and/or Bachelors in Computer Science) or equivalent experience,Be part of a well-funded early-stage start-up,Market competitive comp and equity incentives to give you a stake in our future,Medical, Vision and Dental for you and your dependents,Pre-tax commuter & parking benefits,Flexible Time Off,An upbeat and collaborative work culture,Company-sponsored outings","Working on data cleansing, batch processing, data transformations, and other data manipulations to enable our data science efforts.,Advanced image manipulation,Geometry/geographic calculations,Serving as part of the core team for the technology stack,Partnering closely with the Founders to bring a disruptive AI based technology platform to the insurance and real estate markets","
As a Senior Data Engineer, you have a strong interest/experience working with remote sensing and imagery. You will play a pivotal role in building the platform that delivers processed data and imagery to our machine learning systems. You are comfortable and able to work in advanced imagery manipulation and GIS processing. The ideal candidate thrives in a collaborative, creative environment that moves fast. You are passionate about designing technology that elegantly solves complex business problems and you have an opinion about doing things the right way.
Think you might be Zesty enough? If yes, we’d love to talk to you.
What You’ll Do:
Working on data cleansing, batch processing, data transformations, and other data manipulations to enable our data science efforts.
Advanced image manipulation
Geometry/geographic calculations
Serving as part of the core team for the technology stack
Partnering closely with the Founders to bring a disruptive AI based technology platform to the insurance and real estate markets
Investigating and prototyping new technologies
Qualifications
What You Bring to the zesty.ai Team:
Bachelor's Degree is required
At least 2 years of employment as a data engineer in a professional setting, or other relevant development experience
Expert in python
Expert working with cloud platforms (AWS, Google Cloud, etc)
Experience with Airflow or other workflow management software
Ability to define data model and data storage strategies, including knowledge of distributed data systems
Ability to manage multiple/competing priorities and make the right tradeoffs and timely delivery of features
Experience or familiarity with geography, geometry and GIS systems
Experience working with satellite/remote imagery
Relevant education (Coding Bootcamp, and/or Bachelors in Computer Science) or equivalent experience
Must be legally eligible to work in the U.S.
Additional Information
Why Zesty.ai:
Be part of a well-funded early-stage start-up
Market competitive comp and equity incentives to give you a stake in our future
Medical, Vision and Dental for you and your dependents
Pre-tax commuter & parking benefits
Flexible Time Off
An upbeat and collaborative work culture
Company-sponsored outings
Free One Medical membership
All your information will be kept confidential according to EEO guidelines.
",https://www.insurancejournal.com/jobs/535815-senior-data-engineer
JOB53651228600,Data Engineer,Data Engineer,"Experience with Informatica tools (PowerCenter, Big Data Management, Master Data Management), Cloudera CDH and ecosystem tools (SOLR, Spark, Impala, Hive, Hue, etc...), MarkLogic, SAS Analytics, python, R and Amazon Web Services preferred.","Planning, building and running enterprise class information management solutions across a variety of technologies (e.g. big data, master data, data profiling, batch processing, and data indexing technologies, ).,Establishing advance search solutions that include synonym, inference and faceted searching.,Ensuring appropriate security and compliance policies are followed for information access and dissemination.,Defining and applying information quality and consistency business rules throughout the data processing lifecycle.,Collaborating with information providers to ensure quality data updates are processed in a timely fashion.,Enforcing and expanding use of AbbVie Common Data Model and industry standard information descriptions (ontologies, taxonomies, vocabularies, lexicons, dictionaries, thesaurasus, glossaries etc...),Managing the information portal and its customer-facing resources (data catalog, data portal, etc...),Bachelor's Degree with 10+ years of related work experience and a strong understanding of specified functional area. Degree in Computer Science or related discipline preferred. Advanced degree preferred.,At least 10 years experience in a several data processing roles such as database developer/administrator, ETL developer, data analyst, BI analytics developer, and/or solution developer of contextual search applications.","
For large enterprise datasets, the data engineer is responsible for curating content to support key business initiatives, working primarily with data scientist and data analysts across functional disciplines. Participants in the acquisition, cataloging, and harmonization of information aligned with the needs of business stakeholders. Supports data consumers in understanding information context, generating fit for purpose datasets, and effectively utilizing advance analytic tools.
Key Responsibilities Include:
Planning, building and running enterprise class information management solutions across a variety of technologies (e.g. big data, master data, data profiling, batch processing, and data indexing technologies, ).
Establishing advance search solutions that include synonym, inference and faceted searching.
Ensuring appropriate security and compliance policies are followed for information access and dissemination.
Defining and applying information quality and consistency business rules throughout the data processing lifecycle.
Collaborating with information providers to ensure quality data updates are processed in a timely fashion.
Enforcing and expanding use of AbbVie Common Data Model and industry standard information descriptions (ontologies, taxonomies, vocabularies, lexicons, dictionaries, thesaurasus, glossaries etc...)
Managing the information portal and its customer-facing resources (data catalog, data portal, etc...)
Basic:
Bachelor's Degree with 10+ years of related work experience and a strong understanding of specified functional area. Degree in Computer Science or related discipline preferred. Advanced degree preferred.
At least 10 years experience in a several data processing roles such as database developer/administrator, ETL developer, data analyst, BI analytics developer, and/or solution developer of contextual search applications.
Experience with Informatica tools (PowerCenter, Big Data Management, Master Data Management), Cloudera CDH and ecosystem tools (SOLR, Spark, Impala, Hive, Hue, etc...), MarkLogic, SAS Analytics, python, R and Amazon Web Services preferred.
Equal Opportunity Employer Minorities/Women/Veterans/Disabled
",https://www.biospace.com/job/1890180/data-engineer/
JOB53838464904,Senior Data Engineer,Senior Data Engineer,"BS/MS degree in Computer Science, Engineering or related field,5 or more years of experience designing complex and inter - dependent data models for analytic , Machine learning use cases.,5 or more years of experience architecting and building processes that extract, process and add value to data sets from multiple source systems.,Experiencing with data modeling and tuning of relational as well as NoSQL datastores (Oracle, Red-shift, Impala, HDFS/Hive, Athena, etc.),Experience working with distributed computing tools (Spark, Hive, etc.),Experience with AWS cloud services: EC2, EMR, RDS, Redshift, S3, Lambda,Experience with data pipeline and workflow management tools: Airflow, etc.,5 or more years of experience with one or more general purpose programming languages, including but not limited to: Java, Scala, C, C++, C#, Swift/Objective C, Python, or JavaScript.,5 or more years experience working with and leading agile development methodologies such as Sprint and Scrum,Experience with Software engineering best-practices, including but not limited to version control (Git, TFS, Subversion, etc.), CI/CD (Jenkins, Maven, Gradle, etc.), automated unit testing, Dev Ops.,Experience with Semantic technologies and approaches is a plus.,Biotech / Pharma experience is a plus,Full stack development using infrastructure cloud services (AWS preferred) and cloud-native tools and design patterns (Containers, Serverless, Docker, etc) is a plus.","The ability to absorb the nuances of the Bio-Tech operations value chain, including supply chain, logistics, and manufacturing source systems;,High personal standards of productivity and quality,Able to function as scrum master for the Data Engineering Team,The ability to contribute in a collaborative and fast paced environment.,Defines and approves data engineering design patterns to be used for general re-use on multiple implementations,Collaborate with Data Architects, Business SME's, and Data Scientists to architect data products and services.,Build data products and service processes which perform data transformation, metadata extraction, workload management and error processing management.,Implement standardized, automated operational and quality control processes to deliver accurate and timely data and reporting to meet or exceed SLAs.,Drive the exploration and adoption of new tools, and techniques and propose improvements to the data pipeline,Integrate the operations data platform with the Data Scientist workbench, the Data Marketplace, and Analytic Tools such as Tableau, Spotfire, R, etc.,Act as a product manager for the operations data platform backlog,Act as a run manager, provide Run/DevOps support","
Amgen is seeking Data Engineers to help realize Amgen's Operations Data Strategy. This program will produce business insights through data science solutions. You will build upon our awarded Enterprise Data Lake to develop value added data products that span the Operations Domain (Process Development, Supply Chain, Quality, Engineering, Manufacturing). There is no more challenging data environment than Life Sciences due to the integration of scientific research, manufacturing, logistics of pharmaceutical products. Expect to make a difference in providing patients with products that meet their medical needs in a competitive landscape.
Successful candidates will have:
The ability to absorb the nuances of the Bio-Tech operations value chain, including supply chain, logistics, and manufacturing source systems;
High personal standards of productivity and quality
Able to function as scrum master for the Data Engineering Team
The ability to contribute in a collaborative and fast paced environment.
Key Activities for the Data Engineer include:
Defines and approves data engineering design patterns to be used for general re-use on multiple implementations
Collaborate with Data Architects, Business SME's, and Data Scientists to architect data products and services.
Build data products and service processes which perform data transformation, metadata extraction, workload management and error processing management.
Implement standardized, automated operational and quality control processes to deliver accurate and timely data and reporting to meet or exceed SLAs.
Drive the exploration and adoption of new tools, and techniques and propose improvements to the data pipeline
Integrate the operations data platform with the Data Scientist workbench, the Data Marketplace, and Analytic Tools such as Tableau, Spotfire, R, etc.
Act as a product manager for the operations data platform backlog
Act as a run manager, provide Run/DevOps support
Basic Qualifications:
Doctorate degree
OR
Master's degree and 3 years of Information Systems experience
OR
Bachelor's degree and 5 years of Information Systems experience
OR
Associate degree and 10 years of Information Systems experience
OR
High school diploma / GED and 12 years of Information Systems experience
Preferred Qualifications:
BS/MS degree in Computer Science, Engineering or related field
5 or more years of experience designing complex and inter - dependent data models for analytic , Machine learning use cases.
5 or more years of experience architecting and building processes that extract, process and add value to data sets from multiple source systems.
Experiencing with data modeling and tuning of relational as well as NoSQL datastores (Oracle, Red-shift, Impala, HDFS/Hive, Athena, etc.)
Experience working with distributed computing tools (Spark, Hive, etc.)
Experience with AWS cloud services: EC2, EMR, RDS, Redshift, S3, Lambda
Experience with data pipeline and workflow management tools: Airflow, etc.
5 or more years of experience with one or more general purpose programming languages, including but not limited to: Java, Scala, C, C++, C#, Swift/Objective C, Python, or JavaScript.
5 or more years experience working with and leading agile development methodologies such as Sprint and Scrum
Experience with Software engineering best-practices, including but not limited to version control (Git, TFS, Subversion, etc.), CI/CD (Jenkins, Maven, Gradle, etc.), automated unit testing, Dev Ops.
Experience with Semantic technologies and approaches is a plus.
Biotech / Pharma experience is a plus
Full stack development using infrastructure cloud services (AWS preferred) and cloud-native tools and design patterns (Containers, Serverless, Docker, etc) is a plus.
Amgen is committed to unlocking the potential of biology for patients suffering from serious illnesses by discovering, developing, manufacturing and delivering innovative human therapeutics. This approach begins by using tools like advanced human genetics to unravel the complexities of disease and understand the fundamentals of human biology.
Amgen focuses on areas of high unmet medical need and leverages its expertise to strive for solutions that improve health outcomes and dramatically improve people's lives. A biotechnology pioneer since 1980, Amgen has grown to be one of the world's leading independent biotechnology companies, has reached millions of patients around the world and is developing a pipeline of medicines with breakaway potential.
Amgen is an Equal Opportunity employer and will consider all qualified applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.
Join Us
If you're seeking a career where you can truly make a difference in the lives of others, a career where you can work at the absolute forefront of biotechnology with the top minds in the field, you'll find it at Amgen.
Amgen, a biotechnology pioneer, discovers, develops and delivers innovative human therapeutics. Our medicines have helped millions of patients in the fight against cancer, kidney disease, rheumatoid arthritis and other serious illnesses.
As an organization dedicated to improving the quality of life for people around the world, Amgen fosters an inclusive environment of diverse, ethical, committed and highly accomplished people who respect each other but compete intensely to win. Together, we live the Amgen values as we continue advancing science to serve patients.
Amgen is an Equal Opportunity employer and will consider all qualified applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.
.
",https://www.biospace.com/job/1947921/senior-data-engineer/
JOB55258994031,Data Engineer (remote/relocation),Data Engineer (remote/relocation),,,"
Employee • Amsterdam, Netherlands • Remote • Hiring in Europe, North America, South America, Asia • Added 4 weeks ago
FindHotel has the ambition that every decision should be based on data and every feature be fuelled with data. To make this happen we invest heavily in our data infrastructure. We are looking for a senior Data Engineer to help us scale and grow. The product catalogue of the Data Infrastructure team ranges from the basics of event delivery, storage and processing to A/B testing and Data Science infrastructure (model development and deployment).
Requirements
Who you are:
- You are a data engineer with previous experience in business intelligence and data warehousing
- You know how to work with high volume heterogeneous data, preferably with distributed systems such as Kafka, Spark, and MPP databases such as Snowflake.
- You are comfortable building and deploying applications in public clouds, in particular in the AWS cloud.
- You know how to write distributed, high-volume services in Golang, Scala, or Java.
- You have hands-on experience with a large number of technologies and programming languages. It allows you to choose the right tool for job, and to not be afraid of contributing to systems across the whole FindHotel organisation.
- You are knowledgeable about data modeling, data access, and data storage techniques.
- You appreciate agile software processes, data-driven development, reliability, and responsible experimentation.
- You strive for excellence, clarity and transparency, shipping business value as early as possible, and building incrementally afterwards.
- (For remote candidates) Based in a time zone between UTC-4 and UTC+6
Bonus points for:
- Experience with e-commerce, clickstream data and event tracking
- Experience or interest in data analysis
What we offer:
- Plenty of chances to learn and grow – you'll be surrounded by some of the brightest minds in the city, be part of a culture which values sharing knowledge every day and has a budget to attend conferences and develop yourself.
- A profitable company with fast growth and a great scale opportunity.
- A competitive compensation package + perks and benefits (including Stock Appreciation Rights).
- Flexible time off (take as many holidays as you need) and a chance to work remotely - we measure results, not time spent in the office.
- You will be part of a highly international team in a fun work environment.
- We value good food and offer catered lunches from various cuisines, great coffee, ice-cream in the fridge and the occasional bbq in our garden.
",https://www.f6s.com/jobs/47059/findhotel/data-engineer-remote-relocation
JOB55350563296,Data Engineer,Data Engineer,"Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.,Experience building and optimizing big data' data pipelines, architectures and data sets.,Strong analytic skills related to working with unstructured datasets.,Build processes supporting data transformation, data structures, metadata, dependency and workload management.,We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a degree in Computer Science, Statistics, Informatics, Information Systems or relevant experience. Below is a list of the type of tech we use, though we don't expect you to have experience in all of it:
Big data tools: Hadoop, Storm, Cassandra, etc.
Relational SQL and NoSQL databases, including Postgres, MySQL, MSSQL.
Data pipeline and workflow management tools such as Google Cloud Dataflow
Cloud services: AWS Redshift, Google BigQuery, etc
Stream-processing systems: Kafka, Storm, Spark-Streaming, etc.
Object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.,Big data tools: Hadoop, Storm, Cassandra, etc.,Relational SQL and NoSQL databases, including Postgres, MySQL, MSSQL.,Data pipeline and workflow management tools such as Google Cloud Dataflow,Cloud services: AWS Redshift, Google BigQuery, etc,Stream-processing systems: Kafka, Storm, Spark-Streaming, etc.,Object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.","Work with our CTO to create and maintain optimal data pipeline architecture and documentation.,Assemble large, complex data sets that meet functional / non-functional business requirements.,Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.,Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using big data' technologies.,Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.,Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.","
At Vetsource, we are on a bold mission to improve the lives of pets by enabling veterinarians to provide better care. We have a big vision; one that is driven by data. You can help shape this vision by joining the Data Engineering Team and enabling us to build better products so veterinarians can provide better service and pet parents can get the care they need for their pets.
We are going big with big data. Data powers our products and services, enables key business decisions, aids veterinary hospitals, and plays an important role in our product development. As you can see in the image below, Vetsource is deeply integrated with a number of data sources and transforms that data into actionable insights.
So where do you come in? We need you to further make this dream a reality. We are looking for talented individuals who contribute to the vision depicted in the image above. You are someone who specializes in at least one aspect of data, whether it's ETL, cloud storage, big data services, or any key technology that helps make lots of data useful. You tell us about your passion and skills and where you fit, and we will make this happen together!
Responsibilities:
As a member of the Data Engineering team, you will be responsible for some or all of the following:
Work with our CTO to create and maintain optimal data pipeline architecture and documentation.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using big data' technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Work with data and analytics experts to strive for greater functionality in our data systems.
Qualifications:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing big data' data pipelines, architectures and data sets.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a degree in Computer Science, Statistics, Informatics, Information Systems or relevant experience. Below is a list of the type of tech we use, though we don't expect you to have experience in all of it:
Big data tools: Hadoop, Storm, Cassandra, etc.
Relational SQL and NoSQL databases, including Postgres, MySQL, MSSQL.
Data pipeline and workflow management tools such as Google Cloud Dataflow
Cloud services: AWS Redshift, Google BigQuery, etc
Stream-processing systems: Kafka, Storm, Spark-Streaming, etc.
Object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
PI124928968
Posted: 2020-10-16 Expires: 2020-11-16
",https://www.careercast.com/jobs/data-engineer-portland-or-97220-119545102-d
JOB59647021549,24 Human Resources jobs with job title Data Engineer,24 Human Resources jobs with job title Data Engineer,,,"
Browse for Human Resources Data Engineer Jobs. Find the job of your dreams on CareerCast.com today!
Search for Similar Listings
",https://www.careercast.com/jobs/human-resources-data-engineer-326942102-b
JOB63676185964,D&C Decision Support Center Business Analyst / Data Engineer,D&C Decision Support Center Business Analyst / Data Engineer,,,"
This Position Is Closed to New Applicants
This position is no longer open for new applications. Either the position has expired or was removed because it was filled. However, there are thousands of other great jobs to be found on Rigzone.
",https://www.rigzone.com/oil/jobs/postings/956581_dc_decision_support_center_business_analyst_data_engineer/
JOB66741496644,"Data Engineer, Analytics (Payments Ecosystem)","Data Engineer, Analytics (Payments Ecosystem)",,," Our more experienced data engineers are clearly characterized by in-depth technical experience and proven progression in leadership responsibility. If you have an interest in being responsible for the dynamics of a fast-paced environment, this is the right role for you. You will be working on many projects at a time, but also focused on the details while finding creative ways to pursue big picture challenges. As part of the payments ecosystem team, you would be responsible for building the data foundations and metrics that are conformed across the Facebook Family of Apps and enable insights to the acquisition, revenue, compliance and risk , engagement/retention across payment products, payouts and provider performance ensure reliability and SLAs. The main consumers of these data artifacts would be the product teams and the executive team. Payments is a top priority for Facebook in 2020 and beyond recently has been made into an independent product organization called Facebook Financials with a focus to platformize the payments services. In this role, you will have the opportunity to define technical specifications for metric definition, logging, define and influence the right metrics and build the core datasets that will be used by our Data Scientists, Machine Learning engineers and product managers. A few examples of the story your dataset will tell: Compliance policies and effectiveness of implementation (KYC, KYB). Understanding the relation between acquisition, reliability, engagement and retention. Provide understanding how payment enables lift across different products. How payments perform on different platforms, products and operating systems.
Data Engineer, Analytics (Payments Ecosystem) Responsibilities
Ensure conformance of metrics and detailed understanding of the metric definitions from business and technical implementation
Craft and own the optimal data processing architecture and systems for new data and ETL pipelines
Build core datasets as well as scalable and fault-tolerant pipelines
Build data anomaly detection, data quality checks, and enable easy root cause analysis
Define and own the data engineering roadmap for payments ecosystem and other areas to ensure seamless integration
Collaborate with Software Engineers and Data Scientists to design technical specification for logging and add logging to production code to generate metrics both online as well as offline
Work with different cross-functional partners - WhatsApp Payments Team, Compliance, Tax and Finance
Build visualizations to provide insights into the data & metrics generated on the Payments Platform
Work with data infrastructure teams to suggest improvements and influence their roadmap
Able to immerse yourself in all aspects of the product, understand the problems, and tie them back to data engineering solutions
Recommend improvements and modifications to existing data and ETL pipelines
Communicate and influence strategies and processes around data modeling and architecture to multi-functional groups and leadership
Drive internal process improvements and automating manual processes for data quality and SLA management
Provide ongoing proactive communication and collaboration throughout the organization
Actively mentor team members in their careers
Minimum Qualifications
4+ years' experience in the data warehouse space
4+ years' experience in payments analytics
4+ years' experience working with either a MapReduce or an MPP system
7+ years' experience in writing complex SQL and ETL processes
4+ years' experience with object-oriented programming languages
7+ years' experience with schema design and dimensional data modeling
Preferred Qualifications
BS/BA in Technical Field, Computer Science or Mathematics
Knowledge in Python or Java
Experience analyzing data to identify deliverables, gaps, and inconsistencies
Experience effectively collaborating and communicating complex technical concepts to a broad variety of audiences
Locations
About the Facebook company
Facebook's mission is to give people the power to build community and bring the world closer together. Through our family of apps and services, we're building a different kind of company that connects billions of people around the world, gives them ways to share what matters most to them, and helps bring people closer together. Whether we're creating new products or helping a small business expand its reach, people at Facebook are builders at heart. Our global teams are constantly iterating, solving problems, and working together to empower people around the world to build community and connect in meaningful ways. Together, we can help people build stronger communities - we're just getting started.
Facebook
",https://www.careerjet.com/jobad/usa3172af21d9f495498c6b96db6790536
JOB66865215897,"We're hiring for Senior Data Engineer, Finance Products at Squarespace","We're hiring for Senior Data Engineer, Finance Products at Squarespace",,,,https://www.themuse.com/jobs/squarespace/senior-data-engineer-finance-products-1f293d
JOB67551875577,Senior Data Engineer,Senior Data Engineer,"Clearance TS//SCI or TS/SCI with current CI scope Polygraph (with one year of currency minimum) OR willing to undergo CI scope Polygraph (based on specific analytical position) PLUS,Education Bachelors Degree OR 10+ years direct relevant experience PLUS,Experience 10+ years of analytical experience (with 8+ years of Identity Intelligence or functional/regional all-source analysis experience) at the operational/strategic level within DoD or equivalent Government agencies,Strong briefing skills to include the ability to clearly articulate information to senior members of the intelligence community,Ability to gather, analyze and collate and fuse available intelligence products to produce IIRs, reports, and briefings including the ability to clearly articulate information,Education: Masters Degree in related field,Certification: Counter Terrorism/Counter Insurgency, Global Regional Issues, HUMINT, CI, POL/MIL/Geopolitical analysis; Senior Intelligence Analysis with familiarity of ICD 203, 204 and 206.
Competed OS301 Fundamentals Course
Completed OS302 OSINT Analytic Tools Course
Completed a Basic Social Media Analysis Course
Complete an Advanced Social Media Analysis Course,Competed OS301 Fundamentals Course,Completed OS302 OSINT Analytic Tools Course,Completed a Basic Social Media Analysis Course,Complete an Advanced Social Media Analysis Course,Experience: 12 years of experience related to the specific labor category with at least a portion of the experience within the last 2 years,Equivalency Chief Warrant Officer 3-5; Field Grade Officer (O4- O5) JISE/ACE Director or Deputy Director",,"
Responsibilities
Designs. implements, and operates data management systems for intelligence needs. Designs how data will be stored, accessed, used, integrated, and managed by different data regimes and digital systems. Works with data users to determine, create, and populate optimal data architectures, structures, and systems. Plans, designs, and optimizes data throughput and query performance. Participates in the selection of backend database technologies (e.g. SQL. NoSQL. IIPC, etc.), their configuration and utilization, and the optimization of the full data pipeline infrastructure to support the actual content, volume, ETL, and periodicity of data to support the intended kinds of queries and analysis to match expected responsiveness.
Qualifications
Required:
Clearance TS//SCI or TS/SCI with current CI scope Polygraph (with one year of currency minimum) OR willing to undergo CI scope Polygraph (based on specific analytical position) PLUS
Education Bachelors Degree OR 10+ years direct relevant experience PLUS
Experience 10+ years of analytical experience (with 8+ years of Identity Intelligence or functional/regional all-source analysis experience) at the operational/strategic level within DoD or equivalent Government agencies
Strong briefing skills to include the ability to clearly articulate information to senior members of the intelligence community
Ability to gather, analyze and collate and fuse available intelligence products to produce IIRs, reports, and briefings including the ability to clearly articulate information
Desired:
Education: Masters Degree in related field
Certification: Counter Terrorism/Counter Insurgency, Global Regional Issues, HUMINT, CI, POL/MIL/Geopolitical analysis; Senior Intelligence Analysis with familiarity of ICD 203, 204 and 206.
Competed OS301 Fundamentals Course
Completed OS302 OSINT Analytic Tools Course
Completed a Basic Social Media Analysis Course
Complete an Advanced Social Media Analysis Course
Experience: 12 years of experience related to the specific labor category with at least a portion of the experience within the last 2 years
Equivalency Chief Warrant Officer 3-5; Field Grade Officer (O4- O5) JISE/ACE Director or Deputy Director
Email this job to a friendRefer
Sorry the Share function is not working properly at this moment. Please refresh the page and try again later.
As a government contractor, Perspecta abides by the following provision
PAY TRANSPARENCY NONDISCRIMINATION PROVISION
The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor's legal duty to furnish information. 41 CFR 60-1.35(c)
Categories
Industry
Posted: 2020-06-26 Expires: 2020-07-26
",http://www.careercast.com/jobs/detail/summary/118258135?contextType=rss&widget=1&type=job&
JOB67743994313,"1 job with job title Data Engineer - Budapest, Budapest, Hungary","1 job with job title Data Engineer - Budapest, Budapest, Hungary",,,"
Browse for Data Engineer Jobs in Budapest, Budapest, Hungary. Find the job of your dreams on CareerCast.com today!
Search for Similar Listings
",https://www.careercast.com/jobs/data-engineer-hungary-380528335-b
JOB69310882668,197 Senior Data Engineer Jobs,197 Senior Data Engineer Jobs,,,"Job Description
If you are a Senior Software Developer with experience in React.js and Node.JS, please read on! Based in Omaha, we are a computer software company that has been providing innovative accounting and business software to businesses across the country for over 40 years. Our industry knowledge has allowed us to leverage new technologies such as Platform as a Serve (PaaS) and cloud computing solutions to assist our clients keep up with a changing marketplace. We are looking for a Senior Software Engineer to join our development team to further develop our new applications and improve our internal applications.What You Will Be Doing - Provide technical leadership on developing new applications and meeting business requirements - Build single page applications with JavaScript/Typescript - Demonstrate ability to provide beautiful user interfaces using HTML, JavaScript, and CSS - Conduct code reviews and ensure scalabilityWhat You Need for this Position - 5+ years of experience building web applications - Strong JavaScript Framework knowledge(React) - Strong API Design/Architecture knowledge(GraphQL in Node.JS and) - Agile/Scrum experience - Test Driven Development(TDD) BONUS: - Golang (Go) - Cross-platform mobile applications(React Native) - Release automation, versioning, and deployment for Front end applicationsWhat's In It for You - 401k match - Medical/Dental/Vision Benefits - Bonus - PTO - Strong Company CultureSo, if you are a Senior Software Developer with experience in React.js and Node.JS please apply today!
",https://www.snagajob.com/search/q-senior+data+engineer
JOB70628063420,Senior Data Engineer,Senior Data Engineer,Connections to recruiters and industry experts through online and live Devex events,"Full access to our jobs board, including over 1,000 exclusive jobs,Your Devex profile highlighted in recruiter search results","
See the full details of this exclusive job – and all of the other big development opportunities hand picked by our team. These positions are only available with a Career Account. Upgrade now to keep your job search moving.
Starting at $9.50, a Devex Career Account provides you:
Full access to our jobs board, including over 1,000 exclusive jobs
Your Devex profile highlighted in recruiter search results
Connections to recruiters and industry experts through online and live Devex events
",https://www.devex.com/jobs/senior-data-engineer-667244
JOB73055442238,Data Engineer (MDM),Data Engineer (MDM),"Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.,Bachelor’s Degree in STEM related field or equivalent,Eight years of related experience,The ability to deliver work at a steady, predictable pace to achieve commitments, deliver complete solutions but release them in small batches, and identify and negotiate important tradeoffs.,Demonstrated track record of domain expertise including understanding technical concepts necessary and industry trends, and possess in-depth knowledge of immediate systems worked on and some knowledge of adjacent systems.,Strong problem solver who ensures systems are built with longevity and creates innovate ways to resolve issues.,Strong written and verbal communication skills with the ability to work collaborate well with team members and business partners.","Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions.,Design complex data solutions,Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes.,Incorporate core data management competencies including data governance, data security and data quality.,Collaborate within and across teams to support delivery and educate end users on complex data products/analytic environment.,Perform data and system analysis, assessment and resolution for complex defects and incidents and correct as appropriate.,Test data movement, transformation code, and data components.,Experience with Informatica MDM (IDD, UserExit, Business Entity, Provisioning tool, Publishing).,Experience with configure Match and Merge and refining match rules based on business requirement and data specification.,Experience with Web services and understanding of micro services architecture, experience integrate with MDM real time services with BES or SIF.,Experience with Database - SQL (Oracle/SQL Server/DB2/Teradata) , NoSQL (MongoDB, DynamoDB).,Experience with Match and Merge.,Basic understanding of Agile preferred.,Basic understanding of DevOps preferred.,Delivery - Intermediate delivery skills including the ability to estimate accurate timelines for tasks and deliver work at a steady, predictable pace to achieve commitments, contribute to the software design strategy and methodologies used to best meet the system requirements, consider and build for many different use cases, avoid over engineering, and ensure automation, deliver complete solutions but release them in small batches, and identify important tradeoffs and negotiate them.,Domain Expertise - Demonstrated track record of domain expertise including understanding technical concepts necessary to do the job effectively and aware of industry trends, demonstrate willingness, cooperation, and concern for business issues and priorities, and possess in depth knowledge of immediate systems worked on and some knowledge of adjacent systems.,Problem Solving - Strong problem solver who ensures solutions are built for the long term, is able to resolve new issues, recognizes mistakes using them as learning and teaching opportunities and consistently breaks down large problems into smaller, more manageable ones.,Communication - Strong communicator who possesses the ability to articulate information clearly and concisely with the business, document work in a clear, easy to follow manner, collaborate well with team members as both a mentor and mentee, take in vague requirements and ask the right questions to ensure clarification, offer feedback appropriately and effectively, seek out and receives constructive criticism well, listen when others are speaking and make space for colleagues to share their thoughts.","
The Travelers Companies, Inc.
Data Engineer (MDM)
Company Summary
Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.
Target Openings
1
Job Description Summary
Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our operational and analytics landscape. In addition to your strong analytical mind, you will bring your inquisitive attitude and ability to translate stories found in data by leveraging a variety of data programming techniques. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights.
This position may be based 100% remotely or in one of our offices.
Primary Job Duties & Responsibilities
Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions.
Design complex data solutions
Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes.
Incorporate core data management competencies including data governance, data security and data quality.
Collaborate within and across teams to support delivery and educate end users on complex data products/analytic environment.
Perform data and system analysis, assessment and resolution for complex defects and incidents and correct as appropriate.
Test data movement, transformation code, and data components.
Experience with Informatica MDM (IDD, UserExit, Business Entity, Provisioning tool, Publishing).
Experience with configure Match and Merge and refining match rules based on business requirement and data specification.
Experience with Web services and understanding of micro services architecture, experience integrate with MDM real time services with BES or SIF.
Experience with Database - SQL (Oracle/SQL Server/DB2/Teradata) , NoSQL (MongoDB, DynamoDB).
Experience with Match and Merge.
Basic understanding of Agile preferred.
Basic understanding of DevOps preferred.
Delivery - Intermediate delivery skills including the ability to estimate accurate timelines for tasks and deliver work at a steady, predictable pace to achieve commitments, contribute to the software design strategy and methodologies used to best meet the system requirements, consider and build for many different use cases, avoid over engineering, and ensure automation, deliver complete solutions but release them in small batches, and identify important tradeoffs and negotiate them.
Domain Expertise - Demonstrated track record of domain expertise including understanding technical concepts necessary to do the job effectively and aware of industry trends, demonstrate willingness, cooperation, and concern for business issues and priorities, and possess in depth knowledge of immediate systems worked on and some knowledge of adjacent systems.
Problem Solving - Strong problem solver who ensures solutions are built for the long term, is able to resolve new issues, recognizes mistakes using them as learning and teaching opportunities and consistently breaks down large problems into smaller, more manageable ones.
Communication - Strong communicator who possesses the ability to articulate information clearly and concisely with the business, document work in a clear, easy to follow manner, collaborate well with team members as both a mentor and mentee, take in vague requirements and ask the right questions to ensure clarification, offer feedback appropriately and effectively, seek out and receives constructive criticism well, listen when others are speaking and make space for colleagues to share their thoughts.
Leadership - Intermediate leadership skills with the ability to help create a safe environment for others to learn and grow as engineers and a proven track record of self-motivation in identifying opportunities and tracking team efforts.
Minimum Qualifications
Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
Four years of data engineering or equivalent experience.
Education, Work Experience, & Knowledge
Bachelor’s Degree in STEM related field or equivalent
Eight years of related experience
Highly proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and a full understanding of modern software engineering practices.
Job Specific Technical Skills & Competencies
The ability to deliver work at a steady, predictable pace to achieve commitments, deliver complete solutions but release them in small batches, and identify and negotiate important tradeoffs.
Demonstrated track record of domain expertise including understanding technical concepts necessary and industry trends, and possess in-depth knowledge of immediate systems worked on and some knowledge of adjacent systems.
Strong problem solver who ensures systems are built with longevity and creates innovate ways to resolve issues.
Strong written and verbal communication skills with the ability to work collaborate well with team members and business partners.
Ability to lead team members and help create a safe environment for others to learn and grow as engineers. and a proven track record of self-motivation in identifying opportunities and tracking team efforts.
Employment Practices
Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences.
If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.
Travelers reserves the right to fill this position at a level above or below the level included in this posting.
To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.
More From The Travelers Companies, Inc.
Related Job Listings
",https://www.insurancejournal.com/jobs/637571-data-engineer-mdm
JOB73778188786,"2 jobs with job title Data Engineer - San Francisco, California, United States","2 jobs with job title Data Engineer - San Francisco, California, United States",,,"
Browse for Data Engineer Jobs in San Francisco, California, United States. Find the job of your dreams on CareerCast.com today!
Search for Similar Listings
",https://www.careercast.com/jobs/data-engineer-san-francisco-california-351394804-b
JOB79466090988,"6 jobs with job title Data Engineer - San Jose, California, United States","6 jobs with job title Data Engineer - San Jose, California, United States",,,"
Browse for Data Engineer Jobs in San Jose, California, United States. Find the job of your dreams on CareerCast.com today!
Search for Similar Listings
",https://www.careercast.com/jobs/data-engineer-san-jose-california-342611411-b
JOB79792405824,Junior Integrity Data Engineer,Junior Integrity Data Engineer,"Configure and implement integrity and reliability systems for the Energy sector,Assemble large, complex datasets that meet functional / non-functional business requirements,Support data scientists in developing cutting edge technologies for data management and data analytics solutions,Support the inspection team setting up inspection databases and work scopes. This might include travelling to the site,Participate in requirement gathering sessions and integrity database specification preparation,Correctly adhere to the Company Health, Safety, Environment, & Quality policies,Diploma or Bachelor's Degree in a relevant Computer Science, Information Management or Engineering discipline,Up to 2 years of experience in integrity management system implementation. Intern experience in data engineering or related studies an asset,Must be familiar with using a variety of databases, and have working knowledge of using SQL with relational databases and query authoring,Must have working knowledge of software development and programming in any of the following (but not limited to): Python, JavaScript, Java, C++, PHP, HTML, REST APIs,Knowledge of data visualization and data analytics reporting (Power BI, Tableau) tools an asset,Must be highly proficient with Microsoft Office products, and have a basic understanding in Visual Basic Application (VBA),Familiarity with engineering codes and standards (API, ASME) and Integrity Management systems (NEXUS, COABIS, PCMS, RBMI, ULTRA PIPE, GE APM) preferred,Highly self-motivated, enthusiastic and committed to delivering first class technology engineering services,Excellent communication skills (written and verbal) in English; bilingualism an asset,Team player with good interpersonal skills and an ability to relate to those in a wide range of organizational roles,Demonstrated ability to understand complex problems and help identify practical and technically sound solutions,Must be US citizen, or authorized to work lawfully in the US, without sponsorship from Wood",,"
Company: Wood
Skills: IT - Analysis & Management, IT - Programming & Database
Experience: 2 + Years
Education: Bachelors/3-5 yr Degree
Location: Houston, Texas, United States
Overview / Responsibilities
Wood is presently recruiting for a Junior Integrity Data Engineer to support our Consulting business. The role is equivalent to a Data Engineer role, and will be seated in our Houston, TX office. The ideal candidate will have a technical background, be highly self-motivated, and have the desire to learn and work with a variety of disciplines on integrity projects.
This is an opportunity to work in a growing multidisciplinary team supporting projects through the development and implementation of software that tracks and controls the condition of key systems and equipment in the energy industry.
Key responsibilities
Configure and implement integrity and reliability systems for the Energy sector
Assemble large, complex datasets that meet functional / non-functional business requirements
Support data scientists in developing cutting edge technologies for data management and data analytics solutions
Support the inspection team setting up inspection databases and work scopes. This might include travelling to the site
Participate in requirement gathering sessions and integrity database specification preparation
Correctly adhere to the Company Health, Safety, Environment, & Quality policies
Skills / Qualifications
Diploma or Bachelor's Degree in a relevant Computer Science, Information Management or Engineering discipline
Up to 2 years of experience in integrity management system implementation. Intern experience in data engineering or related studies an asset
Must be familiar with using a variety of databases, and have working knowledge of using SQL with relational databases and query authoring
Must have working knowledge of software development and programming in any of the following (but not limited to): Python, JavaScript, Java, C++, PHP, HTML, REST APIs
Knowledge of data visualization and data analytics reporting (Power BI, Tableau) tools an asset
Must be highly proficient with Microsoft Office products, and have a basic understanding in Visual Basic Application (VBA)
Familiarity with engineering codes and standards (API, ASME) and Integrity Management systems (NEXUS, COABIS, PCMS, RBMI, ULTRA PIPE, GE APM) preferred
Highly self-motivated, enthusiastic and committed to delivering first class technology engineering services
Excellent communication skills (written and verbal) in English; bilingualism an asset
Team player with good interpersonal skills and an ability to relate to those in a wide range of organizational roles
Demonstrated ability to understand complex problems and help identify practical and technically sound solutions
Must be US citizen, or authorized to work lawfully in the US, without sponsorship from Wood
Company Overview
Wood is a global leader in engineering and consultancy across energy and the built environment, helping to unlock solutions to some of the world's most critical challenges. We provide consulting, projects and operations solutions in more than 60 countries, employing around 45,000 people. www.woodplc.com
Diversity Statement
We are an equal opportunity employer that recognises the value of a diverse workforce. All suitably qualified applicants will receive consideration for employment on the basis of objective criteria and without regard to the following (which is a non-exhaustive list): race, colour, age, religion, gender, national origin, disability, sexual orientation, gender identity, protected veteran status, or other characteristics in accordance with the relevant governing laws.
",https://www.rigzone.com/oil/jobs/postings/1106821_junior_integrity_data_engineer/
JOB79812793624,"Data Engineer (ETL, Ab Initio)","Data Engineer (ETL, Ab Initio)","Bachelor’s degree or its equivalent in work experience.,Delivery - Intermediate delivery skills including the ability to estimate accurate timelines for tasks and deliver work at a steady, predictable pace to achieve commitments, contribute to the software design strategy and methodologies used to best meet the system requirements, consider and build for many different use cases, avoid over engineering, and ensure automation, deliver complete solutions but release them in small batches, and identify important tradeoffs and negotiate them.,Domain Expertise - Demonstrated track record of domain expertise including understanding technical concepts necessary to do the job effectively and aware of industry trends, demonstrate willingness, cooperation, and concern for business issues and priorities, and possess in depth knowledge of immediate systems worked on and some knowledge of adjacent systems.,Problem Solving - Strong problem solver who ensures solutions are built for the long term, is able to resolve new issues, recognizes mistakes using them as learning and teaching opportunities and consistently breaks down large problems into smaller, more manageable ones.,Communication - Strong communicator who possesses the ability to articulate information clearly and concisely with the business, document work in a clear, easy to follow manner, collaborate well with team members as both a mentor and mentee, take in vague requirements and ask the right questions to ensure clarification, offer feedback appropriately and effectively, seek out and receives constructive criticism well, listen when others are speaking and make space for colleagues to share their thoughts.","Responsible for system programming and analysis tasks of advanced complexity within multiple systems.,Acts as subject matter expert for assigned applications, systems or technologies. Responsible for transforming business specifications/ Reverse Engineering documents and requirements into organized technical activities.,Responsibilities include performing complex analysis, assessment, resolution, design, configuration (includes defining technical requirements) and programming functions at an expert level with a high degree of accuracy and speed, operating as an individual contributor to team goals.,Leads investigation and resolution efforts for critical/ high impact defects, problems, and incidents. Collaborates with project team and other key stakeholders to identify, estimate, and prioritize project and/or enhancement activities.,Builds, maintains, and utilizes partnerships across the enterprise.,Provides team direction, mentorship, and feedback to technical resources.,Ensures work complies with Travelers standards, processes, and protocols. Applies knowledge of current industry trends and techniques to formulate solutions within the context of assigned projects and/or enhancements.,Provide technical guidance and mentorship to less experienced employees.,Seek opportunities to expand technical knowledge and capabilities.","
The Travelers Companies, Inc.
Data Engineer (ETL, Ab Initio)
Company Summary
Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.
Target Openings
1
Job Description Summary
Do you have experience in Data and Analytics including ETL tools such as Ab Initio? Are you seeking a dynamic, diverse and growth oriented environment in technology? Is passion for problem solving in your DNA? Are you seeking a company that offers comprehensive benefits including a pension and a matching 401K? Imagine the possibilities at Travelers!
The Reinsurance Technology group is seeking an Ab Initio Developer who performs expert programming, configuring, and analysis. Individual will complete advanced end to end engineering tasks for specific system assignments including designing, developing, analyzing, configuring, testing, debugging, troubleshooting, documenting, and implementing based on user or system specifications, consulting with users to determine hardware, software or system functional specifications, managing interaction between the systems and other technical support areas and defining technical requirements and coordinating team resources to solve problems. Individual will also lead technical work efforts and provide technical guidance to team members.
This position may be based 100% remotely or in one of our offices.
Primary Job Duties & Responsibilities
Responsible for system programming and analysis tasks of advanced complexity within multiple systems.
Acts as subject matter expert for assigned applications, systems or technologies. Responsible for transforming business specifications/ Reverse Engineering documents and requirements into organized technical activities.
Responsibilities include performing complex analysis, assessment, resolution, design, configuration (includes defining technical requirements) and programming functions at an expert level with a high degree of accuracy and speed, operating as an individual contributor to team goals.
Leads investigation and resolution efforts for critical/ high impact defects, problems, and incidents. Collaborates with project team and other key stakeholders to identify, estimate, and prioritize project and/or enhancement activities.
Builds, maintains, and utilizes partnerships across the enterprise.
Provides team direction, mentorship, and feedback to technical resources.
Ensures work complies with Travelers standards, processes, and protocols. Applies knowledge of current industry trends and techniques to formulate solutions within the context of assigned projects and/or enhancements.
Provide technical guidance and mentorship to less experienced employees.
Seek opportunities to expand technical knowledge and capabilities.
Work independently to tackle well-scoped and loosely scoped problems.
Minimum Qualifications
Bachelor’s degree or its equivalent in work experience.
Two years of programming/development experience.
Education, Work Experience, & Knowledge
Six years of programming/development experience preferred.
Experience with ETL tools such as Ab Initio preferred.
Cobol experience is preferred.
Experience with AWS is preferred.
Experience in an agile environment is preferred.
Leadership/Guidance/Mentoring experience needed
Job Specific Technical Skills & Competencies
Delivery - Intermediate delivery skills including the ability to estimate accurate timelines for tasks and deliver work at a steady, predictable pace to achieve commitments, contribute to the software design strategy and methodologies used to best meet the system requirements, consider and build for many different use cases, avoid over engineering, and ensure automation, deliver complete solutions but release them in small batches, and identify important tradeoffs and negotiate them.
Domain Expertise - Demonstrated track record of domain expertise including understanding technical concepts necessary to do the job effectively and aware of industry trends, demonstrate willingness, cooperation, and concern for business issues and priorities, and possess in depth knowledge of immediate systems worked on and some knowledge of adjacent systems.
Problem Solving - Strong problem solver who ensures solutions are built for the long term, is able to resolve new issues, recognizes mistakes using them as learning and teaching opportunities and consistently breaks down large problems into smaller, more manageable ones.
Communication - Strong communicator who possesses the ability to articulate information clearly and concisely with the business, document work in a clear, easy to follow manner, collaborate well with team members as both a mentor and mentee, take in vague requirements and ask the right questions to ensure clarification, offer feedback appropriately and effectively, seek out and receives constructive criticism well, listen when others are speaking and make space for colleagues to share their thoughts.
Leadership - Intermediate leadership skills with the ability to help create a safe environment for others to learn and grow as engineers and a proven track record of self-motivation in identifying opportunities and tracking team efforts.
Employment Practices
Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences.
If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.
Travelers reserves the right to fill this position at a level above or below the level included in this posting.
To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.
More From The Travelers Companies, Inc.
Related Job Listings
",https://www.insurancejournal.com/jobs/634082-data-engineer-etl-ab-initio
JOB80963280962,"Director, Big Data Engineer, Global Data Science Center of Excellence, Visa","Director, Big Data Engineer, Global Data Science Center of Excellence, Visa","8 - 10 years' application development and support experience.,Deep knowledge of distributed data architecture, commonly-used BI tools, and approaches/packages deployed for machine learning build,Experience creating production software/systems and a proven track record of identifying and resolving performance bottlenecks for production systems.,Experience in machine learning algorithm design, feature engineering, validation, prediction, recommendation, and measurement.,Experience with complex, high volume, multi-dimensional data, as well as machine learning models based on unstructured, structured, and streaming datasets.,Good understanding of the Payments and Banking Industry including aspects such as consumer credit, consumer debit, prepaid, small business, commercial, co-branded and merchant,Experience planning, organising, and managing multiple large projects with diverse cross-functional teams,Demonstrated ability to incorporate new techniques to solve business problems,Post Graduate Degree in Information Technology,Qualification in Computer Science or Engineering ideal.,Certification in Hadoop (Cloudera or Hortonworks) and Apache Spark.,Working knowledge of Hadoop ecosystem and associated technologies, e.g., Apache Spark, MLlib, GraphX, iPython, sci-kit, and Pandas,Advanced experience in writing and optimizing efficient SQL queries and Python scripts; Scala and C++ experience is ideal,Deliver results within committed scope, timeline and budget,Very strong people/project management skills and experience,Ability to travel within CEMEA on short notice,Results-oriented with strong problem solving skills and demonstrated intellectual and analytical rigor,Good business acumen with a track record in solving business problems through data-driven quantitative methodologies. Experience in payment, retail banking, or retail merchant industries is preferred,Team oriented, collaborative, diplomatic, and flexible style,Very detailed oriented, is expected to ensure highest level of quality/rigor in reports and data analysis,Proven skills in translating analytics output to actionable recommendations and delivery,Experience in presenting ideas and analysis to stakeholders whilst tailoring data-driven results to various audience levels,Exhibits intellectual curiosity and a desire for continuous learning,Exhibits intellectual curiosity and a desire for continuous learning,Demonstrates integrity, maturity and a constructive approach to business challenges,Role model for the organization and implementing core Visa Values,Respect for the Individuals at all levels in the workplace,Strive for Excellence and extraordinary results,Use sound insights and judgments to make informed decisions in line with business strategy and needs,Leadership skills include an ability to allocate tasks and resources across multiple lines of businesses and geographies. Leadership extends to ability to influence senior management within and outside Analytics groups,Ability to successfully persuade/influence internal stakeholders for building best-in-class solutions","Design local modifications to our global data architecture, including new tools and technologies where necessary to meet regional use-cases,Provide direction to the development of bespoke, client-specific data sandboxes,Create and maintain optimal data pipeline architecture(s), based on our Global Technology Stack,Identify, design, and implement internal process improvements to provide greater scalability to our existing client solutions,Develop custom-built packages and “glue code” to support the needs of Data Scientists across the region,Work with broader business stakeholders to assist clients and consultants with their data and infrastructure needs","
Director, Big Data Engineer, Global Data Science Center of Excellence, Visa
As the world's leader in digital payments technology, Visa's mission is to connect the world through the most creative, reliable and secure payment network - enabling individuals, businesses, and economies to thrive. Our advanced global processing network, VisaNet, provides secure and reliable payments around the world, and is capable of handling more than 65,000 transaction messages a second. The company's dedication to innovation drives the rapid growth of connected commerce on any device, and fuels the dream of a cashless future for everyone, everywhere. As the world moves from analog to digital, Visa is applying our brand, products, people, network and scale to reshape the future of commerce.
At Visa, your individuality fits right in. Working here gives you an opportunity to impact the world, invest in your career growth, and be part of an inclusive and diverse workplace. We are a global team of disruptors, trailblazers, innovators and risk-takers who are helping drive economic growth in even the most remote parts of the world, creatively moving the industry forward, and doing meaningful work that brings financial literacy and digital commerce to millions of unbanked and underserved consumers.
You're an Individual. We're the team for you. Together, let's transform the way the world pays.
Position Summary
The Director of Data Science is a lead Data Engineer role in the Central Europe, Middle East and Africa region (CEMEA) based out of Bangalore. We are looking for an expert with deep expertise in data warehousing and can build large-scale data processing systems by using the latest database technologies. This is a Pan-regional position and plays a critical role in enabling the data platforms through which Data Scientists, Analysts, and BI Users drive solutions for our Visa clients. Also, the role provides a bridge between our local end-users and our Visa Technology colleagues in San Francisco, influencing the development of our global data platforms whilst provisioning local tools and technologies as required. The Data Engineer takes responsibility for building and running data pipelines, designing our local data warehouse and data frameworks, and catering for different data presentation techniques.
Principal Responsibilities
Design local modifications to our global data architecture, including new tools and technologies where necessary to meet regional use-cases
Provide direction to the development of bespoke, client-specific data sandboxes
Create and maintain optimal data pipeline architecture(s), based on our Global Technology Stack
Identify, design, and implement internal process improvements to provide greater scalability to our existing client solutions
Develop custom-built packages and “glue code” to support the needs of Data Scientists across the region
Work with broader business stakeholders to assist clients and consultants with their data and infrastructure needs
Design architecture
Work with Visa’s Global Technology team to leverage our existing architecture to best effect, whilst identifying new and complementary tools and technology that will better enable our local solutions; serve as key contact and subject matter expert in working with the Visa Technology functions around the world (both global and regional)
Design sandbox architecture
Provide SME support to the design and build of client-specific data sandboxes that may leverage the advantages of cloud technologies whilst ensuring strong security and privacy controls
Build data pipelines
Build and operate stable, scalable data pipelines that cleanse, structure and integrate data sets into accessible formats for Data Scientists and other end-users, ensuring that testing and monitoring functions are performed appropriately
Supporting external clients’ data architecture
Provide Data Engineering expertise support to Visa’s select top-level clients, advising on how to implement, acquire, and improve their existing and planned data solutions. Such solutions can involve complex data integration from various sources (from an internal data warehouse, applicable VisaNet transaction data or third-party data) within the constraints of the client’s legal and regulatory limitations.
Implement for scale
Co-create and contribute to the design and deployment of scalable, high volume and real-time data solutions (dashboards, data feeds, and algorithms) running in production systems to ensure optimal functioning and sustainability of solutions built
Support Data Scientists
Provide advisory and hands-on support to Data Scientists by providing quality assurance to teams writing poor-quality data queries on our queue, and developing custom-built packages and “glue code” that take algorithms into production
Serve as subject matter expert
Provide support and advisory assistance to business stakeholders (client relationship managers, consultants, and other internal stakeholders) in framing potential use-cases, client engagements, and internal initiatives
Professional Experience
8 - 10 years' application development and support experience.
Deep knowledge of distributed data architecture, commonly-used BI tools, and approaches/packages deployed for machine learning build
Experience creating production software/systems and a proven track record of identifying and resolving performance bottlenecks for production systems.
Experience in machine learning algorithm design, feature engineering, validation, prediction, recommendation, and measurement.
Experience with complex, high volume, multi-dimensional data, as well as machine learning models based on unstructured, structured, and streaming datasets.
Good understanding of the Payments and Banking Industry including aspects such as consumer credit, consumer debit, prepaid, small business, commercial, co-branded and merchant
Experience planning, organising, and managing multiple large projects with diverse cross-functional teams
Demonstrated ability to incorporate new techniques to solve business problems
Demonstrated resource planning and delivery skills
Technical Expertise
Post Graduate Degree in Information Technology
Qualification in Computer Science or Engineering ideal.
Certification in Hadoop (Cloudera or Hortonworks) and Apache Spark.
Working knowledge of Hadoop ecosystem and associated technologies, e.g., Apache Spark, MLlib, GraphX, iPython, sci-kit, and Pandas
Advanced experience in writing and optimizing efficient SQL queries and Python scripts; Scala and C++ experience is ideal
Deliver results within committed scope, timeline and budget
Very strong people/project management skills and experience
Ability to travel within CEMEA on short notice
Business Experience
Results-oriented with strong problem solving skills and demonstrated intellectual and analytical rigor
Good business acumen with a track record in solving business problems through data-driven quantitative methodologies. Experience in payment, retail banking, or retail merchant industries is preferred
Team oriented, collaborative, diplomatic, and flexible style
Very detailed oriented, is expected to ensure highest level of quality/rigor in reports and data analysis
Proven skills in translating analytics output to actionable recommendations and delivery
Experience in presenting ideas and analysis to stakeholders whilst tailoring data-driven results to various audience levels
Exhibits intellectual curiosity and a desire for continuous learning
Leadership Competencies
Exhibits intellectual curiosity and a desire for continuous learning
Demonstrates integrity, maturity and a constructive approach to business challenges
Role model for the organization and implementing core Visa Values
Respect for the Individuals at all levels in the workplace
Strive for Excellence and extraordinary results
Use sound insights and judgments to make informed decisions in line with business strategy and needs
Leadership skills include an ability to allocate tasks and resources across multiple lines of businesses and geographies. Leadership extends to ability to influence senior management within and outside Analytics groups
Ability to successfully persuade/influence internal stakeholders for building best-in-class solutions
Change management leadership
",https://usa.visa.com/careers/job-details.jobid.743999691305943.deptid.1146504.html
JOB81877275114,"2 jobs with job title Data Engineer - Vancouver, British Columbia, Canada","2 jobs with job title Data Engineer - Vancouver, British Columbia, Canada",,," Browse for Data Engineer Jobs in Vancouver, British Columbia, Canada. Find the job of your dreams on CareerCast.com today!
Search for Similar Listings ",https://www.careercast.com/jobs/data-engineer-canada-364135600-b
JOB83437606167,Data Engineer (MicroStrategy),Data Engineer (MicroStrategy),"Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.,Four years of MicroStrategy reporting/development experience.,Familiarity with other BI technologies is plus.,Tech lead experience. Willingness to mentor other developers.,In depth understanding of databases and data warehouse principles (including proficiency in SQL query/SQL server DB/Oracle DB etc.).,Data normalization, dimensional modeling and OLAP cube experiences.,Strong verbal communication skill is a must, resilient in fast-paced challenging and agile environment.,Possesses a passion for data and data visualization.,Bachelor’s Degree in STEM related field or equivalent,Eight years of related experience,The ability to deliver work at a steady, predictable pace to achieve commitments, deliver complete solutions but release them in small batches, and identify and negotiate important tradeoffs.,Demonstrated track record of domain expertise including understanding technical concepts necessary and industry trends, and possess in-depth knowledge of immediate systems worked on and some knowledge of adjacent systems.,Strong problem solver who ensures systems are built with longevity and creates innovate ways to resolve issues.,Strong written and verbal communication skills with the ability to work collaborate well with team members and business partners.","Develop reporting solutions in business intelligence tools (MicroStrategy), this includes: performing analysis, design, development, and configuration functions (includes defining technical requirements) with a high degree of accuracy and speed, operating as a technical lead.,Maintain and stabilize reporting environment, this includes: analysis, assessment and resolution for defects and incidents of advanced complexity and escalate appropriately.,Work independently to tackle well-scoped and loosely scoped problems in regard to both business intelligence tools (MicroStrategy etc.) and data visualization artifacts (standard and ad hoc reports, queries, dashboards etc.).,Seek opportunities to expand technical knowledge and capabilities.,Provide technical guidance and mentorship to less experienced employees. In particular, mentor and train other developers in mastering business intelligence tools (MicroStrategy).,Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions.,Design complex data solutions,Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes.,Incorporate core data management competencies including data governance, data security and data quality.,Collaborate within and across teams to support delivery and educate end users on complex data products/analytic environment.,Perform data and system analysis, assessment and resolution for complex defects and incidents and correct as appropriate.","
The Travelers Companies, Inc.
Data Engineer (MicroStrategy)
Company Summary
Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.
Target Openings
1
Job Description Summary
Travelers is seeking a MicroStrategy Data Engineer II to join our organization as we grow and transform our reporting Technology landscape. Individual will complete advanced end to end reporting/business intelligence engineering tasks for complex system assignments including standard and ad hoc report/dashboard/metadata framework and other visual insights designing, developing, analyzing, configuring, testing, debugging, troubleshooting, documenting, health monitoring/alerting, and implementing based on reporting/analytics specifications, consulting with architects and report user stakeholders to determine hardware, software or system functional specifications, managing interaction between the systems and other technical support areas and defining technical requirements and coordinating team resources to solve problems.
Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape. In addition to your strong analytical mind, you will bring your inquisitive attitude and ability to translate stories found in data by leveraging a variety of data programming techniques. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights.
This position may be based 100% remotely or in one of our offices.
Primary Job Duties & Responsibilities
Develop reporting solutions in business intelligence tools (MicroStrategy), this includes: performing analysis, design, development, and configuration functions (includes defining technical requirements) with a high degree of accuracy and speed, operating as a technical lead.
Maintain and stabilize reporting environment, this includes: analysis, assessment and resolution for defects and incidents of advanced complexity and escalate appropriately.
Work independently to tackle well-scoped and loosely scoped problems in regard to both business intelligence tools (MicroStrategy etc.) and data visualization artifacts (standard and ad hoc reports, queries, dashboards etc.).
Seek opportunities to expand technical knowledge and capabilities.
Provide technical guidance and mentorship to less experienced employees. In particular, mentor and train other developers in mastering business intelligence tools (MicroStrategy).
Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions.
Design complex data solutions
Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes.
Incorporate core data management competencies including data governance, data security and data quality.
Collaborate within and across teams to support delivery and educate end users on complex data products/analytic environment.
Perform data and system analysis, assessment and resolution for complex defects and incidents and correct as appropriate.
Test data movement, transformation code, and data components.
Minimum Qualifications
Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
Four years of data engineering or equivalent experience.
Education, Work Experience, & Knowledge
Four years of MicroStrategy reporting/development experience.
Familiarity with other BI technologies is plus.
Tech lead experience. Willingness to mentor other developers.
In depth understanding of databases and data warehouse principles (including proficiency in SQL query/SQL server DB/Oracle DB etc.).
Data normalization, dimensional modeling and OLAP cube experiences.
Strong verbal communication skill is a must, resilient in fast-paced challenging and agile environment.
Possesses a passion for data and data visualization.
Bachelor’s Degree in STEM related field or equivalent
Eight years of related experience
Highly proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and a full understanding of modern software engineering practices.
Job Specific Technical Skills & Competencies
The ability to deliver work at a steady, predictable pace to achieve commitments, deliver complete solutions but release them in small batches, and identify and negotiate important tradeoffs.
Demonstrated track record of domain expertise including understanding technical concepts necessary and industry trends, and possess in-depth knowledge of immediate systems worked on and some knowledge of adjacent systems.
Strong problem solver who ensures systems are built with longevity and creates innovate ways to resolve issues.
Strong written and verbal communication skills with the ability to work collaborate well with team members and business partners.
Ability to lead team members and help create a safe environment for others to learn and grow as engineers. and a proven track record of self-motivation in identifying opportunities and tracking team efforts.
Employment Practices
Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences.
If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.
Travelers reserves the right to fill this position at a level above or below the level included in this posting.
To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.
More From The Travelers Companies, Inc.
Related Job Listings
",https://www.insurancejournal.com/jobs/634492-data-engineer-microstrategy
JOB84957231798,Intern-Data Engineer,Intern-Data Engineer,Be wary of Google Hangout or Skype interviews as these are not publicly-listed numbers that can be used to verify the legitimacy of the interviewer.,"Intern-Data Engineer,Attend meetings to learn about business practices, and internal processes and procedures.,Assist in developing and maintaining data solutions that support short and long-term information & analysis goals.,Develop and maintain ETL procedures for optimal processing of data from a wide variety of data sources. Ensure data is verified and quality is checked,Create and maintain SSRS reports to ensure business partners have information to make informed decisions.,Build analytic data sets to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.,Work with various Midco stakeholders to assist with data-related technical issues and support their data infrastructure needs.,Ensure data integrity through regular communications with IT developers, Analysts and SMEs,Write database documentation, including data standards, procedures and definitions for the data dictionary ('metadata').,Communicate effectively and professionally in all forms of communication with internal and external customers.,Adhere to Midco privacy guidelines to ensure each customer's privacy.,Maintain regular attendance as required by your position.,Function as an effective team member while supporting the efforts and concepts of other departments.,Support the mission, vision, and values of Midco.,Apply personal ethics, honesty, initiative, flexibility, responsibility and confidentiality in all areas of responsibility.,Possess an enthusiastic, energetic, self-motivated, and detail-oriented approach towards work and all work projects.,Possess strong problem solving and decision making skills while using good judgment.,Multi-task and change from one task to another without loss of efficiency or composure.,Maintain a positive work atmosphere by acting and communicating in a manner so that you get along with customers, clients, co-workers and management.,Identify opportunities for improvement while creating and implementing viable solutions,Actively follow Midco policies and procedures.,Perform other duties as assigned.,High School Diploma or GED equivalent and enrollment in a college or university pursuing an Associate's or Bachelor's degree in MIS or related field. Junior or Senior level student status, or recent graduate is highly preferred.,Experience or knowledge in dimensional modelling is preferred.,Knowledge of SQL server scripts and SSIS preferred.,Employees may be required to work in excess of 40 hours per week and other than normal business hours, such as holidays, evenings and weekends as business demands.,The employee is occasionally required to reach with hands and arms, stoop, kneel, or crouch. The employee must occasionally lift and/or carry loads of up to 30 lbs.,The noise level in the work environment is moderate.,Free and discounted Midco internet / cable,Tuition reimbursement,Support of employee involvement in the communities we serve,Employee referral program,Wellness programs,Never accept a check or other funds from a company to purchase materials necessary for your position.,Avoid and report situations where employers require payment or work without compensation as part of the application process.,Avoid corresponding with anyone who reaches out via text or email or outside of the Chegg Internships platform that you don't recognize.","
Intern-Data Engineer
Description
JOB PURPOSE: Support all aspects of Midco data strategy and enterprise data analytics. Focus on SQL development and ETL processes across Midco departments. Provide support in the database design, data flow and analysis activities. KEY FUNCTIONS:
Attend meetings to learn about business practices, and internal processes and procedures.
Assist in developing and maintaining data solutions that support short and long-term information & analysis goals.
Develop and maintain ETL procedures for optimal processing of data from a wide variety of data sources. Ensure data is verified and quality is checked
Create and maintain SSRS reports to ensure business partners have information to make informed decisions.
Build analytic data sets to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with various Midco stakeholders to assist with data-related technical issues and support their data infrastructure needs.
Ensure data integrity through regular communications with IT developers, Analysts and SMEs
Write database documentation, including data standards, procedures and definitions for the data dictionary ('metadata').
Communicate effectively and professionally in all forms of communication with internal and external customers.
Adhere to Midco privacy guidelines to ensure each customer's privacy.
Maintain regular attendance as required by your position.
ADDITIONAL FUNCTIONS AND RESPONSIBILITIES:
Function as an effective team member while supporting the efforts and concepts of other departments.
Support the mission, vision, and values of Midco.
Apply personal ethics, honesty, initiative, flexibility, responsibility and confidentiality in all areas of responsibility.
Possess an enthusiastic, energetic, self-motivated, and detail-oriented approach towards work and all work projects.
Possess strong problem solving and decision making skills while using good judgment.
Multi-task and change from one task to another without loss of efficiency or composure.
Maintain a positive work atmosphere by acting and communicating in a manner so that you get along with customers, clients, co-workers and management.
Identify opportunities for improvement while creating and implementing viable solutions
Actively follow Midco policies and procedures.
Perform other duties as assigned.
EXPERIENCE AND EDUCATION:
High School Diploma or GED equivalent and enrollment in a college or university pursuing an Associate's or Bachelor's degree in MIS or related field. Junior or Senior level student status, or recent graduate is highly preferred.
Experience or knowledge in dimensional modelling is preferred.
Knowledge of SQL server scripts and SSIS preferred.
WORK ENVIRONMENT AND PHYSICAL DEMANDS:
Employees may be required to work in excess of 40 hours per week and other than normal business hours, such as holidays, evenings and weekends as business demands.
The employee is occasionally required to reach with hands and arms, stoop, kneel, or crouch. The employee must occasionally lift and/or carry loads of up to 30 lbs.
The noise level in the work environment is moderate.
ABOUT MIDCO: Midco has been blazing trails since 1931, bringing innovation to the world of telecommunications and delighting customers with exceptional service. Through ambition, imagination and a genuine commitment to each other, Midco proudly serves more than 385,000 residential and business customers in 342 communities in Kansas, Minnesota, North Dakota, South Dakota, and Wisconsin. By 2025, Midco will deploy 10G, the next great leap for broadband while also expanding its fixed wireless network to rural areas. We're also dedicated to making our communities better places to live, work and play. Ready to work at Midco? We thought so. Here are a few more reasons why Midco is one of the best places to work:
Free and discounted Midco internet / cable
Tuition reimbursement
Support of employee involvement in the communities we serve
Employee referral program
Wellness programs
Visit MidcoCareers.com to learn about employment opportunities and apply today. Midco is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, creed, national origin, disability, protected Veteran status, age, marital status, status with regard to public assistance, familial status, membership or activity in a local commission, or any other characteristic protected by law.SDL2017
Skills
data analysis, database design, ssis, transact-sql (t-sql), microsoft sql server, ssrs, analytics, etl, databases, tableau, r programming, database administration, python, data mining, sas
Always be on the alert for potentially fraudulent job postings online. Report potential fraud to us if you're unsure about the legitimacy of a job posting or employer on Chegg Internships.
Never accept a check or other funds from a company to purchase materials necessary for your position.
Avoid and report situations where employers require payment or work without compensation as part of the application process.
Avoid corresponding with anyone who reaches out via text or email or outside of the Chegg Internships platform that you don't recognize.
Be wary of Google Hangout or Skype interviews as these are not publicly-listed numbers that can be used to verify the legitimacy of the interviewer.
",https://www.internships.com/posting/sam_3471021032
JOB86105707855,Senior Data Engineer,Senior Data Engineer,,," Employee • Singapore, Singapore • Added Oct 23 '18
• Ships high-quality code and believe in TDD
• Has deep experience with one or more programming languages such as Java, Scala and
Python
• Has experience designing micro-services or service-oriented architectures
• Has experience working with and understanding of Relational Databases
• Has experience working with one or more cloud providers, preferably AWS
• Enjoys digging into open-source projects and contributing back
• Is well versed with tools of the trade – Git, IDEs and build tools
• Has a keen desire to learn and grow
",https://www.f6s.com/tookitaki/jobs/38669/senior-data-engineer
JOB89501619459,"Lead Data Engineer (Python, ETL, AWS) - Remote","Lead Data Engineer (Python, ETL, AWS) - Remote","Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.,Bachelor’s Degree in STEM related field or equivalent,Experience with Python, AWS, ETL (Ab Initio),Excellent delivery skills with the ability to examine and assess the effectiveness of software design strategies and methodologies, devise, apply, and share ways to ensure the quality of complex computer systems, incorporate awareness and understanding of work happening outside of the team, and develop widely used technical metrics that enable engineers to better understand and deliver their work.,Demonstrated track record of domain expertise including the ability to improve company level capabilities within domain, consult on business priorities and optimize value by identifying business aligned solutions and thoughtfully and practically introduce concepts and technologies from the industry.,Strong problem solving skills with the ability to create architecture that is particularly robust against single points of failure, both in terms of systems and people, and looks ahead 6-12 months to identify areas of need and turns this into action.,Excellent communication skills with the ability to describe technology concepts in ways the business can understand, document effectively, collaborate across disparate groups, and model and assist others in the practice of mindful communication, active listening, and messaging.","Incorporate assurance processes into data solutions.,Guide team members as they build complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.,Design complex data solutions, including incorporating new data sources and ensuring designs are consistent across projects and aligned to data strategies.,Define and build frameworks for data solutions that can be applied to multiple projects.,Perform analysis of complex sources to determine value and utilize your subject matter expertise to recommend data to include in analytical processes.,Incorporate core data management competencies including data governance, data security and data quality.,Collaborate and build consensus with leadership and diverse groups of stakeholders in defining, estimating, prioritizing and planning of projects.,Perform data and system analysis, assessment and resolution for defects and incidents of high complexity and correct as appropriate.","
The Travelers Companies, Inc.
Lead Data Engineer (Python, ETL, AWS) - Remote
Company Summary
Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.
Target Openings
1
Job Description Summary
Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Lead Data Engineer you will work with business partners to modernize design standards and development practices to grow and transform our analytics landscape. Your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data will support Artificial Intelligence, Machine Learning and business intelligence/insights. As a data and technology subject matter expert you will influence strategy, support delivery, and translate complex data into user-friendly terminology to educate end users on data products and the analytic environment.
The role will be part of a full-stack data & reporting team to create data pipelines, ensure quality & accuracy, design & build BI visualizations, automate SQL scripts, all to deliver world-class data visualizations and analytics for our customers. Create and enhance data solutions that enable seamless integration and flow of data across the data ecosystem. Provide technical analysis and develop ETL code and scripting to meet all technical specifications and business requirements according to the established designs. Successful candidate will have a broad, conceptual understanding of the business and technology architecture trends and directions coupled with demonstrated technical mastery for technologies, frameworks, and/or languages and has the ability to influence and/or set technical direction.
This position may be based 100% remotely or in one of our offices.
Primary Job Duties & Responsibilities
Incorporate assurance processes into data solutions.
Guide team members as they build complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.
Design complex data solutions, including incorporating new data sources and ensuring designs are consistent across projects and aligned to data strategies.
Define and build frameworks for data solutions that can be applied to multiple projects.
Perform analysis of complex sources to determine value and utilize your subject matter expertise to recommend data to include in analytical processes.
Incorporate core data management competencies including data governance, data security and data quality.
Collaborate and build consensus with leadership and diverse groups of stakeholders in defining, estimating, prioritizing and planning of projects.
Perform data and system analysis, assessment and resolution for defects and incidents of high complexity and correct as appropriate.
Define standards and frameworks for testing on data movement and transformation code and data components.
Minimum Qualifications
Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
Seven years of data engineering or equivalent experience.
Education, Work Experience, & Knowledge
Bachelor’s Degree in STEM related field or equivalent
Experience with Python, AWS, ETL (Ab Initio)
Experience with Salesforce or MongoDB a plus
Job Specific Technical Skills & Competencies
Excellent delivery skills with the ability to examine and assess the effectiveness of software design strategies and methodologies, devise, apply, and share ways to ensure the quality of complex computer systems, incorporate awareness and understanding of work happening outside of the team, and develop widely used technical metrics that enable engineers to better understand and deliver their work.
Demonstrated track record of domain expertise including the ability to improve company level capabilities within domain, consult on business priorities and optimize value by identifying business aligned solutions and thoughtfully and practically introduce concepts and technologies from the industry.
Strong problem solving skills with the ability to create architecture that is particularly robust against single points of failure, both in terms of systems and people, and looks ahead 6-12 months to identify areas of need and turns this into action.
Excellent communication skills with the ability to describe technology concepts in ways the business can understand, document effectively, collaborate across disparate groups, and model and assist others in the practice of mindful communication, active listening, and messaging.
Strong leadership skills with the ability to engage with other leaders and networks to solve problems as well as work to improve the entire engineering organization by teaching others and sharing knowledge while creating opportunities for others to showcase and develop skills.
Employment Practices
Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences.
If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.
Travelers reserves the right to fill this position at a level above or below the level included in this posting.
To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.
More From The Travelers Companies, Inc.
Related Job Listings
",https://www.insurancejournal.com/jobs/634495-lead-data-engineer-python-etl-aws-remote
JOB89915617295,Cloud Data Engineer,Cloud Data Engineer,,,"
Overview
As a modernized technology company, our Slalom Technologists are disrupting the market and bringing to life the art of the possible for our clients. We have passion for building strategies, solutions and creative products to help our clients solve their most complex and interesting business problems. We surround our technologists with interesting challenges, innovative minds and emerging technologies. The Data & Analytics practice in Seattle is a full-service data practice with competencies across information strategy, modern data architecture, data visualization, and data science. We are seeking a Cloud Data Engineer to join our local Seattle consulting team.
What You’ll Do
• Partner with teams and customers to meet and exceed delivery commitments
• Use common data architecture practices to architect, design, and develop data/analytic platforms (e.g., data warehouses, data lakes) that are used to produce analytic products, like reports, dashboards, ML models, etc.
• Move, integrate, and cleanse data in highly collaborative agile environments
• Create impact through excellent client delivery, either independently or as part of a delivery team
• Deliver high-quality written, verbal, and/or visual communication to clients
What You’ll Bring
• 4+ years of data engineering and/or data warehousing experience
• 2+ years of experience building cloud data solutions (Azure, AWS, GCP, Snowflake)
• Deep experience with designing and deploying end to end solutions with a cloud platform’s analytic services including storage, permissions, private cloud, database services, virtual machines, and parallel processing technologies
• Experience with big data application development and/or with cloud data warehousing (e.g. Hadoop, Spark, Redshift, Snowflake, Azure SQL DW, BigQuery, S3)
• Experience owning technical solution delivery for small to medium-sized projects
About Slalom
Slalom is a modern consulting firm focused on strategy, technology, and business transformation. In 40 markets around the world, Slalom's teams have autonomy to move fast and do what's right. We are backed by regional innovation hubs, a global culture of collaboration, and partnerships with the world's top technology providers. Founded in 2001 and headquartered in Seattle, Slalom has organically grown to over 10,000 employees. Slalom has been named one of Fortune's 100 Best Companies to Work For five years running and is regularly recognized by employees as a best place to work.
Slalom prides itself on helping team members thrive in their work and life. As a result, Slalom is proud it invest in benefits that include: meaningful time off and paid holidays, parental leave, 401(k) with a match, a range of choices for highly subsidized health, dental, & vision coverage, adoption and fertility assistance, and short/long-term disability. We also offer additional benefits such as a yearly $350 reimbursement account for any well-being related expenses as well as discounted home, auto, and pet insurance.
Slalom is an equal opportunity employer that is committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veterans status, or any other characteristic protected by federal, state, or local laws.
",https://www.geekwire.com/jobs/job/slalom-seattle-2-cloud-data-engineer/
JOB90033272989,Data Engineer,Data Engineer,,"Full access to our jobs board, including over 1,000 exclusive jobs,Your Devex profile highlighted in recruiter search results,Connections to recruiters and industry experts through online and live Devex events","
See the full details of this exclusive job – and all of the other big development opportunities hand picked by our team. These positions are only available with a Career Account. Upgrade now to keep your job search moving.
Starting at $9.50, a Devex Career Account provides you:
Full access to our jobs board, including over 1,000 exclusive jobs
Your Devex profile highlighted in recruiter search results
Connections to recruiters and industry experts through online and live Devex events
",https://www.devex.com/jobs/data-engineer-697808
JOB90252328266,Graduate Data Engineer - Subsea Projects,Graduate Data Engineer - Subsea Projects,"Support the delivery of a diverse portfolio of data-driven and machine learning projects for Wood's global energy, environment, and infrastructure clients.,Develop data-driven solutions, dashboards and workflow automations using high-level programming languages (such as Python and R) and low-code platforms such as the MS Power Platform and Palantir Foundry.,Prepare large and complex data sets using high-level programming languages and data and cloud compute services (mainly Azure, but also AWS).,Continually learn new technologies and data solution platforms.,Assist with preparation & delivery project technical presentations and reports.,Travel as required for project meetings & workshops across the global business.,Data and analytics programming experience with Python and/or R.,Comfortable with the prospect of handling engineering and sensor data from equipment and machines (e.g., pressures, temperatures, flowrates, fluid densities) to derive insight (working alongside various subject matter experts internal and external to the business).,Experience of working with at least one mainstream cloud computing service such as Microsoft Azure or Amazon Web Services.,Working knowledge of SQL for data access, manipulation, and validation.,Presentation, reporting and excellent communication skills.,Flexibility and openness to work on a variety of data challenges across various business domains, for both internal and external clients.,Bachelor's degree in an applicable engineering discipline, engineering science, computer science, or data analytics.,Bachelor's degree in an applicable engineering discipline, engineering science, computer science, or data analytics.",,"
Company: Wood
Skills: Subsea Engineering
Education: Bachelors/3-5 yr Degree
Location: Galway, County Galway, Ireland
Overview / Responsibilities
Graduate Data Engineer - Subsea Projects - Wood Ireland (Galway office based)
Company Description:
Wood is an international energy services company that operates in more than 60 countries worldwide, working with clients to design, build, operate and improve facilities across the oil and gas, industrial, clean energy, and power generation industries.
Wood's operations support and technical services teams use advanced data analytics, cloud, and software services to optimise the operation, inspection, and integrity management of energy infrastructure for global clients.
Role Overview:
Wood is seeking to recruit a Graduate Data Engineer to be part of a leading global technical services business. This is a significant opportunity to develop your digital career and thrive in a problem solving, solutions-focused environment, where you will be responsible for the delivery and development of data-driven solutions to our global customers.
Key Responsibilities:
Support the delivery of a diverse portfolio of data-driven and machine learning projects for Wood's global energy, environment, and infrastructure clients.
Develop data-driven solutions, dashboards and workflow automations using high-level programming languages (such as Python and R) and low-code platforms such as the MS Power Platform and Palantir Foundry.
Prepare large and complex data sets using high-level programming languages and data and cloud compute services (mainly Azure, but also AWS).
Continually learn new technologies and data solution platforms.
Assist with preparation & delivery project technical presentations and reports.
Travel as required for project meetings & workshops across the global business.
Competencies & Skills Required:
Data and analytics programming experience with Python and/or R.
Comfortable with the prospect of handling engineering and sensor data from equipment and machines (e.g., pressures, temperatures, flowrates, fluid densities) to derive insight (working alongside various subject matter experts internal and external to the business).
Experience of working with at least one mainstream cloud computing service such as Microsoft Azure or Amazon Web Services.
Working knowledge of SQL for data access, manipulation, and validation.
Presentation, reporting and excellent communication skills.
Flexibility and openness to work on a variety of data challenges across various business domains, for both internal and external clients.
Qualifications & Experience Requirements:
Bachelor's degree in an applicable engineering discipline, engineering science, computer science, or data analytics.
Skills / Qualifications
Qualifications & Experience Requirements:
Bachelor's degree in an applicable engineering discipline, engineering science, computer science, or data analytics.
Company Overview
Wood is a global leader in engineering and consultancy across energy and the built environment, helping to unlock solutions to some of the world's most critical challenges. We provide consulting, projects and operations solutions in more than 60 countries, employing around 45,000 people. www.woodplc.com
Diversity Statement
We are an equal opportunity employer that recognises the value of a diverse workforce. All suitably qualified applicants will receive consideration for employment on the basis of objective criteria and without regard to the following (which is a non-exhaustive list): race, colour, age, religion, gender, national origin, disability, sexual orientation, gender identity, protected veteran status, or other characteristics in accordance with the relevant governing laws.
",https://www.rigzone.com/oil/jobs/postings/1103473_Graduate_Data_Engineer_-_Subsea_Projects/
JOB90381334952,We're hiring for Staff Big Data Engineer at Integral Ad Science,We're hiring for Staff Big Data Engineer at Integral Ad Science,,,,https://www.themuse.com/jobs/integraladscience/staff-big-data-engineer-a834fa
JOB90820425883,Consultant : Data Engineer,Consultant : Data Engineer,Connections to recruiters and industry experts through online and live Devex events,"Full access to our jobs board, including over 1,000 exclusive jobs,Your Devex profile highlighted in recruiter search results","
See the full details of this exclusive job – and all of the other big development opportunities hand picked by our team. These positions are only available with a Career Account. Upgrade now to keep your job search moving.
Starting at $9.50, a Devex Career Account provides you:
Full access to our jobs board, including over 1,000 exclusive jobs
Your Devex profile highlighted in recruiter search results
Connections to recruiters and industry experts through online and live Devex events
",https://www.devex.com/jobs/consultant-data-engineer-686278
JOB92249597280,"22,000+Results for ""Data Engineer Jobs in India""(1,149 new)","22,000+Results for ""Data Engineer Jobs in India""(1,149 new)",,,,https://in.linkedin.com/jobs/data-engineer-jobs
JOB93371208988,Senior Data Engineer - MicroStrategy,Senior Data Engineer - MicroStrategy,"Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.,Bachelor’s Degree in STEM related field or equivalent.,10 years of software engineering experience within the Data and Analytics field.,Hands on experience working in MicroStrategy is a must.,Design MicroStrategy architecture and construct reporting solutions including standard reports, documents, Dossiers, etc.,Experience with other Analytic/Data Visualization tools (e.g.: Qlik, Cognos) preferred.,Experience with one or more Data platforms and Data Integration tools (e.g.: Snowflake, Teradata, Talend) preferred.,Experience with AWS would be a plus.,Must demonstrate a proactive nature with willingness to contribute, collaborate and work in an agile team environment.,Exposure with DevOps pipeline and implementation practices.","Architect MicroStrategy platform-based Business Intelligence projects.,Design complex data solutions, including incorporating new data sources and ensuring designs are consistent across projects and aligned to data strategies.,Interacts with business engagement teams to define dashboards and reporting solutions to meet diverse, complex business needs.,Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes.,Incorporate core data management competencies including data governance, data security and data quality.,Act as a data and technology subject matter expert within lines of business to support delivery and educate end users on data products/analytic environment.","
The Travelers Companies, Inc.
Senior Data Engineer - MicroStrategy
Company Summary
Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.
Target Openings
1
Job Description Summary
As a Senior Data Engineer you will accelerate growth and transformation of our analytics landscape. You will bring a strong desire to guide team members' growth and develop data solutions that translate complex data into user-friendly terminology. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights.
This position may be based 100% remotely or in one of our offices.
Primary Job Duties & Responsibilities
Architect MicroStrategy platform-based Business Intelligence projects.
Design complex data solutions, including incorporating new data sources and ensuring designs are consistent across projects and aligned to data strategies.
Interacts with business engagement teams to define dashboards and reporting solutions to meet diverse, complex business needs.
Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes.
Incorporate core data management competencies including data governance, data security and data quality.
Act as a data and technology subject matter expert within lines of business to support delivery and educate end users on data products/analytic environment.
Collaborate across team to support delivery and educate end users on complex data products/analytic environment.
Minimum Qualifications
Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
Five years of data engineering or equivalent experience.
Education, Work Experience, & Knowledge
Bachelor’s Degree in STEM related field or equivalent.
10 years of software engineering experience within the Data and Analytics field.
Advanced knowledge of tools, techniques, and manipulation including cloud platforms, programming languages, and modern software engineering practices.
Job Specific Technical Skills & Competencies
Hands on experience working in MicroStrategy is a must.
Design MicroStrategy architecture and construct reporting solutions including standard reports, documents, Dossiers, etc.
Experience with other Analytic/Data Visualization tools (e.g.: Qlik, Cognos) preferred.
Experience with one or more Data platforms and Data Integration tools (e.g.: Snowflake, Teradata, Talend) preferred.
Experience with AWS would be a plus.
Must demonstrate a proactive nature with willingness to contribute, collaborate and work in an agile team environment.
Exposure with DevOps pipeline and implementation practices.
Enjoy learning new technologies with strong learning ability.
Employment Practices
Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences.
If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.
Travelers reserves the right to fill this position at a level above or below the level included in this posting.
To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.
More From The Travelers Companies, Inc.
Related Job Listings
",https://www.insurancejournal.com/jobs/636221-senior-data-engineer-microstrategy
JOB93670180750,Data Engineer,Data Engineer,"BS/MS degree in Computer Science, Engineering or related field,3 or more years of experience architecting and building processes that extract, process and add value to data sets from multiple source systems.,Experiencing with data modeling and tuning of relational as well as NoSQL datastores (Oracle, Red-shift, Impala, HDFS/Hive, Athena, etc.),Experience working with distributed computing tools (Spark, Hive, etc.),Experience with AWS cloud services: EC2, EMR, RDS, Redshift, S3, Lambda,Experience with data pipeline and workflow management tools: Airflow, etc.,3 or more years of experience with one or more general purpose programming languages, including but not limited to: Java, Scala, C, C++, C#, Swift/Objective C, Python, or JavaScript.,3 or more years experience working with and leading agile development methodologies such as Sprint and Scrum,Experience with Software engineering best-practices, including but not limited to version control (Git, TFS, Subversion, etc.), CI/CD (Jenkins, Maven, Gradle, etc.), automated unit testing, Dev Ops.,Experience with Semantic technologies and approaches is a plus.,Biotech / Pharma experience is a plus","Collaborate with Data Architects, Business SME's, and Data Scientists to architect data products and services.,Build data products and service processes which perform data transformation, metadata extraction, workload management and error processing management.,Implement standardized, automated operational and quality control processes to deliver accurate and timely data and reporting to meet or exceed SLAs.,Contribute to the Exploration and understanding of new tools, and techniques and propose improvements to the data pipeline,Integrate the operations data platform with the Data Scientist workbench, the Data Marketplace, and Analytic Tools such as Tableau, Spotfire, R, etc.,Act as a product manager for the operations data platform backlog"," Amgen is committed to unlocking the potential of biology for patients suffering from serious illnesses by discovering, developing, manufacturing and delivering creative human therapeutics. This approach begins by using tools like advanced human genetics to unravel the complexities of disease and understand the fundamentals of human biology.
Amgen focuses on areas of high unmet medical need and uses its expertise to strive for solutions that improve health outcomes and dramatically improve people's lives. A biotechnology pioneer since 1980, Amgen has grown to be one of the world's leading independent biotechnology companies, has reached millions of patients around the world and is developing a pipeline of medicines with breakaway potential.
'Main Job Purpose:
Amgen is seeking Data Engineers to help realize Amgen's Operations Data Strategy. This program will produce business insights through data science solutions. You will build upon our awarded Enterprise Data Lake to develop value added data products that span the Operations Domain (Process Development, Supply Chain, Quality, Engineering, Manufacturing). There is no more challenging data environment than Life Sciences due to the integration of scientific research, manufacturing, logistics of pharmaceutical products. Expect to make a difference in providing patients with products that meet their medical needs in a competitive landscape.
Key Activities for the Data Engineer include:
Collaborate with Data Architects, Business SME's, and Data Scientists to architect data products and services.
Build data products and service processes which perform data transformation, metadata extraction, workload management and error processing management.
Implement standardized, automated operational and quality control processes to deliver accurate and timely data and reporting to meet or exceed SLAs.
Contribute to the Exploration and understanding of new tools, and techniques and propose improvements to the data pipeline
Integrate the operations data platform with the Data Scientist workbench, the Data Marketplace, and Analytic Tools such as Tableau, Spotfire, R, etc.
Act as a product manager for the operations data platform backlog
Act as a run manager, provide Run/DevOps support
Basic Qualifications:
Master's degree
OR
Bachelor's degree and 2 years of Information Systems experience
OR
Associate degree and 6 years of Information Systems experience
OR
High school diploma / GED and 8 years of Information Systems experience
Preferred Qualifications:
BS/MS degree in Computer Science, Engineering or related field
3 or more years of experience architecting and building processes that extract, process and add value to data sets from multiple source systems.
Experiencing with data modeling and tuning of relational as well as NoSQL datastores (Oracle, Red-shift, Impala, HDFS/Hive, Athena, etc.)
Experience working with distributed computing tools (Spark, Hive, etc.)
Experience with AWS cloud services: EC2, EMR, RDS, Redshift, S3, Lambda
Experience with data pipeline and workflow management tools: Airflow, etc.
3 or more years of experience with one or more general purpose programming languages, including but not limited to: Java, Scala, C, C++, C#, Swift/Objective C, Python, or JavaScript.
3 or more years experience working with and leading agile development methodologies such as Sprint and Scrum
Experience with Software engineering best-practices, including but not limited to version control (Git, TFS, Subversion, etc.), CI/CD (Jenkins, Maven, Gradle, etc.), automated unit testing, Dev Ops.
Experience with Semantic technologies and approaches is a plus.
Biotech / Pharma experience is a plus
Full stack development using infrastructure cloud services (AWS preferred) and cloud-native tools and design patterns (Containers, Serverless, Docker, etc) is a plus.
Our culture is what makes Amgen a special place to work. We have a powerful shared purpose around our mission - to serve patients. We respect one another, recognize contributions, and have embedded collaboration, trust, empowerment and inclusion in all that we do.
We equip all our staff members to live well-rounded, healthy lives. Most recently, Amgen added benefits for transgender employees and continues to pride itself on industry-leading, family-friendly offerings for families of all compositions.
Amgen is an Equal Opportunity employer and will consider you without regard to your race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.
",https://www.biospace.com/job/1982985/data-engineer/
JOB94443835480,Data Engineer,Data Engineer,,,"
What You'll Do:
As a Data Engineer, you are responsible for architecting, developing, scaling and maintaining data pipelines and analytics infrastructure, covering a wide range of technologies, with a specific focus on high availability, scalability and security of customer data.
This position also consists of architecting, building, and launching new data models, systems and tools to enable the team to understand and consume data faster.
The role is for highly technical software engineers who combine outstanding communication skills and a deep expertise in large-scale and data-intensive cloud-based systems.
You will also have the capability to architect highly scalable distributed systems, using open source tools.
Who You'll Work With:
The team is made of highly talented engineers with passion for innovation who turn disruptive ideas into products that impact the industry.
They are tackling their next challenge and are looking for agile, pragmatic and talented engineers with deep expertise.
and hands-on experience in data, cloud and highly scalable infrastructure. If technology and innovation is your passion, this could be the place for you.
Who You Are:
You are a talented Data Engineer keen to build innovative solutions that have the potential to disrupt whole industries.
You thrive in a fast-paced, dynamic environment that requires a unique blend of innovation, risk taking and speed of execution.
Extensive coding and programming in a range of languages such as Python, Scala, Java, R, etc.
Experience with building stream-processing systems, using solutions such as Storm or Spark-Streaming.
Good understanding of Lambda Architecture, along with its advantages and drawbacks.
Solid experience with dimensional data modelling and schema design for NoSQL databases at scale.
How to Apply?
Click on the link below
Click here for more information about this job
Contact Details
Contact Name: Josh Whitehead
",https://www.cio.com.au/jobs/view/26275/data-engineer/
JOB96436294956,"Data Engineer ( Microstrategy, Ab Initio, Talend )","Data Engineer ( Microstrategy, Ab Initio, Talend )","Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.,Experience with Microstrategy, Ab Initio and/or Talend required,Bachelor’s Degree in STEM related field or equivalent,Six years of related experience,The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions.,Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on.,Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems.,Strong verbal and written communication skills with the ability to interact with team members and business partners.","Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.,Design data solutions.,Analyze sources to determine value and recommend data to include in analytical processes.,Incorporate core data management competencies including data governance, data security and data quality.,Collaborate within and across teams to support delivery and educate end users on data products/analytic environment.,Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate.","
The Travelers Companies, Inc.
Data Engineer ( Microstrategy, Ab Initio, Talend )
Company Summary
Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.
Target Openings
1
Job Description Summary
Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape. In addition to your strong analytical mind, you will bring your inquisitive attitude and ability to translate the stories found in data. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights.
This position may be based 100% remotely or in one of our offices.
Primary Job Duties & Responsibilities
Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.
Design data solutions.
Analyze sources to determine value and recommend data to include in analytical processes.
Incorporate core data management competencies including data governance, data security and data quality.
Collaborate within and across teams to support delivery and educate end users on data products/analytic environment.
Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate.
Test data movement, transformation code, and data components.
Minimum Qualifications
Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
Four years of data engineering or equivalent experience.
Education, Work Experience, & Knowledge
Experience with Microstrategy, Ab Initio and/or Talend required
Bachelor’s Degree in STEM related field or equivalent
Six years of related experience
Proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and an understanding of software engineering practices.
Job Specific Technical Skills & Competencies
The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions.
Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on.
Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems.
Strong verbal and written communication skills with the ability to interact with team members and business partners.
Leadership - Intermediate leadership skills with a proven track record of self-motivation in identifying personal growth opportunities.
Employment Practices
Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences.
If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.
Travelers reserves the right to fill this position at a level above or below the level included in this posting.
To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.
More From The Travelers Companies, Inc.
Related Job Listings
",https://www.insurancejournal.com/jobs/639205-data-engineer-microstrategy-ab-initio-talend
JOB96558207436,8 jobs with job title Data Engineer at Wells Fargo,8 jobs with job title Data Engineer at Wells Fargo,,,,https://www.careercast.com/jobs/wells-fargo-data-engineer-367372630-b
JOB97542811674,Data Engineer,Data Engineer,"Minimum of 3 years of professional software development experience in a hands-on data-centric role in data engineering, architecture, streaming or warehousing is REQUIRED.,Experience with at least one modern server-side language (such as Python, Java, or similar) is REQUIRED.,Experience with at least one relational database technology (MySQL, Postgres, MS SQL, etc.) is REQUIRED.,Proficient with SQL is REQUIRED.,Familiarity with cloud services and infrastructure, preferably AWS,Familiarity with columnar store databases (Vertica, Redshift, Snowflake, etc.),Experience building out data ingest pipelines,Experience building out or working within Extract, Load, Transform / Data Lake architectures,Comfortable working with a mix of structured & unstructured data from a variety of sources is preferred,Experience with schema design,Experience with Spark, DataFrames, pandas a big plus,Experience transforming partially or fully unstructured data into more easily queryable formats,Experience tuning databases for performance,Experience working in an agile environment such as Scrum or Kanban,Knowledge of machine learning tools & concepts a plus,Fun, collaborative environment,Optional work-from-home Wednesdays,Competitive compensation and benefits package, including medical, dental, and vision insurance,5 weeks of PTO and 10 paid holidays (total 7 weeks),401k,Stock options,Commuter benefits,Stocked kitchens, with coffee, soda, and snacks,Regular team activities, including Mariners games, ping pong tournaments, movies, etc.","You’re passionate about getting at data and creating high quality, easy to consume views into that data,You continually improve by learning from others, and you jump in when a teammate could use your help,You care about your customers, and understand how your data contributes to the goals of the business,You have an agile mindset, and are comfortable refining vague requirements,You can sense miscommunications among team members, and do your part to improve understanding,You thrive in and contribute to a positive work environment, where everyone shares constructive thoughts and suggestions","
Overview
Yapta’s mission is simple: To give our customers confidence in travel. To that end, we are one of the world’s leading companies for fare transparency and cost savings. We analyze billions of rates every month, and turn all that data into meaningful notifications and reports. We provide automated services for corporate travelers to save money, by tracking prices on airline tickets and hotels, and sending alerts when prices drop.
We were recently named to Deloitte’s Fast 500, are highly profitable, and have grown 400% in the past 4 years. Our team is fast paced and focused, but we maintain a healthy work/life balance and have fun. We value integrity, flexibility, accountability, drive, and collaboration.
Are you excited about the convergence of technology and travel? Do you want to be a part of a cohesive agile team? Do you fall asleep thinking about indexes, transforms, and solutions for streaming data ingest? Come help us build our cutting-edge data platform, powering insights used by some of the biggest brands in the world.
How you’ll succeed on the team:
You’re passionate about getting at data and creating high quality, easy to consume views into that data
You continually improve by learning from others, and you jump in when a teammate could use your help
You care about your customers, and understand how your data contributes to the goals of the business
You have an agile mindset, and are comfortable refining vague requirements
You can sense miscommunications among team members, and do your part to improve understanding
You thrive in and contribute to a positive work environment, where everyone shares constructive thoughts and suggestions
Requirements: (Must have experience to be eligible for consideration.)
Minimum of 3 years of professional software development experience in a hands-on data-centric role in data engineering, architecture, streaming or warehousing is REQUIRED.
Experience with at least one modern server-side language (such as Python, Java, or similar) is REQUIRED.
Experience with at least one relational database technology (MySQL, Postgres, MS SQL, etc.) is REQUIRED.
Proficient with SQL is REQUIRED.
Preferred Experience: (Very helpful skills as they will be important in this role.)
Familiarity with cloud services and infrastructure, preferably AWS
Familiarity with columnar store databases (Vertica, Redshift, Snowflake, etc.)
Experience building out data ingest pipelines
Experience building out or working within Extract, Load, Transform / Data Lake architectures
Comfortable working with a mix of structured & unstructured data from a variety of sources is preferred
Experience with schema design
Experience with Spark, DataFrames, pandas a big plus
Experience transforming partially or fully unstructured data into more easily queryable formats
Experience tuning databases for performance
Experience working in an agile environment such as Scrum or Kanban
Knowledge of machine learning tools & concepts a plus
What we offer:
Fun, collaborative environment
Optional work-from-home Wednesdays
Competitive compensation and benefits package, including medical, dental, and vision insurance
5 weeks of PTO and 10 paid holidays (total 7 weeks)
401k
Stock options
Commuter benefits
Stocked kitchens, with coffee, soda, and snacks
Regular team activities, including Mariners games, ping pong tournaments, movies, etc.
This position is based in Pioneer Square in Downtown Seattle. Candidates must be eligible to work in the US.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.
Our sole focus is to save our customers money. Founded in 2007, Yapta is guided by technology experts and veterans of the travel management industry. We know what it’s like to balance travel budgets, wondering whether it’s better to book now or wait and see. To find the greatest savings, we developed FareIQ TM and RoomIQ TM Intelligent Price Tracking TM services for corporate travel and Yapta price tracking technology for personal travel. We’re delighted with the results. We’ve tracked pricing on millions of flights, executed billions of price checks and identified over $550 million in savings for travelers.
",https://www.geekwire.com/jobs/job/yapta-seattle-wa-2-data-engineer-2/
JOB97965184315,Data Engineer - Data Catalog,Data Engineer - Data Catalog,"Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.,Bachelor’s Degree in STEM related field or equivalent,Prior experience with data catalog tools including experience with data lineage, meta data management.,The ability to deliver work at a steady, predictable pace to achieve commitments, deliver complete solutions but release them in small batches, and identify and negotiate important tradeoffs.,Strong problem solver who ensures systems are built with longevity and creates innovate ways to resolve issues.","Incorporate core data management competencies including data governance, data security and data quality.,Collaborate within and across teams to support delivery and educate end users on complex data products/analytic environment.,Perform data and system analysis, assessment and resolution for complex defects and incidents and correct as appropriate.,Test data movement, transformation code, and data components.,Stay up to date on all features and functions of software tools.,Work, update, escalate, and resolve trouble tickets submitted by end users.,Work with end users to identify root cause of issues, resolve and train on proper procedure.,Work with development team to gain expert level understanding of the software and extended features.,Develop end user documentation on software functions, procedures, tasks, and troubleshooting.,Train new hires on the use and function of both the software and endpoint device.,Assist in data reconciliation efforts.","
The Travelers Companies, Inc.
Data Engineer - Data Catalog
Company Summary
Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.
Target Openings
1
Job Description Summary
Travelers Data Engineering team contextualize and provide easy access to data for the entire enterprise.
As a Data Engineer Data Catalog, you will play a key role in growing and transforming our analytics landscape. In addition to your strong analytical mind, you will bring your inquisitive attitude and ability to design, build and deploy data solutions that capture explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights.
Primary Job Duties & Responsibilities
Incorporate core data management competencies including data governance, data security and data quality.
Collaborate within and across teams to support delivery and educate end users on complex data products/analytic environment.
Perform data and system analysis, assessment and resolution for complex defects and incidents and correct as appropriate.
Test data movement, transformation code, and data components.
Stay up to date on all features and functions of software tools.
Work, update, escalate, and resolve trouble tickets submitted by end users.
Work with end users to identify root cause of issues, resolve and train on proper procedure.
Work with development team to gain expert level understanding of the software and extended features.
Develop end user documentation on software functions, procedures, tasks, and troubleshooting.
Train new hires on the use and function of both the software and endpoint device.
Assist in data reconciliation efforts.
Perform other duties as assigned.
Minimum Qualifications
Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
Four years of data engineering or equivalent experience.
Education, Work Experience, & Knowledge
Bachelor’s Degree in STEM related field or equivalent
Highly proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and a full understanding of modern software engineering practices.
Job Specific Technical Skills & Competencies
Prior experience with data catalog tools including experience with data lineage, meta data management.
The ability to deliver work at a steady, predictable pace to achieve commitments, deliver complete solutions but release them in small batches, and identify and negotiate important tradeoffs.
Strong problem solver who ensures systems are built with longevity and creates innovate ways to resolve issues.
Strong written and verbal communication skills with the ability to work collaborate well with team members and business partners.
Employment Practices
Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences.
If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.
Travelers reserves the right to fill this position at a level above or below the level included in this posting.
To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.
More From The Travelers Companies, Inc.
Related Job Listings
",https://www.insurancejournal.com/jobs/634475-data-engineer-data-catalog
JOB98300266411,Data Engineer,Data Engineer,,," DATA ENGINEER Location: New York, NY or Toronto, ON Black Diamond Therapeutics
is a next-wave cancer precision medicine company. Black Diamond pioneered the development of selective medicines for patients with genetically defined cancers driven by oncogenes activated by allosteric mutations. Using its mutation, allostery and pharmacology (MAP) computational and discovery platform, Black Diamond is uncovering new ways to functionally assess the mutational landscape of individual oncogenes - to discover and validate new targets and develop novel approaches to creating highly selective therapeutics. Black Diamond has an immediate need for a Data Engineer. Reporting to the Director of Computational Sciences & Proteomics, the incumbent will implement bioinformatic workflows and relational databases to analyze and store genomic data. Working closely with a team of scientists with diverse backgrounds, the Data Engineer will contribute to the drive of drug discovery projects to reshape and extend the pipeline of precision oncology medicines.
Key Duties & Responsibilities:
• Implement and maintain databases for storing and manipulating genomic/proteomic data
• Develop web interfaces for genomic data interpretation and dissemination
• Contribute in the design and development of cloud-based bioinformatics workflows
• Responsible for data protection and must have a working knowledge of AWS computing
• Maintain current knowledge of data related technologies, software development and overall best practices.
Qualifications:
• BSc. or MSc. in Computer Science, Bioinformatics, Computational Biology or a related quantitative discipline.
• 1-3+ years of industry experience
• Excellent programming skills in Python, bash, SQL in a Linux environment
• Demonstrate a solid understanding of statistical concepts, experience with R programming
• Working knowledge of Git or a similar source control tool
• Experience with Docker or other containerization technologies
• Excellent oral and written communication skills
Black Diamond Therapeutics is an equal opportunity employer and welcomes and encourages all applications. Diversity and inclusion are important core values and will encourage our creativity and growth as a company. Accommodations are available on request for candidates taking part in all aspects of the selection process. We thank all applicants for their interest, however, only those selected will be invited for an interview.
",https://www.biospace.com/job/2007766/data-engineer/
JOB99243669939,We're hiring for Digital Supply Chain Data Engineer - EC Hub at Unilever,We're hiring for Digital Supply Chain Data Engineer - EC Hub at Unilever,,,,https://www.themuse.com/jobs/unilever/digital-supply-chain-data-engineer-ec-hub
JOB100368110867,Data Engineer – Predictive Model Implementations,Data Engineer – Predictive Model Implementations,,,"
Company Information
Solid reputation, passionate people and endless opportunities. That's Travelers. Our superior financial strength and consistent record of strong operating returns mean security for our customers - and opportunities for our employees. You will find Travelers to be full of energy and a workplace in which you truly can make a difference.
Job Summary
The Claim Business Intelligence & Analytics organization is looking for a Data Engineer to join our Analytic Platform team. This position will focus on implementing predictive models within our models as a service framework and will work with and develop APIs, batch services and real-time services. This position will support all lines of business and will partner closely with the Claim Technology group. The role will work with many different tools and technologies, and successful candidates should be comfortable working with SQL and Python. Experience working in an agile and/or test-driven development framework, experience working with a big data platform (i.e. Hadoop) and/or experience working with a cloud platform (i.e. AWS) are all pluses.
Marketing Description
Primary Job Duties & Responsibilities
Data Analysis, Acquisition, Preparation, and Exploration: Independently perform Data Acquisition, Prep and Exploration: reviews, prepares, basic design, and integrates data. Able to correct minor problems and implements data cleansing/quality solutions. Apply moderate and develops basic data derivations, business transformation rules, and data requirements. Present simple data visualizations to help support data exploration as needed. Data Solutions & Analytic Implementations: Operationalize and automate well defined simple data products independently. Build, test, and implement simple analytic processes, including pilots and proof of concept. Assist in training business users on data products/analytic environment. Delivers basic training. Apply knowledge of current industry trends and techniques to formulate solutions within the context of assigned projects. Data Culture: Continue to develop insurance and business intelligence knowledge while learning how work assignments address business issues. Understand Travelers standards, processes, and environmental landscape. Incorporate core data management competencies - data governance, data security, data quality. Share knowledge with peer users on data or analytic products. Perform other duties as assigned.
Minimum Qualifications
1 year of relevant experience with data tools, techniques, and manipulation required.
Education, Work Experience & Knowledge
Education: College Degree in STEM related field Technical Knowledge: Intermediate knowledge of data tools, techniques, and manipulation preferred. Examples (but not limited to): Big data and Cloud platforms Programming languages - SAS, SQL, Spark, Python, Hive, AWS Visualization platforms: QlikView, Tableau and Qlik Sense Experience: 3 years of relevant experience with data tools, techniques, and manipulation preferred.
Job Specific & Technical Skills & Competencies
Communication Skills: Ability to communicate thoughts/designs/ideas in an unambiguous manner and adjusts communication based on audience. Exhibits active and effective communication skills with team members - including active listening and effective written and verbal communication skills. Effectively contributes and communicates with the immediate team. Problem Solving & Decision Making: Able to recognize and analyze business and data issues of intermediate complexity with minimal supervision. Recognize when escalation is necessary. Able to leverage previous experience to consider a variety of alternatives to arrive at a timely, practical, and cost-effective solution to resolve defects or incidents. Relationship Management: Ability to foster relationships with peers to achieve objectives. Practices objectivity and openness to others' views. Able to recognize and support team priorities. Planning and Project Management: Ability to manage time and competing priorities and provide management with accurate and timely status information. Able to effectively evaluate and estimate routine tasks with clear precedent.
Physical Requirements
Operates standard office equipment - Continuously Sitting (Can stand at will) - Continuously Use of Keyboards, Sporadic 10-Key - Continuously.
#Dice
Equal Employment Opportunity Statement
Travelers is an equal opportunity employer.
",https://www.insurancejournal.com/jobs/555607-data-engineer-predictive-model-implementations
JOB100470931969,Senior Data Engineer – (BERLIN),Senior Data Engineer – (BERLIN),A competitive salary,"A Data Engineer, BI or database developer who is passionate about having a meaningful, global impact,Experience in data integration, cleaning, validation and analysis,Strong SQL skills, proficiency with R and Git,DevOps, System or Database Administration experience,History of working with Docker and Azure, or familiar services,A pro-active problem-solver with strong analytical skills and a good sense for code and data quality,Further technical expertise, such as web development or data visualisation is very welcome,Expertise in finance is a big plus,Fluent English,Design and implement systems to make our data analysis reliable, transparent and reproducible,Maintain, extend and improve our existing data infrastructure and related services,Support and train colleagues for continuous improvement of skills,Handle technical communication with stakeholders and external partners,Evaluate and develop technical solutions for new projects and use cases,A meaningful impact on one of the planet’s most pressing issues,Engaging working environment in a young, international and rapidly expanding team and the chance to work at a cutting-edge think tank,Flexible working hours,Chance to take on responsibility and shape a project from your first day onwards,Opportunity for significant career development","
Job Description
Who we are:
A global, independent think tank on the integration of long-term and climate-related objectives and risks into financial market metrics, processes and regulation.
Since its set up in 2012 with the mission to align financial markets with climate goals, the 2° Investing Initiative (2°ii) has become a pioneering think tank on the integration of long-term risks and policy objectives into financial markets and regulatory frameworks. Over the past years, 2°ii has led one of the largest global research programmes on long-term risks in financial markets, working with over 50 research partners. It developed the first scenario analysis tool linking financial portfolios to international climate goal which was applied by >1,500 financial institutions by now. A core principle of its mission is to reduce transaction costs across companies, financial institutions and policymakers, while guiding financial markets towards the long-term future.
Current research includes market outlook reports, physical risk incorporation and enhancement of existing, analytical methods. 2°ii combines business intelligence databases from several climate-relevant sectors with financial datasets and climate scenarios as well as with other relevant third-party datasets to assess climate risks such as physical risk maps, etc. This database is used to assess the exposure of stocks, bonds and other financial instruments to energy-related technologies, as well as to build a sustainability-ready, open-source robo-adviser.
2°ii has a multi-stakeholder and independent governance framework designed to ensure the intellectual integrity of its work and its independence. More information can be found at www.2degrees-investing.org
What we are looking for:
A Data Engineer, BI or database developer who is passionate about having a meaningful, global impact
Experience in data integration, cleaning, validation and analysis
Strong SQL skills, proficiency with R and Git
DevOps, System or Database Administration experience
History of working with Docker and Azure, or familiar services
A pro-active problem-solver with strong analytical skills and a good sense for code and data quality
Further technical expertise, such as web development or data visualisation is very welcome
Expertise in finance is a big plus
Fluent English
What you will be doing:
Design and implement systems to make our data analysis reliable, transparent and reproducible
Maintain, extend and improve our existing data infrastructure and related services
Support and train colleagues for continuous improvement of skills
Handle technical communication with stakeholders and external partners
Evaluate and develop technical solutions for new projects and use cases
What we offer:
A meaningful impact on one of the planet’s most pressing issues
Engaging working environment in a young, international and rapidly expanding team and the chance to work at a cutting-edge think tank
Flexible working hours
Chance to take on responsibility and shape a project from your first day onwards
Opportunity for significant career development
A competitive salary
How to Apply
Interested in changing finance to fight climate change? Please send your CV and cover letter in English indicating your earliest possible start date to: jobs@2degrees-investing.org We are committed to building a diverse team and encourage applications from female and minority candidates.
Apply for this Job
Message *
Upload resumé (pdf, doc, docx, zip, txt, rtf)
",https://feedproxy.google.com/~r/RJobs/~3/GrutIRqnl5U/
JOB101709039342,SQL Data Engineer,SQL Data Engineer,,"Managing the investigation of corporate data requirements, documenting them according to the required standards utilising the prescribed methods and tools,Implementing data flows to connect operational systems, data for analytics and BI systems. Re-engineer manual data flows to enable scaling and repeatable use,Working closely with data architects (to determine what data management systems are appropriate) and data scientists (to determine what data is needed for analysis).,Tackling problems associated with database integration and unstructured data sets,Ensuring that those using the data structures and associated components have a good understanding and that any queries are dealt with promptly and efficiently,Strong technical process understanding regardless of technology,Wide range of strong technical skills (i.e. Azure Devops, Azure Data Factory, Data Bricks, SQL, python),Core SQL Competencies – SSMS, SSIS, T-SQL, Stored Procedures,ADF Pipelines to build and populate SQL databases,Background in migrating traditional MS products to Azure,Ability to create efficient DW or DL structures to minimise cost of orchestration / processing and ingestion of data,Very high attention to detail,Strong communication skills,Efficient in building ETL and ELT processes for enterprise solutions,Strong software delivery methods and knowledge,Digital delivery – has a track record of working on DevOps delivery,Exposure in Climate Change data legislation, practices and stakeholders,Experience in Environmental related industries i.e Water, Energy, Forestry related,Presentation skills,Understanding of architecting solutions taking into account wider considerations","
SQL Data Engineer
Job purpose and background
Are you a capable SQL Data Engineer who is passionate about the power of data to solve environmental issues? CDP are looking for an SQL Data Engineer to shape delivery by collaborating with data architects and modellers to contribute to the acquisition of corporate data requirements, documenting them according to the required standards utilising the prescribed methods and Azure data tools, in order to build our centralised data platform.
This is a permanent role, with responsibility for developing, constructing, testing and maintaining architectures such as data pipelines and large-scale data processing warehouses. The post-holder will leverage industry best practice while delivering changes, such as agile backlogs, code repositories, automated builds, testing and releases. They will be responsible for ensuring data scientists can pull relevant data sets for their analyses, implement data pipelines to connect operational systems, data for analytics and BI systems. The role includes re-engineering manual data flows to enable automation, scaling and repeatable use and developing data set processes for data modelling, mining and production.
The post-holder will work closely with data architects (to determine what data management systems are appropriate) and data scientists (to determine which data are needed for analysis). They will provide clean, usable data to the business through the data platform in accordance with governance, and analyse, design, plan, execute and evaluate data requirements to support business activities and projects. The post-holder will be central in ensuring the delivery of world-class digital products and changing the delivery culture in CDP.
About CDP's data engineering team:
The Data Engineering Team’s primary remit is to improve the usability of the climate change, water, forests and cities data disclosed to CDP through robust and transparent methods. The team will create sustainable data pipelines for data quality monitoring, data cleaning, reporting and data science modelling. Harmonised data collected from external sources will enrich the data assets’ value and enhance accessibility for CDP’s stakeholders. The team will produce value-adding insight delivering it through data products that help internal and external stakeholders to better understand the quantitative and qualitative results of their actions. This in turn helps stakeholders to make data-led decisions and optimise for all constraints. Through every stage the data assets are governed by the industry practice standards in a robust and transparent manner.
Key responsibilities include:
Managing the investigation of corporate data requirements, documenting them according to the required standards utilising the prescribed methods and tools
Implementing data flows to connect operational systems, data for analytics and BI systems. Re-engineer manual data flows to enable scaling and repeatable use
Working closely with data architects (to determine what data management systems are appropriate) and data scientists (to determine what data is needed for analysis).
Tackling problems associated with database integration and unstructured data sets
Ensuring that those using the data structures and associated components have a good understanding and that any queries are dealt with promptly and efficiently
In liaison with the information management or IT management functions, contributing to the development and maintenance of corporate data standards
Required skills and experience:
Strong technical process understanding regardless of technology
Wide range of strong technical skills (i.e. Azure Devops, Azure Data Factory, Data Bricks, SQL, python)
Core SQL Competencies – SSMS, SSIS, T-SQL, Stored Procedures
ADF Pipelines to build and populate SQL databases
Background in migrating traditional MS products to Azure
Ability to create efficient DW or DL structures to minimise cost of orchestration / processing and ingestion of data
Very high attention to detail
Strong communication skills
Efficient in building ETL and ELT processes for enterprise solutions
Strong software delivery methods and knowledge
Strong performance-tuning skills.
Desired skills and experience
Digital delivery – has a track record of working on DevOps delivery
Exposure in Climate Change data legislation, practices and stakeholders
Experience in Environmental related industries i.e Water, Energy, Forestry related
Presentation skills
Understanding of architecting solutions taking into account wider considerations
Structured problem solving techniques.
This is a permanent full-time role, reporting to the Head of Data Engineering, which will be delivered remotely to start with. The post holder will be required to travel to CDP’s London office from time to time when it reopens.
Salary and benefits: Between £45,000 - £48,500 per annum dependent on experience, 30 days holiday excluding bank holidays, flexible working opportunities and others benefits.
Interested applicants must be eligible to work legally in the United Kingdom.
Before you apply
We’ll only use the information you provide to process your application. For more details on how we use your information, see our applicants privacy notice. By emailing us your CV and covering letter, you are permitting CDP to use the information you have provided for recruitment purposes.
To apply please email your CV and a covering letter setting out how you meet the required skills and experience or key responsibilities, which should be no more than two pages, to recruitment@cdp.net with ‘DI-SQL Data Engineer, Firstname Surname’ in the subject. Applications will be reviewed on a rolling basis, so early applications are strongly encouraged. The deadline is 8.00 am on 19 October 2020.
Are you interested in a career at CDP working in one of our global offices?
Explore our current job vacancies
",https://www.cdp.net/fr/info/careers/sql-data-engineer-2
JOB101905535450,Data Engineer,Data Engineer,,,"
DESCRIPTION
Do you want to build the analytics to understand and accelerate large scale migrations to AWS? Migrating to AWS is one of the most impactful business decisions AWS customers make and we want your help to better understand our customers' migration journeys. For customers large and small, migrating to AWS can have an enormously positive impact on their costs, agility, and employee growth. Here in the Migration Services team, we€™re working closely with customers to invent new approaches to migrations, build scalable systems, and use machine learning to solve problems that haven€™t been solved yet.
As a Data Engineer in AWS Migration Services you will work on the data pipeline and analytics to provide business and engineering stakeholders key insights into our customers€™ migration journeys. You will get the exciting opportunity to interact with very large data sets in one of the most complex data warehouse environments. Our data pipeline combines metrics from multiple data sources including Amazon Redshift, Salesforce, and Amazon S3. You will have the opportunity to help business and engineering stakeholders determine what migration related metrics they should be tracking and establish new and expand existing automated data collection to feed into the data pipeline. You will regularly apply your analytical and problem solving skills and perform analysis with tools like Jupyter, SageMaker, and Pandas so we better understand customer migrations and how we can accelerate their migrations.
Day-to-day you will:
· Work closely with product management, sales, and business stakeholders to analyze data from a multitude of sources about customers€™ migrations and how we can accelerate their migrations.
· Design, implement, and maintain a data pipeline and analytical environment using third-party and in-house reporting tools, modeling metadata, and building reports and dashboards.
· Use creative problem-solving to automate the collection and analysis from available data sources in order to deliver actionable output.
· Iteratively improve analysis and identify new metrics to improve analytics.
BASIC QUALIFICATIONS
· 2+ years of relevant work experience in analytics, data engineering, business intelligence or related field
· 2+ years of programming experience in languages like Python
· Demonstrable ability in data modeling, ETL development, and data warehousing, or similar skills
· Experience with reporting tools like Tableau, Excel or other BI packages
· Experience in working and delivering end-to-end projects independently.
· SQL proficiency
· B.S. degree in mathematics, statistics, computer science or a similar quantitative field
PREFERRED QUALIFICATIONS
· Graduate degree in mathematics, statistics, computer science or a similar quantitative field
· 5+ years of hands-on experience in writing complex, optimized SQL queries across large datasets.
· 5+ years of hands-on experience with data analysis tools like Jupyter and Pandas.
· Experience working with a diverse set of business and engineering stakeholders at all levels
· Experience with AWS technologies including Redshift, SageMaker, EMR, RDS, S3, and Kinesis
· Demonstrated ability to coordinate projects across functional teams, including engineering, sales, product management, finance, and operations
· Proven track record of successful communication of analytical outcomes through written communication, including an ability to effectively communicate with both business and technical teams
Amazon is an Equal Opportunity-Affirmative Action Employer €“ Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.
",https://www.careercast.com/jobs/data-engineer-boston-ma-02109-118802877-d
JOB102030424227,Senior Data Engineer: Sustainability,Senior Data Engineer: Sustainability,,"Full access to our jobs board, including over 1,000 exclusive jobs,Your Devex profile highlighted in recruiter search results,Connections to recruiters and industry experts through online and live Devex events","
See the full details of this exclusive job - and all of the other big development opportunities hand picked by our team. These positions are only available with a Career Account. Upgrade now to keep your job search moving.
Starting at $9.50, a Devex Career Account provides you:
Full access to our jobs board, including over 1,000 exclusive jobs
Your Devex profile highlighted in recruiter search results
Connections to recruiters and industry experts through online and live Devex events
",https://www.devex.com/jobs/senior-data-engineer-sustainability-591021
JOB103541253819,"Virginia Tech: Data Engineer [Blacksburg, VA]","Virginia Tech: Data Engineer [Blacksburg, VA]","BS in Computer Science, Computer Engineering, Data Analytics/Data Science, Physics, Mathematics, Information Systems, Engineering or other quantitative disciplines.,Experience in extracting, processing, curating, integrating, and analyzing data using Python, Spark, SQL,Hands on experience with AWS services – Kinesis, S3, Glue, Lambda, Cloudformation, RDS, EC2, EMR or HDFS, Hadoop Yarn, Hbase, Hive, Pig,Hands on experience in ELT/ETL and dimensional data modeling,Proficiency in Python and at least one SQL language such as T-SQL or PL/SQL,Excellent knowledge of relational and non-relational database systems,Ability to think creatively, and solve problems,Ability to work in a highly collaborative and dynamic work environment,Effective written and oral communication skills,Experience in building production data pipelines using Python, SQL, Spark and AWS environment (Kinesis, S3, Glue, Lambda, Cloudformation, RDS) or HDFS (Hadoop Yarn, Hbase, Hive, Pig),Strong programming experience in Python, Spark, Scala,Experience in ETL/ELT and dimensional data modeling,Experience in working with relational/non-relational databases and advanced SQL/NoSQL scripting,Familiarity with data pipeline and workflow management tools such as Airflow, AWS Step functions, Nifi","Experienced data pipeline developers with a proven track-record of developing, deploying, and optimizing data systems to support analytics from the ground up,Data and tech savvy,Innately curious and fast learners,Self-motivated team players with a drive to get things done,Design, develop, scale, and maintain data pipelines that extract, load, transform, and integrate data from wide variety of data sources to provide uniform view.,Automate and optimize the data pipelines to improve productivity, processing performance and reliability, and minimize error-prone processes.,Monitor data consumption patterns and ensure responsible use of provisioned data by the data consumers.,Collaborate with data stewards and data governance teams to implement the data governance and compliance best practices.,Support data scientists and data analysts by optimizing data management and delivery processes.","
At: Virginia Tech
Location: Blacksburg, VA
Web: vt.edu
Position: Data Engineer
Apply here.
About Virginia Tech:
Virginia Tech is a public land-grant university, committed to teaching and learning, research, and outreach to the Commonwealth of Virginia, the nation, and the world. Building on its motto of Ut Prosim (that I may serve), Virginia Tech is dedicated to InclusiveVT—serving in the spirit of community, diversity, and excellence. We seek candidates who adopt and practice the Principles of Community, which are fundamental to our on-going efforts to increase access and inclusion, and to create a community that nurtures learning and growth for all of its members. Virginia Tech actively seeks a broad spectrum of candidates to join our community in preparing leaders for the world.
Position Summary:
The Office of Academic Decision Support is looking for a data engineer to help design and build data pipelines and data systems to support the development of data products and solutions that will help decision makers at all levels of the institution gain necessary insights to improve the – services, student and faculty experience, resource management, and institutional effectiveness. We are looking for professionals who are,
Experienced data pipeline developers with a proven track-record of developing, deploying, and optimizing data systems to support analytics from the ground up
Data and tech savvy
Innately curious and fast learners
Self-motivated team players with a drive to get things done
Responsibilities:
Design, develop, scale, and maintain data pipelines that extract, load, transform, and integrate data from wide variety of data sources to provide uniform view.
Automate and optimize the data pipelines to improve productivity, processing performance and reliability, and minimize error-prone processes.
Monitor data consumption patterns and ensure responsible use of provisioned data by the data consumers.
Collaborate with data stewards and data governance teams to implement the data governance and compliance best practices.
Support data scientists and data analysts by optimizing data management and delivery processes.
Required Qualifications:
BS in Computer Science, Computer Engineering, Data Analytics/Data Science, Physics, Mathematics, Information Systems, Engineering or other quantitative disciplines.
Experience in extracting, processing, curating, integrating, and analyzing data using Python, Spark, SQL
Hands on experience with AWS services – Kinesis, S3, Glue, Lambda, Cloudformation, RDS, EC2, EMR or HDFS, Hadoop Yarn, Hbase, Hive, Pig
Hands on experience in ELT/ETL and dimensional data modeling
Proficiency in Python and at least one SQL language such as T-SQL or PL/SQL
Excellent knowledge of relational and non-relational database systems
Ability to think creatively, and solve problems
Ability to work in a highly collaborative and dynamic work environment
Effective written and oral communication skills
Preferred Qualifications:
Experience in building production data pipelines using Python, SQL, Spark and AWS environment (Kinesis, S3, Glue, Lambda, Cloudformation, RDS) or HDFS (Hadoop Yarn, Hbase, Hive, Pig)
Strong programming experience in Python, Spark, Scala
Experience in ETL/ELT and dimensional data modeling
Experience in working with relational/non-relational databases and advanced SQL/NoSQL scripting
Familiarity with data pipeline and workflow management tools such as Airflow, AWS Step functions, Nifi
Must have a conviction check: Yes
Employment Comments:
Virginia Tech has a strong commitment to the principle of diversity and, in that spirit, seeks a broad spectrum of candidates including women, minorities, and people with disabilities. Individuals with disabilities desiring accommodations in the application process should contact University ADA services at (540) 231-9331, and TTY number: (800) 828-1120 by the application deadline.
How to Apply for this Job:
Interested candidates should apply online at www.jobs.vt.edu (posting number AP0190104 ) and include a letter of application that addresses qualifications for and interest in the position along with a comprehensive curriculum vita and contact information for three references.
For further information, please contact Abhay Joshi, Director, Academic Data Analysis and Visualization, abhayaj@vt.edu, 540-239-9781.
Review of materials begins on April 22, 2019.
Employee Category: Administrative and Professional Faculty
Appointment Type: Regular
FLSA Status: Exempt: Not eligible for overtime
Tenure Status: Non-Tenure Track
Academic Year or Calendar Year: Calendar Year
Percent Employment: Full-time
Pay Range: Commensurate with Experience
Location: Blacksburg
Department: Academic Decision Support Services
Location Zip Code: 24061
Work Schedule: M-F 8-5
Review Begin Date:04/22/2019
Restricted to university employees only? No
Equal Opportunity/Affirmative Action Statement:
Virginia Tech does not discriminate against employees, students, or applicants on the basis of age, color, disability, sex (including pregnancy), gender, gender identity, gender expression, genetic information, national origin, political affiliation, race, religion, sexual orientation, or veteran status, or otherwise discriminate against employees or applicants who inquire about, discuss, or disclose their compensation or the compensation of other employees or applicants, or on any other basis protected by law.
Reasonable Accommodation Statement:
If you are an individual with a disability and desire accommodation please contact the hiring department.
Quick Link: http://listings.jobs.vt.edu/postings/96257
PI109712808
",https://www.kdnuggets.com/jobs/19/05-06-virginia-tech-data-engineer.html
JOB103693423929,Avail - Staff Data Engineer (Remote Home Based Worker),Avail - Staff Data Engineer (Remote Home Based Worker),"6 or more years of related experience,Experience in best practices for building secure and high-performance integrations for data ingestion from external data sources and APIs,Experience in creating maintainable and scalable ETL data pipelines,Advanced experience in Data Modelling or Data Warehousing and creating ETL pipelines,Advanced skills in software engineering and SDLC (our stack includes Python and Rust).,Must consider code readability, reuse, and extensibility a priority when developing solutions.","Design and implement scalable data workflows and pipelines, and integrate diverse data sources and sinks,Design appropriate complex database schemas and optimize database deployment architectures for analytics query loads,Implement data transforms and organization for various data stores (data lakes and warehouses),Design and implement new platform architectures for building and serving computationally challenging machine learning models under tight response time requirements,Provide tooling and automation for infrastructure, continuous testing, and continuous deploy of data systems,Work with the platform operations team to monitor and maintain live production systems","
Allstate
Avail - Staff Data Engineer (Remote Home Based Worker)
Avail is a car sharing service to help people get where they want to go–whether that’s to run errands, take an unforgettable road trip, or explore a new city–while helping locals earn cash from their unused cars. We are passionate about making shared transportation safe, simple, and affordable, and redefining what it means to own a car.
We’ve assembled some of the sharpest folks from across industries to compete against the antiquated system of traditional car rental. We put ideas into action and learn along the way in an open, collaborative work environment. As a part of Avail, you’ll make a direct impact and help build a business from the ground up. No matter where you’ve been, we’re always looking for fresh thinking and new perspectives.
Summary
As part of the Avail Data Engineering team, you will be working to manage our ever-growing collection of vehicle sharing and usage data. We support our business analytics and marketing teams by performing data integration and ETL between an increasingly diverse set of data sources and our data warehouse. We will also build big-data applications leveraging techniques from operations research and machine learning to directly enrich, personalize and optimize the Avail car-sharing product. This is a green field opportunity to contribute to the design and implementation of a flexible, scalable data framework for an exciting new sector of the sharing economy.
Job Description
Design and implement scalable data workflows and pipelines, and integrate diverse data sources and sinks
Design appropriate complex database schemas and optimize database deployment architectures for analytics query loads
Implement data transforms and organization for various data stores (data lakes and warehouses)
Design and implement new platform architectures for building and serving computationally challenging machine learning models under tight response time requirements
Provide tooling and automation for infrastructure, continuous testing, and continuous deploy of data systems
Work with the platform operations team to monitor and maintain live production systems
Job Qualifications
Education and Experience
6 or more years of related experience
Bachelor’s degree or equivalent experience
Functional Experience
Experience in best practices for building secure and high-performance integrations for data ingestion from external data sources and APIs
Experience in creating maintainable and scalable ETL data pipelines
Advanced experience in Data Modelling or Data Warehousing and creating ETL pipelines
Advanced skills in software engineering and SDLC (our stack includes Python and Rust).
Must consider code readability, reuse, and extensibility a priority when developing solutions.
Demonstrated experience in performing operations and automation of various data ecosystems in production environments on AWS or a related cloud service
Compensation Data
Compensation range for this position is $96,500 - $174,600 per year, based on experience and qualifications.
That’s the day to day, here’s the bigger picture.
Avail was founded by The Allstate Corporation in 2018. But you’ll be working for (and at) Avail. Our work environment blends the ingenuity and flexibility of a startup with the scale and strengths of a Fortune 100 company. Perks include a generous PTO policy, flexible working options, and a focus on leadership, wellness, and culture. We also offer 401k, health insurance, and other employment benefits for your future.
See a job you love? We encourage you to apply, even if your experience isn’t a perfect match.
Learn more about life at Avail. Connect with us on Instagram and LinkedIn.
We generally do not sponsor individuals for employment-based visas for this position.
Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.
For jobs in San Francisco, please click “here” for information regarding the San Francisco Fair Chance Ordinance.
For jobs in Los Angeles, please click “here” for information regarding the Los Angeles Fair Chance Initiative for Hiring Ordinance.
To view the “EEO is the Law” poster click “here”. This poster provides information concerning the laws and procedures for filing complaints of violations of the laws with the Office of Federal Contract Compliance Programs
To view the FMLA poster, click “here”. This poster summarizing the major provisions of the Family and Medical Leave Act (FMLA) and telling employees how to file a complaint.
It is the Company’s policy to employ the best qualified individuals available for all jobs. Therefore, any discriminatory action taken on account of an employee’s ancestry, age, color, disability, genetic information, gender, gender identity, gender expression, sexual and reproductive health decision, marital status, medical condition, military or veteran status, national origin, race (include traits historically associated with race, including, but not limited to, hair texture and protective hairstyles), religion (including religious dress), sex, or sexual orientation that adversely affects an employee's terms or conditions of employment is prohibited. This policy applies to all aspects of the employment relationship, including, but not limited to, hiring, training, salary administration, promotion, job assignment, benefits, discipline, and separation of employment.
More From Allstate
Related Job Listings
",https://www.insurancejournal.com/jobs/614926-avail-staff-data-engineer-remote-home-based-worker
JOB105184116075,ETC-TC- Data Science Technical Delivery - Data Engineer,ETC-TC- Data Science Technical Delivery - Data Engineer,"Understand the business use of data to support work processes and strategic business objectives. Leverage data, analytics and data science techniques to create business value through solution delivery and/or self-service enablement.,Identifies, acquires, and cleanses/prepares data (including data architecture) aligned with defined architecture patterns.,Collaborates with data scientists to identify, build and integrate advanced analytics models into solutions.,Enables the data scientists to develop the most advanced analytics models.,Uses an agile approach to develop analytic solutions and technical components of the platform (data ingestion, data preparation, analytics processing, visualization).,Deploys solution including model, documentation, training, integration.,B.S or M.S. in Computer Science or related field,5+ years industry experience developing data products and/or analytics solutions (business intelligence and data warehousing, data science…),Data Architecture, modeling and Integration
Experience in Analytics/Data Product solution architecture (Hadoop, Microsoft Azure Analytics)
Experience in Data Extract, Load and transformation technics and tools (Hadoop, SSIS, Microsoft Azure Data Factory).
Understanding of relational and dimensional data models.,Experience in Analytics/Data Product solution architecture (Hadoop, Microsoft Azure Analytics),Experience in Data Extract, Load and transformation technics and tools (Hadoop, SSIS, Microsoft Azure Data Factory).,Understanding of relational and dimensional data models.,Data Visualization and Analytics
Experience with analytics solutions (Microsoft Azure Analytics Paas/Saas).
Experience in Data Visualization (Spotfire, PowerBI).,Experience with analytics solutions (Microsoft Azure Analytics Paas/Saas).,Experience in Data Visualization (Spotfire, PowerBI).,Software Engineering
Experience in software engineering, Agile and DevOps methodologies and tools (Jira, Jenkins, VSTS).
Experience with programming languages / scripting tools (Java, Python, R, C).
Experience with information security management.,Experience in software engineering, Agile and DevOps methodologies and tools (Jira, Jenkins, VSTS).,Experience with programming languages / scripting tools (Java, Python, R, C).,Experience with information security management.,Learning Agility
Work productively in uncertain and fast changing environments. Finds opportunities in ambiguity; Embraces and adapts to change; adept of learning by doing.,Work productively in uncertain and fast changing environments. Finds opportunities in ambiguity; Embraces and adapts to change; adept of learning by doing.,Analytical thinking and problem solving:
Knowledge of techniques and tools that promote effective analysis, determine the root cause of problems and create alternative solutions to solve them in the best interest of the business.,Knowledge of techniques and tools that promote effective analysis, determine the root cause of problems and create alternative solutions to solve them in the best interest of the business.",,"
This is a position only for Buenos Aires, Argentina
Chevron is accepting online applications for the position of Data Engineer located in Buenos Aires through April 16th at 11:59 p.m. (Eastern Standard Time).
HIGH LEVEL JOB DESCRIPTION/SCOPE:
Within the data science technical delivery team, the data engineer delivers data science and analytics solutions, as well as components of the Enterprise Data Analytics platform (big data on Microsoft Azure Analytics and Hadoop Cloudera). This is a data centric role, that contributes to the scientific process of transforming data into business insights.
Responsibilities for this position may include but are not limited to:
Understand the business use of data to support work processes and strategic business objectives. Leverage data, analytics and data science techniques to create business value through solution delivery and/or self-service enablement.
Identifies, acquires, and cleanses/prepares data (including data architecture) aligned with defined architecture patterns.
Collaborates with data scientists to identify, build and integrate advanced analytics models into solutions.
Enables the data scientists to develop the most advanced analytics models.
Uses an agile approach to develop analytic solutions and technical components of the platform (data ingestion, data preparation, analytics processing, visualization).
Deploys solution including model, documentation, training, integration.
Special Considerations:
B.S or M.S. in Computer Science or related field
5+ years industry experience developing data products and/or analytics solutions (business intelligence and data warehousing, data science…)
Selection Criteria
Data Architecture, modeling and Integration
Experience in Analytics/Data Product solution architecture (Hadoop, Microsoft Azure Analytics)
Experience in Data Extract, Load and transformation technics and tools (Hadoop, SSIS, Microsoft Azure Data Factory).
Understanding of relational and dimensional data models.
Data Visualization and Analytics
Experience with analytics solutions (Microsoft Azure Analytics Paas/Saas).
Experience in Data Visualization (Spotfire, PowerBI).
Software Engineering
Experience in software engineering, Agile and DevOps methodologies and tools (Jira, Jenkins, VSTS).
Experience with programming languages / scripting tools (Java, Python, R, C).
Experience with information security management.
Learning Agility
Work productively in uncertain and fast changing environments. Finds opportunities in ambiguity; Embraces and adapts to change; adept of learning by doing.
Analytical thinking and problem solving:
Knowledge of techniques and tools that promote effective analysis, determine the root cause of problems and create alternative solutions to solve them in the best interest of the business.
This position is for Buenos Aires Argentina only
This is a position only for Buenos Aires, Argentina
",https://www.rigzone.com/oil/jobs/postings/967704_etctc_data_science_technical_delivery_data_engineer/
JOB107771155729,"Data Engineer I (Java, SQL, AWS, Kubernetes)","Data Engineer I (Java, SQL, AWS, Kubernetes)","Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.,Bachelor’s Degree in STEM related field or equivalent,Six years of related experience,Primary Technologies: Java, SQL, PL/SQL, Gradle, Windows Shell Scripting, SOAP, REST, JSON, XML, XSLT, SpringBoot, JSF, Kubernetes (PKS/TKGI), Autosys,Nice-to-have Technologies: AWS, Kafka, JavaScript, Angular, React, NodeJS, PCF, Oracle SQL,Tools: Websphere Liberty, Spring, IntelliJ, Eclipse, Git/Github, SVN, Jenkins, Urban Code Deploy, ReadyAPI/SoapUI, Postman, Dynatrace, PMD, JMeter, SonarQube, Mulesoft,enjoys collaborating to solve complex problems,able to dive into a problem to do root cause analysis,eagerness to learn new things,data transformation experience,Web-service, UI and batch experience,Self-starter,Flexibility to shift priorities in an agile environment,Not afraid to utilize teammates’ inherent knowledge by asking questions,Efficient with problem solving, pivoting around road-blocks,Passion for continuous improvement of applications and technology ecosystem,Fast learner in a complex environment,The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions.,Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on.,Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems.,Strong verbal and written communication skills with the ability to interact with team members and business partners.","Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.,Design data solutions.,Analyze sources to determine value and recommend data to include in analytical processes.,Incorporate core data management competencies including data governance, data security and data quality.,Collaborate within and across teams to support delivery and educate end users on data products/analytic environment.,Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate.","
The Travelers Companies, Inc.
Data Engineer I (Java, SQL, AWS, Kubernetes)
Company Summary
Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.
Target Openings
1
Job Description Summary
Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape. In addition to your strong analytical mind, you will bring your inquisitive attitude and ability to translate the stories found in data. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights.
Primary Job Duties & Responsibilities
Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.
Design data solutions.
Analyze sources to determine value and recommend data to include in analytical processes.
Incorporate core data management competencies including data governance, data security and data quality.
Collaborate within and across teams to support delivery and educate end users on data products/analytic environment.
Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate.
Test data movement, transformation code, and data components.
Minimum Qualifications
Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
Four years of data engineering or equivalent experience.
Education, Work Experience, & Knowledge
Bachelor’s Degree in STEM related field or equivalent
Six years of related experience
Proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and an understanding of software engineering practices.
Job Specific Technical Skills & Competencies
Primary Technologies: Java, SQL, PL/SQL, Gradle, Windows Shell Scripting, SOAP, REST, JSON, XML, XSLT, SpringBoot, JSF, Kubernetes (PKS/TKGI), Autosys
Nice-to-have Technologies: AWS, Kafka, JavaScript, Angular, React, NodeJS, PCF, Oracle SQL
Tools: Websphere Liberty, Spring, IntelliJ, Eclipse, Git/Github, SVN, Jenkins, Urban Code Deploy, ReadyAPI/SoapUI, Postman, Dynatrace, PMD, JMeter, SonarQube, Mulesoft
enjoys collaborating to solve complex problems
able to dive into a problem to do root cause analysis
eagerness to learn new things
data transformation experience
Web-service, UI and batch experience
Self-starter
Flexibility to shift priorities in an agile environment
Not afraid to utilize teammates’ inherent knowledge by asking questions
Efficient with problem solving, pivoting around road-blocks
Passion for continuous improvement of applications and technology ecosystem
Fast learner in a complex environment
The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions.
Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on.
Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems.
Strong verbal and written communication skills with the ability to interact with team members and business partners.
Leadership - Intermediate leadership skills with a proven track record of self-motivation in identifying personal growth opportunities.
Employment Practices
Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences.
If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.
Travelers reserves the right to fill this position at a level above or below the level included in this posting.
To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.
More From The Travelers Companies, Inc.
Related Job Listings
",https://www.insurancejournal.com/jobs/634479-data-engineer-i-java-sql-aws-kubernetes
JOB115308155329,Principal Data Engineer Job,Principal Data Engineer Job,"10+ years of relevant experience,BS/MS/PhD in Computer Science or related field,Experience with Java, Scala & Python,Expert knowledge of machine learning algorithms and operationalization of data science pipelines,Demonstrable experience with ETL/ELT tools,Expert Knowledge of distributed data processing such as Hadoop ecosystem and spark,Strong knowledge of SQL (eg: MySQL) & Linux,Comfortable with Data Security Concepts & SDLC,Familiarity with leading cloud vendors such as GCP, Azure, AWS and related tools",,"
Requisition ID: 268089
Work Area: Software-Design and Development
Expected Travel: 0 - 10%
Career Status: Professional
Employment Type: Regular Full Time
COMPANY DESCRIPTION
SAP started in 1972 as a team of five colleagues with a desire to do something new. Together, they changed enterprise software and reinvented how business was done. Today, as a market leader in enterprise application software, we remain true to our roots. Thats why we engineer solutions to fuel innovation, foster equality and spread opportunity for our employees and customers across borders and cultures.
SAP values the entrepreneurial spirit, fostering creativity and building lasting relationships with our employees. We know that a diverse and inclusive workforce keeps us competitive and provides opportunities for all. We believe that together we can transform industries, grow economics, lift up societies and sustain our environment. Because its the best-run businesses that make the world run better and improve peoples lives.
About SAP SuccessFactors
SAP SuccessFactors is a world-leading provider of cloud human experience management (HXM) the new people-focused market category for Human Resource technology. Our HXM suite lets more than 7,000 global customers provide their employees with experiences that recognize their individual value and consistently motivate them to achieve peak performance levels values we also live by. Working on the SAP SuccessFactors team means making an impact to over 160m global users with a market leading cloud solution.
Summary
The Data Platform group within SAP SuccessFactors is looking for a data engineer/ machine learning engineer to design, develop, and deliver automated multi-tenant artificial intelligence and machine-learning based solutions that integrate with SAP SuccessFactors business applications.
The Role
You are a curious and experienced Data Engineer interested in building data driven enterprise solutions with knowledge of machine learning in commercial environments and build scalable platform to handle large data sets. You are a quick learner and comfortable working cross-functionally with product managers, engineers, and business users to understand business problems and collaborate with the team on a viable solution. You take ownership of a project and plan to deliver a solution in a timely manner.
Education & Qualification Requirements
10+ years of relevant experience
BS/MS/PhD in Computer Science or related field
Experience with Java, Scala & Python
Expert knowledge of machine learning algorithms and operationalization of data science pipelines
Demonstrable experience with ETL/ELT tools
Expert Knowledge of distributed data processing such as Hadoop ecosystem and spark
Strong knowledge of SQL (eg: MySQL) & Linux
Comfortable with Data Security Concepts & SDLC
Familiarity with leading cloud vendors such as GCP, Azure, AWS and related tools
#SOF2020
WHAT YOU GET FROM US
Success is what you make it. At SAP, we help you make it your own. A career at SAP can open many doors for you. If youre searching for a company thats dedicated to your ideas and individual growth, recognizes you for your unique contributions, fills you with a strong sense of purpose, and provides a fun, flexible and inclusive work environment apply now.
SAP'S DIVERSITY COMMITMENT
To harness the power of innovation, SAP invests in the development of its diverse employees. We aspire to leverage the qualities and appreciate the unique competencies that each person brings to the company.
SAP is committed to the principles of Equal Employment Opportunity and to providing reasonable accommodations to applicants with physical and/or mental disabilities. If you are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to Recruiting Operations Team (Americas:Careers.NorthAmerica@sap.comorCareers.LatinAmerica@sap.com, APJ:Careers.APJ@sap.com, EMEA:Careers@sap.com).
Successful candidates might be required to undergo a background verification with an external vendor.
Additional Locations:
Nearest Major Market: San Francisco
Nearest Secondary Market: Oakland
Job Segment: Database, ERP, Engineer, Computer Science, SAP, Technology, Engineering
Categories
Posted: 2020-11-03 Expires: 2020-12-05
",http://www.careercast.com/jobs/detail/summary/119761807?contextType=rss&widget=1&type=job&
JOB116249455608,Senior Java Data engineer,Senior Java Data engineer,,,"If you are interested in working with talented and passionate teammates and becoming a driving force for the evolution of Big Data systems, then Playtika Minsk will be the right fit for you. You’ll work with many exciting Big Data technologies like Apache Storm, Apache Spark, Hadoop, HP-Vertica, as well UTL/ETL/ELT integration solutions using event and messaging systems such as Flume and Kafka.
Responsibilities:
* Be part of the global team building a next generation data warehouse, using Big Data technologies
* Build and deploy scalable and reliable data pipelines to move large amounts of data
* ETL pipelines development and maintenance
* Daily data management and conversion activities
* Design and implementation of data warehousing systems and solutions
Requirements:
* Must be a quick learner
* English (both spoken & written)
* Passionate about data quality
* Strong coding skills in Java and/or Scala
* Skills in writing SQL
Advantages for:
* Familiarity with data warehousing / BI / big data concepts and systems. If not present, on the job guided self-training will be required.
* Basic understanding of Linux concepts
Technology stack:
Hadoop 2.x, Spark, Storm, Vertica, Cloudera, Kafka
",https://hh.ru/vacancy/22047441
JOB117286944070,Graduate Data Engineer,Graduate Data Engineer,"Support the delivery of a diverse portfolio of data-driven and machine learning projects for Wood's global energy, environment, and infrastructure clients.,Develop data-driven solutions, dashboards and workflow automations using high-level programming languages (such as Python and R) and low-code platforms such as the MS Power Platform and Palantir Foundry.,Prepare large and complex data sets using high-level programming languages and data and cloud compute services (mainly Azure, but also AWS).,Continually learn new technologies and data solution platforms.,Assist with preparation & delivery project technical presentations and reports.,Travel as required for project meetings & workshops across the global business.,Data and analytics programming experience with Python and/or R.,Comfortable with the prospect of handling engineering and sensor data from equipment and machines (e.g., pressures, temperatures, flowrates, fluid densities) to derive insight (working alongside various subject matter experts internal and external to the business).,Experience of working with at least one mainstream cloud computing service such as Microsoft Azure or Amazon Web Services.,Working knowledge of SQL for data access, manipulation, and validation.,Presentation, reporting and excellent communication skills.,Flexibility and openness to work on a variety of data challenges across various business domains, for both internal and external clients.,Bachelor's degree in an applicable engineering discipline, engineering science, computer science, or data analytics.",,"
Company: Wood
Skills: IT - Analysis & Management, IT - Software Development
Education: Bachelors/3-5 yr Degree
Location: Galway, County Galway, Ireland
Overview / Responsibilities
Company Description:
Wood is an international energy services company that operates in more than 60 countries worldwide, working with clients to design, build, operate and improve facilities across the oil and gas, industrial, clean energy, and power generation industries.
Wood's operations support and technical services teams use advanced data analytics, cloud, and software services to optimise the operation, inspection, and integrity management of energy infrastructure for global clients.
Role Overview:
Wood is seeking to recruit a Graduate Data Engineer to be part of a leading global technical services business. This is a significant opportunity to develop your digital career and thrive in a problem solving, solutions-focused environment, where you will be responsible for the delivery and development of data-driven solutions to our global customers.
Key Responsibilities:
Support the delivery of a diverse portfolio of data-driven and machine learning projects for Wood's global energy, environment, and infrastructure clients.
Develop data-driven solutions, dashboards and workflow automations using high-level programming languages (such as Python and R) and low-code platforms such as the MS Power Platform and Palantir Foundry.
Prepare large and complex data sets using high-level programming languages and data and cloud compute services (mainly Azure, but also AWS).
Continually learn new technologies and data solution platforms.
Assist with preparation & delivery project technical presentations and reports.
Travel as required for project meetings & workshops across the global business.
Skills / Qualifications
Competencies & Skills Required:
Data and analytics programming experience with Python and/or R.
Comfortable with the prospect of handling engineering and sensor data from equipment and machines (e.g., pressures, temperatures, flowrates, fluid densities) to derive insight (working alongside various subject matter experts internal and external to the business).
Experience of working with at least one mainstream cloud computing service such as Microsoft Azure or Amazon Web Services.
Working knowledge of SQL for data access, manipulation, and validation.
Presentation, reporting and excellent communication skills.
Flexibility and openness to work on a variety of data challenges across various business domains, for both internal and external clients.
Qualifications & Experience Requirements:
Bachelor's degree in an applicable engineering discipline, engineering science, computer science, or data analytics.
Company Overview
Wood is a global leader in engineering and consultancy across energy and the built environment, helping to unlock solutions to some of the world's most critical challenges. We provide consulting, projects and operations solutions in more than 60 countries, employing around 45,000 people. www.woodplc.com
Diversity Statement
We are an equal opportunity employer that recognises the value of a diverse workforce. All suitably qualified applicants will receive consideration for employment on the basis of objective criteria and without regard to the following (which is a non-exhaustive list): race, colour, age, religion, gender, national origin, disability, sexual orientation, gender identity, protected veteran status, or other characteristics in accordance with the relevant governing laws.
",https://www.rigzone.com/oil/jobs/postings/1101246_graduate_data_engineer/
JOB118676886795,Data Engineer - Data Quality,Data Engineer - Data Quality,"Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.,Four years of data engineering or equivalent experience.,Bachelor’s Degree in STEM related field or equivalent,Demonstrated track record of Data quality expertise including understanding technical concepts necessary and industry trends,Prior experience of using data quality tools in the enterprise setting. Exposure to TALEND data quality tool will be a plus.,Understanding of tools, techniques, and manipulation including Cloud platforms, programming languages, and a full understanding of modern software engineering practices.,The ability to deliver work at a steady, predictable pace to achieve commitments, deliver complete solutions but release them in small batches, and identify and negotiate important tradeoffs.,Demonstrated track record of Data quality expertise including understanding technical concepts necessary and industry trends, and possess in-depth knowledge of immediate systems worked on and some knowledge of adjacent systems.,Strong problem solver who ensures systems are built with longevity and creates innovate ways to resolve issues.,Strong written and verbal communication skills with the ability to work collaborate well with team members and business partners.,Ability to lead team members and help create a safe environment for others to learn and grow as engineers. and a proven track record of self-motivation in identifying opportunities and tracking team efforts.","Implement core data management competencies including data governance, data security and data quality.,Collaborate within and across teams to support delivery and educate end users on complex data products/analytic environment.,Work, update, escalate, and resolve trouble tickets submitted by end users.,Work with end users to identify root cause of issues, resolve and train on proper procedure.,Work with the vendors to understand the capabilities of the tools used for data quality. Help implement those capabilities and train users on using those capabilities.,Perform data and system analysis, assessment and resolution for complex defects and incidents and correct as appropriate.,Test data movement, transformation code, and data components.,Develop end user documentation on software functions, procedures, tasks, and troubleshooting.,Assist in data reconciliation efforts.","
The Travelers Companies, Inc.
Data Engineer - Data Quality
Company Summary
Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.
Target Openings
1
Job Description Summary
Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Data Engineer working in the data quality space, you will play a key role in improving the data quality function and there by growing and transforming our analytics landscape. In addition to your strong analytical mind and focus on data quality, you will bring your inquisitive attitude and ability to translate stories found in data by leveraging a variety of data programming techniques.
This position may be based 100% remotely or in one of our offices.
Primary Job Duties & Responsibilities
Implement core data management competencies including data governance, data security and data quality.
Collaborate within and across teams to support delivery and educate end users on complex data products/analytic environment.
Work, update, escalate, and resolve trouble tickets submitted by end users.
Work with end users to identify root cause of issues, resolve and train on proper procedure.
Work with the vendors to understand the capabilities of the tools used for data quality. Help implement those capabilities and train users on using those capabilities.
Perform data and system analysis, assessment and resolution for complex defects and incidents and correct as appropriate.
Test data movement, transformation code, and data components.
Develop end user documentation on software functions, procedures, tasks, and troubleshooting.
Assist in data reconciliation efforts.
Minimum Qualifications
Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
Four years of data engineering or equivalent experience.
Education, Work Experience, & Knowledge
Bachelor’s Degree in STEM related field or equivalent
Demonstrated track record of Data quality expertise including understanding technical concepts necessary and industry trends
Prior experience of using data quality tools in the enterprise setting. Exposure to TALEND data quality tool will be a plus.
Understanding of tools, techniques, and manipulation including Cloud platforms, programming languages, and a full understanding of modern software engineering practices.
Job Specific Technical Skills & Competencies
The ability to deliver work at a steady, predictable pace to achieve commitments, deliver complete solutions but release them in small batches, and identify and negotiate important tradeoffs.
Demonstrated track record of Data quality expertise including understanding technical concepts necessary and industry trends, and possess in-depth knowledge of immediate systems worked on and some knowledge of adjacent systems.
Strong problem solver who ensures systems are built with longevity and creates innovate ways to resolve issues.
Strong written and verbal communication skills with the ability to work collaborate well with team members and business partners.
Ability to lead team members and help create a safe environment for others to learn and grow as engineers. and a proven track record of self-motivation in identifying opportunities and tracking team efforts.
Employment Practices
Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences.
If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.
Travelers reserves the right to fill this position at a level above or below the level included in this posting.
To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.
More From The Travelers Companies, Inc.
Related Job Listings
",https://www.insurancejournal.com/jobs/637016-data-engineer-data-quality
JOB119904539114,Data Engineer,Data Engineer,"Bachelors Degree,At least 2 years of experience using database management tools (SQL),At least 1 year of experience creating data visualizations using Tableau,At least 1 year of experience using relational database systems (Snowflake, PostgreSQL, or MySQL),1+ years of coding experience,2+ years of experience creating Tableau visualizations,2+ years of experience with relational database systems including Snowflake, PostgreSQL, or MySQL,3+ years of experience building data pipelines and using ETL tools,3+ years of experience creating automated solutions",Build data pipeline frameworks to automate high-volume and real-time data delivery to our cloud platform,"
McLean 2 (19052), United States of America, McLean, Virginia
At Capital One, were building a leading information-based technology company. Still founder-led by Chairman and Chief Executive Officer Richard Fairbank, Capital One is on a mission to help our customers succeed by bringing ingenuity, simplicity, and humanity to banking. We measure our efforts by the success our customers enjoy and the advocacy they exhibit. We are succeeding because they are succeeding.
Guided by our shared values, we thrive in an environment where collaboration and openness are valued. We believe that innovation is powered by perspective and that teamwork and respect for each other lead to superior results. We elevate each other and obsess about doing the right thing. Our associates serve with humility and a deep respect for their responsibility in helping our customers achieve their goals and realize their dreams. Together, we are on a quest to change banking for good.
Data Engineer
We are looking for a savvy Data Engineer to join our growing team of analytics experts. You should be proficient in using Tableau and other BI tools to create new and update existing reports. You should have experience with traditional and modern technologies such as Apache Spark, NoSQL databases, Python, REST API, relational databases, Snowflake, PostgreSQL, Git, Javascript, Shell scripting, AWS, and Nifi.
In this role, you will be responsible for creating, maintaining and optimizing our data delivery and extraction from multiple data sources into our data warehouse. You will also create, enhance, and optimize Tableau visualizations that are used by our business customers and internal leaders.
Responsibilities of the role include:
Build data pipeline frameworks to automate high-volume and real-time data delivery to our cloud platform
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS big data technologies
Develop and enhance applications using a modern technology stack such as Python, Shell Scripting, Scala, Postgres, Angular JS, React, and Nifi
Utilize reporting tools, such as Tableau, to build and maintain dashboards used by internal leadership teams
Basic Qualifications:
Bachelors Degree
At least 2 years of experience using database management tools (SQL)
At least 1 year of experience creating data visualizations using Tableau
At least 1 year of experience using relational database systems (Snowflake, PostgreSQL, or MySQL)
At least 1 year of experience building data pipelines and using ETL tools
Preferred Qualifications:
1+ years of coding experience
2+ years of experience creating Tableau visualizations
2+ years of experience with relational database systems including Snowflake, PostgreSQL, or MySQL
3+ years of experience building data pipelines and using ETL tools
3+ years of experience creating automated solutions
AWS Certification
At this time, Capital One will not sponsor a new applicant for employment authorization for this position.
Categories
Posted: 2020-05-20 Expires: 2020-06-26
",https://www.careercast.com/jobs/data-engineer-117907793-d
JOB128846019949,Big Data Engineer,Big Data Engineer,"Building and supporting reusable frameworks to ingest, integrate and provision data,Automating of end to end data pipeline with metadata, data quality checks, and audit,Building and supporting a big data platform on the cloud,Building and supporting data pipelines for data extraction, transformation, and loading processes using cloud native services or custom scripting using python, pyspark, etc.,,Developing, and operationalizing large-scale enterprise data solutions and/or reporting platforms,Be a Graduate in Computer Science/Software Engineering/Mathematics, or related field with a minimum of 4 yrs of experience in information technology,Have several years of experience in data warehouse/data lake technical architecture and in Big Data and Big Data tools like Redshift, S3, Glue, Athena, DynamoDB, Python, Pyspark etc.,Have experience in Kafka, Spark, Hadoop is preferred,Have experience working in cloud data platforms or tools,Have familiarity with batch processing and workflow tools like AirFlow,Having AWS certifications will be a plus,Working flexible hours - flexing the times when you work in the day to help you fit everything in and work when you are the most productive,Contemporary work-life balance policies and wellbeing activities,Comprehensive private medical care options,Safety net of life insurance and disability programs,Additional elected or voluntary benefits",,"
Company: Baker Hughes
Skills: IT - Software Development
Education: Bachelors/3-5 yr Degree
Location: Budapest, Hungary
Are you passionate about being part of a successful team?
Do you enjoy hands-on technical work and working with data?
Join our Digital Technology - Data Analytics Team
Our team is responsible for Data platform architecture and operations. You will be part of the team implementing next gen data platform. Partner with CTO team to align on Enterprise standards, continue to position D&A technology to support the growing demands across BH.
Partner with the best
You will design, build, and implement production data pipelines from ingestion to consumption within a big data architecture. Using AWS native or custom programming and partners with data engineering, architecture, and cloud team members.
As a Data Engineer, you will be responsible for:
Building and supporting reusable frameworks to ingest, integrate and provision data
Automating of end to end data pipeline with metadata, data quality checks, and audit
Building and supporting a big data platform on the cloud
Building and supporting data pipelines for data extraction, transformation, and loading processes using cloud native services or custom scripting using python, pyspark, etc.,
Developing, and operationalizing large-scale enterprise data solutions and/or reporting platforms
Fuel your passion
To be successful in this role you will:
Be a Graduate in Computer Science/Software Engineering/Mathematics, or related field with a minimum of 4 yrs of experience in information technology
Have several years of experience in data warehouse/data lake technical architecture and in Big Data and Big Data tools like Redshift, S3, Glue, Athena, DynamoDB, Python, Pyspark etc.
Have experience in Kafka, Spark, Hadoop is preferred
Have experience working in cloud data platforms or tools
Have familiarity with batch processing and workflow tools like AirFlow
Having AWS certifications will be a plus
Work in a way that works for you
We recognize that everyone is different and that the way in which people want to work and deliver at their best is different for everyone too. In this role, we can offer the following flexible working patterns:
Working flexible hours - flexing the times when you work in the day to help you fit everything in and work when you are the most productive
Working with us
Our people are at the heart of what we do at Baker Hughes. We know we are better when all of our people are developed, engaged and able to bring their whole authentic selves to work. We invest in the health and well-being of our workforce, train and reward talent and develop leaders at all levels to bring out the best in each other.
Working for you
Our inventions have revolutionized energy for over a century. But to keep going forward tomorrow, we know we have to push the boundaries today. We prioritize rewarding those who embrace change with a package that reflects how much we value their input. Join us, and you can expect:
Contemporary work-life balance policies and wellbeing activities
Comprehensive private medical care options
Safety net of life insurance and disability programs
Additional elected or voluntary benefits
About Us:
With operations in over 120 countries, we provide better solutions for our customers and richer opportunities for our people. As a leading partner to the energy industry, we're committed to achieving net-zero carbon emissions by 2050 and we're always looking for the right people to help us get there. People who are as passionate as we are about making energy safer, cleaner and more efficient.
Join Us:
Are you seeking an opportunity to make a real difference in a company that values innovation and progress? Join us and become part of a team of people who will challenge and inspire you! Let's come together and take energy forward.
Baker Hughes Company is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national or ethnic origin, sex, sexual orientation, gender identity or expression, age, disability, protected veteran status or other characteristics protected by law.
",https://www.rigzone.com/oil/jobs/postings/1107072_big_data_engineer/
JOB132062335485,184 jobs with job title Data Engineer,184 jobs with job title Data Engineer,,,"
Browse for Data Engineer Jobs. Find the job of your dreams on CareerCast.com today!
Search for Similar Listings
",https://www.careercast.com/jobs/data-engineer-29541725-b
JOB133200394629,We're hiring for Senior Data Engineer - Customer Operations Data at Squarespace,We're hiring for Senior Data Engineer - Customer Operations Data at Squarespace,,,,https://www.themuse.com/jobs/squarespace/senior-data-engineer-customer-operations-data
JOB143648123735,Data Engineer Specialist,Data Engineer Specialist,,"Participate in software design meetings and analyze user needs to determine technical requirements.,Write technical specifications based on conceptual design and stated business requirements.,Knowledge of standards relevant to the software industry , e.g., ISO, CMM, Six Sigma,You are very organized and detail-oriented; able to work with shifting priorities,You love analyzing issues and devising efficiencies to better the client experience,You are looking to join our team and build a long-term career with FIS,Knowledge of financial services industry,Health coverage offered for you and your family through Health/Vision/Dental/Insurance plans,401K with company contribution and Employee Stock Purchase Program with company match,FIS Gives Back Program - charitable events and activities to help support our local community"," Position Type :
Full time
Type Of Hire :
Experienced (relevant combo of work and education)
Education Desired :
Bachelor of Computer Engineering
Travel Percentage :
0%
Job Description
Are you curious, motivated, and forward-thinking? At FIS, you'll have the opportunity to work on some of the most challenging and relevant issues in financial services and technology. Our talented people empower us, and we believe in being part of a team that is open, collaborative, entrepreneurial, passionate and above all fun.
ABOUT THE TEAM:
FIS is looking for a Data Cloud Engineer Specialist to join our Data Team in any US-based location. In this role, you will develop core versions of software applications, identify technical specifications, and interact with engineering groups to assist in design changes to equipment and/or software.
This is an expert level role with team leadership duties, including instructing, assigning and checking the work of other Software Engineers. Assists in planning, organizing and controlling the activities of the team. Will acts as an expert technical resource to software engineering staff in the development, testing and implementation processes. Frequently acts as a Project Leader.
WHAT YOU WILL BE DOING?
Analyzing, designing, programming, debugging and modifying software enhancements and internal data projects. * Interact with internal teams to define system requirements and/or necessary modifications.
Participate in software design meetings and analyze user needs to determine technical requirements.
Write technical specifications based on conceptual design and stated business requirements.
WHAT YOU BRING:
The ideal candidate will have in-depth experience with Machine Learning and cloud based technology, AWS predominately/preferred.
Knowledge of end-to-end systems development life cycles, e.g., iterative and other modern approaches to software development * A background in leadership highly desired
Knowledge of standards relevant to the software industry , e.g., ISO, CMM, Six Sigma
You are very organized and detail-oriented; able to work with shifting priorities
You love analyzing issues and devising efficiencies to better the client experience
You are looking to join our team and build a long-term career with FIS
ADDED BONUS IF YOU HAVE:
Financial technology industry experience * Knowledge of FIS products and services; in-depth knowledge of products and services in assigned line(s) of business
Knowledge of financial services industry
WHAT WE OFFER YOU:
At FIS, we value new ideas and we pride ourselves on providing a wide-range of opportunities for professional growth in a fast-paced environment. FIS offers an open-minded collaborative culture with enthusiastic technologists. A true partner. We are dedicated to our team members and our customers equally. We strive to create an environment to help you succeed.
Additional Perks and Benefits such as:
Company Paid Volunteer Day * A generous paid time off program in which the benefits increase along with your tenure
Health coverage offered for you and your family through Health/Vision/Dental/Insurance plans
401K with company contribution and Employee Stock Purchase Program with company match
FIS Gives Back Program - charitable events and activities to help support our local community
Privacy Statement
FIS is committed to protecting the privacy and security of all personal information that we process in order to provide services to our clients. For specific information on how FIS protects personal information online, please see the
EEOC Statement
FIS is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, marital status, genetic information, national origin, disability, veteran status, and other protected characteristics. The EEO is the Law poster is supplement document
For positions located in the US, the following conditions apply. If you are made a conditional offer of employment, you will be required to undergo a drug test. ADA Disclaimer: In developing this job description care was taken to include all competencies needed to successfully perform in this position. However, for Americans with Disabilities Act (ADA) purposes, the essential functions of the job may or may not have been described for purposes of ADA reasonable accommodation. All reasonable accommodation requests will be reviewed and evaluated on a case-by-case basis.
Sourcing Model
Recruitment at FIS works primarily on a direct sourcing model; a relatively small portion of our hiring is through recruitment agencies. FIS does not accept resumes from recruitment agencies which are not on the preferred supplier list and is not responsible for any related fees for resumes submitted to job postings, our employees, or any other part of our company.
#pridepass
CareerBuilder
",https://www.careerjet.com/jobad/usd81ce03dc16f74c43f0a23dfc2283d69
JOB144401389449,Data Engineer and Analyst,Data Engineer and Analyst,"Experience and demonstrated proficiency in database development and management;,Experience extracting, cleaning, and transforming data for analysis required;,Experience preferred in a higher education data analysis and reporting setting (institutional research, enrollment analysis, etc.) and/or a higher education IT setting;,Advanced knowledge of SQL required;,Advanced knowledge of relational databases required;,Experience preferred with SQL server and Oracle;,Advanced practical experience with SQL-based data query tools such as BRIO/Hyperion, Toad, and Toad Intelligence Central strongly preferred;,Practical experience with data management tools such as Alteryx preferred;,Familiarity with dimensional data modeling concepts (e.g. Star Schema) preferred;,Familiarity with Python and/or other open source data engineering tools a plus;,Strong orientation to detail;,Strong organization skills;,Excellent interpersonal and communication skills, including a strong customer service orientation;,Ability to manage concurrent projects and activities with a high degree of quality and data accuracy;,Ability to meet deadlines and deliver projects in a timely manner;,Bachelor’s degree required, master’s degree preferred.","Work with the Director of Institutional Research and UDS analytic team to identify common metrics for both internal and external data requests, gather requirements for datasets, and translate those requirements into actionable projects;,Build, manage and “clean” large datasets, creating curated, focused, fit-for-purpose datasets that optimize efficiency in UDS reporting and analysis;,Train UDS analysts on available datasets, including field/variable definitions;,Closely collaborate with the Director of Institutional Research and UDS analysts to update and refine datasets on an annual or as-needed basis, as specifications evolve;,As needed, prepare data and tabulate metrics to meet internal and/or external reporting requirements from accreditors, state and federal governments, and other agencies and organizations;,Develop and standardize reporting procedures and streamline reporting activities and processes, in order to establish efficient methods of reporting;,Thoroughly document reporting efforts in UDS records for future reference;,Identify, investigate, and work to resolve data quality issues with relevant functional units and data administration and governance colleagues.","
Job Duties
Northeastern University's Decision Support Office (UDS) is seeking a Data Engineer and Analyst to develop data sources that will play a key role in efficient internal and external reporting and build the unit’s overall analytic capacities. Reporting to the Director for Institutional Research, the Data Engineer and Analyst will work side by side with UDS analysts to identify common data constructs and metrics that are required by external entities such as IPEDS, US News & World Report, the Princeton Review, and many other guidebooks, rankings, and publications. The Data Engineer and Analyst will delve into existing, complex university data sources of structured and semi-structured data, combine them when necessary, clean the resulting data, and build calculated variables where needed to create curated datasets that are easily consumable for analysis and that are aligned to external reporting needs. The Data Engineer and Analyst will build expertise on the university’s robust Operational Data Store (ODS), and will draw from the ODS, along with other university data sources as needed, to develop smaller, focused datasets for specific purposes that can be used by analysts across the office. The Data Engineer and Analyst is responsible for designing, developing, and maintaining the resulting datasets, and for training other UDS analysts on the included variables and their associated definitions.
The UDS office regularly receives requests for various data and metrics from individuals across the university; external requests for data from entities such as IPEDS, US News & World Report, the Princeton Review, and many other guidebooks, rankings, and publications; and requests for support with data compilation and presentation in preparation for programmatic, college, or university accreditation and approval. On occasion, the Data Engineer and Analyst will also be responsible for supporting the fulfillment of these data requests. The balance between data engineering responsibilities and data analyst responsibilities will vary over time. In general, the role will focus on data engineering and the curation of datasets for analysis and reporting; however, during times of high need, the Data Engineer and Analyst will also be responsible for querying, compiling, and analyzing data to fulfill incoming requests.
Key Responsibilities of the Data Engineer and Analyst include:
Work with the Director of Institutional Research and UDS analytic team to identify common metrics for both internal and external data requests, gather requirements for datasets, and translate those requirements into actionable projects;
Build, manage and “clean” large datasets, creating curated, focused, fit-for-purpose datasets that optimize efficiency in UDS reporting and analysis;
Train UDS analysts on available datasets, including field/variable definitions;
Closely collaborate with the Director of Institutional Research and UDS analysts to update and refine datasets on an annual or as-needed basis, as specifications evolve;
As needed, prepare data and tabulate metrics to meet internal and/or external reporting requirements from accreditors, state and federal governments, and other agencies and organizations;
Develop and standardize reporting procedures and streamline reporting activities and processes, in order to establish efficient methods of reporting;
Thoroughly document reporting efforts in UDS records for future reference;
Identify, investigate, and work to resolve data quality issues with relevant functional units and data administration and governance colleagues.
Job Qualifications
The role of Data Engineer and Analyst will require strong technical expertise, in addition to strong written and verbal communication skills. A learning mentality is desirable—an interest in expanding upon existing skill sets, learning new technical skills, and participating in informal and formal learning opportunities is strongly preferred. This position involves a significant amount of time working independently on a computer; however, it also involves interaction with others, and requires a customer service mentality in order to adequately respond to requests from both university offices and external agencies. The Data Engineer and Analyst must have strong technical and analytic skills, the capacity to work with large-scale datasets, be detail-oriented, and have a strong commitment to data quality and accuracy. The Data Engineer and Analyst must have the ability to think critically and analytically, work independently, problem solve, and handle multiple concurrent tasks and projects with a variety of internal and external deadlines. An advanced knowledge of SQL and relational databases is required. Advanced Excel, Hyperion/BRIO, Toad, Toad Intelligence Central, Cognos, Tableau, Alteryx, or similar data analysis and visualization tools is strongly preferred.
Specific qualifications include:
Experience and demonstrated proficiency in database development and management;
Experience extracting, cleaning, and transforming data for analysis required;
Experience preferred in a higher education data analysis and reporting setting (institutional research, enrollment analysis, etc.) and/or a higher education IT setting;
Advanced knowledge of SQL required;
Advanced knowledge of relational databases required;
Experience preferred with SQL server and Oracle;
Advanced practical experience with SQL-based data query tools such as BRIO/Hyperion, Toad, and Toad Intelligence Central strongly preferred;
Practical experience with data management tools such as Alteryx preferred;
Familiarity with dimensional data modeling concepts (e.g. Star Schema) preferred;
Familiarity with Python and/or other open source data engineering tools a plus;
Strong orientation to detail;
Strong organization skills;
Excellent interpersonal and communication skills, including a strong customer service orientation;
Ability to manage concurrent projects and activities with a high degree of quality and data accuracy;
Ability to meet deadlines and deliver projects in a timely manner;
Bachelor’s degree required, master’s degree preferred.
Institution Description
Founded in 1898, Northeastern is a global research university and the recognized leader in experience-driven lifelong learning. Our world-renowned experiential approach empowers our students, faculty, alumni, and partners to create impact far beyond the confines of discipline, degree, and campus.
Our locations—in Boston; Charlotte, North Carolina; London; Portland, Maine; San Francisco; Seattle; Silicon Valley; Toronto; Vancouver; and the Massachusetts communities of Burlington and Nahant—are nodes in our growing global university system. Through this network, we expand opportunities for flexible, student-centered learning and collaborative, solutions-focused research.
Northeastern’s comprehensive array of undergraduate and graduate programs— in a variety of on-campus and online formats—lead to degrees through the doctorate in nine colleges and schools. Among these, we offer more than 195 multi-discipline majors and degrees designed to prepare students for purposeful lives and careers.
",https://www.airweb.org/resources/job-board/2879
JOB144504683851,Amazon Web Services (AWS) Big Data Engineer,Amazon Web Services (AWS) Big Data Engineer,"Building and supporting reusable frameworks to ingest, integrate and provision data,Automating of end to end data pipeline with metadata, data quality checks, and audit,Building and supporting a big data platform on the cloud,Building and supporting data pipelines for data extraction, transformation, and loading processes using cloud native services or custom scripting using python, pyspark, etc.,,Be a Graduate in Computer Science/Software Engineering/Mathematics, or related field with a minimum of 4 yrs of experience in information technology,Have 3+ yrs' experience in data warehouse/data lake technical architecture,Have minimum of 2 yrs of Big Data and Big Data tools like Redshift, S3, Glue, Athena, DynamoDB, Python, Pyspark etc.,Have experience in Kafka, Spark, Hadoop is preferred,Have 3+ yrs of experience working in cloud data platforms or tools,Have familiarity with batch processing and workflow tools like AirFlow,Working flexible hours - flexing the times when you work in the day to help you fit everything in and work when you are the most productive,Contemporary work-life balance policies and wellbeing activities,Comprehensive private medical care options,Safety net of life insurance and disability programs,Tailored financial programs",,"
Company: Baker Hughes
Skills: IT - Analysis & Management, IT - Software Development
Education: Bachelors/3-5 yr Degree
Location: Bengaluru, Karnataka, India
Big Data Engineer
Are you passionate about being part of a successful team?
Do you enjoy hands-on technical work and working with data?
Join our Digital Technology - Data Analytics Team
Our team is responsible for Data platform architecture and operations. You will be part of the team implementing next gen data platform. Partner with CTO team to align on Enterprise standards, continue to position D&A technology to support the growing demands across BH.
Partner with the best
You will design, build, and implement production data pipelines from ingestion to consumption within a big data architecture. Using AWS native or custom programming and partners with data engineering, architecture, and cloud team members.
As a Data Engineer, you will be responsible for:
Building and supporting reusable frameworks to ingest, integrate and provision data
Automating of end to end data pipeline with metadata, data quality checks, and audit
Building and supporting a big data platform on the cloud
Building and supporting data pipelines for data extraction, transformation, and loading processes using cloud native services or custom scripting using python, pyspark, etc.,
Developing, and operationalizing large-scale enterprise data solutions and/or reporting platforms
Fuel your passion
To be successful in this role you will:
Be a Graduate in Computer Science/Software Engineering/Mathematics, or related field with a minimum of 4 yrs of experience in information technology
Have 3+ yrs' experience in data warehouse/data lake technical architecture
Have minimum of 2 yrs of Big Data and Big Data tools like Redshift, S3, Glue, Athena, DynamoDB, Python, Pyspark etc.
Have experience in Kafka, Spark, Hadoop is preferred
Have 3+ yrs of experience working in cloud data platforms or tools
Have familiarity with batch processing and workflow tools like AirFlow
Having AWS certifications will be a plus
Work in a way that works for you
We recognize that everyone is different and that the way in which people want to work and deliver at their best is different for everyone too. In this role, we can offer the following flexible working patterns:
Working flexible hours - flexing the times when you work in the day to help you fit everything in and work when you are the most productive
Working with us
Our people are at the heart of what we do at Baker Hughes. We know we are better when all of our people are developed, engaged and able to bring their whole authentic selves to work. We invest in the health and well-being of our workforce, train and reward talent and develop leaders at all levels to bring out the best in each other.
Working for you
Our inventions have revolutionized energy for over a century. But to keep going forward tomorrow, we know we have to push the boundaries today. We prioritize rewarding those who embrace change with a package that reflects how much we value their input. Join us, and you can expect:
Contemporary work-life balance policies and wellbeing activities
Comprehensive private medical care options
Safety net of life insurance and disability programs
Tailored financial programs
Additional elected or voluntary benefits
About Us
With operations in over 120 countries, we provide better solutions for our customers and richer opportunities for our people. As a leading partner to the energy industry, we're committed to achieving net-zero carbon emissions by 2050 and we're always looking for the right people to help us get there. People who are as passionate as we are about making energy safer, cleaner and more efficient.
Join Us
Are you seeking an opportunity to make a real difference in a company with a global reach and exciting services and clients? Come join us and grow with a team of people who will energize and inspire you!
About Us:
With operations in over 120 countries, we provide better solutions for our customers and richer opportunities for our people. As a leading partner to the energy industry, we're committed to achieving net-zero carbon emissions by 2050 and we're always looking for the right people to help us get there. People who are as passionate as we are about making energy safer, cleaner and more efficient.
Join Us:
Are you seeking an opportunity to make a real difference in a company that values innovation and progress? Join us and become part of a team of people who will challenge and inspire you! Let's come together and take energy forward.
Baker Hughes Company is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national or ethnic origin, sex, sexual orientation, gender identity or expression, age, disability, protected veteran status or other characteristics protected by law.
",https://www.rigzone.com/oil/jobs/postings/1106031_big_data_engineer/
JOB146316425355,Data Engineer Consultant,Data Engineer Consultant,,"Full access to our jobs board, including over 1,000 exclusive jobs,Your Devex profile highlighted in recruiter search results,Connections to recruiters and industry experts through online and live Devex events","
See the full details of this exclusive job - and all of the other big development opportunities hand picked by our team. These positions are only available with a Career Account. Upgrade now to keep your job search moving.
Starting at $9.50, a Devex Career Account provides you:
Full access to our jobs board, including over 1,000 exclusive jobs
Your Devex profile highlighted in recruiter search results
Connections to recruiters and industry experts through online and live Devex events
",https://www.devex.com/jobs/data-engineer-consultant-590923
JOB146587551295,Data Manager : Data Engineer,Data Manager : Data Engineer,,,"
South San Francisco
California, United States of America
The Position
As Data Manager you will be accountable for study/studies and non-study project deliverables. You partner with cross-functional teams and external partners and work with considerable independence.
MINIMUM QUALIFICATIONS
● BSc or MSc in Life Sciences, Data/Computer Science, Bioinformatics OR equivalent industry experience.
● Demonstrated strong collaboration and excellent communication skills – both written and oral (proficiency in English required).
● Knowledge of CDISC data standards.
● Knowledge of ICH-GCP and working in regulated environments.
● Project Management skills.
● Able to manage multiple requests and priorities.
● Experience in leading CDM study teams and maintaining oversight of all start-up, conduct and close-out activities for multiple or complex studies,
ensuring fit for purpose quality (including oversight of FSPs, Vendors, CROs and Collaborative Groups).
● Experience in leading the collection of clinical trial and/or Real World Data.
● Good understanding of molecule and disease area strategies, healthcare environments, as well as strong scientific and technical expertise.
● Fluency in programming languages (SAS, R, Python, SQL etc.).
● Experience producing interactive outputs (e.g. Shiny, Tableau).
PREFERRED ADDITIONAL QUALIFICATIONS
● Experience with SDTM implementation
● Experience in enterprise level operating systems and familiarity with databases (Relational Database Management System, RDBMS).● Some experience with advanced analytics approaches (e.g. machine learning, AI).
● Experience with tools related to technologies required to undertake analyses on large data sources or with computationally intensive steps (SQL, parallelization, Hadoop, Spark, etc.).● Experience implementing reproducible research practices like version control (e.g., using Git, Rmarkdown) and literate programmer.
RESPONSIBILITIES
PROJECT MANAGEMENT : Develop risk management strategies and proactively manage timelines to ensure successful oversight and delivery of studies, projects and coding responsibilities, including the implementation and adoption of new technologies.
● STAKEHOLDER MANAGEMENT: Proactively engage with stakeholders across the business to understand their needs and influence their understanding of decisions made in our function. Inform stakeholders of status of key deliverables and act on changing milestones.
● VENDOR MANAGEMENT: Partner with relevant functions for external data vendor selection and management. Oversee development of data transfer agreements with vendors ensuring use of standards, fit-for-purpose data models and transfer intervals.
● DATA COLLECTION AND ACQUISITION: Act as experts for data collection, advising teams and stakeholders on best practices and proposing innovative solutions. Ensure a high quality of data and compliance with applicable pharma industry regulations and standards.
● PROVIDE DATA SOLUTIONS: Stay current with and adopt emergent data collection, data management, visualisation and provision tools and applications to ensure fit-for-purpose and impactful approaches. Deliver on solutions as needed.
● DATA QUALITY REVIEW : Use data surveillance tools and strategies to provide aggregate level reviews designed to identify patterns or anomalies in our data to ensure high quality results.
● DATA CURATION: Organization and integration of data collected from various sources. Maintain value of data through application of FAIR (Findable, Accessible, Interoperable, Reusable) principles.
● SUPPORT ANALYSES: Partner with stakeholders to understand their data insight needs and offer Data Management solutions. Demonstrate a strong understanding of the data flow from collection through to analysis and filing.
● FUNCTIONAL EXCELLENCE : Collaborate and contribute to functional/cross-functional initiatives or goals to promote new ways of working, including emerging technologies. Enable broader and more effective use of data to support the business.
● TECHNICAL CONSULTANT : Offer guidance and advice to peers within the function, to key stakeholders and to FSPs, CRO and collaborative groups on technical solutions to ensure high quality data collection and delivery. Deliver on solutions as needed.
This is a local hire only designated position, as relocation assistance is not available for the position
Who We Are
A member of the Roche Group, Genentech has been at the forefront of the biotechnology industry for more than 40 years, using human genetic information to develop novel medicines for serious and life-threatening diseases. Genentech has multiple therapies on the market for cancer & other serious illnesses. Please take this opportunity to learn about Genentech where we believe that our employees are our most important asset & are dedicated to remaining a great place to work.
The next step is yours. To apply today, click on the ""Apply online"" button.
Genentech is an equal opportunity employer & prohibits unlawful discrimination based on race, color, religion, gender, sexual orientation, gender identity/expression, national origin/ancestry, age, disability, marital & veteran status. For more information about equal employment opportunity, visit our Genentech Careers page.
",https://www.gene.com/careers/detail/202004-110938/Data-Manager-Data-Engineer
JOB146841981655,Sorry! That job has been removed. Here are similar Senior Data Engineer with strong Java AND Python scripting jobs in 95002,Sorry! That job has been removed. Here are similar Senior Data Engineer with strong Java AND Python scripting jobs in 95002,,,"
",https://www.ziprecruiter.com/clk/akidev-corporation-00000000-senior-data-engineer-with-strong-java-and-python-scripting-10485492_033080?clk=6Ckrh7grhLALAi9fPGt_dEejiJQcuRv8Q54zViAddbTNhP70h9wPjqakwhAzrkEOQoC4SBSo_ak9p8jjrjHGiLZKsqzV9MUcBWLtL_E8PDL8zxM3oR1eT4OBC8vOO6IxploWCbHBV4WL1wJxnkpPyK0Arcl2TVW40522vK0e_uTgGMpkZaIfhc5JZ_EDT0iG3G_kbpg50olC1Nx1TiEJxxppb5iE_EkqmbvXkjFt7r9KawiMqxj_eyI5WN7XNi0zEIFgRODxOl4qWXvbFwtWubhYF5cqmK-42P73lUG_ZY22xb9_IIJ_eG0hQAtCeRn2r2QUBEGxazTfm7wTCl_6y3pheju08aF-lO-1PGJPvH20Cm3ijz3KctQaOtR0V1o9USqWyNmg98wBX4uelDKkIb4-TsTUEezWVV8kuRIeHihpWZmXuWMyVBSCyZfKNsBDGOUEiyQYN0icT5KZhZRCMRKmdCDrVVQs78ZZ2MnNmoSiLtDbrSPdr1zhfILTvjcnBrOH78UP2gbq7h-6BnDUkCH286kC71ISs1xn-gFyEKro2o6-E2v1YRCDZ4Qe4NlToNzJdFYxj3FEWvqoL58AC5eF1FCbCeoCWTXzqY-W-ByNJ5OXlnEjynPQue3Ooin7hGsFYcJSskHT_sKWbtbWVxtl3ZxqyD-O3ZSx66S9cl49DAlhfK2291GLxBpr8PFUkkOuNFK-GAqOSLiKBr6vdYOskMMMTn7x3_-kbrJN9fg.85331d24cd0235de6a8995d289f75488
JOB147310254876,Senior Data Engineer,Senior Data Engineer,"Bachelor's degree in Computer Science, Engineering or a related field, or equivalent training, fellowship, or work experience","Translate business requirements into data models that are easy to understand and used by different disciplines across the company,Design, implement and build pipelines that deliver data with measurable quality under the SLA,Partner with business domain experts, data analysts and engineering teams to build foundational data sets that are trusted, well understood, aligned with business strategy and enable self-service,Be a champion of the overall strategy for data governance, security, privacy, quality and retention that will satisfy business policies and requirements,Own and document foundational company metrics with a clear definition and data lineage,Identify, document and promote best practices,5+ years of experience working in data architecture, data modeling, master data management, metadata management,Recent accomplishments working with relational as well as NoSQL data stores, methods and approaches (logging, columnar, star and snowflake, dimensional modeling),Proven track record in scaling and optimizing schemas, performance tuning SQL and ETL pipelines in OLAP and Data Warehouse environments,Demonstrated skills with either Python or Java programming language,Familiar with data governance frameworks, SDLC, and Agile methodology,Excellent written and verbal communication and interpersonal skills, and ability to effectively collaborate with technical and business partners,Hands-on experience with Big Data technologies (e.g Hadoop, Hive, Spark) is a big plus","Senior Data Engineer
Slack is looking for expert data engineers to join our Data Engineering team. In this role, you will be working cross-functionally with business domain experts, analytics, and engineering teams to design and implement our Data Warehouse model. You will design, implement and scale data pipelines that transform billions of records into actionable data models that enable data insights.
You will lead initiatives to formalize data governance and management practices, rationalize our information lifecycle and key company metrics. You will provide mentorship and hands-on technical support to build trusted and reliable metrics.
You have deep technical skills, be comfortable contributing to a nascent data ecosystem, and building a strong data foundation for the company. You are a self-starter, detail and quality oriented, and passionate about having a huge impact at Slack.
What you will be doing
Translate business requirements into data models that are easy to understand and used by different disciplines across the company
Design, implement and build pipelines that deliver data with measurable quality under the SLA
Partner with business domain experts, data analysts and engineering teams to build foundational data sets that are trusted, well understood, aligned with business strategy and enable self-service
Be a champion of the overall strategy for data governance, security, privacy, quality and retention that will satisfy business policies and requirements
Own and document foundational company metrics with a clear definition and data lineage
Identify, document and promote best practices
What you should have
5+ years of experience working in data architecture, data modeling, master data management, metadata management
Recent accomplishments working with relational as well as NoSQL data stores, methods and approaches (logging, columnar, star and snowflake, dimensional modeling)
Proven track record in scaling and optimizing schemas, performance tuning SQL and ETL pipelines in OLAP and Data Warehouse environments
Demonstrated skills with either Python or Java programming language
Familiar with data governance frameworks, SDLC, and Agile methodology
Excellent written and verbal communication and interpersonal skills, and ability to effectively collaborate with technical and business partners
Hands-on experience with Big Data technologies (e.g Hadoop, Hive, Spark) is a big plus
Bachelor's degree in Computer Science, Engineering or a related field, or equivalent training, fellowship, or work experience
Slack is an Equal Opportunity Employer and participant in the U.S. Federal E-Verify program. Women, minorities, individuals with disabilities and protected veterans are encouraged to apply. Slack will consider qualified applicants with criminal histories in a manner consistent with the San Francisco Fair Chance Ordinance.
Slack is a layer of the business technology stack that brings together people, data, and applications – a single place where people can effectively work together, find important information, and access hundreds of thousands of critical applications and services to do their best work. From global Fortune 100 companies to corner markets, businesses and teams of all kinds use Slack to bring the right people together with all the right information. Slack is headquartered in San Francisco, CA and has ten offices around the world. For more information on how Slack makes teams better connected, visit slack.com.
Ensuring a diverse and inclusive workplace where we learn from each other is core to Slack’s values. We welcome people of different backgrounds, experiences, abilities and perspectives. We are an equal opportunity employer and a pleasant and supportive place to work.
Come do the best work of your life here at Slack.
",https://slack.com/careers/1585704/senior-data-engineer
JOB148705019803,Data Engineer - Biologics Drug Discovery,Data Engineer - Biologics Drug Discovery,"BS or MS in computational sciences (computational biology, bioinformatics, or related fields), computer science, applied math/statistics,Experience in scientific programming,Experience in data analysis (especially as pertains to protein sequence and structure, and/or next-generation DNA sequence analysis),Excellent problem-solving skills,Knowledge of biochemistry, bioinformatics, protein structures, molecular biology, and NGS data analysis,Ability to execute and automate standard statistical analyses using tools/languages including UNIX, Python, R, SQL, etc.,Knowledge of cloud computing, AWS, Docker, etc.,Experience in scientific software administration and tool development,Strong communication skills","Using programming and scripting to parse/prepare data,Building and maintaining scientific tools and infrastructure,Applying machine learning to uncover novel trends in experimental data,Working effectively with project teams to develop informatics solutions to satisfy business needs"," Amgen is dedicated to discovering transformative medicines that address the leading causes of death and disability. As part of a multi-year initiative to unlock the potential of data generated from Amgen's past and current research projects, we are currently seeking a computational data engineer to join our multidisciplinary research team of computational and experimental scientists. In this role, you will be working with bench scientists and data scientists to develop tools and processes to capture and analyze data and to derive actionable insights from discovery research. The key responsibilities will include data preparation, analysis, visualization, and building and maintaining scientific tools and infrastructures for drug discovery research.
Key responsibilities will include:
Using programming and scripting to parse/prepare data
Building and maintaining scientific tools and infrastructure
Applying machine learning to uncover novel trends in experimental data
Working effectively with project teams to develop informatics solutions to satisfy business needs
Communicating research results internally and externally
#LI--POST
Basic Qualifications:
Master's degree and 2 years of data analysis experience
OR
Bachelor's degree and 4 years of data analysis experience
Preferred Qualifications:
BS or MS in computational sciences (computational biology, bioinformatics, or related fields), computer science, applied math/statistics
Experience in scientific programming
Experience in data analysis (especially as pertains to protein sequence and structure, and/or next-generation DNA sequence analysis)
Excellent problem-solving skills
Knowledge of biochemistry, bioinformatics, protein structures, molecular biology, and NGS data analysis
Ability to execute and automate standard statistical analyses using tools/languages including UNIX, Python, R, SQL, etc.
Knowledge of cloud computing, AWS, Docker, etc.
Experience in scientific software administration and tool development
Strong communication skills
Enthusiasm for working in an interdisciplinary team environment
Amgen is an Equal Opportunity employer and will consider all qualified applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.
",https://www.biospace.com/job/2000054/data-engineer-biologics-drug-discovery/
JOB153254395251,Amazon Web Services (AWS) Big Data Engineer,Amazon Web Services (AWS) Big Data Engineer,"Building and supporting reusable frameworks to ingest, integrate and provision data,Automating of end to end data pipeline with metadata, data quality checks, and audit,Building and supporting a big data platform on the cloud,Building and supporting data pipelines for data extraction, transformation, and loading processes using cloud native services or custom scripting using python, pyspark, etc.,,Be a Graduate in Computer Science/Software Engineering/Mathematics, or related field with a minimum of 4 yrs of experience in information technology,Have 3+ yrs' experience in data warehouse/data lake technical architecture,Have minimum of 2 yrs of Big Data and Big Data tools like Redshift, S3, Glue, Athena, DynamoDB, Python, Pyspark etc.,Have experience in Kafka, Spark, Hadoop is preferred,Have 3+ yrs of experience working in cloud data platforms or tools,Have familiarity with batch processing and workflow tools like AirFlow,Working flexible hours - flexing the times when you work in the day to help you fit everything in and work when you are the most productive,Contemporary work-life balance policies and wellbeing activities,Comprehensive private medical care options,Safety net of life insurance and disability programs,Tailored financial programs",,"
Company: Baker Hughes
Skills: IT - Software Development, Software Specialist
Education: Bachelors/3-5 yr Degree
Location: Bengaluru, Karnataka, India
Big Data Engineer
Are you passionate about being part of a successful team?
Do you enjoy hands-on technical work and working with data?
Join our Digital Technology - Data Analytics Team
Our team is responsible for Data platform architecture and operations. You will be part of the team implementing next gen data platform. Partner with CTO team to align on Enterprise standards, continue to position D&A technology to support the growing demands across BH.
Partner with the best
You will design, build, and implement production data pipelines from ingestion to consumption within a big data architecture. Using AWS native or custom programming and partners with data engineering, architecture, and cloud team members.
As a Data Engineer, you will be responsible for:
Building and supporting reusable frameworks to ingest, integrate and provision data
Automating of end to end data pipeline with metadata, data quality checks, and audit
Building and supporting a big data platform on the cloud
Building and supporting data pipelines for data extraction, transformation, and loading processes using cloud native services or custom scripting using python, pyspark, etc.,
Developing, and operationalizing large-scale enterprise data solutions and/or reporting platforms
Fuel your passion
To be successful in this role you will:
Be a Graduate in Computer Science/Software Engineering/Mathematics, or related field with a minimum of 4 yrs of experience in information technology
Have 3+ yrs' experience in data warehouse/data lake technical architecture
Have minimum of 2 yrs of Big Data and Big Data tools like Redshift, S3, Glue, Athena, DynamoDB, Python, Pyspark etc.
Have experience in Kafka, Spark, Hadoop is preferred
Have 3+ yrs of experience working in cloud data platforms or tools
Have familiarity with batch processing and workflow tools like AirFlow
Having AWS certifications will be a plus
Work in a way that works for you
We recognize that everyone is different and that the way in which people want to work and deliver at their best is different for everyone too. In this role, we can offer the following flexible working patterns:
Working flexible hours - flexing the times when you work in the day to help you fit everything in and work when you are the most productive
Working with us
Our people are at the heart of what we do at Baker Hughes. We know we are better when all of our people are developed, engaged and able to bring their whole authentic selves to work. We invest in the health and well-being of our workforce, train and reward talent and develop leaders at all levels to bring out the best in each other.
Working for you
Our inventions have revolutionized energy for over a century. But to keep going forward tomorrow, we know we have to push the boundaries today. We prioritize rewarding those who embrace change with a package that reflects how much we value their input. Join us, and you can expect:
Contemporary work-life balance policies and wellbeing activities
Comprehensive private medical care options
Safety net of life insurance and disability programs
Tailored financial programs
Additional elected or voluntary benefits
About Us
With operations in over 120 countries, we provide better solutions for our customers and richer opportunities for our people. As a leading partner to the energy industry, we're committed to achieving net-zero carbon emissions by 2050 and we're always looking for the right people to help us get there. People who are as passionate as we are about making energy safer, cleaner and more efficient.
Join Us
Are you seeking an opportunity to make a real difference in a company with a global reach and exciting services and clients? Come join us and grow with a team of people who will energize and inspire you!
About Us:
With operations in over 120 countries, we provide better solutions for our customers and richer opportunities for our people. As a leading partner to the energy industry, we're committed to achieving net-zero carbon emissions by 2050 and we're always looking for the right people to help us get there. People who are as passionate as we are about making energy safer, cleaner and more efficient.
Join Us:
Are you seeking an opportunity to make a real difference in a company that values innovation and progress? Join us and become part of a team of people who will challenge and inspire you! Let's come together and take energy forward.
Baker Hughes Company is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national or ethnic origin, sex, sexual orientation, gender identity or expression, age, disability, protected veteran status or other characteristics protected by law.
",https://www.rigzone.com/oil/jobs/postings/1105931_big_data_engineer/
JOB154081723912,Clinical Supply Center Data Engineer II/Senior Data Engineer,Clinical Supply Center Data Engineer II/Senior Data Engineer,B.S. Degree in Engineering or related discipline with 8 to 12 years of experience in pharmaceutical/biotech (6 to 10 years of experience with Master’s Degree),"Strong PT behaviors, with an emphasis on continuous improvement","
South San Francisco, California
The Position
The Clinical Supply Center Data Engineer II/Senior Data Engineer is an integral part of the Clinical Supply Center (CSC) team, in South San Francisco (SSF). The SSF CSC is designed to be a state-of-the-art large molecule drug substance facility which supports GMP production for phase 1, 2 and early phase 3 clinical trials. The CSC will employ a ballroom design, utilize single-use technology, new analytical techniques and digital manufacturing systems to deliver a best in class bioprocess facility. We are looking for individuals to support this facility who are comfortable with ambiguity, have an entrepreneurial spirit within a GMP environment, have demonstrated strong Pharma Technical Behaviors, and have an agile mindset. Ability to collaborate is crucial as success will be measured as a member of a team, not just as an individual. Ideal candidates would have experience in a broad range of functional roles in support of biopharmaceutical production.
In this role, the qualified individual will initially be part of the CSC project team that designs, delivers, and starts up the automation systems in the facility and will then transition to operational support of the facility. The candidate will establish relationships with customer groups, network teams and vendors by seeking opportunities for collaboration, proactively communicating and presenting information and offering relevant data driven information to impact decisions. More than one individual may be selected under this overall job description. Candidates are initially expected to have mid to senior level expertise in data engineering, data analytics, data modeling, AI/VI, or machine learning and will develop additional expertise over time through a combination of role assignments and coaching. The final level for a successful candidate will be based on their demonstrated skills, experience, and capabilities.
This position can be performed remotely for the next approximately 6 months, however will gradually transition to require at least partial on-site presence in order to perform the essential project and operational responsibilities of the role. As we transition to “normal” the option to work flexibly should be available as appropriate given business needs and with management endorsement.
Responsibilities:
The CSC Data Engineer II/Senior Data Engineer provides emerging subject matter expertise and technical leadership of the advanced analytic tools to develop deeper understanding of our processes. This position will focus on developing the requirements and delivering data analytics and data modeling tools, evaluating design prototypes and alternatives, and is responsible for the successful implementation and start-up of the CSC solutions. The role will continue into an ongoing role where the responsibilities include collaborating closely with digital transformation colleagues and subject matter experts in order to curate, transform and construct features which feed directly into our data engineering and modeling approaches. Responsible for finding improvements in advanced data analytical models and data architecture.
In the operational role the CSC Data Engineer II/Senior Data Engineer will interface with process SMEs using state of the art technologies, while also being able to communicate complex strategies to non-technical audiences. They will acquire, ingest and process data from multiple sources and systems into Big Data platforms. They will also provide ongoing system ownership and continuous improvement leveraging data engineering to add more value for patients over time. The CSC Data Engineer II/Senior Data Engineer will also drive data innovation, and partner with operations to provide high value solutions to technical challenges. There is an expectation that the CSC Data Engineer II/Senior Data Engineer will continue to expand expertise in emerging technologies such as machine learning, data analytics and robotics. As an emerging technical expert the CSC Data Engineer II/Senior Data Engineer is expected to identify opportunities to challenge the status-quo and develop creative solutions within the framework of Global Standards and processes. The CSC Data Engineer II/Senior Data Engineer partners proactively with key customers, while being open and approachable with a friendly, positive and professional attitude.
This position requires strong adherence to compliance and safety requirements, cGMPs, SOPs, and other manufacturing documents. As with any position in a manufacturing environment, the job requires an ability to adapt to rapidly changing priorities and the flexibility to support operations in accordance with the manufacturing schedule.
Skills and Behavior Profile:
Strong PT behaviors, with an emphasis on continuous improvement
Ability to work in an agile and ambiguous environment
Commitment to quality
Growth mindset
Entrepreneurial spirit within a GMP environment
Servant leader with strong coaching skills
Qualifications:
B.S. Degree in Engineering or related discipline with 8 to 12 years of experience in pharmaceutical/biotech (6 to 10 years of experience with Master’s Degree)
Proven and significant experience building and managing data pipelines.
Ability to build and manage data pipelines with Python, Scala or Java.
Meaningful experience in multiple database technologies (such as Hadoop, MS SQL Server, Oracle, MySQL, Teradata).
Ability to execute complex automation projects in a GMP environment.
Understand current GMP requirements and regulations
Emerging strategic thinker
Possess excellent interpersonal and communication skills
Strong problem solving and critical thinking skills
#AfroTech2020
#ptd
#ptcareers
#LI-DW1
#AfroTechPT
Who We Are
Genentech, a member of the Roche group and founder of the biotechnology industry, is dedicated to pursuing groundbreaking science to discover and develop medicines for people with serious and life-threatening diseases. To solve the world's most complex health challenges, we ask bigger questions that challenge our industry and the boundaries of science to transform society. Our transformational discoveries include the first targeted antibody for cancer and the first medicine for primary progressive multiple sclerosis.
Diversity and Inclusion (D&I) are critical to the success of our company and our impact on society. We believe that by championing diversity of background, thought and experience, we can foster a sense of belonging and provide an environment where every employee feels valued, included, and able to contribute their best for the patients we serve. We’re focused on attracting, retaining, developing and advancing our people to their full potential by rewarding bold ways of thinking and integrating inclusive behaviors into every aspect of our work.
The next step is yours. To apply today, click on the ""Apply for this job"" button.
Genentech is an equal opportunity employer & prohibits unlawful discrimination based on race, color, religion, gender, sexual orientation, gender identity/expression, national origin/ancestry, age, disability, marital & veteran status. For more information about equal employment opportunity, visit our Genentech Careers page.
Join our Talent Community. By joining our Talent Community, your resume will be available to our recruitment team, Join today!
",https://www.gene.com/careers/detail/202009-122921/Clinical-Supply-Center-Data-Engineer-II-Senior-Data-Engineer
JOB154928370996,Data Engineer,Data Engineer,"Bachelor’s degree or equivalent experience,None,Database development knowledge and experience (i.e. SQL),Programming skills (i.e. Python, R, Java),Computer Proficiency in Oracle, UNIX/Linux,Intermediate Analytic, Data Sourcing, and Data Management skills,Ability to extract data from various data sources.,Solid experience in time and task management,Ability to learn new technologies,Strong attention to detail,Intermediate written and verbal communication skills, including the ability to effectively collaborate with multi-disciplinary groups and all organizational levels","Work with Data Scientists and business partners on cross functional teams; developing subject matter expertise in the business as well as advanced analytics.,Provide support on requirement development for analytic data sources, breaking down business problems into solvable components and assist with documenting requirements with minimal supervision.,Execute rapid development of new data and analytic work tracks with fast iteration over quick sprints,Help develop and deliver the data infrastructure required to support needs of predictive modeling and analytics with minimal supervision.,Builds test scripts, executes testing, works with data scientists and business to ensure end user acceptance,Leverage “agile” data analysis with technology fluency in parallel processing/programming, software/programming languages and technologies (i.e. Oracle, MongoDB, SQL, Python, Spark, Kafka, Scala and Hadoop), paired with a high degree of analytic agility to be able to meet fluid and dynamic business needs in this space.,Participate in the development of enterprise data assets, information platforms or data spaces designed for exploring and understanding the data.,Participate in the development of new concepts, proof of concept designs, and prototypes for business or research data solutions so that business users or predictive modelers may visually understand and explore a new feature or functionality before implementation to expose design assumptions and drive ideation.","
The world isn’t standing still, and neither is Allstate. We’re moving quickly, looking across our businesses and brands and taking bold steps to better serve customers’ evolving needs. That’s why now is an exciting time to join our team. As a leader in a corporation with 83,000 employees and agency force members, you’ll have a hand in transforming not only Allstate but a dynamic industry. You’ll have opportunities to take risks, challenge the status quo and shape the future for the greater good.
You’ll do all this in an environment of excellence and the highest ethical standards – a place where values such as integrity, inclusive diversity and accountability are paramount. We empower every employee to lead, drive change and give back where they work and live. Our people are our greatest strength, and we work as one team in service of our customers and communities.
Everything we do at Allstate is driven by a shared purpose: to protect people from life’s uncertainties so they can realize their hopes and dreams. For 89 years we’ve thrived by staying a step ahead of whatever’s coming next – to give customers peace of mind no matter what changes they face. We acted with conviction to advocate for seat belts, air bags and graduated driving laws. We help give survivors of domestic violence a voice through financial empowerment. We’ve been an industry leader in pricing sophistication, telematics, digital photo claims and, more recently, device and identity protection. We are the Good Hands. We don’t follow the trends. We set them.
Job Description
Job Summary:
This role is responsible for the use and development of data infrastructure projects & proof of concept business solutions for users in analytics and Data Science. This person works directly with data scientists and analytic engineers on needs and tactical solutions. This role will execute new data engineering work tracks for Data Science and analytics from inception and prototyping to fully developed solutions.
Key Responsibilities:
Work with Data Scientists and business partners on cross functional teams; developing subject matter expertise in the business as well as advanced analytics.
Provide support on requirement development for analytic data sources, breaking down business problems into solvable components and assist with documenting requirements with minimal supervision.
Execute rapid development of new data and analytic work tracks with fast iteration over quick sprints
Help develop and deliver the data infrastructure required to support needs of predictive modeling and analytics with minimal supervision.
Builds test scripts, executes testing, works with data scientists and business to ensure end user acceptance
Leverage “agile” data analysis with technology fluency in parallel processing/programming, software/programming languages and technologies (i.e. Oracle, MongoDB, SQL, Python, Spark, Kafka, Scala and Hadoop), paired with a high degree of analytic agility to be able to meet fluid and dynamic business needs in this space.
Participate in the development of enterprise data assets, information platforms or data spaces designed for exploring and understanding the data.
Participate in the development of new concepts, proof of concept designs, and prototypes for business or research data solutions so that business users or predictive modelers may visually understand and explore a new feature or functionality before implementation to expose design assumptions and drive ideation.
Mentor other team members in a business technical environment and promote an environment that supports innovation and process improvement.
Supervisory Responsibilities:
This job does not have supervisory responsibilities.
Job Qualifications
Preferred Qualifications:
Education and Experience
Bachelor’s degree or equivalent experience
2 or more years of related experience
Certificates, Licenses, Registrations
None
Functional Skills
Database development knowledge and experience (i.e. SQL)
Programming skills (i.e. Python, R, Java)
Computer Proficiency in Oracle, UNIX/Linux
Intermediate Analytic, Data Sourcing, and Data Management skills
Ability to extract data from various data sources.
Solid experience in time and task management
Ability to learn new technologies
Strong attention to detail
Intermediate written and verbal communication skills, including the ability to effectively collaborate with multi-disciplinary groups and all organizational levels
The candidate(s) offered this position will be required to submit to a background investigation, which includes a drug screen.
Good Work. Good Life. Good Hands®.
As a Fortune 100 company and industry leader, we provide a competitive salary – but that’s just the beginning. Our Total Rewards package also offers benefits like tuition assistance, medical and dental insurance, as well as a robust pension and 401(k). Plus, you’ll have access to a wide variety of programs to help you balance your work and personal life -- including a generous paid time off policy.
Learn more about life at Allstate. Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video.
Allstate generally does not sponsor individuals for employment-based visas for this position.
Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.
For jobs in San Francisco, please click “here” for information regarding the San Francisco Fair Chance Ordinance.
For jobs in Los Angeles, please click “here” for information regarding the Los Angeles Fair Chance Initiative for Hiring Ordinance.
To view the “EEO is the Law” poster click “here”. This poster provides information concerning the laws and procedures for filing complaints of violations of the laws with the Office of Federal Contract Compliance Programs
To view the FMLA poster, click “here”. This poster summarizing the major provisions of the Family and Medical Leave Act (FMLA) and telling employees how to file a complaint.
It is the Company’s policy to employ the best qualified individuals available for all jobs. Therefore, any discriminatory action taken on account of an employee’s ancestry, age, color, disability, genetic information, gender, gender identity, gender expression, sexual and reproductive health decision, marital status, medical condition, military or veteran status, national origin, race (include traits historically associated with race, including, but not limited to, hair texture and protective hairstyles), religion (including religious dress), sex, or sexual orientation that adversely affects an employee's terms or conditions of employment is prohibited. This policy applies to all aspects of the employment relationship, including, but not limited to, hiring, training, salary administration, promotion, job assignment, benefits, discipline, and separation of employment.
",https://www.insurancejournal.com/jobs/589098-data-engineer
JOB155959202254,"2 jobs with job title Data Engineer - Boston, Massachusetts, United States","2 jobs with job title Data Engineer - Boston, Massachusetts, United States",,,"
Browse for Data Engineer Jobs in Boston, Massachusetts, United States. Find the job of your dreams on CareerCast.com today!
Search for Similar Listings
",https://www.careercast.com/jobs/data-engineer-boston-massachusetts-374630297-b
JOB157641872681,Big Data Engineer,Big Data Engineer,,,"
Allstate
Big Data Engineer
The world isn’t standing still, and neither is Allstate. We’re moving quickly, looking across our businesses and brands and taking bold steps to better serve customers’ evolving needs. That’s why now is an exciting time to join our team. You’ll have opportunities to take risks, challenge the status quo and shape the future for the greater good.
You’ll do all this in an environment of excellence and the highest ethical standards – a place where values such as integrity, inclusive diversity and accountability are paramount. We empower every employee to lead, drive change and give back where they work and live. Our people are our greatest strength, and we work as one team in service of our customers and communities.
Everything we do at Allstate is driven by a shared purpose: to protect people from life’s uncertainties so they can realize their hopes and dreams. For more than 89 years we’ve thrived by staying a step ahead of whatever’s coming next – to give customers peace of mind no matter what changes they face. We acted with conviction to advocate for seat belts, air bags and graduated driving laws. We help give survivors of domestic violence a voice through financial empowerment. We’ve been an industry leader in pricing sophistication, telematics, digital photo claims and, more recently, device and identity protection. We are the Good Hands. We don’t follow the trends. We set them.
Job Summary
Job Family Summary
Data Science incorporates techniques across many disciplines – including mathematics/statistics, computer programming, data engineering and ETL, software development, and high performance computing – with traditional business expertise with the goal of extracting meaning from data to optimize future business decisions. Individuals in this field should be an expert/fluent in several of these disciplines and sufficiently proficient in others to effectively design, build, and deliver end to end predictive analytics products to optimize future decisions. Individual demonstrates sufficient analytic agility to quickly develop new skills across these disciplines as those disciplines evolve. The Big Data Engineer job family is accountable for end to end engineering of data solutions which includes designing and building systems for data storage and analytics that enable Allstate analysts to make better decisions to achieve Allstate’s goals.
Job Summary
This role is responsible for providing input on tracks of work to deliver Big Data solutions enabling advanced data science and analytics. This includes working with the team on new Big Data systems for analyzing data; the coding & development of advanced analytics solutions to make/optimize business decisions and processes; integrating new tools to improve descriptive, predictive, and prescriptive analytics. This role contributes to the structured and unstructured Big Data / Data Science tools.
Key Responsibilities
Key Responsibilities
 Executes basic to moderately complex functional work tracks for the team.
 Partners with ATSV teams on Big Data efforts.
 Partners closely with team members on Big Data solutions for our data science community and analytic users.
 Provides support to team on development of basic to moderately complex technical solutions using Big Data techniques in data & analytics processes.
 Develops innovative solutions to Big Data issues and challenges within the team
 Provides support to team on the development of basic to moderately complex prototypes and department applications that integrate big data and advanced analytics to make business decisions.
 Uses new areas of Big Data technologies, (ingestion, processing, and distribution) that can solve business problems.
Job Qualifications
Knowledge/Skills/Abilities/Experience
 0 - 2 Years of experience or equivalent skills & ability
 Bachelors or Master’s preferred in a quantitative or scientific field such as computer science, computer engineering or equivalent experience.
 Understanding of using software development to drive data science & analytic efforts.
 Experience with database & ETL concepts.
 Experience with various data types (e.g. Relational, Unstructured, Hierarchical, and Linked “Graph” Data).
 Experience in working with statistical software such as SAS, SPSS, MatLab, R, CART, etc.
 Ability to code and develop prototypes in languages such as Python, Perl, Java, C, R, SQL, XSLT.
 Ability to communicate and present technical topics to technical audiences.
Level Guide: Please refer to the Allstate Level Guide on MyHr Knowledge
Regular, predictable attendance is an essential function of this job.
Compensation Data
Salary range is $74,000 to $90,000. Salary conmensurate with exprience.
The candidate(s) offered this position will be required to submit to a background investigation, which includes a drug screen.
Good Work. Good Life. Good Hands®.
As a Fortune 100 company and industry leader, we provide a competitive salary – but that’s just the beginning. Our Total Rewards package also offers benefits like tuition assistance, medical and dental insurance, as well as a robust pension and 401(k). Plus, you’ll have access to a wide variety of programs to help you balance your work and personal life -- including a generous paid time off policy. For a full description of Allstate’s benefits, visit allstate.jobs/benefits/
Learn more about life at Allstate. Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video.
Allstate generally does not sponsor individuals for employment-based visas for this position.
Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.
For jobs in San Francisco, please click “here” for information regarding the San Francisco Fair Chance Ordinance.
For jobs in Los Angeles, please click “here” for information regarding the Los Angeles Fair Chance Initiative for Hiring Ordinance.
To view the “EEO is the Law” poster click “here”. This poster provides information concerning the laws and procedures for filing complaints of violations of the laws with the Office of Federal Contract Compliance Programs
To view the FMLA poster, click “here”. This poster summarizing the major provisions of the Family and Medical Leave Act (FMLA) and telling employees how to file a complaint.
It is the Company’s policy to employ the best qualified individuals available for all jobs. Therefore, any discriminatory action taken on account of an employee’s ancestry, age, color, disability, genetic information, gender, gender identity, gender expression, sexual and reproductive health decision, marital status, medical condition, military or veteran status, national origin, race (include traits historically associated with race, including, but not limited to, hair texture and protective hairstyles), religion (including religious dress), sex, or sexual orientation that adversely affects an employee's terms or conditions of employment is prohibited. This policy applies to all aspects of the employment relationship, including, but not limited to, hiring, training, salary administration, promotion, job assignment, benefits, discipline, and separation of employment.
More From Allstate
Related Job Listings
",https://www.insurancejournal.com/jobs/628003-big-data-engineer
JOB159615177174,6 jobs with job title Data Engineer at UnitedHealth Group,6 jobs with job title Data Engineer at UnitedHealth Group,,,"
Browse for Data Engineer Jobs for UnitedHealth Group. Find the job of your dreams on CareerCast.com today!
Search for Similar Listings
",https://www.careercast.com/jobs/unitedhealth-group-data-engineer-330564200-b
JOB160465078158,Global Information Protection Sr Associate Data Engineer,Global Information Protection Sr Associate Data Engineer,"3 or more years working in Agile and/or devOps teams (SCRUM),Experience with AWS cloud services: EC2, EMR, RDS, Redshift, S3, Lambda,Experience with data pipeline and workflow management tools: MuleSoft, Informatica Cloud, etc.,Familiarity with various application technology stacks (BI stacks) and technology domains (Data Analytics),Working experience with data analytic tools (e.g., Tableau, Splunk, Spotfire, Hadoop),Clear understanding of Relational and Dimensional database modeling,Skilled programmer with sufficient experience in high level programming languages such as C++, C#, Java, Python, Visual Basic,Experience programming in compiled (C, C++) and interpreted languages (Python, Ruby etc.),DevOps experience building and deploying infrastructure with cloud deployment, build and test automation technologies like ansible, chef, puppet, docker, jenkins, etc.,Experience with Big Data, Advanced Analytic techniques and Real Time data,Full stack development using infrastructure cloud services (AWS preferred) and cloud-native tools and design patterns (Containers, Serverless, Docker, etc.),Demonstrated ability to adopt new cloud technologies and other paradigms such as emerging Big Data technologies (Hadoop, hive, etc.),Exceptional teaming skills encompassing cross-functional teams, peer relationships, informing, understanding and appreciating differences,Proven experience as a member and leader of a high performing team,Strong ability to convey and influence complex technical issues in a manner that is easily understood and actionable,Experience applying change management methodologies in large / global corporate environments involving multiple businesses,Certified Information Security Manager (CISM),CompTIA Security+,Certified Information Systems Security Professional (CISSP)","Lead the development of Relational Database Service (RDS) structure; overseeing the key technical contributors when assessing and evaluating future reporting solutions,Contribute to the design and development for on-demand reporting solutions to support key stakeholders,Assess and leverage new technologies to ensure that the data solutions are stable, efficient, and responsive to appropriate business needs,Maintain and upkeep the program's vision and ensure interoperability cost effective and authorized technologies (e.g., cloud environments),Maintain awareness of the changing analytics environment by partnering with Amgen's Analytics team and industry (e.g., AI, machine learning, etc.),Take ownership of relevant issues and remediate problems through to completion, to include providing on-call support for data and integration solutions,Work with data engineers to provide clear documentation for delivered solutions and processes, integrating documentation with the appropriate corporate stakeholders,Develop, implement, and sustain operational scripts, data structures, libraries and programming code that optimize security in emergent compute patterns with diverse applications throughout the global environment,Analyze, design, develop and operate programs, shell scripts, tests, and infrastructure automation capabilities in an advanced security context,Collaborate cross-functionally with analysts, engineers, data scientists to identify & prioritize requirements, brainstorm solutions, and clarify business objectives for data-centric solutions to achieve continuous improvement in cyber defense/resilience,Assist with data discovery for enhancing reports and designing efficient data stores,Contribute to the exploration and understanding of new tools, and techniques and propose improvements to the data pipeline,Self-starter with a high degree of initiative,Must be highly motivated and able to work effectively under minimal supervision"," The Senior Associate Data Engineer is a member of the Global Information Protection (GIP) Metrics & Analytics team responsible for developing, administering, and enhancing Amgen's cybersecurity metrics and analytics platform which collocates GIP's data in a data warehouse on the Enterprise Data Lake (EDL) and structures it in a central repository in preparation for strategic, operational, and tactical reporting for GIP's internal and external stakeholders.
The Engineer will be responsible for ensuring the data is properly architected to effectively measure performance against GIP's initiatives and display appropriate data in consolidated dashboards for various stakeholders. The Engineer will require collaboration with the data warehouse team, service owners, system owners, and external vendors in various time zones to develop, maintain, and enhance GIP's metrics platform.
Key responsibilities:
Lead the development of Relational Database Service (RDS) structure; overseeing the key technical contributors when assessing and evaluating future reporting solutions
Contribute to the design and development for on-demand reporting solutions to support key stakeholders
Assess and leverage new technologies to ensure that the data solutions are stable, efficient, and responsive to appropriate business needs
Maintain and upkeep the program's vision and ensure interoperability cost effective and authorized technologies (e.g., cloud environments)
Maintain awareness of the changing analytics environment by partnering with Amgen's Analytics team and industry (e.g., AI, machine learning, etc.)
Take ownership of relevant issues and remediate problems through to completion, to include providing on-call support for data and integration solutions
Work with data engineers to provide clear documentation for delivered solutions and processes, integrating documentation with the appropriate corporate stakeholders
Develop, implement, and sustain operational scripts, data structures, libraries and programming code that optimize security in emergent compute patterns with diverse applications throughout the global environment
Analyze, design, develop and operate programs, shell scripts, tests, and infrastructure automation capabilities in an advanced security context
Collaborate cross-functionally with analysts, engineers, data scientists to identify & prioritize requirements, brainstorm solutions, and clarify business objectives for data-centric solutions to achieve continuous improvement in cyber defense/resilience
Assist with data discovery for enhancing reports and designing efficient data stores
Contribute to the exploration and understanding of new tools, and techniques and propose improvements to the data pipeline
Self-starter with a high degree of initiative
Must be highly motivated and able to work effectively under minimal supervision
Must have strong communication and organizational skills and customer service focus
Minimum Qualifications
Master's degree
OR
Bachelor's degree and 2 years of Data Science / Data Science Engineering / Product Engineering experience
OR
Associate's degree and 6 years of Data Science / Data Science Engineering / Product Engineering experience
OR
High school diploma / GED and 8 years of Data Science / Data Science Engineering / Product Engineering experience
Preferred Qualifications
3 or more years working in Agile and/or devOps teams (SCRUM)
Experience with AWS cloud services: EC2, EMR, RDS, Redshift, S3, Lambda
Experience with data pipeline and workflow management tools: MuleSoft, Informatica Cloud, etc.
Familiarity with various application technology stacks (BI stacks) and technology domains (Data Analytics)
Working experience with data analytic tools (e.g., Tableau, Splunk, Spotfire, Hadoop)
Clear understanding of Relational and Dimensional database modeling
Skilled programmer with sufficient experience in high level programming languages such as C++, C#, Java, Python, Visual Basic
Experience programming in compiled (C, C++) and interpreted languages (Python, Ruby etc.)
DevOps experience building and deploying infrastructure with cloud deployment, build and test automation technologies like ansible, chef, puppet, docker, jenkins, etc.
Experience with Big Data, Advanced Analytic techniques and Real Time data
Full stack development using infrastructure cloud services (AWS preferred) and cloud-native tools and design patterns (Containers, Serverless, Docker, etc.)
Demonstrated ability to adopt new cloud technologies and other paradigms such as emerging Big Data technologies (Hadoop, hive, etc.)
Exceptional teaming skills encompassing cross-functional teams, peer relationships, informing, understanding and appreciating differences
Proven experience as a member and leader of a high performing team
Strong ability to convey and influence complex technical issues in a manner that is easily understood and actionable
Experience applying change management methodologies in large / global corporate environments involving multiple businesses
Proven adherence to SOPs, methodologies, and policies to include security policies
One or more of the following certifications, including but not limited to:
Certified Information Security Manager (CISM)
CompTIA Security+
Certified Information Systems Security Professional (CISSP)
SANS Global Information Assurance Certifications (GIAC)
Amgen is committed to unlocking the potential of biology for patients suffering from serious illnesses by discovering, developing, manufacturing and delivering innovative human therapeutics. This approach begins by using tools like advanced human genetics to unravel the complexities of disease and understand the fundamentals of human biology.
Amgen focuses on areas of high unmet medical need and leverages its expertise to strive for solutions that improve health outcomes and dramatically improve people's lives. A biotechnology pioneer since 1980, Amgen has grown to be one of the world's leading independent biotechnology companies, has reached millions of patients around the world and is developing a pipeline of medicines with breakaway potential.
",https://www.biospace.com/job/1980682/global-information-protection-sr-associate-data-engineer/
JOB160785252881,Associate Researcher – Data Engineer for Chapin Hall @ Chicago,Associate Researcher – Data Engineer for Chapin Hall @ Chicago,"Demonstrated knowledge of SQL and relational databases such as PostgreSQL. Professional experience with complex data systems strongly preferred; experience with public sector data and data systems preferred.,Programming experience in either Python or R (experience in both is preferred).,Familiarity with version control systems such as git is preferred.,Ability to balance many competing demands, as well as to demonstrate good decision-making and initiative.,Excellent written and verbal communication skills, including in discussing technical concepts with non-technical users.,Ability to work independently with a high degree of initiative required.,Ability to manage multiple, concurrent tasks required.,Demonstrated judgment and discretion in the handling of sensitive information required.,Must be able to remain in a stationary position for extended periods of time.,Must be able to operate a computer extensively for four (4) or more hours per day.","Converts, merges and/or assembles data for analysis. Develops and maintains programs that convert data into analyzable formats and/or that can be utilized for data analysis, with a strong emphasis on generalizability and transparency.,Contributes to the ongoing automation of existing and emerging processes for importing, documenting, integrating, and updating data as well as to coding best practices such as code review and version control.,Develops static and interactive reports and visualizations to facilitate improved data use by agencies and organizations that seek to improve the wellbeing of children and families.,Collaborates with researchers, data scientists, policy and implementation specialists, and IT staff in project and system design activities.","
Job Description
GENERAL SUMMARY
Chapin Hall is an independent policy research center affiliated with the University of Chicago, one of the world’s premier research universities. Chapin Hall provides public and private decision-makers with rigorous data analysis and achievable solutions to support them in improving the lives of our most vulnerable children, youth and families. Chapin Hall’s impact derives largely from the distinctive marriage of the most rigorous academic research with innovative partnerships with the public systems, institutions, organizations, and programs that are in a position to best deploy that research. For more information about Chapin Hall, please visit our website at www.chapinhall.org.
Chapin Hall at the University of Chicago is seeking an experienced individual to work with a team of researchers in conducting empirical, analytical and conceptual studies on children, families and neighborhoods and in improving the ability of organizations serving these individuals to use and interpret data and evidence. The Associate Researcher will join a team of data scientists and researchers in organizing and presenting data, including development of data management pipelines and databases, maintaining large project codebases, and creating interactive reports and visualizations in R and Python. Chapin Hall maintains a secure Linux data environment, a series of PostgreSQL databases, and a suite of data processing and analytic tools including Python, R, SQL, and SAS.
The position will report directly to Nick Mader, Senior Researcher.
ESSENTIAL FUNCTIONS
The primary responsibilities of the position are as follows:
Converts, merges and/or assembles data for analysis. Develops and maintains programs that convert data into analyzable formats and/or that can be utilized for data analysis, with a strong emphasis on generalizability and transparency.
Contributes to the ongoing automation of existing and emerging processes for importing, documenting, integrating, and updating data as well as to coding best practices such as code review and version control.
Develops static and interactive reports and visualizations to facilitate improved data use by agencies and organizations that seek to improve the wellbeing of children and families.
Collaborates with researchers, data scientists, policy and implementation specialists, and IT staff in project and system design activities.
QUALIFICATIONS
Education & Experience
Master’s degree in public policy, computer science, or another relevant field plus a minimum of two years of relevant experience required OR a relevant bachelor’s degree plus a minimum of five years of relevant experience required.
Other Qualifications
Demonstrated knowledge of SQL and relational databases such as PostgreSQL. Professional experience with complex data systems strongly preferred; experience with public sector data and data systems preferred.
Programming experience in either Python or R (experience in both is preferred).
Familiarity with version control systems such as git is preferred.
Ability to balance many competing demands, as well as to demonstrate good decision-making and initiative.
Excellent written and verbal communication skills, including in discussing technical concepts with non-technical users.
Ability to work independently with a high degree of initiative required.
Ability to manage multiple, concurrent tasks required.
Demonstrated judgment and discretion in the handling of sensitive information required.
MINIMUM PHYSICAL REQUIREMENTS
The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
Must be able to remain in a stationary position for extended periods of time.
Must be able to operate a computer extensively for four (4) or more hours per day.
______________________________________________________________________________________________________
Pre-employment background checks are required for all Chapin Hall at the University of Chicago positions.
To express interest in this opening, please visit https://csschcc.sentrichr.com.
Formal expressions of interest are accepted online only. A cover letter, resume, writing sample, and reference contact information are required to be considered for this position.
Individuals in need of reasonable accommodations to complete the application process should contact Human Resources by calling (773) 256-5157, or by sending an email to humanresources@chapinhall.org.
Chapin Hall at the University of Chicago is an Affirmative Action, Equal Opportunity Employer that values and actively seeks diversity in its workforce. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, status as an individual with disability, age, protected veteran status, or any other status protected by law.
How to Apply
To express interest in this opening, please visit https://csschcc.sentrichr.com/?requisition=0260
Apply for this Job
Message *
",https://feedproxy.google.com/~r/RJobs/~3/5aZkPqydST0/
JOB162431826595,Intern - Data Engineer (Predictive Analytics),Intern - Data Engineer (Predictive Analytics),,,"Description
**Intern - Data Engineer (Predictive Analytics)** **Description** **PEARSON INTERNSHIP PROGRAM** **Data Engineer (Predictive Analytics)** Pearson Interns - Helping shape the future of education **Why join Pearsons intern program?** Pearson is the worlds learning company. We help people of all ages acquire the knowledge and skills they need to be successful in their work and careers. We believe that everyone should be able to keep learning, every day and in every way, throughout their lives. Bringing together everything we know about the science of learning and the latest technology, were shaping the future of teaching and learning. Were looking for the next generation of talented undergraduates to join our team for an unforgettable 10-week internship. An internship at Pearson is an opportunity to bring your own unique perspective as a learner, together with your academic knowledge, technical skills, and enthusiasm, to help create products used by students like you. As one of our interns, you will gain a comprehensive introduction to our business. Youll be assigned to a team and work on real-life projects that bring our products and services to life. On the job training and professional development will be provided to enable you to contribute to the business. Youll also have direct access to a senior member of the team, as each intern will be mentored to help you make the most of the ten-week program. We foster a work environment thats inclusive as well as diverse, where our people can be themselves. Every idea and perspective is valued so that our products reflect the people we serve our teachers and learners. **What Does the Internship Program Offer?** Successful candidates will spend 10 weeks working with our technology teams. Youll be paid for the duration of your internship. The internship begins on Monday, June 1st and ends Friday, August 7th. Pearson is an Equal Opportunity and Affirmative Action Employer and a member of E-Verify. All qualified applicants, including minorities, women, protected veterans, and individuals with disabilities are encouraged to apply. **Qualifications** **What are we looking for in an Intern** + Enrolled in an undergraduate or graduate technical degree in Information Science / Information Technology, Computer Science, Engineering, Mathematics, Physics, or a related field + Strong communication skills with the ability to discuss any issues with a wide variety of individuals and groups + Creative and innovative skills with regards to knowledge and awareness of industry trends and digital advances as they relate to new opportunities and business needs + Ability to work autonomously + Ability to learn quickly and apply learning to problems or activities + A strategic thinker and listener who acquires good problem-solving techniques + An organized team player who can manage multiple tasks + Familiarity with Excel, SQL, AWS, Google Cloud, Java, Go, Python, R, QL, TensorFlow, or Tableau + Min 3.0 GPA + Graduation date between 2020 and 2022 + Interns should be within driving distance of office location **Job description** + Build predictive analytics capabilities that aim to predict events or sequence of events in the next future period + Using machine learning algorithms and techniques build Supply chain & Financial Data models in our Enterprise Data Warehouse + Work with IT senior team members to design and model new business solutions + Build Data visualizations using tableau for the design predictive data models. + Prepare documentation and presentation to leadership on newly released features. Pearson is an Equal Opportunity and Affirmative Action Employer and a member of E-Verify. All qualified applicants, including minorities, women, protected veterans, and individuals with disabilities are encouraged to apply. **Primary Location:** US-NC-Durham **Work Locations:** US-NC-Durham-5425 Page Churchill 5425 Page Road Durham 27703 **Job:** Project/Temporary Workforce **Organization:** Technology & Operations **Employee Status:** Fixed Term **Job Type:** Internship **Shift:** Day Job **Job Posting:** Jan 6, 2020 **Job Unposting:** Ongoing **Schedule:** Full-time Temporary **Req ID:** 1916947Pearson is an Equal Opportunity and Affirmative Action Employer and a member of E-Verify. All qualified applicants, including minorities, women, protected veterans, and individuals with disabilities are encouraged to apply.
",https://www.internships.com/posting/sam_3455602688
JOB162525267519,PTI Raw Materials Data Engineer / Sr. Data Engineer,PTI Raw Materials Data Engineer / Sr. Data Engineer,"Bachelor’s, Master’s, or Ph.D. degree in computer science/electrical engineering or relevant field,Proven and significant experience building and managing data pipelines.,Ability to build and manage data pipelines with Python, Scala or Java.,Knowledge of software engineering best practices such code reviews, testing frameworks, maintainability and readability.,Commercial client-facing project experience is helpful, including working in close-knit teams,Ability to work across structured, semi-structured, and unstructured data, extract information and identify linkages across disparate data sets.,Meaningful experience in multiple database technologies (such as Hadoop, MS SQL Server, Oracle, MySQL, Teradata).,Confirmed ability in clearly communicating complex solutions,Deep understanding of Information Security principles to ensure compliant handling and management of process data,Experience and interest in Cloud platforms such as: AWS, Azure, or Google Platform,Familiarity with data warehousing and deploying ETL processes with Python. Extraordinary attention to detail.,Strong organizational and interpersonal skills: can get things done in a way that optimizes results, strengthens internal and external relationships, and with consideration of resources.,Knowledge of cGMP’s, Health Authority regulations, and Quality Systems.,Work Environment/Physical Demands/Safety Considerations,Ability to work in international/global environment. 10-30% travel anticipated.,May work in the clean room environment that requires gowning in the form of hospital scrubs,,Ability to sit, stand and move within work space for extended periods","Hybrid technical role interfacing with process SMEs using state of the art technologies, whilst also being able to communicate complex intractable ideas to non-technical audiences.,Collect clear requirements from SMEs and process experts.,Work with our process experts to model their data landscape, obtain data extracts and define secure data exchange approaches,Acquire, ingest, and process data from multiple sources and systems into Big Data platforms,Understanding, assessing and mapping the data landscape,Collaborate with our data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models,Maintaining our Information Security standards on the engagement,Defining the technology stack to be provisioned by our infrastructure team","
PTI Raw Materials Data Engineer / Sr. Data Engineer
South San Francisco
California, United States of America
The Position
Note: This role may be filled as a Data Engineer or Sr. Data Engineer. The position description is written at the Data Engineer level.
As a member of the PTI Raw Material – Data Engineering and Architecture Team, you will work in multi-disciplinary environments harnessing data to provide real-world impact for our processes and products. You’ll work closely with a team of data scientists, subject matter experts and other data engineers in order to curate, transform and construct features which feed directly into our modeling approach.
Must collaborate, listen and learn from colleagues, challenge thoughtfully and prioritize impact of work. Responsible for finding improvements in advanced data analytic models and data architecture. Looking for someone who can quickly adapt to ever changing environment, has a passion to learn and can be trusted to work in the best interests of colleagues.
Job Responsibilities
Hybrid technical role interfacing with process SMEs using state of the art technologies, whilst also being able to communicate complex intractable ideas to non-technical audiences.
Collect clear requirements from SMEs and process experts.
Work with our process experts to model their data landscape, obtain data extracts and define secure data exchange approaches
Acquire, ingest, and process data from multiple sources and systems into Big Data platforms
Understanding, assessing and mapping the data landscape
Collaborate with our data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models
Building modular pipeline to construct features and modeling tables
Supplementary Responsibilities
Maintaining our Information Security standards on the engagement
Defining the technology stack to be provisioned by our infrastructure team
Use new and creative techniques to deliver impact for our clients as well as internal R&D projects
Job Requirements
Education and Experience
Bachelor’s, Master’s, or Ph.D. degree in computer science/electrical engineering or relevant field
8+ years of experience in bio-pharmaceutical industry specializing in bioprocess manufacturing sciences and technology.
Knowledge, Skills and Abilities
Proven and significant experience building and managing data pipelines.
Ability to build and manage data pipelines with Python, Scala or Java.
Knowledge of software engineering best practices such code reviews, testing frameworks, maintainability and readability.
Commercial client-facing project experience is helpful, including working in close-knit teams
Ability to work across structured, semi-structured, and unstructured data, extract information and identify linkages across disparate data sets.
Meaningful experience in multiple database technologies (such as Hadoop, MS SQL Server, Oracle, MySQL, Teradata).
Confirmed ability in clearly communicating complex solutions
Deep understanding of Information Security principles to ensure compliant handling and management of process data
Experience and interest in Cloud platforms such as: AWS, Azure, or Google Platform
Familiarity with data warehousing and deploying ETL processes with Python. Extraordinary attention to detail.
Strong organizational and interpersonal skills: can get things done in a way that optimizes results, strengthens internal and external relationships, and with consideration of resources.
Knowledge of cGMP’s, Health Authority regulations, and Quality Systems.
Work Environment/Physical Demands/Safety Considerations
Ability to work in international/global environment. 10-30% travel anticipated.
May work in the clean room environment that requires gowning in the form of hospital scrubs,
Ability to sit, stand and move within work space for extended periods
Able to work on co-located or remote cross-functional teams.
#LI-DW1
Who We Are
A member of the Roche Group, Genentech has been at the forefront of the biotechnology industry for more than 40 years, using human genetic information to develop novel medicines for serious and life-threatening diseases. Genentech has multiple therapies on the market for cancer & other serious illnesses. Please take this opportunity to learn about Genentech where we believe that our employees are our most important asset & are dedicated to remaining a great place to work.
The next step is yours. To apply today, click on the ""Apply online"" button.
Genentech is an equal opportunity employer & prohibits unlawful discrimination based on race, color, religion, gender, sexual orientation, gender identity/expression, national origin/ancestry, age, disability, marital & veteran status. For more information about equal employment opportunity, visit our Genentech Careers page.
",https://www.gene.com/careers/detail/202003-109174/PTI-Raw-Materials-Data-Engineer-Sr-Data-Engineer
JOB163655727803,Data Engineer Intern,Data Engineer Intern,Be wary of Google Hangout or Skype interviews as these are not publicly-listed numbers that can be used to verify the legitimacy of the interviewer.,"Never accept a check or other funds from a company to purchase materials necessary for your position.,Avoid and report situations where employers require payment or work without compensation as part of the application process.,Avoid corresponding with anyone who reaches out via text or email or outside of the Chegg Internships platform that you don't recognize.","
Description
Data Engineer Intern Company: Integral Ad Science Location: Chicago Posted on: January 12, 2020 Job Description: SunIRef:Manu:title Data Engineer Intern Integral Ad Science 13 reviews - Chicago, IL 60654 Integral Ad Science 13 reviews Read what people are saying about working here. Integral Ad Science (IAS) is a global technology and data company that builds verification, optimization, and analytics solutions for the advertising industry and we're looking for a Data Engineering Intern to join our Data Engineering team. If you are excited by technology that has the power to handle hundreds of thousands of transactions per second; collect tens of billions of events each day; and evaluate thousands of data-points in real-time all while responding in just a few milliseconds, then IAS is the place for you! Our data pipelines process between 2B to 5B events per hour. Experience gained on such data pipelines are in high demand. As a Data Engineering Intern you will work with more senior engineers in building new data pipelines on AWS, migrate pipelines to AWS or extend features and optimize performance of existing data pipelines. What you'll get to do: Implement data processing solutions using Big Data stack including but not limited to Hadoop, Spark, EMR and Snowflake Work with data engineers and data scientists to analyze, design, code, debug, test, document, and deploy changes to the system Participate in sprint meetings and daily stand-ups Attend intern activities designed to allow you to develop your skills, better understand your career interests and identify opportunities for future employment Network with other interns and IAS employeesWho you are and what you have: A rising senior actively working towards obtaining a BA/BS degree in Computer Science, Mathematics, or a related field looking for a full-time position upon graduation Relevant coursework, and interest, in build, test, automation, and DevOps frameworks Experience programming in object oriented languages such as Java, C++, Scala or Python as well as proficiency in Linux Basic understanding of algorithms and data structures Ability to communicate clearly, verbally and in writing Effective time management skills and ability to work in a team atmosphereWhat puts you over the top: Some practical experience working on AWS or another cloud provider Some practical experience developing with Apache Spark and/or Hive Good knowledge of SQL and experience with columnar datastores About Integral Ad Science Integral Ad Science (IAS) is the global market leader in digital ad verification, offering technologies that drive high-quality advertising media. IAS equips advertisers and publishers with both the insight and technology to protect their advertising investments from fraud and unsafe environments as well as to capture consumer attention, and drive business outcomes. Founded in 2009, IAS is headquartered in New York with global operations in 18 offices across 13 countries. IAS is part of the Vista Equity Partners portfolio of software companies. For more on how IAS is powering great impressions for top publishers and advertisers around the world, visit *************** ( *********************** ). Equal Opportunity Employer: IAS is an equal opportunity employer, committed to our diversity and inclusiveness. We will consider all qualified applicants without regard to race, color, nationality, gender, gender identity or expression, sexual orientation, religion, disability or age. We strongly encourage women, people of color, members of the LGBTQIA community, people with disabilities and veterans to apply. California Applicant Pre-Collection Notice: We collect personal information (PI) from you in connection with your application for employment or engagement with IAS, including the following categories of PI: identifiers, personal records, commercial information, professional or employment or engagement information, non-public education records, and inferences drawn from your PI. We collect your PI for our purposes, including performing services and operations related to your potential employment or engagement. For additional details or if you have questions, contact us at **************************. To learn more about us, please visit *********************** ( *********************** ) and *********************** ( *********************** ) Attention agency/3rd party recruiters: IAS does not accept any unsolicited resumes or candidate profiles. If you are interested in becoming an IAS recruiting partner, please send an email introducing your company to **********************************. We will get back to you if there's interest in a partnership. Integral Ad Science - Just posted report job - original job
Skills
python, c++ programming, algorithm development, data structures, data science, computer science, java, hive, apache spark, hadoop, optimization, linux, sql, scala, mathematics
Always be on the alert for potentially fraudulent job postings online. Report potential fraud to us if you're unsure about the legitimacy of a job posting or employer on Chegg Internships.
Never accept a check or other funds from a company to purchase materials necessary for your position.
Avoid and report situations where employers require payment or work without compensation as part of the application process.
Avoid corresponding with anyone who reaches out via text or email or outside of the Chegg Internships platform that you don't recognize.
Be wary of Google Hangout or Skype interviews as these are not publicly-listed numbers that can be used to verify the legitimacy of the interviewer.
",https://www.internships.com/posting/bug_38696125909
JOB172518838780,"2 jobs with job title Data Engineer - Minneapolis, Minnesota, United States","2 jobs with job title Data Engineer - Minneapolis, Minnesota, United States",,," Browse for Data Engineer Jobs in Minneapolis, Minnesota, United States. Find the job of your dreams on CareerCast.com today!
Search for Similar Listings ",https://www.careercast.com/jobs/data-engineer-minneapolis-minnesota-350748187-b
JOB176906039354,Lead Big Data Engineer,Lead Big Data Engineer,You understand our desire to be the best place to work and that trust is the foundation of that.,"Interface with end users to gather, understand and translate requirements into the Agile delivery process,Work closely with other Data Platform engineers to provide data requirements,Work closely with product owners, designers, other developers, architects, quality engineers, and DevOps to deliver innovative solutions that solve complex healthcare problems,Design and implement highly performing ETL used internally by Operation, Product teams,Building generic ingestion engine, data processing through AWS EMR, synchronizing data between up and down streams; AWS RDS, Dynamo, ElasticSearch, RedShift, s3, and dockerizing anything running in production,Manage individual sprint priorities, deadlines and deliverables.,Ensure that we are continuously raising our standard of data engineering excellence by implementing best practices for coding, testing and deploying,In addition to being able to carry out the above responsibilities, we’re looking for someone comfortable working in a fast paced, ever changing environment who has a good deal of experience with SaaS applications, as indicated by the following attributes,8+ years software development experience,Strong experience in database technologies (SQL / MySQL) and data integration,Strong experience with scripting languages; Python and Shell Script,Experience with Amazon Web Services,Hands-on experience with Hive and Pig,Experience in real stream processing with Spark/Kafka/Kinesis (nice to have),Experience in building and working in a heavy agile, collaborative, innovative, flexible and team-oriented environment,Self-driven and ability to lead complex projects,Ability to influence others and direction of projects,An excellent leader with a “can-do” attitude,Hands-on, detail-oriented, methodical & inquisitive,A motivated self-starter with a solid level of experience that quickly grasps complex challenges,A skillful communicator with experience working with technical management teams,A strong customer focus and metrics driven,A quick learner with a passion to challenge him/herself outside of the comfort zone.,Fantastic collaborator, team player, negotiator, and influencer,Fast fail entrepreneurial and innovative spirit,Thrives in a fast-paced environment where continuous improvement is the norm and the bar for quality is extremely high,Excited by the challenges of working in a product team undergoing rapid growth serving millions of customers,Locally-based applicants highly preferred (Seattle),Making a difference is what we do. We do the right thing for the right reasons – and we do it well, even when it’s hard.,You operate from a perspective of truly caring about our employees, clients, and customers and creating value for them.
We are strong individually and together, we’re powerful.,We roll up our sleeves and get stuff done.,We’re boldly and relentlessly reinventing healthcare.","
Overview
The Opportunity:
Do you want to participate in creating and delivering the next generation of technology to simplify access to healthcare, enable informed and intelligent healthcare choices and reduce healthcare costs for millions of consumers? Are you bored of working in ecommerce, or a small functionality of a big product where you don’t see your impact? If your answers are yes, please read on!
As a core member of Accolade’s data platform team you will be designing, building and delivering V1 cloud native, service-oriented products to meet the growth trajectory of the company in data ingestion, processing and business intelligence needs. You will work closely with both internal and external stakeholders to gather requirements and translate them into world class software with the latest technologies.
A Day in the Life:
Interface with end users to gather, understand and translate requirements into the Agile delivery process
Work closely with other Data Platform engineers to provide data requirements
Work closely with product owners, designers, other developers, architects, quality engineers, and DevOps to deliver innovative solutions that solve complex healthcare problems
Design and implement highly performing ETL used internally by Operation, Product teams
What kind of projects will you support?
Building generic ingestion engine, data processing through AWS EMR, synchronizing data between up and down streams; AWS RDS, Dynamo, ElasticSearch, RedShift, s3, and dockerizing anything running in production
What key things will you accomplish?
Manage individual sprint priorities, deadlines and deliverables.
Ensure that we are continuously raising our standard of data engineering excellence by implementing best practices for coding, testing and deploying
What do you need to bring to the table to be successful in this role?
In addition to being able to carry out the above responsibilities, we’re looking for someone comfortable working in a fast paced, ever changing environment who has a good deal of experience with SaaS applications, as indicated by the following attributes
8+ years software development experience
Strong experience in database technologies (SQL / MySQL) and data integration
Strong experience with scripting languages; Python and Shell Script
Experience with Amazon Web Services
Hands-on experience with Hive and Pig
Experience in real stream processing with Spark/Kafka/Kinesis (nice to have)
Experience in building and working in a heavy agile, collaborative, innovative, flexible and team-oriented environment
Self-driven and ability to lead complex projects
Ability to influence others and direction of projects
Desired Personal Characteristics:
An excellent leader with a “can-do” attitude
Hands-on, detail-oriented, methodical & inquisitive
A motivated self-starter with a solid level of experience that quickly grasps complex challenges
A skillful communicator with experience working with technical management teams
A strong customer focus and metrics driven
A quick learner with a passion to challenge him/herself outside of the comfort zone.
Fantastic collaborator, team player, negotiator, and influencer
Fast fail entrepreneurial and innovative spirit
Thrives in a fast-paced environment where continuous improvement is the norm and the bar for quality is extremely high
Excited by the challenges of working in a product team undergoing rapid growth serving millions of customers
Locally-based applicants highly preferred (Seattle)
Values we admire:
We find joy and purpose in serving others.
Making a difference is what we do. We do the right thing for the right reasons – and we do it well, even when it’s hard.
You operate from a perspective of truly caring about our employees, clients, and customers and creating value for them.
We are strong individually and together, we’re powerful.
We believe in each other, in honesty, and in having fun. You won’t find egos or office walls here because we aren’t defined by titles – but by actions, behaviors and results.
We roll up our sleeves and get stuff done.
We’re boldly and relentlessly reinventing healthcare.
We are a company changing the world, one person at a time.
Super high expectations? Bring it on? Our curiosity drives us.
You understand our desire to be the best place to work and that trust is the foundation of that.
Where it all began…
Accolade is an on-demand healthcare concierge for employers, health plans, health systems and consumers. Our team of compassionate, exceptional professionals is supported by breakthrough science and technologies to guide people through the healthcare system in a deeply personalized manner. By taking the time to get to know each person, understand the context of their healthcare decisions, build trust and influence decisions, we deliver industry-leading engagement levels, satisfaction scores unseen in healthcare, better health outcomes, and cost savings of more than 10 percent.
Accolade has been recognized as one of the nation’s 25 most promising companies by Forbes magazine, the fastest-growing private healthcare company by Inc. 500 and a Top Workplace in Philadelphia for five consecutive years. For more information, visit www.accolade.com.
#LI-JH1
",https://www.geekwire.com/jobs/job/accolade-seattle-wa-2-lead-big-data-engineer-2/
JOB179209803038,"Associate Data Engineer (SQL, Cognos, Python)","Associate Data Engineer (SQL, Cognos, Python)","Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.,Bachelor’s Degree in STEM related field or equivalent,Two years of related experience,Developing knowledge of tools, techniques, and manipulation including Cloud platforms, programming languages, and software engineering practices.,SQL (query language), basic understanding of transactional and reporting databases, strong problem-solving skills and ability to work independently,Python, Github, Rally, AWS, Cognos, Microstrategies, SQL Server Integration Studio (SSIS), familiarity with Kanban/Agile practices, test driven development, experience with cloud technologies preferred.","Build rudimentary data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.,Assist in the operationalization and automation of data products.,Analyze common sources to determine value and recommend data to include in analytical processes.,Interact and collaborate with team and business users to support delivery and educate end users on data products/analytic environment.,Perform data and systems analysis, assessment and resolution for defects and incidents.","
The Travelers Companies, Inc.
Associate Data Engineer (SQL, Cognos, Python)
Company Summary
Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.
Target Openings
1
Job Description Summary
Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As an Associate Data Engineer you will aid in growing and transforming our analytics landscape. You will leverage your ability to rapidly grasp and design new technologies, as well as your creativity and curiosity to capture, explore and transform data to support Artificial Intelligence, Machine Learning and business intelligence/insights.
This position may be based 100% remotely or in one of our offices.
Primary Job Duties & Responsibilities
Build rudimentary data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.
Assist in the operationalization and automation of data products.
Analyze common sources to determine value and recommend data to include in analytical processes.
Interact and collaborate with team and business users to support delivery and educate end users on data products/analytic environment.
Perform data and systems analysis, assessment and resolution for defects and incidents.
Test data movement, transformation code and data components.
Minimum Qualifications
Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
One year of data engineering or equivalent experience.
Education, Work Experience, & Knowledge
Bachelor’s Degree in STEM related field or equivalent
Two years of related experience
Developing knowledge of tools, techniques, and manipulation including Cloud platforms, programming languages, and software engineering practices.
SQL (query language), basic understanding of transactional and reporting databases, strong problem-solving skills and ability to work independently
Python, Github, Rally, AWS, Cognos, Microstrategies, SQL Server Integration Studio (SSIS), familiarity with Kanban/Agile practices, test driven development, experience with cloud technologies preferred.
Knowledge of investments and/or finance a plus.
Employment Practices
Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences.
If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.
Travelers reserves the right to fill this position at a level above or below the level included in this posting.
To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.
More From The Travelers Companies, Inc.
Related Job Listings
",https://www.insurancejournal.com/jobs/640968-associate-data-engineer-sql-cognos-python
JOB179571296188,Principal Data Engineer (Graph Technologies),Principal Data Engineer (Graph Technologies),,"Work with business and client IS to develop analytic applications using graph technologies.,Participate in requirements and design workshops with internal business and client IS partners.,Develop information models,Design and develop data pipelines to extract data from varous sources using APIs, perform data transformation, and load triples into graph database/RDF triple store.,Participate in all aspects of the software development process using Agile development methodologies.,Maintain awareness and knowledge of industry trends and proactively identify and drive identification of opportunities to be leveraged.,Learn, evaluate and conduct proof of concepts on new technologies as they emerge and that are pertaining to Amgen environment.,Develop training, roadshow materials, and outreach events to increase the adoption of various solutions developed and of the platforms used.","
Amgen (NASDAQ:AMGN), a biotechnology pioneer, discovers, develops and delivers innovative human therapeutics. Our medicines have helped millions of patients in the fight against cancer, kidney disease, rheumatoid arthritis and other serious illnesses.
The Principal Data Engineer (Graph Technologies) will be part of the Enterprise Engineering and Analytics (EEA) organization. This role is based in Thousand Oaks, CA. This role will be part of the product team that is implementing Enterprise Data Fabric (connected data ecosystem) within Amgen. This role will be responsible for developing analytic solutions using graph technologies, multi-functional information modeling, development of data pipelines, and automation. This position involves working with large-scale graph data in order to provide analytics and insight into the data ingested into the Enterprise Data Lake. The candidate should have good working knowledge of RDF graph data models and be comfortable using existing standards for representing data in a graph. The candidate should have working experience designing and implementing graph database schemas and applications using Cambridge Semantics or Stardog or PoolParty or other RDF/SPARQL-compatible technologies. The candidate should be fluent in Python, and familiar with writing APIs built on cloud-native platforms such as AWS
Responsibilities:
Work with business and client IS to develop analytic applications using graph technologies.
Participate in requirements and design workshops with internal business and client IS partners.
Develop information models
Design and develop data pipelines to extract data from varous sources using APIs, perform data transformation, and load triples into graph database/RDF triple store.
Participate in all aspects of the software development process using Agile development methodologies.
Maintain awareness and knowledge of industry trends and proactively identify and drive identification of opportunities to be leveraged.
Learn, evaluate and conduct proof of concepts on new technologies as they emerge and that are pertaining to Amgen environment.
Develop training, roadshow materials, and outreach events to increase the adoption of various solutions developed and of the platforms used.
Basic Qualifications
Doctorate degree and 2 years of Information Systems experience
OR
Master's degree & 6 years of Information Systems experience
OR
Bachelor's degree & 8years of Information Systems experience
OR
Associates degree & 10 years of Information Systems experience
Or
High School Diploma /GED and 12 years of Information Systems experience
Preferred Qualifications:
Degree in Computer Science, Information Science, Information Management or related field
2+ years' experience with graph databases and graph analytics: Cambridge Semantics, Stardog, PoolParty, TomSawyer, Apache Giraph or others
2+ years' experience working with Resource Description Framework (RDF) and SPARQL
4+ years of hands-on experience developing data pipelines using Python
Experience doing information modeling at an enterprise scale
Experience with a visualization framework such as D3.js and experience using JavaScript
Experience with NoSQL databases, RDBMS and SQL
Experience working in a cloud-native environment using AWS or Azure or GoogleCloud.
Familiar with taxonomy / ontology development. Familiar with semantic web standards such as RDF, OWL and SKOS
Good understanding of software development, DevOps, unit test, automated testing, GitLab, continuous integration (Jenkins), and continuous deployment (Docker and Kubernetes)
Strong written and oral communication skills
Our culture is what makes Amgen a special place to work. We have a powerful shared purpose around our mission - to serve patients. We respect one another, recognize contributions, and have embedded collaboration, trust, empowerment and inclusion in all that we do.
We equip all our staff members to live well-rounded, healthy lives. Most recently, Amgen added benefits for transgender employees and continues to pride itself on industry-leading, family-friendly offerings for families of all compositions.
Amgen focuses on areas of high unmet medical need and uses its expertise to strive for solutions that improve health outcomes and dramatically improve people's lives. A biotechnology pioneer since 1980, Amgen has grown to be one of the world's leading independent biotechnology companies, has reached millions of patients around the world and is developing a pipeline of medicines with breakaway potential.
Amgen is an Equal Opportunity employer and will consider you without regard to your race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.
We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.
Join Us
If you're seeking a career where you can truly make a difference in the lives of others, a career where you can work at the absolute forefront of biotechnology with the top minds in the field, you'll find it at Amgen.
Amgen, a biotechnology pioneer, discovers, develops and delivers innovative human therapeutics. Our medicines have helped millions of patients in the fight against cancer, kidney disease, rheumatoid arthritis and other serious illnesses.
As an organization dedicated to improving the quality of life for people around the world, Amgen fosters an inclusive environment of diverse, ethical, committed and highly accomplished people who respect each other but compete intensely to win. Together, we live the Amgen values as we continue advancing science to serve patients.
Amgen is an Equal Opportunity employer and will consider all qualified applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.
",https://www.biospace.com/job/2093557/principal-data-engineer-graph-technologies-/
JOB182277949374,Associate Data Engineer,Associate Data Engineer,"Proven attention to detail and proactive communication,Proficient in one of the following coding languages: Python, Java, Scala,Demonstrable experience writing SQL using any RDBMS (Redshift, Postgres, MySQL, Teradata, Oracle, etc.),Experience with Schema Design & Dimensional data modeling,Experience with AWS Services like EC2, S3, Redshift/Spectrum, Glue, Athena, RDS, Lambda, and API gateway,Experience with software DevOps CI/CD tools, such as Git, Jenkins, Linux, and Shell Script,Experience with Spark, Hive, Kafka, Kinesis, Spark Streaming, and Airflow,Hands-on experience using Databricks/Jupyter or similar notebook environment,Experience building data warehouses and ETL pipelines a plus
Our culture is what makes Amgen a special place to work. We have a powerful shared purpose around our mission - to serve patients. We respect one another, recognize contributions, and have embedded collaboration, trust, empowerment and inclusion in all that we do.
We equip all our staff members to live well-rounded, healthy lives. Most recently, Amgen added benefits for transgender employees and continues to pride itself on industry-leading, family-friendly offerings for families of all compositions.
Amgen focuses on areas of high unmet medical need and uses its expertise to strive for solutions that improve health outcomes and dramatically improve people's lives. A biotechnology pioneer since 1980, Amgen has grown to be one of the world's leading independent biotechnology companies, has reached millions of patients around the world and is developing a pipeline of medicines with breakaway potential.
Amgen is an Equal Opportunity employer and will consider you without regard to your race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.","Contribute to the design and development for ETL solutions to support key partners,Collaborate with Application Architects and Business SMEs to design and develop end-to-end data pipelines and supporting infrastructure,Build and operationally support new infrastructure and analytics tools in a DevOps model using Python, SQL and AWS,Proactively identify & implement opportunities to automate tasks and develop reusable frameworks,Participate in efforts to design, build, and develop rapid Proof-of-Concept (POC) solutions and services
Basic Qualifications
Bachelor's degree
Or
Associate's degree and 4 years of Information Systems experience
Or
High school diploma / GED and 6 years of Information Systems experience
Preferred Qualifications","
Amgen is seeking a technology associate with the passion to drive innovation in a highly-integrated financial planning landscape. The Associate Data Engineer will be an integral member of a newly formed Agile Product Team that will implement and own ground-breaking solutions for global professionals in Finance, Research and Development, and Global Commercial Operations. Got a mind for creating a simplified system of interconnected data sources to drive powerful financial insights? Come join our team and be a part of something new that we can be proud of!
The Associate Data Engineer will report to the Senior Manager Information Systems and will work out of Amgen's Capability Center in Tampa, FL. At Amgen, our mission is simple: to serve patients. Our new Tampa Capability Center provides essential services that enable us to better pursue this mission. This state-of-the-art center serves as a base for finance, information systems, and human resources professionals to make a meaningful impact at one of the world's leading biotechnology companies.
Responsibilities
With guidance, applies knowledge of basic principles, methods and practices to simple and moderately complex assignments as follows:
Contribute to the design and development for ETL solutions to support key partners
Collaborate with Application Architects and Business SMEs to design and develop end-to-end data pipelines and supporting infrastructure
Build and operationally support new infrastructure and analytics tools in a DevOps model using Python, SQL and AWS
Proactively identify & implement opportunities to automate tasks and develop reusable frameworks
Participate in efforts to design, build, and develop rapid Proof-of-Concept (POC) solutions and services
Basic Qualifications
Bachelor's degree
Or
Associate's degree and 4 years of Information Systems experience
Or
High school diploma / GED and 6 years of Information Systems experience
Preferred Qualifications
Proven attention to detail and proactive communication
Proficient in one of the following coding languages: Python, Java, Scala
Demonstrable experience writing SQL using any RDBMS (Redshift, Postgres, MySQL, Teradata, Oracle, etc.)
Experience with Schema Design & Dimensional data modeling
Experience with AWS Services like EC2, S3, Redshift/Spectrum, Glue, Athena, RDS, Lambda, and API gateway
Experience with software DevOps CI/CD tools, such as Git, Jenkins, Linux, and Shell Script
Experience with Spark, Hive, Kafka, Kinesis, Spark Streaming, and Airflow
Hands-on experience using Databricks/Jupyter or similar notebook environment
Experience building data warehouses and ETL pipelines a plus
Our culture is what makes Amgen a special place to work. We have a powerful shared purpose around our mission - to serve patients. We respect one another, recognize contributions, and have embedded collaboration, trust, empowerment and inclusion in all that we do.
We equip all our staff members to live well-rounded, healthy lives. Most recently, Amgen added benefits for transgender employees and continues to pride itself on industry-leading, family-friendly offerings for families of all compositions.
Amgen focuses on areas of high unmet medical need and uses its expertise to strive for solutions that improve health outcomes and dramatically improve people's lives. A biotechnology pioneer since 1980, Amgen has grown to be one of the world's leading independent biotechnology companies, has reached millions of patients around the world and is developing a pipeline of medicines with breakaway potential.
Amgen is an Equal Opportunity employer and will consider you without regard to your race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.
Join Us
If you're seeking a career where you can truly make a difference in the lives of others, a career where you can work at the absolute forefront of biotechnology with the top minds in the field, you'll find it at Amgen.
Amgen, a biotechnology pioneer, discovers, develops and delivers innovative human therapeutics. Our medicines have helped millions of patients in the fight against cancer, kidney disease, rheumatoid arthritis and other serious illnesses.
As an organization dedicated to improving the quality of life for people around the world, Amgen fosters an inclusive environment of diverse, ethical, committed and highly accomplished people who respect each other but compete intensely to win. Together, we live the Amgen values as we continue advancing science to serve patients.
Amgen is an Equal Opportunity employer and will consider all qualified applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.
",https://www.biospace.com/job/2105667/associate-data-engineer/
JOB182711305920,SQL Data Engineer,SQL Data Engineer,,"Managing the investigation of corporate data requirements, documenting them according to the required standards utilising the prescribed methods and tools,Implementing data flows to connect operational systems, data for analytics and BI systems. Re-engineer manual data flows to enable scaling and repeatable use,Working closely with data architects (to determine what data management systems are appropriate) and data scientists (to determine what data is needed for analysis).,Tackling problems associated with database integration and unstructured data sets,Ensuring that those using the data structures and associated components have a good understanding and that any queries are dealt with promptly and efficiently,Strong technical process understanding regardless of technology,Wide range of strong technical skills (i.e. Azure Devops, Azure Data Factory, Data Bricks, SQL, python),Core SQL Competencies – SSMS, SSIS, T-SQL, Stored Procedures,ADF Pipelines to build and populate SQL databases,Background in migrating traditional MS products to Azure,Ability to create efficient DW or DL structures to minimise cost of orchestration / processing and ingestion of data,Very high attention to detail,Strong communication skills,Efficient in building ETL and ELT processes for enterprise solutions,Strong software delivery methods and knowledge,Digital delivery – has a track record of working on DevOps delivery,Exposure in Climate Change data legislation, practices and stakeholders,Experience in Environmental related industries i.e Water, Energy, Forestry related,Presentation skills,Understanding of architecting solutions taking into account wider considerations","
SQL Data Engineer
Job purpose and background
Are you a capable SQL Data Engineer who is passionate about the power of data to solve environmental issues? CDP are looking for an SQL Data Engineer to shape delivery by collaborating with data architects and modellers to contribute to the acquisition of corporate data requirements, documenting them according to the required standards utilising the prescribed methods and Azure data tools, in order to build our centralised data platform.
This is a permanent role, with responsibility for developing, constructing, testing and maintaining architectures such as data pipelines and large-scale data processing warehouses. The post-holder will leverage industry best practice while delivering changes, such as agile backlogs, code repositories, automated builds, testing and releases. They will be responsible for ensuring data scientists can pull relevant data sets for their analyses, implement data pipelines to connect operational systems, data for analytics and BI systems. The role includes re-engineering manual data flows to enable automation, scaling and repeatable use and developing data set processes for data modelling, mining and production.
The post-holder will work closely with data architects (to determine what data management systems are appropriate) and data scientists (to determine which data are needed for analysis). They will provide clean, usable data to the business through the data platform in accordance with governance, and analyse, design, plan, execute and evaluate data requirements to support business activities and projects. The post-holder will be central in ensuring the delivery of world-class digital products and changing the delivery culture in CDP.
About CDP's data engineering team:
The Data Engineering Team’s primary remit is to improve the usability of the climate change, water, forests and cities data disclosed to CDP through robust and transparent methods. The team will create sustainable data pipelines for data quality monitoring, data cleaning, reporting and data science modelling. Harmonised data collected from external sources will enrich the data assets’ value and enhance accessibility for CDP’s stakeholders. The team will produce value-adding insight delivering it through data products that help internal and external stakeholders to better understand the quantitative and qualitative results of their actions. This in turn helps stakeholders to make data-led decisions and optimise for all constraints. Through every stage the data assets are governed by the industry practice standards in a robust and transparent manner.
Key responsibilities include:
Managing the investigation of corporate data requirements, documenting them according to the required standards utilising the prescribed methods and tools
Implementing data flows to connect operational systems, data for analytics and BI systems. Re-engineer manual data flows to enable scaling and repeatable use
Working closely with data architects (to determine what data management systems are appropriate) and data scientists (to determine what data is needed for analysis).
Tackling problems associated with database integration and unstructured data sets
Ensuring that those using the data structures and associated components have a good understanding and that any queries are dealt with promptly and efficiently
In liaison with the information management or IT management functions, contributing to the development and maintenance of corporate data standards
Required skills and experience:
Strong technical process understanding regardless of technology
Wide range of strong technical skills (i.e. Azure Devops, Azure Data Factory, Data Bricks, SQL, python)
Core SQL Competencies – SSMS, SSIS, T-SQL, Stored Procedures
ADF Pipelines to build and populate SQL databases
Background in migrating traditional MS products to Azure
Ability to create efficient DW or DL structures to minimise cost of orchestration / processing and ingestion of data
Very high attention to detail
Strong communication skills
Efficient in building ETL and ELT processes for enterprise solutions
Strong software delivery methods and knowledge
Strong performance-tuning skills.
Desired skills and experience
Digital delivery – has a track record of working on DevOps delivery
Exposure in Climate Change data legislation, practices and stakeholders
Experience in Environmental related industries i.e Water, Energy, Forestry related
Presentation skills
Understanding of architecting solutions taking into account wider considerations
Structured problem solving techniques.
This is a permanent full-time role, reporting to the Head of Data Engineering, which will be delivered remotely to start with. The post holder will be required to travel to CDP’s London office from time to time when it reopens.
Salary and benefits: Between £45,000 - £48,500 per annum dependent on experience, 30 days holiday excluding bank holidays, flexible working opportunities and others benefits.
Interested applicants must be eligible to work legally in the United Kingdom.
Before you apply
We’ll only use the information you provide to process your application. For more details on how we use your information, see our applicants privacy notice. By emailing us your CV and covering letter, you are permitting CDP to use the information you have provided for recruitment purposes.
To apply please email your CV and a covering letter setting out how you meet the required skills and experience or key responsibilities, which should be no more than two pages, to recruitment@cdp.net with ‘DI-SQL Data Engineer, Firstname Surname’ in the subject. Applications will be reviewed on a rolling basis, so early applications are strongly encouraged. The deadline is 8.00 am on 19 October 2020.
Are you interested in a career at CDP working in one of our global offices?
Explore our current job vacancies
",https://www.cdp.net/language/pt?redirect=%2Fen%2Finfo%2Fcareers%2Fsql-data-engineer-2
JOB185915348278,Sr Data Engineer,Sr Data Engineer,"4 years of relevant experience with data tools, techniques, and manipulation required.,College Degree in STEM related field,Advanced knowledge of data tools, techniques, and manipulation preferred. Examples (but not limited to):,ETL Tools: Talend (Preferred), Ab Initio or other similar ETL Tools,​Big data and Cloud platforms,5 years of relevant experience with data tools, techniques, and manipulation preferred.,Data concepts - Data Warehouse, Data Lake, Data Model, DB Design, Data Mapping,Data platforms - RDBMS, Big Data and Cloud,Data integration tools - Talend, Ab Initio,Scheduling tools - Autosys, Control-M,Programming languages - Spark, Python, Java,Dev Ops - Continuous Integration, Continuous Deployment, Version Control,Data serialization formats - Parquet, Orc,Cloud services - Ex: AWS (EC2, EMR, RDS, Redshift, S3, Lambda), Snowflake, Databricks,Ability to communicate thoughts/designs/ideas in an unambiguous manner and adjusts communication based on audience.,Exhibits active and effective communication skills with team members – including active listening and effective written and verbal communication skills.,Able to recognize, analyze, and diagnose business and data issues of advanced complexity.,Able to creatively evaluate alternative solutions.,Able to reuse previously completed processes.","Independently review, prepare, design and integrate complex (type, quality, volume) data, correcting problems and recommend data cleansing/quality solutions to issues. Review unfamiliar data sources.,Develop moderate data derivations and apply with complex business transformation rules and data requirements.,Lead the operationalizing and automation of complex data (more systems, data sets and streams, size of data sets more substantial) products into business.,Establish frameworks to acquire, integrate and operationalize data.,Build, test, and implement complex analytic business processes, including pilots and proof of concepts.,Present and translate complex information in relevant business terms.,Work within Travelers standards, processes, and protocols.","
The Travelers Companies, Inc.
Sr Data Engineer
Company Summary
Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.
Target Openings
1
Job Description Summary
Travelers is seeking a Senior Data Engineer to join our team as we grow and transform our analytics landscape. In our agile organization, you will lead the design, build and will oversee the deployment and operation of data solutions that capture, store, transform and utilize data to support our data analytics needs.
Primary Job Duties & Responsibilities
Data Analysis, Acquisition, Preparation, and Exploration:
Independently review, prepare, design and integrate complex (type, quality, volume) data, correcting problems and recommend data cleansing/quality solutions to issues. Review unfamiliar data sources.
Develop moderate data derivations and apply with complex business transformation rules and data requirements.
Perform analysis of complex (type, quality, volume) sources to determine value and use. Determine and recommend data to include in analytical projects.
Data Solutions & Analytic Implementations:
Lead the operationalizing and automation of complex data (more systems, data sets and streams, size of data sets more substantial) products into business.
Establish frameworks to acquire, integrate and operationalize data.
Build, test, and implement complex analytic business processes, including pilots and proof of concepts.
Apply knowledge of current industry trends and techniques to formulate solutions within the context of assigned projects and/or enhancements.
Data Culture:
Present and translate complex information in relevant business terms.
Work within Travelers standards, processes, and protocols.
Incorporate core data management competencies – data governance, data security, data quality.
Minimum Qualifications
4 years of relevant experience with data tools, techniques, and manipulation required.
Education, Work Experience, & Knowledge
Education:
College Degree in STEM related field
Technical Knowledge:
Advanced knowledge of data tools, techniques, and manipulation preferred. Examples (but not limited to):
ETL Tools: Talend (Preferred), Ab Initio or other similar ETL Tools
​Big data and Cloud platforms
Programming languages - SQL, Spark, Python, Hive, AWS, ETL
Experience:
5 years of relevant experience with data tools, techniques, and manipulation preferred.
Job Specific Technical Skills & Competencies
Advanced knowledge of one or more of the following tools and techniques:
Data concepts - Data Warehouse, Data Lake, Data Model, DB Design, Data Mapping
Data platforms - RDBMS, Big Data and Cloud
Data integration tools - Talend, Ab Initio
Scheduling tools - Autosys, Control-M
Programming languages - Spark, Python, Java
Dev Ops - Continuous Integration, Continuous Deployment, Version Control
Data serialization formats - Parquet, Orc
Cloud services - Ex: AWS (EC2, EMR, RDS, Redshift, S3, Lambda), Snowflake, Databricks
Containerization technologies - Docker, Kubernetes
Communication Skills:
Ability to communicate thoughts/designs/ideas in an unambiguous manner and adjusts communication based on audience.
Exhibits active and effective communication skills with team members – including active listening and effective written and verbal communication skills.
Effectively contributes and communicates with the immediate team.
Problem Solving & Decision Making:
Able to recognize, analyze, and diagnose business and data issues of advanced complexity.
Able to creatively evaluate alternative solutions.
Able to reuse previously completed processes.
Demonstrates the ability to make routine decisions independently and escalates when necessary.
Employment Practices
Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences.
If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.
Travelers reserves the right to fill this position at a level above or below the level included in this posting.
More From The Travelers Companies, Inc.
Related Job Listings
",https://www.insurancejournal.com/jobs/627633-sr-data-engineer
JOB192989287779,Data Engineer (remote/relocation),Data Engineer (remote/relocation),,,"
Employee • Amsterdam, Netherlands • Remote • Hiring in Europe, North America, South America, Asia • Added 4 weeks ago
FindHotel has the ambition that every decision should be based on data and every feature be fuelled with data. To make this happen we invest heavily in our data infrastructure. We are looking for a senior Data Engineer to help us scale and grow. The product catalogue of the Data Infrastructure team ranges from the basics of event delivery, storage and processing to A/B testing and Data Science infrastructure (model development and deployment).
Requirements
Who you are:
- You are a data engineer with previous experience in business intelligence and data warehousing
- You know how to work with high volume heterogeneous data, preferably with distributed systems such as Kafka, Spark, and MPP databases such as Snowflake.
- You are comfortable building and deploying applications in public clouds, in particular in the AWS cloud.
- You know how to write distributed, high-volume services in Golang, Scala, or Java.
- You have hands-on experience with a large number of technologies and programming languages. It allows you to choose the right tool for job, and to not be afraid of contributing to systems across the whole FindHotel organisation.
- You are knowledgeable about data modeling, data access, and data storage techniques.
- You appreciate agile software processes, data-driven development, reliability, and responsible experimentation.
- You strive for excellence, clarity and transparency, shipping business value as early as possible, and building incrementally afterwards.
- (For remote candidates) Based in a time zone between UTC-4 and UTC+6
Bonus points for:
- Experience with e-commerce, clickstream data and event tracking
- Experience or interest in data analysis
What we offer:
- Plenty of chances to learn and grow – you'll be surrounded by some of the brightest minds in the city, be part of a culture which values sharing knowledge every day and has a budget to attend conferences and develop yourself.
- A profitable company with fast growth and a great scale opportunity.
- A competitive compensation package + perks and benefits (including Stock Appreciation Rights).
- Flexible time off (take as many holidays as you need) and a chance to work remotely - we measure results, not time spent in the office.
- You will be part of a highly international team in a fun work environment.
- We value good food and offer catered lunches from various cuisines, great coffee, ice-cream in the fridge and the occasional bbq in our garden.
",https://www.f6s.com/jobs/47059/findhotel/data-engineer-remote-relocation?connect
JOB193973747041,Amazon Web Services Data Engineer,Amazon Web Services Data Engineer,"Building and supporting reusable frameworks to ingest, integrate and provision data,Automating of end to end data pipeline with metadata, data quality checks, and audit,Building and supporting a big data platform on the cloud,Building and supporting data pipelines for data extraction, transformation, and loading processes using cloud native services or custom scripting using python, pyspark, spark etc.,,Designing, building and operationalizing large scale enterprise data solutions and applications using one or more of AWS D7A services AWS services in combination with RedShift, DynamoDB, Lambda, Glue, Athena, EMR, Spark etc.,,Be a Graduate in Computer Science/Software Engineering/Mathematics, or related field with a minimum of 3 yrs of experience in information technology,Have 3+ yrs' experience in data warehouse/data lake technical architecture,Have minimum of 3 yrs of Big Data and Big Data tools - Redshift, Redshift, S3, Glue, Athena, DynamoDB, Python, Pyspark etc.,Have experience in Kafka, Spark, Hadoop is preferred,Have 3+ yrs of experience working in cloud data platforms or tools "" AWS experience is preferred,Have experience with Database Architecture & Schema design,Have familiarity with batch processing and workflow tools like AirFlow,Have AWS certifications will be a plus,Have full professional proficiency in English,Working flexible hours - flexing the times when you work in the day to help you fit everything in and work when you are the most productive,Contemporary work-life balance policies and wellbeing activities,Comprehensive private medical care options,Safety net of life insurance and disability programs,Additional elected or voluntary benefits",,"
Company: Baker Hughes
Skills: IT - Analysis & Management
Education: Bachelors/3-5 yr Degree
Location: Budapest, Hungary
Are you passionate about being part of a successful team?
Do you enjoy hands-on technical work and working with data?
Join our Digital Technology - Data Analytics Team
Our team is responsible for Data platform architecture and operations. You will be part of the team implementing next gen data platform. Partner with CTO team to align on Enterprise standards, continue to position D&A technology to support the growing demands across BH.
Partner with the best
You will design, build and implement production data pipelines from ingestion to consumption within a big data architecture. Using AWS native or custom programming and partners with data engineering, architecture and cloud team members.
As a Data Engineer, you will be responsible for:
Building and supporting reusable frameworks to ingest, integrate and provision data
Automating of end to end data pipeline with metadata, data quality checks, and audit
Building and supporting a big data platform on the cloud
Building and supporting data pipelines for data extraction, transformation, and loading processes using cloud native services or custom scripting using python, pyspark, spark etc.,
Designing, building and operationalizing large scale enterprise data solutions and applications using one or more of AWS D7A services AWS services in combination with RedShift, DynamoDB, Lambda, Glue, Athena, EMR, Spark etc.,
Fuel your passion
To be successful in this role you will:
Be a Graduate in Computer Science/Software Engineering/Mathematics, or related field with a minimum of 3 yrs of experience in information technology
Have 3+ yrs' experience in data warehouse/data lake technical architecture
Have minimum of 3 yrs of Big Data and Big Data tools - Redshift, Redshift, S3, Glue, Athena, DynamoDB, Python, Pyspark etc.
Have experience in Kafka, Spark, Hadoop is preferred
Have 3+ yrs of experience working in cloud data platforms or tools "" AWS experience is preferred
Have experience with Database Architecture & Schema design
Have familiarity with batch processing and workflow tools like AirFlow
Have AWS certifications will be a plus
Have full professional proficiency in English
Work in a way that works for you
We recognize that everyone is different and that the way in which people want to work and deliver at their best is different for everyone too. In this role, we can offer the following flexible working patterns:
Working flexible hours - flexing the times when you work in the day to help you fit everything in and work when you are the most productive
Working with us
Our people are at the heart of what we do at Baker Hughes. We know we are better when all of our people are developed, engaged and able to bring their whole authentic selves to work. We invest in the health and well-being of our workforce, train and reward talent and develop leaders at all levels to bring out the best in each other.
Working for you
Our inventions have revolutionized energy for over a century. But to keep going forward tomorrow, we know we have to push the boundaries today. We prioritize rewarding those who embrace change with a package that reflects how much we value their input. Join us, and you can expect:
Contemporary work-life balance policies and wellbeing activities
Comprehensive private medical care options
Safety net of life insurance and disability programs
Additional elected or voluntary benefits
About Us:
With operations in over 120 countries, we provide better solutions for our customers and richer opportunities for our people. As a leading partner to the energy industry, we're committed to achieving net-zero carbon emissions by 2050 and we're always looking for the right people to help us get there. People who are as passionate as we are about making energy safer, cleaner and more efficient.
Join Us:
Are you seeking an opportunity to make a real difference in a company that values innovation and progress? Join us and become part of a team of people who will challenge and inspire you! Let's come together and take energy forward.
Baker Hughes Company is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national or ethnic origin, sex, sexual orientation, gender identity or expression, age, disability, protected veteran status or other characteristics protected by law.
",https://www.rigzone.com/oil/jobs/postings/1104160_amazon_web_services_data_engineer/
JOB196065546692,"4 jobs with job title Data Engineer - Los Angeles, California, United States","4 jobs with job title Data Engineer - Los Angeles, California, United States",,," Browse for Data Engineer Jobs in Los Angeles, California, United States. Find the job of your dreams on CareerCast.com today!
Search for Similar Listings ",https://www.careercast.com/jobs/data-engineer-los-angeles-california-365351432-b
JOB198574383083,Data Engineer San Francisco,Data Engineer San Francisco,Embed with our billing team to create billing pipelines that enable more granular bills and help our better users understand their costs.,"Work with teams to build and continue to evolve data models and data flows to enable data driven decision-making,Design alerting and testing to ensure the accuracy and timeliness of these pipelines. (e.g., improve instrumentation, optimize logging, etc),Identify the shared data needs across Stripe, understand their specific requirements, and build efficient and scalable data pipelines to meet the various needs to enable data-driven decisions across Stripe,Work with our data platform team to identify and integrate new tools into our data stack. For example we’re currently evaluating Presto for use as an ad-hoc query tool.,Have a strong engineering background and are interested in data. You’ll be writing production Scala and Python code along with occasional ad-hoc SQL queries,Have experience in writing and debugging ETL jobs using a distributed data framework (Hadoop/Spark etc…),Have experience managing and designing data pipelines,Can follow the flow of data through various pipelines to debug data issues,Have experience with Scalding or Spark,Have experience with Airflow or other similar scheduling tools,Write a unified user data model that gives a complete view of our users across a varied set of products like Stripe Connect and Stripe Atlas,Continuing to lower the latency and bridge the gap between our production systems and our data warehouse,Working on our customer support data pipeline to help us track our time to response for our users and our total support ticket volume to help us staff our support team appropriately","
As a platform company powering businesses all over the world, Stripe processes payments, runs marketplaces, detects fraud, helps entrepreneurs start an internet business from anywhere in the world. Stripe’s Data Engineers will work to manage all of that data for both our internal and external users.
While we don’t have as much data as Twitter or Facebook we care a great deal about the quality of our data. Because every record in our data warehouse can be vitally important for the businesses that use Stripe, we’re looking for people with a strong background in big data systems to help us scale while maintaining correct and complete data. You’ll be working with a variety of internal teams, some engineering and some business, to help them solve their data needs. Your work will give teams visibility into how Stripe’s products are being used and where we can improve to serve our users needs better.
You will:
Work with teams to build and continue to evolve data models and data flows to enable data driven decision-making
Design alerting and testing to ensure the accuracy and timeliness of these pipelines. (e.g., improve instrumentation, optimize logging, etc)
Identify the shared data needs across Stripe, understand their specific requirements, and build efficient and scalable data pipelines to meet the various needs to enable data-driven decisions across Stripe
Work with our data platform team to identify and integrate new tools into our data stack. For example we’re currently evaluating Presto for use as an ad-hoc query tool.
You might be a fit for this role if you:
Have a strong engineering background and are interested in data. You’ll be writing production Scala and Python code along with occasional ad-hoc SQL queries
Have experience in writing and debugging ETL jobs using a distributed data framework (Hadoop/Spark etc…)
Have experience managing and designing data pipelines
Can follow the flow of data through various pipelines to debug data issues
Bonus:
Have experience with Scalding or Spark
Have experience with Airflow or other similar scheduling tools
It’s not expected that you’ll have deep expertise in every dimension above, but you should be interested in learning any of the areas that are less familiar.
Some things you might work on:
Write a unified user data model that gives a complete view of our users across a varied set of products like Stripe Connect and Stripe Atlas
Continuing to lower the latency and bridge the gap between our production systems and our data warehouse
Working on our customer support data pipeline to help us track our time to response for our users and our total support ticket volume to help us staff our support team appropriately
Embed with our billing team to create billing pipelines that enable more granular bills and help our better users understand their costs.
What’s it like to work at Stripe?
Stripe is helping the internet fulfill its potential as a platform for economic progress by building software tools that accelerate global economic access and technological development. Stripe makes it easy to start, run and scale an internet business from anywhere in the world.
Stripe is, at its heart, an engineering company. To provide a missing pillar of core internet infrastructure, we hire people with a broad set of technical skills (and from a wide variety of backgrounds) who are ready to take on some of the most challenging problems in the industry – from reliably handling 100M API requests per day, to building adaptive machine learning as a result of years of data science and infrastructure work, and enabling entrepreneurs worldwide to start a global internet business.
We look at Stripe as a constant work in progress and the same is true of our people; for all of us, we believe the best is yet to come. We’re here to support each other in our curiosity and creativity – which we pursue through thoughtful discussion and knowledge-sharing among a diverse set of peers and colleagues.
We encourage all engineers to transition teams once every year and a half and also take on short-term projects with other teams across Stripe. This enables engineers to learn how different parts of Stripe work while also establishing stronger ties and cross-pollination between groups.
We contribute to existing open-source projects and the people working on them, and we release several tools as open-source.
We want to work in a company of warm, inclusive people who treat their colleagues exceptionally well. The kind of people who are committed to going out of their way to help other Stripes in the short-term and pushing them to improve over the long-term (by helping them to get better at what they do).
We’re a highly cross-functional organization and view that as part of the fun: we design our space to encourage as much collaboration as possible. We have long tables in the kitchen for a reason (to enable everyone to meet new people and learn from them). We also have a culture of transparency that we carry through to email communication, ensuring that Stripes all around the world have the information they need to make good local decisions.
In both our products and our people, we aim to reflect, represent and advocate for all of our users, globally. Our users transcend geography, culture and language; what we share, collectively, is a drive to create a fairer, more economically interconnected world.
",https://stripe.com/jobs/positions/data-engineer
JOB202324720976,Data Scientist/ Data Engineer (Trading Analytics),Data Scientist/ Data Engineer (Trading Analytics),,,"
Company: Qatar Petroleum
Skills: IT - Analysis & Management
Experience: 5 + Years
Education: Bachelors/3-5 yr Degree
Location: Qatar
Department
INFORMATION & COMMUNICATION TECHNOLOGY
Title
DATA SCIENTIST / DATA ENGINEER (TRADING ANALYTICS)
Primary Purpose of Job
Member of the IT team in charge of Trading solutions, fully immerse in QP Trading (QPT) departments: • Develop and implement greenfield data architecture and processes within the front office of a global LNG trading organisation to enable market analysis and trading functionality. • Design and construct economic models for market analysis and price prediction, implemented primarily in Python & VBA • Contribute and support data analysis and model outputs to contextualize and employ data in support of LNG trading activity. Build, maintain, and expand structured databases (MS SQL, Oracle) for the storage and retrieval of global gas & power pricing and fundamentals data. • Build bespoke data collection (e.g. API connectivity, FTP, HTML web scraping) tools and connections to a variety of remote sources, including non-standard (such as non-western language) web sources. Lead construction of visualisation, reporting, and modelling tools (bespoke web applications, Power BI, Tableau) and provide technical expertise to the wider team in this area. • Take primary responsibility for driving data quality and integrity standards across the LNG trading organisation, driving processes, standards, and raising general awareness of the importance of world-class data quality throughout the business. • Provide timely expert and technical support on Trading analytics systems. Contribute as required to IT projects to implement new or transform existing QPT solutions. • Document and share knowledge & practices related to Trading analytics systems. • Apply security measures by following security procedures and standards to ensure secure environment. Manage and address Trading systems vulnerabilities and threats.
Education
• Academic background in a computing/data science/mathematics/engineering field.
Experience & Skills
• Minimum of 5 years of experience working as a data engineer or front office developer within a commodity trading environment • Adept at constructing and managing large datasets, including database implementation, data scraping and collection, data clean-up, retrieval, and eventual visualisation & reporting • Experienced in construction from scratch of detailed and bespoke economic models which interface with data warehouses • An understanding of the global Gas and LNG markets as well as related Trading business is strongly preferred. Knowledge and experience dealing with LNG/G&P data types & sources • Expert knowledge of Python, VBA, SQL, and ideally Javascript and web app development • Extensive knowledge and experience in the implementation and use of visualisation and reporting tools and models, ideally within a front office commodities trading environment • Extensive experience developing front office trading tools and models • Knowledge of ETL/ETLS and Data Warehousing concepts and technologies • Ability to implement solutions using Agile methods, including prototyping and tactical solutions to meet the short-term and dynamic needs of the business • Excellent stakeholder management skills, at a variety of organisational levels. • Excellent written and verbal communications skills • Self-reliance and self-sufficiency; willingness to help build a business from the ground upwards in a phased manner but with quick short-term solutions essential for success. • Strong delivery focus is critical.
",https://www.rigzone.com/oil/jobs/postings/1108573_data_scientist_data_engineer_trading_analytics/
JOB204413654316,"Data Engineer (Ab Initio, Talend, ETL)","Data Engineer (Ab Initio, Talend, ETL)","Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.,Experience with Ab Initio and/or Talend, ETL required,Bachelor’s Degree in STEM related field or equivalent,Eight years of related experience,The ability to deliver work at a steady, predictable pace to achieve commitments, deliver complete solutions but release them in small batches, and identify and negotiate important tradeoffs.,Demonstrated track record of domain expertise including understanding technical concepts necessary and industry trends, and possess in-depth knowledge of immediate systems worked on and some knowledge of adjacent systems.,Strong problem solver who ensures systems are built with longevity and creates innovate ways to resolve issues.,Strong written and verbal communication skills with the ability to work collaborate well with team members and business partners.","Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions.,Design complex data solutions,Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes.,Incorporate core data management competencies including data governance, data security and data quality.,Collaborate within and across teams to support delivery and educate end users on complex data products/analytic environment.,Perform data and system analysis, assessment and resolution for complex defects and incidents and correct as appropriate.","
The Travelers Companies, Inc.
Data Engineer (Ab Initio, Talend, ETL)
Company Summary
Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.
Target Openings
1
Job Description Summary
Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape. In addition to your strong analytical mind, you will bring your inquisitive attitude and ability to translate stories found in data by leveraging a variety of data programming techniques. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights.
This position may be based 100% remotely or in one of our offices.
Primary Job Duties & Responsibilities
Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions.
Design complex data solutions
Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes.
Incorporate core data management competencies including data governance, data security and data quality.
Collaborate within and across teams to support delivery and educate end users on complex data products/analytic environment.
Perform data and system analysis, assessment and resolution for complex defects and incidents and correct as appropriate.
Test data movement, transformation code, and data components.
Minimum Qualifications
Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
Four years of data engineering or equivalent experience.
Education, Work Experience, & Knowledge
Experience with Ab Initio and/or Talend, ETL required
Bachelor’s Degree in STEM related field or equivalent
Eight years of related experience
Highly proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and a full understanding of modern software engineering practices.
Job Specific Technical Skills & Competencies
The ability to deliver work at a steady, predictable pace to achieve commitments, deliver complete solutions but release them in small batches, and identify and negotiate important tradeoffs.
Demonstrated track record of domain expertise including understanding technical concepts necessary and industry trends, and possess in-depth knowledge of immediate systems worked on and some knowledge of adjacent systems.
Strong problem solver who ensures systems are built with longevity and creates innovate ways to resolve issues.
Strong written and verbal communication skills with the ability to work collaborate well with team members and business partners.
Ability to lead team members and help create a safe environment for others to learn and grow as engineers. and a proven track record of self-motivation in identifying opportunities and tracking team efforts.
Employment Practices
Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences.
If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.
Travelers reserves the right to fill this position at a level above or below the level included in this posting.
To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.
More From The Travelers Companies, Inc.
Related Job Listings
",https://www.insurancejournal.com/jobs/639219-data-engineer-ab-initio-talend-etl
JOB205850301697,"Sr. Data Engineer (ETL, Informatica, Talend)","Sr. Data Engineer (ETL, Informatica, Talend)","Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.,Bachelor’s Degree in STEM related field or equivalent,Ten years of related experience,Strong delivery skills including the ability to determine the software design strategy and methodology to be used for efforts, use automated tests, analysis, and informed feedback loops to ensure the quality and production readiness of work before release, monitor the health of work efforts and that of adjacent systems.,Demonstrated track record of domain expertise including the ability to develop business partnerships and influence priorities by identifying solutions that are aligned with current business objective and closely follow industry trends relevant to domain, understanding how to apply them, and sharing knowledge with coworkers.,Strong problem solver who utilizes data and proofs of concepts to find creative solutions to difficult problems involving a significant number of factors with broad implications, reflects on solutions, measures impact, and uses that information to ideate and optimize.,Excellent communication skills with the ability to develop business partnerships, describe technology concepts in ways the business can understand, document initiatives in a concise and clear manner, and empathetically and attentively listen to others thoughts and ideas.","Analyze, design and build ETL solutions based on business requirement in complex data environment including data profiling/cleansing and transformation,Experience implementing ETL solution with Informatica IDQ or PowerCenter (V10.X) or Talend (7.X) required,Experience working with SQL on RDMBS such as Oracle required.,Experience working with NoSQL database like MongoDB preferred,Experience with integration with Informatica MDM is preferred","
The Travelers Companies, Inc.
Sr. Data Engineer (ETL, Informatica, Talend)
Company Summary
Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.
Target Openings
1
Job Description Summary
Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Senior Data Engineer you will accelerate growth and transformation of our operational and analytics landscape. You will bring a strong desire to guide team members' growth and develop data solutions that translate complex data into user-friendly terminology. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights.
This position may be based 100% remotely or in one of our offices.
Primary Job Duties & Responsibilities
Analyze, design and build ETL solutions based on business requirement in complex data environment including data profiling/cleansing and transformation
Experience implementing ETL solution with Informatica IDQ or PowerCenter (V10.X) or Talend (7.X) required
Experience working with SQL on RDMBS such as Oracle required.
Experience working with NoSQL database like MongoDB preferred
Experience with integration with Informatica MDM is preferred
Experience in integrating messaging and web service as part of ETL solution is preferred
Minimum Qualifications
Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
Five years of data engineering or equivalent experience.
Education, Work Experience, & Knowledge
Bachelor’s Degree in STEM related field or equivalent
Ten years of related experience
Advanced knowledge of tools, techniques, and manipulation including cloud platforms, programming languages, and modern software engineering practices.
Job Specific Technical Skills & Competencies
Strong delivery skills including the ability to determine the software design strategy and methodology to be used for efforts, use automated tests, analysis, and informed feedback loops to ensure the quality and production readiness of work before release, monitor the health of work efforts and that of adjacent systems.
Demonstrated track record of domain expertise including the ability to develop business partnerships and influence priorities by identifying solutions that are aligned with current business objective and closely follow industry trends relevant to domain, understanding how to apply them, and sharing knowledge with coworkers.
Strong problem solver who utilizes data and proofs of concepts to find creative solutions to difficult problems involving a significant number of factors with broad implications, reflects on solutions, measures impact, and uses that information to ideate and optimize.
Excellent communication skills with the ability to develop business partnerships, describe technology concepts in ways the business can understand, document initiatives in a concise and clear manner, and empathetically and attentively listen to others thoughts and ideas.
Ability to lead and take action even when there is no clear owner, inspire and motivate others, and be effective at influencing team members.
Employment Practices
Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences.
If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.
Travelers reserves the right to fill this position at a level above or below the level included in this posting.
To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.
More From The Travelers Companies, Inc.
Related Job Listings
",https://www.insurancejournal.com/jobs/637566-sr-data-engineer-etl-informatica-talend
JOB209044051218,ATSV - Big Data Engineer Internship - University Relations,ATSV - Big Data Engineer Internship - University Relations,,"Participate in strategic planning discussions with technical and non-technical partners.,Effective and efficient utilization of programming tools and techniques.,Responsible for design, prototyping, and delivery of software solutions within a big data eco-system.,Responsible for development of advanced analytics solutions and integrating new tools to improve.,Inquisitive and continues to seek development opportunities.,Works on geographically dispersed team embracing Agile and DevOps principles.,Bachelor’s Degree towards Computer Science or Computer Engineering.,Solid foundational understanding of object-oriented programing principles.,Familiarity with source control solutions (ex git, GitHub, Jenkins, Artifactory).,Strong Python, Java, or other OOP language skills.,Strong communication, collaboration, and problem-solving skills.","
NA
Compensation Data
The salary for this role will be determined based on the school year you are entering in 2021
Job Description
This is a 12-week long Summer 2021 internship in the Allstate Technology Strategic Ventures (ATSV) department at Allstate. With fast growing team of highly skilled personnel, ATSV provides a unique learning environment through formal training curriculum, mentoring, informal everyday coaching and hands-on training. Allstate is looking to hire a Big Data Engineer Intern with Java experience.
Responsibilities:
Participate in strategic planning discussions with technical and non-technical partners.
Effective and efficient utilization of programming tools and techniques.
Responsible for design, prototyping, and delivery of software solutions within a big data eco-system.
Responsible for development of advanced analytics solutions and integrating new tools to improve.
Inquisitive and continues to seek development opportunities.
Works on geographically dispersed team embracing Agile and DevOps principles.
Essential Criteria:
Bachelor’s Degree towards Computer Science or Computer Engineering.
Solid foundational understanding of object-oriented programing principles.
Familiarity with source control solutions (ex git, GitHub, Jenkins, Artifactory).
Strong Python, Java, or other OOP language skills.
Strong communication, collaboration, and problem-solving skills.
Passion for working collaboratively with multiple areas, across shores.
Job Qualifications
Big Data Processing like Hadoop.
Java/Scala
Unix
IntelliJ
Good Work. Good Life. Good Hands®.
As a Fortune 100 company and industry leader, we provide a competitive salary – but that’s just the beginning. Our Total Rewards package also offers benefits like tuition assistance, medical and dental insurance, as well as a robust pension and 401(k). Plus, you’ll have access to a wide variety of programs to help you balance your work and personal life -- including a generous paid time off policy.
Learn more about life at Allstate. Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video.
",https://www.insurancejournal.com/jobs/603146-atsv-big-data-engineer-internship-university-relations
JOB212399356089,Data Engineer,Data Engineer,,"Full access to our jobs board, including over 1,000 exclusive jobs,Your Devex profile highlighted in recruiter search results,Connections to recruiters and industry experts through online and live Devex events","
See the full details of this exclusive job – and all of the other big development opportunities hand picked by our team. These positions are only available with a Career Account. Upgrade now to keep your job search moving.
Starting at $9.50, a Devex Career Account provides you:
Full access to our jobs board, including over 1,000 exclusive jobs
Your Devex profile highlighted in recruiter search results
Connections to recruiters and industry experts through online and live Devex events
",https://www.devex.com/jobs/data-engineer-685068
JOB215986145193,Data Engineer,Data Engineer,"BS/MS degree in Computer Science, Engineering or related field,3 or more years of experience architecting and building processes that extract, process and add value to data sets from multiple source systems.,Experiencing with data modeling and tuning of relational as well as NoSQL datastores (Oracle, Red-shift, Impala, HDFS/Hive, Athena, etc.),Experience working with distributed computing tools (Spark, Hive, etc.),Experience with AWS cloud services: EC2, EMR, RDS, Redshift, S3, Lambda,Experience with data pipeline and workflow management tools: Airflow, etc.,3 or more years of experience with one or more general purpose programming languages, including but not limited to: Java, Scala, C, C++, C#, Swift/Objective C, Python, or JavaScript.,3 or more years experience working with and leading agile development methodologies such as Sprint and Scrum,Experience with Software engineering best-practices, including but not limited to version control (Git, TFS, Subversion, etc.), CI/CD (Jenkins, Maven, Gradle, etc.), automated unit testing, Dev Ops.,Experience with Semantic technologies and approaches is a plus.,Biotech / Pharma experience is a plus,Full stack development using infrastructure cloud services (AWS preferred) and cloud-native tools and design patterns (Containers, Serverless, Docker, etc) is a plus.","Collaborate with Data Architects, Business SME's, and Data Scientists to architect data products and services.,Build data products and service processes which perform data transformation, metadata extraction, workload management and error processing management.,Implement standardized, automated operational and quality control processes to deliver accurate and timely data and reporting to meet or exceed SLAs.,Contribute to the Exploration and understanding of new tools, and techniques and propose improvements to the data pipeline,Integrate the operations data platform with the Data Scientist workbench, the Data Marketplace, and Analytic Tools such as Tableau, Spotfire, R, etc.,Act as a product manager for the operations data platform backlog,Act as a run manager, provide Run/DevOps support","
Amgen is seeking Data Engineers to help realize Amgen's Operations Data Strategy. This program will produce business insights through data science solutions. You will build upon our awarded Enterprise Data Lake to develop value added data products that span the Operations Domain (Process Development, Supply Chain, Quality, Engineering, Manufacturing). There is no more challenging data environment than Life Sciences due to the integration of scientific research, manufacturing, logistics of pharmaceutical products. Expect to make a difference in providing patients with products that meet their medical needs in a competitive landscape.
Successful candidates will have the requisite technical skills; the ability to absorb the nuances of the Bio-Tech operations value chain, including supply chain, logistics, and manufacturing source systems; high personal standards of productivity and quality; and the ability to contribute in a collaborative environment.
Key Activities for the Data Engineer include:
Collaborate with Data Architects, Business SME's, and Data Scientists to architect data products and services.
Build data products and service processes which perform data transformation, metadata extraction, workload management and error processing management.
Implement standardized, automated operational and quality control processes to deliver accurate and timely data and reporting to meet or exceed SLAs.
Contribute to the Exploration and understanding of new tools, and techniques and propose improvements to the data pipeline
Integrate the operations data platform with the Data Scientist workbench, the Data Marketplace, and Analytic Tools such as Tableau, Spotfire, R, etc.
Act as a product manager for the operations data platform backlog
Act as a run manager, provide Run/DevOps support
Basic Qualifications:
Master's degree
OR
Bachelor's degree and 2 years of Information Systems experience
OR
Associate degree and 6 years of Information Systems experience
OR
High school diploma / GED and 8 years of Information Systems experience
Preferred Qualifications:
BS/MS degree in Computer Science, Engineering or related field
3 or more years of experience architecting and building processes that extract, process and add value to data sets from multiple source systems.
Experiencing with data modeling and tuning of relational as well as NoSQL datastores (Oracle, Red-shift, Impala, HDFS/Hive, Athena, etc.)
Experience working with distributed computing tools (Spark, Hive, etc.)
Experience with AWS cloud services: EC2, EMR, RDS, Redshift, S3, Lambda
Experience with data pipeline and workflow management tools: Airflow, etc.
3 or more years of experience with one or more general purpose programming languages, including but not limited to: Java, Scala, C, C++, C#, Swift/Objective C, Python, or JavaScript.
3 or more years experience working with and leading agile development methodologies such as Sprint and Scrum
Experience with Software engineering best-practices, including but not limited to version control (Git, TFS, Subversion, etc.), CI/CD (Jenkins, Maven, Gradle, etc.), automated unit testing, Dev Ops.
Experience with Semantic technologies and approaches is a plus.
Biotech / Pharma experience is a plus
Full stack development using infrastructure cloud services (AWS preferred) and cloud-native tools and design patterns (Containers, Serverless, Docker, etc) is a plus.
Amgen is committed to unlocking the potential of biology for patients suffering from serious illnesses by discovering, developing, manufacturing and delivering innovative human therapeutics. This approach begins by using tools like advanced human genetics to unravel the complexities of disease and understand the fundamentals of human biology.
Amgen focuses on areas of high unmet medical need and leverages its expertise to strive for solutions that improve health outcomes and dramatically improve people's lives. A biotechnology pioneer since 1980, Amgen has grown to be one of the world's leading independent biotechnology companies, has reached millions of patients around the world and is developing a pipeline of medicines with breakaway potential.
Join Us
If you're seeking a career where you can truly make a difference in the lives of others, a career where you can work at the absolute forefront of biotechnology with the top minds in the field, you'll find it at Amgen.
Amgen, a biotechnology pioneer, discovers, develops and delivers innovative human therapeutics. Our medicines have helped millions of patients in the fight against cancer, kidney disease, rheumatoid arthritis and other serious illnesses.
As an organization dedicated to improving the quality of life for people around the world, Amgen fosters an inclusive environment of diverse, ethical, committed and highly accomplished people who respect each other but compete intensely to win. Together, we live the Amgen values as we continue advancing science to serve patients.
Amgen is an Equal Opportunity employer and will consider all qualified applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.
.
",https://www.biospace.com/job/1947932/data-engineer/
JOB221180611917,Data Engineer,Data Engineer,"An existing affinity with: Data Science, Machine Learning, Cloud Computing, Networking, Security, Encryption, RESTful interfaces and DevOps","Gain broad experience and grow into the role of Data Solution Architect and build Data (Lake) solutions for the biggest and most complex international organizations.,Be expected as a technology and innovation driven person who is keen to work with new technologies and platforms and take them to the next level in Data Science.,Work with a diverse and global team of highly skilled people.,Alternate between working for clients and creating our own products.,Be a guru but behave as a consultant.,Be responsible for providing technical leadership to enterprise scale projects and solutions,Develop, maintain, and improve architectures, including reference and target architectures, principles, roadmaps, patterns, etc.,You have a Masters in Computer Science, Software Engineering or a comparable discipline.,You have hands on experience with Hadoop, Spark, Kubernetes.,You have strong OO and programming skills in any of Java, Scala, Python, R, C/C++.,You have experience with (Cloud based) Data warehouse, Data lake, ETL Pipelines, and Data Modelling tools,You have experience with cloud native, micro-services oriented, and big data/non-relational data architectures.,Flourish working with like-minded people, yet you can function autonomously.,Are excited about new technology and innovation.,Like to learn outside of your core activities in order to broaden your field of expertise.,Value great quality in your work and thinking ahead come natural to you while being pragmatic.,Are willing to work on client location and travel abroad.,Have or are willing to gain managerial skills and in time apply them,Affinity with Data and Architecture,Experience to articulate the trade-offs, benefits and risks of all architecture and design solutions","
Big Four | Master Data Management | Hadoop | Spark | Python | Architecture
Your new role
Our growing team of technology and analytics enthusiasts go beyond merely applying algorithms on large data sets. We are pragmatic in our approach: where we use any platform, tool, or method that fits the case, and in fact build our own. We perform Data analysis for clients and we develop our own tools and products, such as our own Hadoop distribution and a revolutionary Open-Source platform for distribution of analytics and data. We are, and have every intention to remain, global leaders in our field. By joining our team as a Senior Consultant, you will:
Gain broad experience and grow into the role of Data Solution Architect and build Data (Lake) solutions for the biggest and most complex international organizations.
Be expected as a technology and innovation driven person who is keen to work with new technologies and platforms and take them to the next level in Data Science.
Work with a diverse and global team of highly skilled people.
Alternate between working for clients and creating our own products.
Be a guru but behave as a consultant.
Be responsible for providing technical leadership to enterprise scale projects and solutions
Develop, maintain, and improve architectures, including reference and target architectures, principles, roadmaps, patterns, etc.
Creation of technical design documents and supporting materials.
Functie-eisen
What you will need to succeed
Technically:
You have a Masters in Computer Science, Software Engineering or a comparable discipline.
You have hands on experience with Hadoop, Spark, Kubernetes.
You have strong OO and programming skills in any of Java, Scala, Python, R, C/C++.
You have experience with (Cloud based) Data warehouse, Data lake, ETL Pipelines, and Data Modelling tools
You have experience with cloud native, micro-services oriented, and big data/non-relational data architectures.
Personally, you:
Flourish working with like-minded people, yet you can function autonomously.
Are excited about new technology and innovation.
Like to learn outside of your core activities in order to broaden your field of expertise.
Value great quality in your work and thinking ahead come natural to you while being pragmatic.
Are willing to work on client location and travel abroad.
Have or are willing to gain managerial skills and in time apply them
Preferably, you have:
Affinity with Data and Architecture
Experience to articulate the trade-offs, benefits and risks of all architecture and design solutions
An existing affinity with: Data Science, Machine Learning, Cloud Computing, Networking, Security, Encryption, RESTful interfaces and DevOps
Bedrijfsprofiel
Your new employer
As one of the Big Four we have an international network of companies with personal attention for its employees. We have a strong market position that we further want to strengthen with a clear vision, strong values and enthusiastic coworkers. Our people work intensively together for renowned clients on a daily basis in an enjoyable and stimulating environment. Personal development is central at our company. With directed training, education and coaching we help our employees to excel and get the best out of themselves.
What you will get in return
As one of the Big Four you will receive excellent primary and secondary benefits (lease car, laptop, smartphone, expense allowance and free of premium pension) tailored to the latest market developments.
Vacature kenmerken
",https://tweakers.net/carriere/it-banen/32896/data-engineer
JOB222546226162,Data Engineer ( Barcelona),Data Engineer ( Barcelona),"Computer Science or Computer Engineering or Mathematics degree,Strong analytical and problem-solving skills,Coding proficiency in at least one modern programming language (Python, Ruby, Java, etc),Experience in data modeling, ETL development, and data warehousing,Data Warehousing Experience (for example Oracle, Redshift, Teradata, etc.),Experience building data products incrementally and integrating and managing datasets from multiple sources,Knowledge of Mathematical Statistics,Experience with Big Data Technologies (Hadoop, Hive, Hbase, Pig, Spark, etc.) a plus,Good English,Free Glovo credits,The opportunity to change the world and see how everyone uses the product you build,Work in an international, dynamic and passionate environment with a great company culture,We consider only variants of relocation to Barcelona, Spain. We cover visa and relocation costs.","Glovo is looking for a world-class data engineer to work in our Barcelona office. You are someone who loves working in a high-paced startup environment and solving difficult problems. You are passionate about data and inventing new and elegant solutions to support our internal customers’ needs and believe in empowering the entire company by facilitating efficient access to data.,You will develop new data pipelines that leverage cloud architecture and perform transformations on existing data to support new use cases. You will be using Redshift as our primary data warehouse solution to create the curated data model for the enterprise to leverage.,Design, implement, and support an analytical platform providing ad-hoc and automated access to large datasets,Interface with internal teams to extract, transform, and load data from a wide variety of data sources using SQL and big data technologies,Continually improve ongoing ETL, reporting and analysis processes, automating or simplifying self-service support for customers","Job description
Glovo is looking for a world-class data engineer to work in our Barcelona office. You are someone who loves working in a high-paced startup environment and solving difficult problems. You are passionate about data and inventing new and elegant solutions to support our internal customers’ needs and believe in empowering the entire company by facilitating efficient access to data.
You will develop new data pipelines that leverage cloud architecture and perform transformations on existing data to support new use cases. You will be using Redshift as our primary data warehouse solution to create the curated data model for the enterprise to leverage.
Responsibilities
Design, implement, and support an analytical platform providing ad-hoc and automated access to large datasets
Interface with internal teams to extract, transform, and load data from a wide variety of data sources using SQL and big data technologies
Continually improve ongoing ETL, reporting and analysis processes, automating or simplifying self-service support for customers
Requirements
Computer Science or Computer Engineering or Mathematics degree
Strong analytical and problem-solving skills
Coding proficiency in at least one modern programming language (Python, Ruby, Java, etc)
Experience in data modeling, ETL development, and data warehousing
Data Warehousing Experience (for example Oracle, Redshift, Teradata, etc.)
Experience building data products incrementally and integrating and managing datasets from multiple sources
Knowledge of Mathematical Statistics
Experience with Big Data Technologies (Hadoop, Hive, Hbase, Pig, Spark, etc.) a plus
Good English
We offer:
Free Glovo credits
The opportunity to change the world and see how everyone uses the product you build
Work in an international, dynamic and passionate environment with a great company culture
Relocation
We consider only variants of relocation to Barcelona, Spain. We cover visa and relocation costs.
",https://hh.ru/vacancy/21628353
JOB222920807688,Sr. Data Engineer,Sr. Data Engineer,"Various experience levels considered. Junior candidates must have a strong background of coursework or academic projects around data engineering or machine learning at scale or have appropriate industry experience contributing to such projects.,Senior candidates must demonstrate a track record of successful technical leadership in the execution of large-scale data projects.,Software Engineering – Level-appropriate experience in software engineering and SDLC (our stack may include Python, Golang and Scala). Must consider code readability, reuse, and extensibility a priority when developing solutions.,Big Data Engineering - Experience in building scalable data pipelines involving machine learning, optimization or prediction,Big Data Devops - Experience in performing operations and automation of various big-data ecosystems in production environments on AWS or a related cloud service,Ability to thrive in a fast paced, cross regional, diverse, and dynamic work environment,Experience with AWS data stack – Redshift, Athena, EMR, Kinesis, DocumentDB, DynamoDB,Experience with establishing well-organized data lakes,Experience setting up and optimizing data warehouses,Background in data modeling and performance tuning in relational and no-SQL databases,Experience with data practices (security, data management and governance),Experience in operations research, machine learning or optimization","Design and implement scalable data workflows and pipelines, and integrate diverse data sources and sinks,Design appropriate database schemas and optimize database deployment architectures for analytics query loads,Implement data transforms and organization for various data stores (data lakes and warehouses),Design and implement new platform architectures for building and serving machine learning models,Work with the platform operations team to monitor and maintain live production systems,Provide tooling and automation for infrastructure, continuous testing, and continuous deploy of data systems","
The world isn’t standing still, and neither is Allstate. We’re moving quickly, looking across our businesses and brands and taking bold steps to better serve customers’ evolving needs. That’s why now is an exciting time to join our team. As a leader in a corporation with 83,000 employees and agency force members, you’ll have a hand in transforming not only Allstate but a dynamic industry. You’ll have opportunities to take risks, challenge the status quo and shape the future for the greater good.
You’ll do all this in an environment of excellence and the highest ethical standards – a place where values such as integrity, inclusive diversity and accountability are paramount. We empower every employee to lead, drive change and give back where they work and live. Our people are our greatest strength, and we work as one team in service of our customers and communities.
Everything we do at Allstate is driven by a shared purpose: to protect people from life’s uncertainties so they can realize their hopes and dreams. For 89 years we’ve thrived by staying a step ahead of whatever’s coming next – to give customers peace of mind no matter what changes they face. We acted with conviction to advocate for seat belts, air bags and graduated driving laws. We help give survivors of domestic violence a voice through financial empowerment. We’ve been an industry leader in pricing sophistication, telematics, digital photo claims and, more recently, device and identity protection. We are the Good Hands. We don’t follow the trends. We set them.
Job Description
Avail (affiliate company of Allstate) is a new car sharing platform focused on improving mobility and reducing the cost of car ownership. We give car owners a way to earn extra income from their idle cars and connect drivers with a convenient, affordable way to drive a car when they want. As part of the Avail Data Engineering team, you will be working to manage our ever-growing collection of vehicle sharing and usage data. We support our business analytics and marketing teams by performing data integration and ETL between an increasingly diverse set of data sources and our data warehouse. We will also build big-data applications leveraging techniques from operations research and machine learning to directly enrich, personalize and optimize the Avail car-sharing product. This is a green field opportunity to contribute to the design and implementation of a flexible, scalable data framework for an exciting new sector of the sharing economy. This position can be based in either of two Avail HQ offices at San Francisco or Chicago, or fully remote with semi-regular travel to SF HQ.
Key Responsibilities
Design and implement scalable data workflows and pipelines, and integrate diverse data sources and sinks
Design appropriate database schemas and optimize database deployment architectures for analytics query loads
Implement data transforms and organization for various data stores (data lakes and warehouses)
Design and implement new platform architectures for building and serving machine learning models
Work with the platform operations team to monitor and maintain live production systems
Provide tooling and automation for infrastructure, continuous testing, and continuous deploy of data systems
Job Qualifications
Requirements:
Various experience levels considered. Junior candidates must have a strong background of coursework or academic projects around data engineering or machine learning at scale or have appropriate industry experience contributing to such projects.
Senior candidates must demonstrate a track record of successful technical leadership in the execution of large-scale data projects.
Software Engineering – Level-appropriate experience in software engineering and SDLC (our stack may include Python, Golang and Scala). Must consider code readability, reuse, and extensibility a priority when developing solutions.
Big Data Engineering - Experience in building scalable data pipelines involving machine learning, optimization or prediction
Big Data Devops - Experience in performing operations and automation of various big-data ecosystems in production environments on AWS or a related cloud service
Ability to thrive in a fast paced, cross regional, diverse, and dynamic work environment
Nice to have:
Experience with AWS data stack – Redshift, Athena, EMR, Kinesis, DocumentDB, DynamoDB
Experience with establishing well-organized data lakes
Experience setting up and optimizing data warehouses
Background in data modeling and performance tuning in relational and no-SQL databases
Experience with data practices (security, data management and governance)
Experience in operations research, machine learning or optimization
The candidate(s) offered this position will be required to submit to a background investigation, which includes a drug screen.
Good Work. Good Life. Good Hands®.
As a Fortune 100 company and industry leader, we provide a competitive salary – but that’s just the beginning. Our Total Rewards package also offers benefits like tuition assistance, medical and dental insurance, as well as a robust pension and 401(k). Plus, you’ll have access to a wide variety of programs to help you balance your work and personal life -- including a generous paid time off policy.
Learn more about life at Allstate. Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video.
Allstate generally does not sponsor individuals for employment-based visas for this position.
Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.
For jobs in San Francisco, please click ""here"" for information regarding the San Francisco Fair Chance Ordinance.
For jobs in Los Angeles, please click ""here"" for information regarding the Los Angeles Fair Chance Initiative for Hiring Ordinance.
It is the policy of Allstate to employ the best qualified individuals available for all jobs without regard to race, color, religion, sex, age, national origin, sexual orientation, gender identity/gender expression, disability, and citizenship status as a veteran with a disability or veteran of the Vietnam Era.
",https://www.insurancejournal.com/jobs/580704-sr-data-engineer
JOB223205719392,Graduate Data Engineer,Graduate Data Engineer,"Support the delivery of a diverse portfolio of data-driven and machine learning projects for Wood's global energy, environment, and infrastructure clients,Develop data-driven solutions, dashboards and workflow automations using high-level programming languages (such as Python and R) and low-code platforms such as the MS Power Platform and Palantir Foundry,Prepare large and complex data sets using high-level programming languages and data and cloud compute services (mainly Azure, but also AWS),Continually learn new technologies and data solution platforms,Assist with preparation & delivery project technical presentations and reports,Travel as required for project meetings & workshops across the global business,Data and analytics programming experience with Python and/or R,Comfortable with the prospect of handling engineering and sensor data from equipment and machines (e.g., pressures, temperatures, flowrates, fluid densities) to derive insight (working alongside various subject matter experts internal and external to the business),Experience of working with at least one mainstream cloud computing service such as Microsoft Azure or Amazon Web Services,Working knowledge of SQL for data access, manipulation, and validation,Presentation, reporting and excellent communication skills,Flexibility and openness to work on a variety of data challenges across various business domains, for both internal and external clients,Bachelor's degree in an applicable engineering discipline, engineering science, computer science, or data analytics",,"
Company: Wood
Skills: IT - Programming & Database
Education: Bachelors/3-5 yr Degree
Location: Galway, County Galway, Ireland
Overview / Responsibilities
Wood is seeking to recruit a Graduate Data Engineer to be part of a leading global technical services business. This is a significant opportunity to develop your digital career and thrive in a problem solving, solutions-focused environment. You will be responsible for the delivery and development of data-driven solutions to our global customers.
Key Responsibilities:
Support the delivery of a diverse portfolio of data-driven and machine learning projects for Wood's global energy, environment, and infrastructure clients
Develop data-driven solutions, dashboards and workflow automations using high-level programming languages (such as Python and R) and low-code platforms such as the MS Power Platform and Palantir Foundry
Prepare large and complex data sets using high-level programming languages and data and cloud compute services (mainly Azure, but also AWS)
Continually learn new technologies and data solution platforms
Assist with preparation & delivery project technical presentations and reports
Travel as required for project meetings & workshops across the global business
Wood's operations support and technical services teams use advanced data analytics, cloud, and software services to optimise the operation, inspection, and integrity management of energy infrastructure for global clients.
Skills / Qualifications
Competencies & Skills Required:
Data and analytics programming experience with Python and/or R
Comfortable with the prospect of handling engineering and sensor data from equipment and machines (e.g., pressures, temperatures, flowrates, fluid densities) to derive insight (working alongside various subject matter experts internal and external to the business)
Experience of working with at least one mainstream cloud computing service such as Microsoft Azure or Amazon Web Services
Working knowledge of SQL for data access, manipulation, and validation
Presentation, reporting and excellent communication skills
Flexibility and openness to work on a variety of data challenges across various business domains, for both internal and external clients
Qualifications & Experience Requirements:
Bachelor's degree in an applicable engineering discipline, engineering science, computer science, or data analytics
Company Overview
Wood is a global leader in engineering and consultancy across energy and the built environment, helping to unlock solutions to some of the world's most critical challenges. We provide consulting, projects and operations solutions in more than 60 countries, employing around 45,000 people. www.woodplc.com
Diversity Statement
We are an equal opportunity employer that recognises the value of a diverse workforce. All suitably qualified applicants will receive consideration for employment on the basis of objective criteria and without regard to the following (which is a non-exhaustive list): race, colour, age, religion, gender, national origin, disability, sexual orientation, gender identity, protected veteran status, or other characteristics in accordance with the relevant governing laws.
",https://www.rigzone.com/oil/jobs/postings/1103472_graduate_data_engineer/
JOB226399965589,"Data Engineer (GCP, AWS, Open-source)","Data Engineer (GCP, AWS, Open-source)",,,"
eLife is a non-profit organisation inspired by research funders and led by scientists. Our mission is to help scientists accelerate discovery by operating a platform for research communication that encourages and recognises the most responsible behaviours in science. eLife Sciences Publications, Ltd is a limited liability non-profit non-stock corporation incorporated in the State of Delaware, USA, with company number 5030732, and is registered in the UK with company number FC030576 and branch number BR015634 at the address:
eLife Sciences Publications, Ltd
Westbrook Centre, Milton Road
Cambridge CB4 1YG
UK
",https://elifesciences.org/jobs/caa6b6f4/data-engineer-gcp-aws-open-source
JOB226824000783,Avail - Staff Data Engineer (Remote Home Based Worker),Avail - Staff Data Engineer (Remote Home Based Worker),"8 or more years of experience in software engineering or equivalent academic experience,Significant prior experience in projects using elements of the current and future Avail tech stack: Redshift, Airflow, Python, PostgresQL, MongoDB, Kafka, EMR, Spark.,Experience in creating both batch and real-time architectures for training machine learning models against large volumes of data (at least 1TB in each daily job) and deploying them to production servers at a global scale. Proven history of ability to implement inference services that respond at speed (within 20ms) and volume (thousands of requests per second).,Deep (5+ years) experience in at least one systems programming language (Java, Scala, Rust, C, C++),Familiarity with theoretical foundations necessary for implementation of training and inference in machine learning models, such as cross validation, vector and matrix operations, statistical sampling and model representation.,Advanced experience in Data Modelling and Data Warehousing and facilitating analytics workflows and functions,Advanced experience in creating ETL pipelines in applications involving high volumes of data (e.g., in e-commerce, ad-tech, finance),Experience building secure and high-performance integrations for data ingestion from external data sources and APIs,Advanced skills in software engineering disciplines and best practices,High degree of familiarity with software development processes such as Scrum, CI/CD,Experience in using Jenkins CI tools to create testing and deployment automation,Experience in performing operations and automation of various data ecosystems in production environments on AWS","Design and implement scalable data workflows and pipelines, and integrate diverse data sources and sinks,Design appropriate complex database schemas and optimize database deployment architectures for analytics query loads,Implement data transforms and organization for various data stores (data lakes and warehouses),Design and implement new platform architectures for building and serving computationally challenging machine learning models under tight response time requirements,Provide tooling and automation for infrastructure, continuous testing, and continuous deploy of data systems,Work with the platform operations team to monitor and maintain live production systems","
Allstate
Avail - Staff Data Engineer (Remote Home Based Worker)
Avail is a car sharing service to help people get where they want to go–whether that’s to run errands, take an unforgettable road trip, or explore a new city–while helping locals earn cash from their unused cars. We are passionate about making shared transportation safe, simple, and affordable, and redefining what it means to own a car.
We’ve assembled some of the sharpest folks from across industries to compete against the antiquated system of traditional car rental. We put ideas into action and learn along the way in an open, collaborative work environment. As a part of Avail, you’ll make a direct impact and help build a business from the ground up. No matter where you’ve been, we’re always looking for fresh thinking and new perspectives.
Summary
Seeking an experienced Staff Data Engineer to implement integrations with various data sources, set up a data warehouse, create scalable data pipelines for ETL and machine learning model training, and deploy machine learning models on production in a scalable way.
Job Description
Design and implement scalable data workflows and pipelines, and integrate diverse data sources and sinks
Design appropriate complex database schemas and optimize database deployment architectures for analytics query loads
Implement data transforms and organization for various data stores (data lakes and warehouses)
Design and implement new platform architectures for building and serving computationally challenging machine learning models under tight response time requirements
Provide tooling and automation for infrastructure, continuous testing, and continuous deploy of data systems
Work with the platform operations team to monitor and maintain live production systems
Job Qualifications
Education and Experience
8 or more years of experience in software engineering or equivalent academic experience
Advanced (Master’s or PhD) degree in Computer Science or Computer Engineering or related technical discipline, or equivalent experience
Functional Experience
Significant prior experience in projects using elements of the current and future Avail tech stack: Redshift, Airflow, Python, PostgresQL, MongoDB, Kafka, EMR, Spark.
Experience in creating both batch and real-time architectures for training machine learning models against large volumes of data (at least 1TB in each daily job) and deploying them to production servers at a global scale. Proven history of ability to implement inference services that respond at speed (within 20ms) and volume (thousands of requests per second).
Deep (5+ years) experience in at least one systems programming language (Java, Scala, Rust, C, C++)
Familiarity with theoretical foundations necessary for implementation of training and inference in machine learning models, such as cross validation, vector and matrix operations, statistical sampling and model representation.
Advanced experience in Data Modelling and Data Warehousing and facilitating analytics workflows and functions
Advanced experience in creating ETL pipelines in applications involving high volumes of data (e.g., in e-commerce, ad-tech, finance)
Experience building secure and high-performance integrations for data ingestion from external data sources and APIs
Advanced skills in software engineering disciplines and best practices
High degree of familiarity with software development processes such as Scrum, CI/CD
Experience in using Jenkins CI tools to create testing and deployment automation
Experience in performing operations and automation of various data ecosystems in production environments on AWS
Familiarity with functional programming languages and experience in defining data pipeline transformations using functional concepts
Compensation Data
Compensation range for this position is $96,500 - $174,600 per year, based on experience and qualifications.
That’s the day to day, here’s the bigger picture.
Avail was founded by The Allstate Corporation in 2018. But you’ll be working for (and at) Avail. Our work environment blends the ingenuity and flexibility of a startup with the scale and strengths of a Fortune 100 company. Perks include a generous PTO policy, flexible working options, and a focus on leadership, wellness, and culture. We also offer 401k, health insurance, and other employment benefits for your future.
See a job you love? We encourage you to apply, even if your experience isn’t a perfect match.
Learn more about life at Avail. Connect with us on Instagram and LinkedIn.
We generally do not sponsor individuals for employment-based visas for this position.
Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.
For jobs in San Francisco, please click “here” for information regarding the San Francisco Fair Chance Ordinance.
For jobs in Los Angeles, please click “here” for information regarding the Los Angeles Fair Chance Initiative for Hiring Ordinance.
To view the “EEO is the Law” poster click “here”. This poster provides information concerning the laws and procedures for filing complaints of violations of the laws with the Office of Federal Contract Compliance Programs
To view the FMLA poster, click “here”. This poster summarizing the major provisions of the Family and Medical Leave Act (FMLA) and telling employees how to file a complaint.
It is the Company’s policy to employ the best qualified individuals available for all jobs. Therefore, any discriminatory action taken on account of an employee’s ancestry, age, color, disability, genetic information, gender, gender identity, gender expression, sexual and reproductive health decision, marital status, medical condition, military or veteran status, national origin, race (include traits historically associated with race, including, but not limited to, hair texture and protective hairstyles), religion (including religious dress), sex, or sexual orientation that adversely affects an employee's terms or conditions of employment is prohibited. This policy applies to all aspects of the employment relationship, including, but not limited to, hiring, training, salary administration, promotion, job assignment, benefits, discipline, and separation of employment.
More From Allstate
Related Job Listings
",https://www.insurancejournal.com/jobs/631564-avail-staff-data-engineer-remote-home-based-worker
JOB227935271100,Data Engineer for International Development Crime Prevention Program,Data Engineer for International Development Crime Prevention Program,"Graduate degree in Computer Science, Information Systems or equivalent quantitative field and 5+ years of experience in a similar Data Engineer role.,Experience working with and extracting value from large, disconnected and/or unstructured datasets,Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management,Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.,Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.,Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.,Experience developing IT frameworks that support business applications.","Work closely with other team members to optimize the organization’s data systems and IT architecture,Design and build the infrastructure for data extraction, preparation, and loading of data from a variety of sources using technology such as SQL and AWS,Build data and analytics tools that will offer deeper insight into the organization’s pipeline, allowing for critical discoveries surrounding key performance indicators and stakeholders’ activity,Determine database structural requirements by analyzing client operations, applications and programming; review objectives with clients and evaluate current systems,Develop database solutions by designing proposed system; define database physical structure and functional capabilities, security, back-up and recovery specifications,Install database systems by developing flowcharts; apply optimum access techniques, coordinate installation actions and document actions,Maintain database performance by identifying and resolving production and application development problems, calculating optimum values for parameters; evaluating, integrating and installing new releases, completing maintenance and answering user questions,Provide database support, responding to user questions and resolving problems","Job Description
Job Summary
PADF is looking for a data engineer to complement its program team dedicated to provide technical assistance and support for designing and supervising the platform that serves for capturing, storing and processing data in a law enforcement / criminal justice sector agency. The ideal candidate has an eye for building and optimizing data systems and will work closely with IT staff in our partner agencies to help direct the flow of data within the organizational pipeline and ensure consistency of data delivery and utilization across multiple units.
Responsibilities
Work closely with other team members to optimize the organization’s data systems and IT architecture
Design and build the infrastructure for data extraction, preparation, and loading of data from a variety of sources using technology such as SQL and AWS
Build data and analytics tools that will offer deeper insight into the organization’s pipeline, allowing for critical discoveries surrounding key performance indicators and stakeholders’ activity
Determine database structural requirements by analyzing client operations, applications and programming; review objectives with clients and evaluate current systems
Develop database solutions by designing proposed system; define database physical structure and functional capabilities, security, back-up and recovery specifications
Install database systems by developing flowcharts; apply optimum access techniques, coordinate installation actions and document actions
Maintain database performance by identifying and resolving production and application development problems, calculating optimum values for parameters; evaluating, integrating and installing new releases, completing maintenance and answering user questions
Provide database support, responding to user questions and resolving problems
Qualifications
Graduate degree in Computer Science, Information Systems or equivalent quantitative field and 5+ years of experience in a similar Data Engineer role.
Experience working with and extracting value from large, disconnected and/or unstructured datasets
Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience developing IT frameworks that support business applications.
About the Organization
Created in 1962 through a unique agreement between the Organization of American States (OAS) and the private sector, the Pan American Development Foundation (PADF) is an independent, non-profit organization that creates public-private partnerships to assist the least advantaged people in Latin America and the Caribbean. Having worked in every country in the region, PADF engages community-based groups, non-governmental organizations (NGOs), and the public and private sector in the process of implementing appropriate solutions for sustainable development. The Pan American Development Foundation empowers disadvantaged people and communities in Latin America and the Caribbean to achieve sustainable economic and social progress, strengthen their communities and civil society, and prepare for and respond to natural disasters and other humanitarian crises, thereby advancing the principles of the Organization of American States.
",https://www.devex.com/jobs/data-engineer-for-international-development-crime-prevention-program-683500
JOB229264905496,"Data Engineer (TALEND, ETL)","Data Engineer (TALEND, ETL)","Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.,Bachelor’s Degree in STEM related field or equivalent,Strong Experience with TALEND,The ability to deliver work at a steady, predictable pace to achieve commitments, deliver complete solutions but release them in small batches, and identify and negotiate important tradeoffs.,Demonstrated track record of domain expertise including understanding technical concepts necessary and industry trends, and possess in-depth knowledge of immediate systems worked on and some knowledge of adjacent systems.,Strong problem solver who ensures systems are built with longevity and creates innovate ways to resolve issues.,Strong written and verbal communication skills with the ability to work collaborate well with team members and business partners.","Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions.,Design complex data solutions,Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes.,Incorporate core data management competencies including data governance, data security and data quality.,Collaborate within and across teams to support delivery and educate end users on complex data products/analytic environment.,Perform data and system analysis, assessment and resolution for complex defects and incidents and correct as appropriate.,Builds, maintains, and utilizes partnerships across the enterprise.,Provides team direction, mentorship, and feedback to technical resources.","
The Travelers Companies, Inc.
Data Engineer (TALEND, ETL)
Company Summary
Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.
Target Openings
1
Job Description Summary
Do you have experience in Data and Analytics including ETL tools such as TALEND? Are you seeking a dynamic, diverse and growth oriented environment in technology? Is passion for problem solving in your DNA? Are you seeking a company that offers comprehensive benefits including a pension and a matching 401K? Imagine the possibilities at Travelers!
Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape. In addition to your strong analytical mind, you will bring your inquisitive attitude and ability to translate stories found in data by leveraging a variety of data programming techniques.
Our Reinsurance Technology group is seeking an Talend Developer who performs expert programming, configuring, and/or analysis. You would participate in the design/development process. This role acts as subject matter expert for assigned applications, systems, and technologies and leads investigation and resolution efforts for critical/high impact problems, defects and incidents. You would provide technical guidance to team members.
This position may be based 100% remotely or in one of our offices.
Primary Job Duties & Responsibilities
Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions.
Design complex data solutions
Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes.
Incorporate core data management competencies including data governance, data security and data quality.
Collaborate within and across teams to support delivery and educate end users on complex data products/analytic environment.
Perform data and system analysis, assessment and resolution for complex defects and incidents and correct as appropriate.
Builds, maintains, and utilizes partnerships across the enterprise.
Provides team direction, mentorship, and feedback to technical resources.
Test data movement, transformation code, and data components.
Minimum Qualifications
Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
Four years of data engineering or equivalent experience.
Education, Work Experience, & Knowledge
Bachelor’s Degree in STEM related field or equivalent
Strong Experience with TALEND
Experience as a Lead / providing technical guidance to team members
Job Specific Technical Skills & Competencies
The ability to deliver work at a steady, predictable pace to achieve commitments, deliver complete solutions but release them in small batches, and identify and negotiate important tradeoffs.
Demonstrated track record of domain expertise including understanding technical concepts necessary and industry trends, and possess in-depth knowledge of immediate systems worked on and some knowledge of adjacent systems.
Strong problem solver who ensures systems are built with longevity and creates innovate ways to resolve issues.
Strong written and verbal communication skills with the ability to work collaborate well with team members and business partners.
Ability to lead team members and help create a safe environment for others to learn and grow as engineers. and a proven track record of self-motivation in identifying opportunities and tracking team efforts.
Employment Practices
Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences.
If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.
Travelers reserves the right to fill this position at a level above or below the level included in this posting.
To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.
More From The Travelers Companies, Inc.
Related Job Listings
",https://www.insurancejournal.com/jobs/634494-data-engineer-talend-etl
JOB231863030215,"19 jobs with job title Data Engineer - Seattle, Washington, United States","19 jobs with job title Data Engineer - Seattle, Washington, United States",,,"
Browse for Data Engineer Jobs in Seattle, Washington, United States. Find the job of your dreams on CareerCast.com today!
Search for Similar Listings
",https://www.careercast.com/jobs/data-engineer-seattle-washington-341462044-b
JOB232216033444,Data Engineer,Data Engineer,Connections to recruiters and industry experts through online and live Devex events,"Full access to our jobs board, including over 1,000 exclusive jobs,Your Devex profile highlighted in recruiter search results","
See the full details of this exclusive job - and all of the other big development opportunities hand picked by our team. These positions are only available with a Career Account. Upgrade now to keep your job search moving.
Starting at $9.50, a Devex Career Account provides you:
Full access to our jobs board, including over 1,000 exclusive jobs
Your Devex profile highlighted in recruiter search results
Connections to recruiters and industry experts through online and live Devex events
",https://www.devex.com/jobs/data-engineer-617935
JOB232527785067,Data Engineer at Crunchbase,Data Engineer at Crunchbase,,,"
Without data you’re just another person with an opinion. - Deming
Engineering at Crunchbase
Our Mission
It’s nearly impossible to find an authoritative source of truth about companies that is both always up-to-date and freely available. Our mission is to continue building the largest high-quality, live, openly editable and accessible dataset of company and people information in the world -- and to build a delightful product with slick, easy-to-use APIs around that dataset.
We love building enjoyable user experiences, complex data schemata, APIs, and scalable systems that support tens of millions of interactions per day. Our team is a group of highly skilled engineers working on formidable problems throughout the stack.
How We Operate
We have a flexible model for team organization at Crunchbase, centered around the principles of agile software development, allowing us to fluidly adapt to new requirements and situations as they arise. We tend towards two main types of teams:
• Feature-oriented teams:operate independently and own their projects from cradle to grave, building everything they need to execute. While they don't necessarily have to do all the work themselves, it's their responsibility to make sure the business needs are met all the way into production.
• Function-oriented teams: provide support to feature teams and have deeper expertise on particular parts of the stack. It's their responsibility to build platforms that are so good the other teams want to use them, rather than being forced into it.
We also ship code as early as we possibly can; getting betas into customer hands is a top priority. Our goal is to tune our process to customer needs as efficiently and quickly as possible. Crunchbase is built with a variety of tools - a core part of our engineering philosophy is to use the right tool for the job:
• Ruby, Scala, Java
• Node.js, Angular.js, Typescript
• Redis, PostgreSQL, ElasticSearch
• Git, Nginx, Docker, NewRelic, Jenkins
• AWS - EC2, ELB, VPC, S3, R53, RDS, SQS, etc.
Data Engineering at Crunchbase
Our data team is responsible for building and maintaining the infrastructure for our data needs. As Crunchbase grows, so too does the amount of data we process, the number of sources it comes from, and the number of ways that people want to slice and dice it. We are currently building out a robust pipeline for our core data and we’re continually expanding use cases for it, so it must be both scalable and flexible.
At its core, Crunchbase is a data company, and data engineering is at the heart of our platform and will propel us into the future. The responsibilities of data engineers at Crunchbase include:
• Architect and build new dimensional data models and schema designs to improve accessibility, efficiency, consistency and quality of both internal and production data.
• Build, monitor, and maintain analytics and production data ETL pipelines.
• Provide the foundation for a data-driven culture by empowering other engineers and the Product team to ask questions of the dataset in an easy, reliable way.
• Enable data scientists to implement NLP and ML algorithms at scale, in fault-tolerant, highly available systems.
Qualifications
• Solid understanding of computer science and software engineering fundamentals.
• Motivated to participate in ongoing learning and growth through pair programming, code reviews, application of new technologies and best practices.
• Excellent verbal and written communication skills.
• Familiarity with tools we presently use is a plus, but not required -- if you know something better, we may use that instead!
What Crunchbase offers
• Competitive salary and equity
• A team of creative, transparent entrepreneurs driven to accomplish our mission
• Daily catered lunches
• Fitness reimbursement (to work off the catered lunches)
• Unlimited Paid Time Off (PTO) -- we don't track vacation days
• Incredible medical, vision and dental benefits for employees and their families
• 401(k) and Roth plans, and free annual financial adviser check-in
• Free One Medical Group membership for employees and their families
• Commuter benefits program
• Free UberX rides anywhere in the Bay Area after late nights at the office
• Prime location in the SoMa district of SF, near CalTrain, and Muni stops
• Company and team offsites, retreats, events and happy hours
",https://angel.co/crunchbase/jobs/105128-data-engineer
JOB236261462499,Principal Data Engineer Job,Principal Data Engineer Job,"10+ years of relevant experience,BS/MS/PhD in Computer Science or related field,Experience with Java, Scala & Python,Expert knowledge of machine learning algorithms and operationalization of data science pipelines,Demonstrable experience with ETL/ELT tools,Expert Knowledge of distributed data processing such as Hadoop ecosystem and spark,Strong knowledge of SQL (eg: MySQL) & Linux,Comfortable with Data Security Concepts & SDLC,Familiarity with leading cloud vendors such as GCP, Azure, AWS and related tools",,"
Requisition ID: 268167
Work Area: Software-Design and Development
Expected Travel: 0 - 10%
Career Status: Professional
Employment Type: Regular Full Time
COMPANY DESCRIPTION
SAP started in 1972 as a team of five colleagues with a desire to do something new. Together, they changed enterprise software and reinvented how business was done. Today, as a market leader in enterprise application software, we remain true to our roots. Thats why we engineer solutions to fuel innovation, foster equality and spread opportunity for our employees and customers across borders and cultures.
SAP values the entrepreneurial spirit, fostering creativity and building lasting relationships with our employees. We know that a diverse and inclusive workforce keeps us competitive and provides opportunities for all. We believe that together we can transform industries, grow economics, lift up societies and sustain our environment. Because its the best-run businesses that make the world run better and improve peoples lives.
Please note: this role can be based from either the Palo Alto or San Ramon office, once offices re-open.
About SAP SuccessFactors
SAP SuccessFactors is a world-leading provider of cloud human experience management (HXM) the new people-focused market category for Human Resource technology. Our HXM suite lets more than 7,000 global customers provide their employees with experiences that recognize their individual value and consistently motivate them to achieve peak performance levels values we also live by. Working on the SAP SuccessFactors team means making an impact to over 160m global users with a market leading cloud solution.
Summary
The Data Platform group within SAP SuccessFactors is looking for a data engineer/ machine learning engineer to design, develop, and deliver automated multi-tenant artificial intelligence and machine-learning based solutions that integrate with SAP SuccessFactors business applications.
The Role
You are a curious and experienced Data Engineer interested in building data driven enterprise solutions with knowledge of machine learning in commercial environments and build scalable platform to handle large data sets. You are a quick learner and comfortable working cross-functionally with product managers, engineers, and business users to understand business problems and collaborate with the team on a viable solution. You take ownership of a project and plan to deliver a solution in a timely manner.
Education & Qualification Requirements
10+ years of relevant experience
BS/MS/PhD in Computer Science or related field
Experience with Java, Scala & Python
Expert knowledge of machine learning algorithms and operationalization of data science pipelines
Demonstrable experience with ETL/ELT tools
Expert Knowledge of distributed data processing such as Hadoop ecosystem and spark
Strong knowledge of SQL (eg: MySQL) & Linux
Comfortable with Data Security Concepts & SDLC
Familiarity with leading cloud vendors such as GCP, Azure, AWS and related tools
#SOF2020
WHAT YOU GET FROM US
Success is what you make it. At SAP, we help you make it your own.
A career at SAP can open many doors for you. If youre searching for a company thats dedicated to your ideas and individual growth, recognizes you for your unique contributions, fills you with a strong sense of purpose, and provides a fun, flexible and inclusive work environment apply now.
SAP'S DIVERSITY COMMITMENT
To harness the power of innovation, SAP invests in the development of its diverse employees. We aspire to leverage the qualities and appreciate the unique competencies that each person brings to the company.
SAP is committed to the principles of Equal Employment Opportunity and to providing reasonable accommodations to applicants with physical and/or mental disabilities. If you are interested in applying for employment with SAP and are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to Recruiting Operations Team. (Americas:Careers.NorthAmerica@sap.com or Careers.LatinAmerica@sap.com, APJ: Careers.APJ@sap.com, EMEA: Careers@sap.com). Requests for reasonable accommodation will be considered on a case-by-case basis. Successful candidates might be required to undergo a background verification with an external vendor.
EOE AA M/F/Vet/Disability:
Qualified applicants will receive consideration for employment without regard to their age, race, religion, national origin, gender, sexual orientation, gender identity, protected veteran status or disability.
Successful candidates might be required to undergo a background verification with an external vendor.
Additional Locations:
Nearest Major Market: San Jose
Nearest Secondary Market: Palo Alto
Job Segment: Database, ERP, Engineer, Computer Science, SAP, Technology, Engineering
Categories
Posted: 2020-11-03 Expires: 2020-12-05
",http://www.careercast.com/jobs/detail/summary/119761808?contextType=rss&widget=1&type=job&
JOB236524734166,SQL Data Engineer,SQL Data Engineer,,"Managing the investigation of corporate data requirements, documenting them according to the required standards utilising the prescribed methods and tools,Implementing data flows to connect operational systems, data for analytics and BI systems. Re-engineer manual data flows to enable scaling and repeatable use,Working closely with data architects (to determine what data management systems are appropriate) and data scientists (to determine what data is needed for analysis).,Tackling problems associated with database integration and unstructured data sets,Ensuring that those using the data structures and associated components have a good understanding and that any queries are dealt with promptly and efficiently,Strong technical process understanding regardless of technology,Wide range of strong technical skills (i.e. Azure Devops, Azure Data Factory, Data Bricks, SQL, python),Core SQL Competencies – SSMS, SSIS, T-SQL, Stored Procedures,ADF Pipelines to build and populate SQL databases,Background in migrating traditional MS products to Azure,Ability to create efficient DW or DL structures to minimise cost of orchestration / processing and ingestion of data,Very high attention to detail,Strong communication skills,Efficient in building ETL and ELT processes for enterprise solutions,Strong software delivery methods and knowledge,Digital delivery – has a track record of working on DevOps delivery,Exposure in Climate Change data legislation, practices and stakeholders,Experience in Environmental related industries i.e Water, Energy, Forestry related,Presentation skills,Understanding of architecting solutions taking into account wider considerations","
SQL Data Engineer
Job purpose and background
Are you a capable SQL Data Engineer who is passionate about the power of data to solve environmental issues? CDP are looking for an SQL Data Engineer to shape delivery by collaborating with data architects and modellers to contribute to the acquisition of corporate data requirements, documenting them according to the required standards utilising the prescribed methods and Azure data tools, in order to build our centralised data platform.
This is a permanent role, with responsibility for developing, constructing, testing and maintaining architectures such as data pipelines and large-scale data processing warehouses. The post-holder will leverage industry best practice while delivering changes, such as agile backlogs, code repositories, automated builds, testing and releases. They will be responsible for ensuring data scientists can pull relevant data sets for their analyses, implement data pipelines to connect operational systems, data for analytics and BI systems. The role includes re-engineering manual data flows to enable automation, scaling and repeatable use and developing data set processes for data modelling, mining and production.
The post-holder will work closely with data architects (to determine what data management systems are appropriate) and data scientists (to determine which data are needed for analysis). They will provide clean, usable data to the business through the data platform in accordance with governance, and analyse, design, plan, execute and evaluate data requirements to support business activities and projects. The post-holder will be central in ensuring the delivery of world-class digital products and changing the delivery culture in CDP.
About CDP's data engineering team:
The Data Engineering Team’s primary remit is to improve the usability of the climate change, water, forests and cities data disclosed to CDP through robust and transparent methods. The team will create sustainable data pipelines for data quality monitoring, data cleaning, reporting and data science modelling. Harmonised data collected from external sources will enrich the data assets’ value and enhance accessibility for CDP’s stakeholders. The team will produce value-adding insight delivering it through data products that help internal and external stakeholders to better understand the quantitative and qualitative results of their actions. This in turn helps stakeholders to make data-led decisions and optimise for all constraints. Through every stage the data assets are governed by the industry practice standards in a robust and transparent manner.
Key responsibilities include:
Managing the investigation of corporate data requirements, documenting them according to the required standards utilising the prescribed methods and tools
Implementing data flows to connect operational systems, data for analytics and BI systems. Re-engineer manual data flows to enable scaling and repeatable use
Working closely with data architects (to determine what data management systems are appropriate) and data scientists (to determine what data is needed for analysis).
Tackling problems associated with database integration and unstructured data sets
Ensuring that those using the data structures and associated components have a good understanding and that any queries are dealt with promptly and efficiently
In liaison with the information management or IT management functions, contributing to the development and maintenance of corporate data standards
Required skills and experience:
Strong technical process understanding regardless of technology
Wide range of strong technical skills (i.e. Azure Devops, Azure Data Factory, Data Bricks, SQL, python)
Core SQL Competencies – SSMS, SSIS, T-SQL, Stored Procedures
ADF Pipelines to build and populate SQL databases
Background in migrating traditional MS products to Azure
Ability to create efficient DW or DL structures to minimise cost of orchestration / processing and ingestion of data
Very high attention to detail
Strong communication skills
Efficient in building ETL and ELT processes for enterprise solutions
Strong software delivery methods and knowledge
Strong performance-tuning skills.
Desired skills and experience
Digital delivery – has a track record of working on DevOps delivery
Exposure in Climate Change data legislation, practices and stakeholders
Experience in Environmental related industries i.e Water, Energy, Forestry related
Presentation skills
Understanding of architecting solutions taking into account wider considerations
Structured problem solving techniques.
This is a permanent full-time role, reporting to the Head of Data Engineering, which will be delivered remotely to start with. The post holder will be required to travel to CDP’s London office from time to time when it reopens.
Salary and benefits: Between £45,000 - £48,500 per annum dependent on experience, 30 days holiday excluding bank holidays, flexible working opportunities and others benefits.
Interested applicants must be eligible to work legally in the United Kingdom.
Before you apply
We’ll only use the information you provide to process your application. For more details on how we use your information, see our applicants privacy notice. By emailing us your CV and covering letter, you are permitting CDP to use the information you have provided for recruitment purposes.
To apply please email your CV and a covering letter setting out how you meet the required skills and experience or key responsibilities, which should be no more than two pages, to recruitment@cdp.net with ‘DI-SQL Data Engineer, Firstname Surname’ in the subject. Applications will be reviewed on a rolling basis, so early applications are strongly encouraged. The deadline is 8.00 am on 19 October 2020.
Are you interested in a career at CDP working in one of our global offices?
Explore our current job vacancies
",https://www.cdp.net/language/en?redirect=%2Fen%2Finfo%2Fcareers%2Fsql-data-engineer-2
JOB237304118633,Senior Data Engineer / Database Developer,Senior Data Engineer / Database Developer,,,"
This Position Is Closed to New Applicants
This position is no longer open for new applications. Either the position has expired or was removed because it was filled. However, there are thousands of other great jobs to be found on Rigzone.
",https://www.rigzone.com/oil/jobs/postings/972776_senior_data_engineer_database_developer/
JOB238384753767,Senior Data Engineer - Uber Everything (NYC) at Uber,Senior Data Engineer - Uber Everything (NYC) at Uber,,,"
The Uber Everything Logistics platform team is currently looking for a Data Engineer to build pipelines to move that information across systems and to build the next generation of tools to enable us to take full advantage of this knowledge. The engineers on this team are a critical part of making UberEATS, UberRUSH and all of Uber Everything successful.
Uber Everything Data Engineers embed with Uber’s logistics delivery marketplace and help solve the most challenging quantitative problems related to Uber’s ambitious initiatives in the logistics space (such as UberEATS and UberRUSH).
Please note: while we would be very happy to relocate candidates, this position requires working in full-time in New York City.
WE'RE LOOKING FOR:
Build data expertise and own data quality for the pipelines
Build and launch new data models that provide intuitive analytics to your customers
Design, build and launch extremely efficient & reliable data pipelines to move data
Design and develop new systems, tools and dashboards to enable folks to consume and understand data faster
Work across multiple teams in high visibility roles and own the solution end-to-end
Experience with Hadoop/hive, Vertica, Redshift, Presto, Pinot/Scuba and data warehouse technologies is preferred
Knowledge of SQL is a must
PERKS:
Showered with Uber credits each month
Beautiful new office in Chelsea
Delicious catered lunches
Sharp, motivated co-workers in a fun office environment
Unlimited vacation policy so you can work hard and take time when you need it
Competitive salary
Equity compensation plan
401(k)
Generous medical, dental and vision coverage to fit your needs
Gym reimbursement
",https://angel.co/uber/jobs/216379-senior-data-engineer-uber-everything-nyc
JOB241143370213,"21 jobs with job title Data Engineer - Washington, United States","21 jobs with job title Data Engineer - Washington, United States",,,"
Browse for Data Engineer Jobs in Washington, United States. Find the job of your dreams on CareerCast.com today!
Search for Similar Listings
",https://www.careercast.com/jobs/data-engineer-washington-29325702-b
JOB248055078496,Junior Data Engineer (Budapest),Junior Data Engineer (Budapest),,,"
Present in the market under the Deutsche Telekom IT Solutions brand name, IT-Services Hungary (ITSH) is a subsidiary of the Deutsche Telekom Group and is the largest ICT employer in Hungary. Established in 2006, the company provides a wide portfolio of IT and telecommunications services with more than 4500 employees. ITSH was awarded with the Best in Educational Cooperation prize by HIPA in 2019, acknowledged as one of the most attractive workplaces by PwC Hungary’s independent survey and rewarded with the title of the Most Ethical Multinational Company in 2019. The company continuously develops its four sites in Budapest, Debrecen, Pécs and Szeged and is looking for skilled IT professionals to join its team.
Please activate “Services from other Companies” in your settings.
",https://www.telekom.com/en/careers/jobsearch/joboffer/junior-data-engineer-budapest-_162523
JOB248813464659,Data Engineer at Caserta Concepts,Data Engineer at Caserta Concepts,,,"
Our client is a publically traded media company based in New York City. The Senior Data Engineer will work alongside the Senior Solutions Architect on a large-scale cloud migration using Python and Spark. 80% Remote.
This is a contract position with the possibility of becoming a FT consultant of Caserta Concepts.
Qualifications:
• Expert/Intermediate Python Programmer along with other languages
• Extensive experience working with big data technologies (Spark)
This is an opportunity to drive innovation, and develop the technical capabilities of an experienced team, while working in a challenging and collaborative environment.
",https://angel.co/caserta-concepts/jobs/226635-data-engineer?src=rec
JOB249172235570,Data Engineer/Analytics Lead- Remote,Data Engineer/Analytics Lead- Remote,"5 years of relevant experience with data tools, techniques, and manipulation required.,Education:,College Degree in STEM related field,Technical Knowledge:,Advanced knowledge of data tools, techniques, and manipulation preferred. Examples (but not limited to):,Data Science/Engineering, Big data and Cloud platforms,Programming languages - SAS, SQL, Spark, Python, R, H2O, KNIME, Hive, AWS,Development and Visualization platforms: Python Notebook, IDEs, GitHub, QlikView, Tableau, MicroStrategy and Qlik Sense,Experience:,Communication Skills,Ability to communicate thoughts/designs/ideas in an unambiguous manner and adjusts communication based on audience.,Exhibits active and effective communication skills with team members - including active listening and effective written and verbal communication skills.,Effectively contributes and communicates with the immediate team.,Able to present complex technical concepts to audiences of varying size and level.,Business Knowledge & Partnership,Able to develop business partnerships and influence business priorities through solution identification aligned with business objectives and goals. Able to communicate in business terms and describe data capabilities and concepts in ways that the business can understand.,Problem Solving & Decision Making,Able to proficiently diagnose root causes and solve complex issues. Able to evaluate alternative solutions and assess risk before taking action. Has the ability to reach sound decisions quickly and escalates appropriately. Demonstrates ability to optimize the use of all available resources.,Team Orientation,Able to maintain and enhance partnerships across the organization to achieve objectives. Practices objectivity and openness to others' views. Able to recognize and support team priorities.,Leadership,Accountable to set technical goals and priorities for self and other team members. Exhibits team leadership and collaborates with partners.,Planning and Project Management,Demonstrates ability to identify critical project tasks and establish clear priorities while keeping the bigger picture in mind. Able to effectively collaborate with Project Manager and utilize sound project management practices. Able to manage time and competing priorities.,Financial Awareness",,"
Company Summary
Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.
Target Openings
1
Job Description Summary
Primary Job Duties & Responsibilities
• Serves as Subject Matter Expert with knowledge of supported platforms and tools (Python, R, H2O, KNIME, and SAS analytic technologies).
• Meets with analytics community leads and users to understand needs and works with platform support leads to address approach and technologies to meet those requirements.
• Leads conversations with the Data Science community and completes work deliverables independently.
• Works closely with analytics engineering staff to ensure technical infrastructure is configured to meet customer expectations.
• Supports new technology proofs of concept evaluations through to production implementation hand-off to analytics engineering staff.
• Assists in the support of the Advanced Analytics Community of Practice and Technical Centers of Excellence.
• Assists in the migration of platforms and support to the Cloud.
• Data Acquisition, Prep and Exploration: Works with complex (type, quality, volume) and unfamiliar data. Connects to value for business. Able to link to systems.
• Responsibilities include complex analysis, assessment, and design at an expert level.
• Leads investigation and resolution efforts for high impact defects and problems.
• Ensures work complies with Travelers standards, processes, and protocols. Identifies gaps, escalating issue to manager.
• Develops and applies complex data derivations, business transformation rules, and data requirements.
• Leads small portfolio of projects or one large project (multiple workstreams), working across departments and business areas.
• Collaborates with project team and other key stakeholders to identify, estimate, and prioritize project and/or enhancement activities.
• Creates complex (technology and features) data visualizations techniques to help support data exploration.
• Liaise with Information Technology to architect and develop strategic analytics solutions including logic, rules, tables, as well as business requirements, governance, and specifications.
• Utilizes business knowledge to explain technical activities in business terms.
• Acts as resource for lower level employees working with less complex tools and data.
• Builds and maintains relationships across the enterprise.
• Analytic Data Discovery: Operationalizes and automates complex (more systems, data sets and streams, size of data sets more substantial) products into business.
• Optimizes and improves complex modeling tools and data products.
• Designs and leads integration of analytic data products and products, including pilots and proof of concept.
• Applies knowledge of current industry trends and techniques to formulate solutions within the context of assigned projects and/or enhancements.
• Analytic Support:Ensures business and data users are properly trained on data products/analytic environment. Identifies training opportunities.
• Ensures customer satisfaction through professional communication, follow-up, and responsiveness to issues.
• Consultation:Participate as data expert for projects with impact to business and enterprise performance.
• Builds, maintains, and utilizes partnerships across the enterprise.
• Develops data strategies within the context of business need. Integrates work efforts within respective business portfolios.
Minimum Qualifications
5 years of relevant experience with data tools, techniques, and manipulation required.
Education, Work Experience, & Knowledge
Education:
College Degree in STEM related field
Technical Knowledge:
Advanced knowledge of data tools, techniques, and manipulation preferred. Examples (but not limited to):
Data Science/Engineering, Big data and Cloud platforms
Programming languages - SAS, SQL, Spark, Python, R, H2O, KNIME, Hive, AWS
Development and Visualization platforms: Python Notebook, IDEs, GitHub, QlikView, Tableau, MicroStrategy and Qlik Sense
Experience:
6 years of relevant experience with data tools, techniques, and manipulation preferred.
Job Specific Technical Skills & Competencies
Communication Skills
Ability to communicate thoughts/designs/ideas in an unambiguous manner and adjusts communication based on audience.
Exhibits active and effective communication skills with team members - including active listening and effective written and verbal communication skills.
Effectively contributes and communicates with the immediate team.
Able to present complex technical concepts to audiences of varying size and level.
Business Knowledge & Partnership
Able to develop business partnerships and influence business priorities through solution identification aligned with business objectives and goals. Able to communicate in business terms and describe data capabilities and concepts in ways that the business can understand.
Problem Solving & Decision Making
Able to proficiently diagnose root causes and solve complex issues. Able to evaluate alternative solutions and assess risk before taking action. Has the ability to reach sound decisions quickly and escalates appropriately. Demonstrates ability to optimize the use of all available resources.
Team Orientation
Able to maintain and enhance partnerships across the organization to achieve objectives. Practices objectivity and openness to others' views. Able to recognize and support team priorities.
Leadership
Accountable to set technical goals and priorities for self and other team members. Exhibits team leadership and collaborates with partners.
Planning and Project Management
Demonstrates ability to identify critical project tasks and establish clear priorities while keeping the bigger picture in mind. Able to effectively collaborate with Project Manager and utilize sound project management practices. Able to manage time and competing priorities.
Financial Awareness
Able to assess the financial impact of recommended designs/solutions.
Employment Practices
Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences.
If you have questions regarding the physical requirements of this role, please send us an email so we may assist you.
Travelers reserves the right to fill this position at a level above or below the level included in this posting.
",https://www.insurancejournal.com/jobs/599781-data-engineeranalytics-lead-remote
JOB254959565189,We're hiring for Senior Big Data Engineer at SpotX,We're hiring for Senior Big Data Engineer at SpotX,,,,https://www.themuse.com/jobs/spotx/senior-big-data-engineer-d62804
JOB255131649975,Sr. Data Engineer,Sr. Data Engineer,,," Omeros is seeking an experienced Sr. Data Engineer to join the Commercial Strategy and Analytics team. This is a unique opportunity to help create a cutting-edge data analytics platform enabling data-driven decisions requires strong hands on technical and data architecture skills, business acumen, and the ability to execute a technical project alongside third parties and internal teams.
You'll need to have extensive experience building data warehouses and analytic solutions along with skills to analyze requirements and translate to technical solutions. This role is a mix of architecture, coding and data analysis. It involves partnering with technical and functional groups to translate data needs and challenges into architecture and specifications for implementation teams with hands on support of the implementations.
This is a high-impact and hands-on role that serves as a key member of the team and collaborates across Commercial business users including Sales, Marketing, Market Access and Commercial Operations as well as vendor teams, and Corporate IT to deliver successful initiatives that drive business value.
Good things are happening at Omeros!
Come join our Commercial Strategy and Analytics Team!
Who is Omeros?
Omeros is a commercial-stage biopharmaceutical company committed to discovering, developing and commercializing small-molecule and protein therapeutics for large-market as well as orphan indications targeting inflammation, complement-mediated diseases and disorders of the central nervous system.
The company's drug product OMIDRIA® (phenylephrine and ketorolac injection) 1% / 0.3% is marketed in the U.S. for use during cataract surgery or intraocular lens (IOL) replacement to maintain pupil size by preventing intraoperative miosis (pupil constriction) and to reduce postoperative ocular pain. In the European Union, the European Commission has approved OMIDRIA for use in cataract surgery and other IOL replacement procedures to maintain mydriasis (pupil dilation), prevent miosis (pupil constriction), and to reduce postoperative eye pain.
Omeros has multiple Phase 3 and Phase 2 clinical-stage development programs focused on: complement-associated thrombotic microangiopathies; complement-mediated glomerulonephropathies; Huntington's disease and cognitive impairment; and addictive and compulsive disorders. In addition, Omeros has a diverse group of preclinical programs and a proprietary G protein-coupled receptor (GPCR) platform through which it controls 54 new GPCR drug targets and corresponding compounds, a number of which are in preclinical development. The company also exclusively possesses a novel antibody-generating platform.
What are your job responsibilities?
Building incredibly valuable data sets that will be leveraged across Omeros
Creatively exploring how to use data to continually add value and translate data questions into flexible methodologies that scale to answer broad problems across the organization
Analyzing requirements from business users, data, etc. and translating into architecture and specifications including business logic for technical teams
Providing support and potentially hands on roles through the development cycle, resolving technical roadblocks, clarifying business rules, testing, and validating
Managing technical vendors to realize project goals related to data, reporting and visualization
Based on the understanding of data and business rules, specifying automated data quality controls with the end goal of providing accurate data to the business
Documenting and updating core technical processes and logic
Proactively generating ideas to solve near term business problems, while keeping an eye on the long-term objectives
Acting as a bridge between the data and the commercial business, enabling insights that can empower better decision-making
Being comfortable outside your comfort zone, you'll explore new technology, making your own tool, or finding a new way to address an old problem
You'll need to have a BS or BA in an analytic field with a minimum of 7+ years of experience in BI, Data Warehousing and Visualization.
Desired experience we are seeking includes:
Technical background in data with a deep understanding of issues in multiple areas such as data management/warehouse, data analysis, query processing, data mining, machine learning and operational excellence of production systems
Exposure to syndicated pharmaceutical datasets is preferred
What skills and knowledge does our ideal candidate have?
Expert level SQL skills
Proficient in BI, Data Warehouse, Python or Scala, AWS and visualization tools (Tableau or similar)
Knowledge of coding techniques in SAS (or R or Python), SQL and VBA; advanced Excel skills
Comfortable with reporting production and automation techniques
Hands-on and versatile team player that is comfortable under pressure
Ability to quickly translate thoughts into reality and lead discussions with technical teams as well as business partners
Demonstrated ability to build and maintain positive relationships with management, peers, etc.
Demonstrated ability to partner with technical and functional groups
Strong communication skills
If you have the skills, knowledge and experience we are looking for, we'd love to hear from you!
Omeros is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to status as a protected veteran or a qualified individual with a disability, or other protected status such as race, religion, color, national origin, sex, age, marital status, or any other factor determined to be unlawful by federal, state, or local statutes.
It is our policy to provide reasonable accommodation to anyone with a disability who needs assistance completing the job application process. If you need assistance, you can either send an e-mail to hr@omeros.com or contact Omeros, asking for Human Resources, at (206) 676-5000.
",https://www.biospace.com/job/2008638/sr-data-engineer/
JOB255800808734,Data Engineer - Python,Data Engineer - Python,"Bachelor’s degree or equivalent experience,None,Development experience in data projects and knowledge with ability to learn new database technologies,Proficient engineering, data sourcing, and data management skills,Proficient programming skills in Python and SQL with ability to learn new technologies,Familiarity with Unix,Strong attention to detail","Uses best practices, with coaching, to develop the data engineering pipelines required to support needs of predictive modeling and analytics. Support the environment; implement monitoring, quality and validation processes to ensure data accuracy.,Work closely with data scientist and business partners to take defined needs and bring them from ideation to working pilots and deliverables.,Communicates findings to the team and leadership and ensures solutions are well understood and incorporated into business processes,Execute data exploration, data engineering, testing and implementation.","
Allstate
Data Engineer - Python
The world isn’t standing still, and neither is Allstate. We’re moving quickly, looking across our businesses and brands and taking bold steps to better serve customers’ evolving needs. That’s why now is an exciting time to join our team. You’ll have opportunities to take risks, challenge the status quo and shape the future for the greater good.
You’ll do all this in an environment of excellence and the highest ethical standards – a place where values such as integrity, inclusive diversity and accountability are paramount. We empower every employee to lead, drive change and give back where they work and live. Our people are our greatest strength, and we work as one team in service of our customers and communities.
Everything we do at Allstate is driven by a shared purpose: to protect people from life’s uncertainties so they can realize their hopes and dreams. For more than 89 years we’ve thrived by staying a step ahead of whatever’s coming next – to give customers peace of mind no matter what changes they face. We acted with conviction to advocate for seat belts, air bags and graduated driving laws. We help give survivors of domestic violence a voice through financial empowerment. We’ve been an industry leader in pricing sophistication, telematics, digital photo claims and, more recently, device and identity protection. We are the Good Hands. We don’t follow the trends. We set them.
Job Description
Job Summary:
The Data Engineer – Python role is responsible for the design of data engineering projects, pipeline & proof of concepts. This data engineer role works directly with business users, actuaries, data scientists, and analytic engineers on needs and tactical solutions. The role will execute new ETL work for data science and analytics from inception and prototyping to fully developed solutions. This role reports into the Product organization.
Key Responsibilities:
Uses best practices, with coaching, to develop the data engineering pipelines required to support needs of predictive modeling and analytics. Support the environment; implement monitoring, quality and validation processes to ensure data accuracy.
Work closely with data scientist and business partners to take defined needs and bring them from ideation to working pilots and deliverables.
Communicates findings to the team and leadership and ensures solutions are well understood and incorporated into business processes
Execute data exploration, data engineering, testing and implementation.
Development of prototypes for business or research solutions and ensures prototypes meet the organization standards, so that business users may visually understand and explore a new feature or functionality, before implementation, to expose design assumptions and drive ideation.
Supervisory Responsibilities:
This job does not have supervisory responsibilities
Job Qualifications
Preferred Qualifications:
Education and Experience
Bachelor’s degree or equivalent experience
2 or more years of related experience
Certificates, Licenses, Registrations
None
Functional Skills
Development experience in data projects and knowledge with ability to learn new database technologies
Proficient engineering, data sourcing, and data management skills
Proficient programming skills in Python and SQL with ability to learn new technologies
Familiarity with Unix
Strong attention to detail
Strong written and verbal communication skills including the ability to effectively collaborate with multi-disciplinary groups and all organizational levels
Compensation Data
Compensation range for this position is $80,000 to $105,000. The salary offered will be commensurate with experience.
The candidate(s) offered this position will be required to submit to a background investigation, which includes a drug screen.
Good Work. Good Life. Good Hands®.
As a Fortune 100 company and industry leader, we provide a competitive salary – but that’s just the beginning. Our Total Rewards package also offers benefits like tuition assistance, medical and dental insurance, as well as a robust pension and 401(k). Plus, you’ll have access to a wide variety of programs to help you balance your work and personal life -- including a generous paid time off policy. For a full description of Allstate’s benefits, visit allstate.jobs/benefits/
Learn more about life at Allstate. Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video.
Allstate generally does not sponsor individuals for employment-based visas for this position.
Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.
For jobs in San Francisco, please click “here” for information regarding the San Francisco Fair Chance Ordinance.
For jobs in Los Angeles, please click “here” for information regarding the Los Angeles Fair Chance Initiative for Hiring Ordinance.
To view the “EEO is the Law” poster click “here”. This poster provides information concerning the laws and procedures for filing complaints of violations of the laws with the Office of Federal Contract Compliance Programs
To view the FMLA poster, click “here”. This poster summarizing the major provisions of the Family and Medical Leave Act (FMLA) and telling employees how to file a complaint.
It is the Company’s policy to employ the best qualified individuals available for all jobs. Therefore, any discriminatory action taken on account of an employee’s ancestry, age, color, disability, genetic information, gender, gender identity, gender expression, sexual and reproductive health decision, marital status, medical condition, military or veteran status, national origin, race (include traits historically associated with race, including, but not limited to, hair texture and protective hairstyles), religion (including religious dress), sex, or sexual orientation that adversely affects an employee's terms or conditions of employment is prohibited. This policy applies to all aspects of the employment relationship, including, but not limited to, hiring, training, salary administration, promotion, job assignment, benefits, discipline, and separation of employment.
More From Allstate
Related Job Listings
",https://www.insurancejournal.com/jobs/632440-data-engineer-python
JOB256920828299,Data Intelligence - Edge Data Engineering - Data Engineer (DI - Edge),Data Intelligence - Edge Data Engineering - Data Engineer (DI - Edge),"Experience with the Hadoop eco-system (HDFS, Spark)","Curate, design and catalogue high quality data models to ensure that data is accessible and reliable,Build highly scalable data processing frameworks for use across a wide range of datasets and applications,Provide data-driven insight and decision-making critical to GS's business processes, in order to expose data in a scalable and effective manner,Understanding existing and potential data sets in both an engineering and business context,Deploy modern data management tools to curate our most important data sets, models and processes, while identifying areas for process automation and further efficiencies,Evaluate, select and acquire new internal & external data sets that contribute to business decision making,Engineer streaming data processing pipelines,Drive adoption of Cloud technology for data processing and warehousing,Engage with data consumers and producers in order to design appropriate models to suit all needs,2-3 years of relevant work experience in a team-focused environment,A Bachelor's degree (Masters preferred) in a computational field (Computer Science, Applied Mathematics, Engineering, or in a related quantitative discipline),Extensive knowledge and proven experience applying domain driven design to build complex business applications,Deep understanding of multidimensionality of data, data curation and data quality, such as traceability, security, performance latency and correctness across supply and demand processes,In-depth knowledge of relational and columnar SQL databases, including database design,General knowledge of business processes, data flows and the quantitative models that generate or consume data,Excellent communications skills and the ability to work with subject matter expert to extract critical business concepts,Independent thinker, willing to engage, challenge or learn,Ability to stay commercially focused and to always push for quantifiable commercial impact,Strong work ethic, a sense of ownership and urgency,Strong analytical and problem solving skills,Ability to collaborate effectively across global teams and communicate complex ideas in a simple manner,Financial Services industry experience,Working knowledge of more than one programming language (Python, Java, C++, C#, etc.)","
WHO WE ARE
At Goldman Sachs, our Engineers don't just make things - we make things possible. Change the world by connecting people and capital with ideas. Solve the most challenging and pressing engineering problems for our clients. Join our engineering teams that build massively scalable software and systems, architect low latency infrastructure solutions, proactively guard against cyber threats, and leverage machine learning alongside financial engineering to continuously turn data into action. Create new businesses, transform finance, and explore a world of opportunity at the speed of markets.
Engineering, which is comprised of our Technology Division and global strategists groups, is at the critical center of our business, and our dynamic environment requires innovative strategic thinking and immediate, real solutions. Want to push the limit of digital possibilities? Start here.
TEAM OVERVIEW
The Data Intelligence organization aims to make data a strategic asset for the enterprise by providing a platform that enables the structuring, management, integration, control, discovery, usage, and governance of our Data Assets.
The team leverages a wide variety of cutting edge technologies including Hadoop, HBase, Spark, Apache Beam, Apache Flink, Kakfa, SQL, OLAP platforms, Presto, Hive, Java and Python.
RESPONSIBILITIES AND QUALIFICATIONS
YOUR IMPACT
Curate, design and catalogue high quality data models to ensure that data is accessible and reliable
Build highly scalable data processing frameworks for use across a wide range of datasets and applications
Provide data-driven insight and decision-making critical to GS's business processes, in order to expose data in a scalable and effective manner
Understanding existing and potential data sets in both an engineering and business context
HOW WILL YOU FULFIL YOUR POTENTIAL
Deploy modern data management tools to curate our most important data sets, models and processes, while identifying areas for process automation and further efficiencies
Evaluate, select and acquire new internal & external data sets that contribute to business decision making
Engineer streaming data processing pipelines
Drive adoption of Cloud technology for data processing and warehousing
Engage with data consumers and producers in order to design appropriate models to suit all needs
BASIC QUALIFICATIONS
2-3 years of relevant work experience in a team-focused environment
A Bachelor's degree (Masters preferred) in a computational field (Computer Science, Applied Mathematics, Engineering, or in a related quantitative discipline)
Extensive knowledge and proven experience applying domain driven design to build complex business applications
Deep understanding of multidimensionality of data, data curation and data quality, such as traceability, security, performance latency and correctness across supply and demand processes
In-depth knowledge of relational and columnar SQL databases, including database design
General knowledge of business processes, data flows and the quantitative models that generate or consume data
Excellent communications skills and the ability to work with subject matter expert to extract critical business concepts
Independent thinker, willing to engage, challenge or learn
Ability to stay commercially focused and to always push for quantifiable commercial impact
Strong work ethic, a sense of ownership and urgency
Strong analytical and problem solving skills
Ability to collaborate effectively across global teams and communicate complex ideas in a simple manner
PREFERRED QUALIFICATIONS
Financial Services industry experience
Working knowledge of more than one programming language (Python, Java, C++, C#, etc.)
Experience with the Hadoop eco-system (HDFS, Spark)
ABOUT GOLDMAN SACHS
The Goldman Sachs Group, Inc. is a leading global investment banking, securities and investment management firm that provides a wide range of financial services to a substantial and diversified client base that includes corporations, financial institutions, governments and individuals. Founded in 1869, the firm is headquartered in New York and maintains offices in all major financial centers around the world.
Â© The Goldman Sachs Group, Inc., 2018. All rights reserved Goldman Sachs is an equal employment/affirmative action employer Female/Minority/Disability/Vet.
",https://www.themuse.com/jobs/goldmansachs/data-intelligence-edge-data-engineering-data-engineer-di-edge
JOB257808483867,"Principal Data Engineer, Product Development Informatics","Principal Data Engineer, Product Development Informatics","15 years of work experience, including 10 years of experience in data engineering,Processing and extracting value from large disconnected datasets,Continuous integration systems (Jenkins, Travis, Drone CI)","Exploring new ways of building, processing, and analysing data in order to deliver insights to our business partners,Lead and drive the creation of a Data Engineering center of excellence in PD Informatics","
Principal Data Engineer, Product Development Informatics
South San Francisco
California, United States of America
The Position
Purpose and Mission
As a Principal Data Engineer, you will work closely with multi-disciplinary teams to solve complex data problems enabling Product Development to transform data into actionable insights. You will partner with other Informatics groups and business stakeholders to co-create data and analytics enabled solutions that help our teams fulfill our mission: to do now what patients need next.
What you’ll be working on
Exploring new ways of building, processing, and analysing data in order to deliver insights to our business partners
Working with cutting edge data processing frameworks, technologies, and platforms
Continuously refining data quality with testing, tooling and performance evaluation
Collaborating in multi-functional agile teams with end-to-end responsibility for product development and delivery within Pharma Development
Responsibilities:
Lead and drive the creation of a Data Engineering center of excellence in PD Informatics
Lead the data engineering efforts to migrate the existing data architecture to modern cloud technology
Design, build and maintain scalable data pipelines
Drive for automation to increase efficiency
Investigate and explore cutting edge advanced analytics methodologies, data processing frameworks, technologies, and platforms
Continuously refine data quality with testing, tooling and performance evaluation
Explore new ways of building, processing, and analysing data in order to deliver insights to our business partners
Partner with architects to design systems required for optimal extraction, transformation, and loading of data from a wide variety of data sources
Work with data and analytics experts to strive for greater functionality in our data systems
Requirements and Qualifications:
15 years of work experience, including 10 years of experience in data engineering
Master’s degree in related fields (Computer Science, Computer Engineering, Mathematical Engineering, Information Systems)
Passionate about technology trends and a leading expert in data engineering
Strong technical background in Big Data, data-driven development, experimentation and agile software processes
Advanced understanding and experience with scaling experiments (PoC), machine learning, deep learning, Neural Networks, anomaly detection, predictive analysis, exploratory data analysis, and other areas of data science, preferably in Pharma or Biotech
Ability to lead cross functional teams through agile product development cycle
Demonstrated experience in effectively presenting information to senior stakeholders
Previous experience in working in matrix organization
Must haves:
Processing and extracting value from large disconnected datasets
Building and optimizing ‘big data’ data pipelines, architectures and data sets
Experience in Data Science, knowledge of R or Python and its Data Science libraries
Experience with data visualization tools (eg. Shiny), data wrangling tools, and with relational and NoSQL databases
Expert knowledge of Service Orchestration and Virtualization using tools such as Kubernetes, Docker
Prototype and develop cloud native architecture solutions for application needs; particularly with AWS.
Hands on experience with AWS Cloud services such as EC2, S3, IAM, Route53, RDS, VPC, LAMBDA, SQS, SNS, EKS, Load Balancers, CloudWatch, API Gateway etc.
Automating software build and deployment to development and production systems
Continuous integration systems (Jenkins, Travis, Drone CI)
Source Control System (Git)
Strong operational experience in Linux/Unix environment, configuration management, and monitoring and systems tools (Ansible, Puppet, etc.)
Strong knowledge of infrastructure as code, such as Terraform, AWS Cloud-formation
Who We Are
A member of the Roche Group, Genentech has been at the forefront of the biotechnology industry for more than 40 years, using human genetic information to develop novel medicines for serious and life-threatening diseases. Genentech has multiple therapies on the market for cancer & other serious illnesses. Please take this opportunity to learn about Genentech where we believe that our employees are our most important asset & are dedicated to remaining a great place to work.
The next step is yours. To apply today, click on the ""Apply online"" button.
Genentech is an equal opportunity employer & prohibits unlawful discrimination based on race, color, religion, gender, sexual orientation, gender identity/expression, national origin/ancestry, age, disability, marital & veteran status. For more information about equal employment opportunity, visit our Genentech Careers page.
",https://www.gene.com/careers/detail/202005-112640/Principal-Data-Engineer-Product-Development-Informatics
JOB258618807598,Sr. Associate Data Engineer,Sr. Associate Data Engineer,"Bachelors degree in STEM (Science, Technology, Engineering, Mathematics) or Business.,2 years of relevant data and analytics experience preferred.,Very proficient is SQL with experience performing data analytics and writing SQL queries.,Demonstrates general understanding of overall data models, data relationships, mapping lineage and business rules.,Acts as subject matter experts on specific aspects of data availability and usage, assisting in the arbitration of differences of data interpretations and guidance to projects, business and technology areas.,Thorough knowledge of tools and software used to extract and analyze data in the data management function preferred.,Insurance knowledge preferred.","Analyzes medium complexity customer requests (internal or external, e.g. data calls) for changes to production systems, determines impact on existing systems, processes and develops appropriate specifications, enhancements and or procedures to comply. Meet with customer to elicit requirements. May act as project lead for medium complexity items.,Handles moderate to complex root cause analysis of business data issues and provides technical data guidance on complex issues. Oversee specification or procedural changes to address issue.,Manage the testing and verification processes ensuring accuracy.,Work with business areas and project team members to understand new business capabilities and perform impact analysis to determine additional data requirements, provide data expertise and data as needed. Conduct fact gathering sessions with customer to define and confirm requirements. Oversee deliverables for compliance (e.g. state/bureau requirements).,Develops, maintains and prioritizes business data requirements and specifications; leveraging data standards, ensuring that solutions (structure, values, relationships, quality standards) meet operational and business need.,Provides input into end to end data flow and lineage from capture at source, to storage, to delivery and its business intent at each stage (i.e. capture, transformation, fragmentation, editing).,Conduct thorough analysis of data in preparation for retiring old capabilities.,Actively participates in the creation and implementation of business information models, and business intelligence and data roadmaps including attributes, structures and relationships. Actively participates in complex entity design, structure and population.,Provides guidance to strategic projects around accuracy and availability of data.,Performs data profiling, analyzes and communicates results in support of data quality processes.,Assists in implementation of processes to certify data quality for business intelligence purposes.,Analyzes medium complexity customer requests (internal or external, e.g. data calls) for changes to production systems, determines impact on existing systems, processes and develops appropriate specifications, enhancements and or procedures to comply. Meet with customer to elicit requirements. May act as project lead for medium complexity items.,Handles moderate to complex root cause analysis of business data issues and provides technical data guidance on complex issues. Oversee specification or procedural changes to address issue.,Manage the testing and verification processes ensuring accuracy.,Work with business areas and project team members to understand new business capabilities and perform impact analysis to determine additional data requirements, provide data expertise and data as needed. Conduct fact gathering sessions with customer to define and confirm requirements. Oversee deliverables for compliance (e.g. state/bureau requirements).,Develops, maintains and prioritizes business data requirements and specifications; leveraging data standards, ensuring that solutions (structure, values, relationships, quality standards) meet operational and business need.,Provides input into end to end data flow and lineage from capture at source, to storage, to delivery and its business intent at each stage (i.e. capture, transformation, fragmentation, editing).,Conduct thorough analysis of data in preparation for retiring old capabilities.,Actively participates in the creation and implementation of business information models, and business intelligence and data roadmaps including attributes, structures and relationships. Actively participates in complex entity design, structure and population.,Provides guidance to strategic projects around accuracy and availability of data.,Performs data profiling, analyzes and communicates results in support of data quality processes.,Assists in implementation of processes to certify data quality for business intelligence purposes.","
The Travelers Companies, Inc.
Company Summary
Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.
Target Openings
1
Job Description Summary
The Bond & Specialty Insurance BI&A organization is seeking a talented professional to join the organization as a Technical Business Data Analyst to assist with our Management Liability program building out a new core capability. This new core capability is centered around data requiring significant data analysis and subject matter expertise within Bond & SI.
To accomplish this the Tech BA will need to partner with internal and external areas to:
• Perform data analysis on complex data
• Build and deliver data requirements
• Address internal data nuances by building & implementing various rules
• Determine root causes for data issues
Proficiency in SQL with a strong aptitude to continue advancing is a must.
Primary Job Duties & Responsibilities
Analyzes medium complexity customer requests (internal or external, e.g. data calls) for changes to production systems, determines impact on existing systems, processes and develops appropriate specifications, enhancements and or procedures to comply. Meet with customer to elicit requirements. May act as project lead for medium complexity items.
Handles moderate to complex root cause analysis of business data issues and provides technical data guidance on complex issues. Oversee specification or procedural changes to address issue.
Manage the testing and verification processes ensuring accuracy.
Work with business areas and project team members to understand new business capabilities and perform impact analysis to determine additional data requirements, provide data expertise and data as needed. Conduct fact gathering sessions with customer to define and confirm requirements. Oversee deliverables for compliance (e.g. state/bureau requirements).
Develops, maintains and prioritizes business data requirements and specifications; leveraging data standards, ensuring that solutions (structure, values, relationships, quality standards) meet operational and business need.
Provides input into end to end data flow and lineage from capture at source, to storage, to delivery and its business intent at each stage (i.e. capture, transformation, fragmentation, editing).
Conduct thorough analysis of data in preparation for retiring old capabilities.
Actively participates in the creation and implementation of business information models, and business intelligence and data roadmaps including attributes, structures and relationships. Actively participates in complex entity design, structure and population.
Provides guidance to strategic projects around accuracy and availability of data.
Performs data profiling, analyzes and communicates results in support of data quality processes.
Assists in implementation of processes to certify data quality for business intelligence purposes.
Analyzes medium complexity customer requests (internal or external, e.g. data calls) for changes to production systems, determines impact on existing systems, processes and develops appropriate specifications, enhancements and or procedures to comply. Meet with customer to elicit requirements. May act as project lead for medium complexity items.
Handles moderate to complex root cause analysis of business data issues and provides technical data guidance on complex issues. Oversee specification or procedural changes to address issue.
Manage the testing and verification processes ensuring accuracy.
Work with business areas and project team members to understand new business capabilities and perform impact analysis to determine additional data requirements, provide data expertise and data as needed. Conduct fact gathering sessions with customer to define and confirm requirements. Oversee deliverables for compliance (e.g. state/bureau requirements).
Develops, maintains and prioritizes business data requirements and specifications; leveraging data standards, ensuring that solutions (structure, values, relationships, quality standards) meet operational and business need.
Provides input into end to end data flow and lineage from capture at source, to storage, to delivery and its business intent at each stage (i.e. capture, transformation, fragmentation, editing).
Conduct thorough analysis of data in preparation for retiring old capabilities.
Actively participates in the creation and implementation of business information models, and business intelligence and data roadmaps including attributes, structures and relationships. Actively participates in complex entity design, structure and population.
Provides guidance to strategic projects around accuracy and availability of data.
Performs data profiling, analyzes and communicates results in support of data quality processes.
Assists in implementation of processes to certify data quality for business intelligence purposes.
Minimum Qualifications
Bachelors degree in STEM (Science, Technology, Engineering, Mathematics) or Business.
2 years of relevant data and analytics experience preferred.
Education, Work Experience, & Knowledge
Very proficient is SQL with experience performing data analytics and writing SQL queries.
Demonstrates general understanding of overall data models, data relationships, mapping lineage and business rules.
Acts as subject matter experts on specific aspects of data availability and usage, assisting in the arbitration of differences of data interpretations and guidance to projects, business and technology areas.
Thorough knowledge of tools and software used to extract and analyze data in the data management function preferred.
Insurance knowledge preferred.
Employment Practices
Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences.
If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.
Travelers reserves the right to fill this position at a level above or below the level included in this posting.
To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.
",https://www.insurancejournal.com/jobs/639955-sr-associate-data-engineer
JOB259695716383,Big Data Engineer,Big Data Engineer,,"ISE,Professional Services offers clients a complete spectrum of software engineering services, including IoT / Telematics, Big Data, Cloud, Mobile App Development and Agile Consulting,Innovation Services provides the capability to achieve and sustain short and long-term growth throughout the entire organization. This approach allows ISE to remain focused on enhancing the customer’s experience as they look for technology solutions","
Title: Big Data Engineer
Location: Coralville, IA or Cedar Rapids, IA
Innovative Software Engineering (ISE) is a leading engineering and systems integration firm that delivers innovative, end-to-end mobile and enterprise solutions. ISE’s business includes three interrelated divisions:
Professional Services offers clients a complete spectrum of software engineering services, including IoT / Telematics, Big Data, Cloud, Mobile App Development and Agile Consulting
Innovation Services provides the capability to achieve and sustain short and long-term growth throughout the entire organization. This approach allows ISE to remain focused on enhancing the customer’s experience as they look for technology solutions
Fleet Services leverages decades of transportation technology expertise to offer a configurable end-to-end solution to manage drivers’ hours-of-service and vehicle maintenance compliance, which results in a safer, more profitable operation
Position Overview
· Work on Big Data Systems across a variety of domain applications. Design and implements the infrastructure to collect, move, transform, clean, analyze and report on Big Data.
Required Skills:
· 3+ years working with Big Data and related tools such as Hadoop and Spark
· 3+ years of work experience in Java and/or Python
· Must be a continual learner with a desire and ability to learn new skills and technologies
Preferred Skills:
· Experience with relevant AWS technologies (S3, Data Pipeline, EMR, RDS, Cloud Formation, Kinesis)
· Experience with Tableau
Trimble Inc. is proud to be an Equal Opportunity and Affirmative Action Employer and considers qualified applicants for employment without regard to race, gender, age, color, religion, national origin, marital status, disability, sexual orientation, status as a covered veteran in accordance with applicable federal, state and local laws, or any other protected factor. EOE/M/F/V/D
#engineering
",https://careers.trimble.com/jobs/engineering/coralville-ia-us/big-data-engineer/P_AAAAAAEAAIzJePtkTIFkHa?lang=en_us
JOB260551048140,Data Engineer based in Ghent,Data Engineer based in Ghent,,"Industrial Engineering - IT,Computer Science","
Data Engineer based in Ghent
Here you find the details for the student job named ""Data Engineer based in Ghent"" in the company Realo.
Details
Name:
Data Engineer based in Ghent
Description:
Realo, market leader in automated valuation models is looking for a data engineer to strengthen its team. Do you have strong programming skills in Python or PHP and a good knowledge of web development, then this might be the job for you.
Target profiles:
Industrial Engineering - IT
Computer Science
Burgerlijk Ingenieur - Computer Science Engineering
Required special knowledge:
Knowledge of Python and PHP, Mysql
You have strong mathematical skills
You have knowledge of web development
You have a university Master's or Docter's degree in Computer Engineering or Mathematics
You are a quick learner and can work independently
Contact:
Vincent Verlee (CEO)
Email: jobs@realo.com
Tel:
",https://vtk.ugent.be/career/students/studentjobs/detail/realo/data-engineer/
JOB264159728979,Data Engineer w/ Computer Vision,Data Engineer w/ Computer Vision,,,"
Employee • Martigny-Ville, Switzerland • Added Jul 15 '19
We are looking for a data engineer to keep the engines running in our data-driven startup. Your job will be to ensure we are constantly gathering data, ensuring our data is useful and of high quality, and that it is readily available for improving our technologies based on computer vision and machine learning / AI. As our focus is on computer vision, you will mostly manage video and images which however can be captured from different sensors: color cameras, depth, infrared, etc.
You will be collaborating closely with our research team, our customers and partners to bridge the gap between them in terms of data opportunities. The success of your job will also require a good understanding of the underlying technology.
This role is open as an internship position as well. Please mention in your application if you are interested in the internship.
Responsibilities:
Record, organize and provide datasets ready for R&D
Understand and communicate collaboration opportunities with our partners in terms of data needs
Enhance our data with annotations, ground truth, etc.
Find creative mechanisms to gather data: use cases, sources, sensors, modalities
Design experiments to validate the quality of our system for specific use cases
Maintain and improve our benchmarking system
Ensure compliance with data protection regulations
Coordinate data-related infrastructure
To be willing to learn, pragmatic, actionable, motivated and with a strong team spirit
REQUIREMENTS
MSc degree in Computer Science, Computer Engineering, or Electrical Engineering
Experience in experimental design
Video and image processing
Knowledge in python
Database management
#Nice-to-have skills
● Experience in computer vision or machine learning
● Experience in continuous integration
Compensation:
Equity: 0.0% – 0.3%
Salary range: $65k – $80k/ year
",https://www.f6s.com/jobs/41791/eyewaretech/data-engineer-w-computer-vision
JOB266317206211,Big Data Engineer,Big Data Engineer,,"Professional Services offers clients a complete spectrum of software engineering services, including IoT / Telematics, Big Data, Cloud, Mobile App Development and Agile Consulting,Innovation Services provides the capability to achieve and sustain short and long-term growth throughout the entire organization. This approach allows ISE to remain focused on enhancing the customer s experience as they look for technology solutions","
Title: Big Data Engineer
Location: Coralville, IA or Cedar Rapids, IA
Innovative Software Engineering (ISE) is a leading engineering and systems integration firm that delivers innovative, end-to-end mobile and enterprise solutions. ISE s business includes three interrelated divisions:
Professional Services offers clients a complete spectrum of software engineering services, including IoT / Telematics, Big Data, Cloud, Mobile App Development and Agile Consulting
Innovation Services provides the capability to achieve and sustain short and long-term growth throughout the entire organization. This approach allows ISE to remain focused on enhancing the customer s experience as they look for technology solutions
Fleet Services leverages decades of transportation technology expertise to offer a configurable end-to-end solution to manage drivers hours-of-service and vehicle maintenance compliance, which results in a safer, more profitable operation
Position Overview
Work on Big Data Systems across a variety of domain applications. Design and implements the infrastructure to collect, move, transform, clean, analyze and report on Big Data.
Required Skills:
Must be a continual learner with a desire and ability to learn new skills and technologies
Preferred Skills:
Trimble Inc. is proud to be an Equal Opportunity and Affirmative Action Employer and considers qualified applicants for employment without regard to race, gender, age, color, religion, national origin, marital status, disability, sexual orientation, status as a covered veteran in accordance with applicable federal, state and local laws, or any other protected factor. EOE/M/F/V/D
",https://www.dice.com/jobs/detail/Big-Data-Engineer-Trimble%2C-Inc.-Coralville-IA-52241/10166629/1501%26%2345171119
JOB267962909219,Junior Data Engineer – (BERLIN),Junior Data Engineer – (BERLIN),A competitive salary,"A Data Engineer, BI or database developer who is passionate about having a meaningful, global impact,Experience in data integration, cleaning, validation and analysis,Strong SQL skills, proficiency with R, and familiarity with Git,DevOps, System or Database Administration experience,A pro-active problem-solver with strong analytical skills and a good sense for code quality,Genuine interest in improving our data infrastructure and related services,Fluent English,In addition, experience with finance is a big plus,Further technical expertise, such as web development or data visualisation, is very welcome as well,Somebody who has the courage to apply, even if they don’t tick all the boxes above!,Support implementing systems to make our data analysis reliable, transparent and reproducible,Maintain, extend and improve our existing data infrastructure and related services,Support colleagues with data queries, SQL trainings for continuous improvement of skills,Evaluate and develop technical solutions for new projects and use cases,A meaningful impact on one of the planet’s most pressing issues,Engaging working environment in a young, international and rapidly expanding team and the chance to work at a cutting-edge think tank,Flexible working hours,Chance to take on responsibility and shape a project from your first day onwards,Opportunity for significant career development","
Job Description
Who we are:
A global, independent think tank on the integration of long-term and climate-related objectives and risks into financial market metrics, processes and regulation.
Since its set up in 2012 with the mission to align financial markets with climate goals, the 2° Investing Initiative (2°ii) has become a pioneering think tank on the integration of long-term risks and policy objectives into financial markets and regulatory frameworks. Over the past years, 2°ii has led one of the largest global research programmes on long-term risks in financial markets, working with over 50 research partners. It developed the first scenario analysis tool linking financial portfolios to international climate goal which was applied by >1,500 financial institutions by now. A core principle of its mission is to reduce transaction costs across companies, financial institutions and policymakers, while guiding financial markets towards the long-term future.
Current research includes market outlook reports, physical risk incorporation and enhancement of existing, analytical methods. 2°ii combines business intelligence databases from several climate-relevant sectors with financial datasets and climate scenarios as well as with other relevant third-party datasets to assess climate risks such as physical risk maps, etc. This database is used to assess the exposure of stocks, bonds and other financial instruments to energy-related technologies, as well as to build a sustainability-ready, open-source robo-adviser.
2°ii has a multi-stakeholder and independent governance framework designed to ensure the intellectual integrity of its work and its independence. More information can be found at www.2degrees-investing.org
What we are looking for:
A Data Engineer, BI or database developer who is passionate about having a meaningful, global impact
Experience in data integration, cleaning, validation and analysis
Strong SQL skills, proficiency with R, and familiarity with Git
DevOps, System or Database Administration experience
A pro-active problem-solver with strong analytical skills and a good sense for code quality
Genuine interest in improving our data infrastructure and related services
Fluent English
In addition, experience with finance is a big plus
Further technical expertise, such as web development or data visualisation, is very welcome as well
Somebody who has the courage to apply, even if they don’t tick all the boxes above!
What you will be doing:
Support implementing systems to make our data analysis reliable, transparent and reproducible
Maintain, extend and improve our existing data infrastructure and related services
Support colleagues with data queries, SQL trainings for continuous improvement of skills
Evaluate and develop technical solutions for new projects and use cases
What we offer:
A meaningful impact on one of the planet’s most pressing issues
Engaging working environment in a young, international and rapidly expanding team and the chance to work at a cutting-edge think tank
Flexible working hours
Chance to take on responsibility and shape a project from your first day onwards
Opportunity for significant career development
A competitive salary
How to Apply
Interested in changing finance to fight climate change? Please send your CV and cover letter in English indicating your earliest possible start date to: jobs@2degrees-investing.org We are committed to building a diverse team and encourage applications from female and minority candidates.
Apply for this Job
Message *
Upload resumé (pdf, doc, docx, zip, txt, rtf)
",https://feedproxy.google.com/~r/RJobs/~3/EVcH2bOXDNE/
JOB273459201773,SQL Data Engineer,SQL Data Engineer,,"Managing the investigation of corporate data requirements, documenting them according to the required standards utilising the prescribed methods and tools,Implementing data flows to connect operational systems, data for analytics and BI systems. Re-engineer manual data flows to enable scaling and repeatable use,Working closely with data architects (to determine what data management systems are appropriate) and data scientists (to determine what data is needed for analysis).,Tackling problems associated with database integration and unstructured data sets,Ensuring that those using the data structures and associated components have a good understanding and that any queries are dealt with promptly and efficiently,Strong technical process understanding regardless of technology,Wide range of strong technical skills (i.e. Azure Devops, Azure Data Factory, Data Bricks, SQL, python),Core SQL Competencies – SSMS, SSIS, T-SQL, Stored Procedures,ADF Pipelines to build and populate SQL databases,Background in migrating traditional MS products to Azure,Ability to create efficient DW or DL structures to minimise cost of orchestration / processing and ingestion of data,Very high attention to detail,Strong communication skills,Efficient in building ETL and ELT processes for enterprise solutions,Strong software delivery methods and knowledge,Digital delivery – has a track record of working on DevOps delivery,Exposure in Climate Change data legislation, practices and stakeholders,Experience in Environmental related industries i.e Water, Energy, Forestry related,Presentation skills,Understanding of architecting solutions taking into account wider considerations","
SQL Data Engineer
Job purpose and background
Are you a capable SQL Data Engineer who is passionate about the power of data to solve environmental issues? CDP are looking for an SQL Data Engineer to shape delivery by collaborating with data architects and modellers to contribute to the acquisition of corporate data requirements, documenting them according to the required standards utilising the prescribed methods and Azure data tools, in order to build our centralised data platform.
This is a permanent role, with responsibility for developing, constructing, testing and maintaining architectures such as data pipelines and large-scale data processing warehouses. The post-holder will leverage industry best practice while delivering changes, such as agile backlogs, code repositories, automated builds, testing and releases. They will be responsible for ensuring data scientists can pull relevant data sets for their analyses, implement data pipelines to connect operational systems, data for analytics and BI systems. The role includes re-engineering manual data flows to enable automation, scaling and repeatable use and developing data set processes for data modelling, mining and production.
The post-holder will work closely with data architects (to determine what data management systems are appropriate) and data scientists (to determine which data are needed for analysis). They will provide clean, usable data to the business through the data platform in accordance with governance, and analyse, design, plan, execute and evaluate data requirements to support business activities and projects. The post-holder will be central in ensuring the delivery of world-class digital products and changing the delivery culture in CDP.
About CDP's data engineering team:
The Data Engineering Team’s primary remit is to improve the usability of the climate change, water, forests and cities data disclosed to CDP through robust and transparent methods. The team will create sustainable data pipelines for data quality monitoring, data cleaning, reporting and data science modelling. Harmonised data collected from external sources will enrich the data assets’ value and enhance accessibility for CDP’s stakeholders. The team will produce value-adding insight delivering it through data products that help internal and external stakeholders to better understand the quantitative and qualitative results of their actions. This in turn helps stakeholders to make data-led decisions and optimise for all constraints. Through every stage the data assets are governed by the industry practice standards in a robust and transparent manner.
Key responsibilities include:
Managing the investigation of corporate data requirements, documenting them according to the required standards utilising the prescribed methods and tools
Implementing data flows to connect operational systems, data for analytics and BI systems. Re-engineer manual data flows to enable scaling and repeatable use
Working closely with data architects (to determine what data management systems are appropriate) and data scientists (to determine what data is needed for analysis).
Tackling problems associated with database integration and unstructured data sets
Ensuring that those using the data structures and associated components have a good understanding and that any queries are dealt with promptly and efficiently
In liaison with the information management or IT management functions, contributing to the development and maintenance of corporate data standards
Required skills and experience:
Strong technical process understanding regardless of technology
Wide range of strong technical skills (i.e. Azure Devops, Azure Data Factory, Data Bricks, SQL, python)
Core SQL Competencies – SSMS, SSIS, T-SQL, Stored Procedures
ADF Pipelines to build and populate SQL databases
Background in migrating traditional MS products to Azure
Ability to create efficient DW or DL structures to minimise cost of orchestration / processing and ingestion of data
Very high attention to detail
Strong communication skills
Efficient in building ETL and ELT processes for enterprise solutions
Strong software delivery methods and knowledge
Strong performance-tuning skills.
Desired skills and experience
Digital delivery – has a track record of working on DevOps delivery
Exposure in Climate Change data legislation, practices and stakeholders
Experience in Environmental related industries i.e Water, Energy, Forestry related
Presentation skills
Understanding of architecting solutions taking into account wider considerations
Structured problem solving techniques.
This is a permanent full-time role, reporting to the Head of Data Engineering, which will be delivered remotely to start with. The post holder will be required to travel to CDP’s London office from time to time when it reopens.
Salary and benefits: Between £45,000 - £48,500 per annum dependent on experience, 30 days holiday excluding bank holidays, flexible working opportunities and others benefits.
Interested applicants must be eligible to work legally in the United Kingdom.
Before you apply
We’ll only use the information you provide to process your application. For more details on how we use your information, see our applicants privacy notice. By emailing us your CV and covering letter, you are permitting CDP to use the information you have provided for recruitment purposes.
To apply please email your CV and a covering letter setting out how you meet the required skills and experience or key responsibilities, which should be no more than two pages, to recruitment@cdp.net with ‘DI-SQL Data Engineer, Firstname Surname’ in the subject. Applications will be reviewed on a rolling basis, so early applications are strongly encouraged. The deadline is 8.00 am on 19 October 2020.
Are you interested in a career at CDP working in one of our global offices?
Explore our current job vacancies
",https://www.cdp.net/en/info/careers/sql-data-engineer-2
JOB157879805,AVAILABLE POSITIONS Principal Data Engineer,AVAILABLE POSITIONS Principal Data Engineer,Work with cool people and impact millions of daily players!,"Build and own multi PB-scale data platform.,Design, code, and develop new features/fix bugs/enhancements to systems and data pipelines (ETLs) while adhering to the SLA.,Follow engineering best methodologies towards ensuring performance, reliability, scalability, and measurability.,Collaborate with other Software Engineers, ML Engineers, Data Scientists, and other stakeholders, taking on learning and leadership opportunities that will arise every single day.,Mentor junior engineers in the team to level them up.,Raise the bar on sustainable engineering by improving best practices, producing best in class of code, documentation, testing and monitoring.,Bachelor’s degree in Computer Science, or a related technical discipline (or equivalent).,6+ years of strong data engineering design/development experience in building massively large scale distributed data platforms/products.,Advanced coding expertise in SQL & Python/JVM-based language.,Expert in heterogeneous data storage systems (relational, NoSQL, in-memory etc).,Deep knowledge of data modeling, lineage, access and its governance.,Excellent skills in AWS services like Redshift, Kinesis, Lambda, EMR, EKS/ECS etc.,Wide exposure to open source software, frameworks and broader cutting edge technologies (Airflow, Spark, Druid etc).,Familiar with infrastructure provisioning tools (e.g Terraform, Chef),Consistent proven ability to deliver work on time with attention to quality.,Excellent written and spoken communication skills and ability to work effectively with others in a team environment.,Work in a studio that has complete P&L ownership of games,Competitive salary, discretionary annual bonus scheme and Zynga RSUs,Full medical, accident as well as life insurance benefits,Catered breakfast, lunch and evening snacks,Child care facilities for women employees and discounted facilities for male employees,Well stocked pantry,Generous Paid Maternity/Paternity leave,Employee Assistance Programs,Active Employee Resource Groups – Women at Zynga,Frequent employee events,Additional leave options for most employees,Flexible working hours on many teams,Casual dress every single day","
We are seeking top engineering talent to join our creative, dynamic, and highly driven team. Zynga’s mission is to “Connect the World through Games” by building a truly social experience that makes the world a better place. The ideal candidate will have a devotion to software craftsmanship, an unwavering commitment to quality, and the desire to have their work seen by tens of millions of people worldwide.
The Analytics Engineering team is responsible for all things data at Zynga. We own the full game and player data pipeline – from ingestion to storage to driving insights and analytics. As a Principal Data Engineer, you will be responsible for the software design and development of quality services and products to support the Analytics needs of our games. In this role, you will be part of our Central Technology group focusing on advanced technology developments for building scalable data infrastructure and end-to-end services which can be leveraged by the various games. We are a 120+ organization servicing 1500 others across 13 global locations.
Your responsibilities will include
Build and own multi PB-scale data platform.
Design, code, and develop new features/fix bugs/enhancements to systems and data pipelines (ETLs) while adhering to the SLA.
Follow engineering best methodologies towards ensuring performance, reliability, scalability, and measurability.
Collaborate with other Software Engineers, ML Engineers, Data Scientists, and other stakeholders, taking on learning and leadership opportunities that will arise every single day.
Mentor junior engineers in the team to level them up.
Raise the bar on sustainable engineering by improving best practices, producing best in class of code, documentation, testing and monitoring.
Bachelor’s degree in Computer Science, or a related technical discipline (or equivalent).
6+ years of strong data engineering design/development experience in building massively large scale distributed data platforms/products.
Advanced coding expertise in SQL & Python/JVM-based language.
Expert in heterogeneous data storage systems (relational, NoSQL, in-memory etc).
Deep knowledge of data modeling, lineage, access and its governance.
Excellent skills in AWS services like Redshift, Kinesis, Lambda, EMR, EKS/ECS etc.
Wide exposure to open source software, frameworks and broader cutting edge technologies (Airflow, Spark, Druid etc).
Familiar with infrastructure provisioning tools (e.g Terraform, Chef)
Consistent proven ability to deliver work on time with attention to quality.
Excellent written and spoken communication skills and ability to work effectively with others in a team environment.
What we offer you:
Work in a studio that has complete P&L ownership of games
Competitive salary, discretionary annual bonus scheme and Zynga RSUs
Full medical, accident as well as life insurance benefits
Catered breakfast, lunch and evening snacks
Child care facilities for women employees and discounted facilities for male employees
Well stocked pantry
Generous Paid Maternity/Paternity leave
Employee Assistance Programs
Active Employee Resource Groups – Women at Zynga
Frequent employee events
Additional leave options for most employees
Flexible working hours on many teams
Casual dress every single day
Work with cool people and impact millions of daily players!
#LI-HK1
Careers region: India
Careers Category: Engineering
Careers location: Bengaluru, India
Careers Type: Full-Time
",https://www.zynga.com/job-listing/principal-data-engineer/
JOB868789805,Data Engineer IT Data Warehousing...,Data Engineer IT Data Warehousing...,,,,https://www.avjobs.com/jobs/positions.asp?q=Data+Engineer+IT+Data+Warehousing
JOB2290103786,Data Engineer & Architect (Midtown),Data Engineer & Architect (Midtown),,," Data Engineer & Architect
LOCATION: Midtown Manhattan or San Francisco area
TYPE OF EMPLOYMENT: Full-Time Permanent
Venture backed startup looking for the person who will be responsible for ensuring that a data-driven approach is at the heart of every piece of this organization and platform. The perfect candidate will lead efforts to create and maintain this company's system architecture to support their data warehousing and reporting efforts. This is a hands-on position that will work directly with their software development and business teams to bring this company's data capabilities to the next level.
RESPONSIBILITIES:
● Design data warehouse schemas that accurately represent our business and make building reports a breeze
● Manage Redshift Data Warehouse
● Create and maintain ETL (Talend or equivalent)
● Understand current and future data sources
● Tableau administration
● Support the development of reports in Tableau
● Maintain data quality by eliminating redundant and unnecessary data
● Learn on the job
● Drive, tinker, build out all of our data initiatives.
● Design data-driven solutions
● Work closely with our engineering and product teams to develop beautiful and data
driven tools to help our users (and us) understand and navigate our systems
REQUIREMENTS:
● Excited by the challenge of developing complex enterprise solutions while delivering simplicity for the end user
● Extensive backend experience but an appreciation for the importance of elegant and beautiful design
● Value hard work, collaboration and the ability to strike the right balance between speed, quality and execution
● Know how to get things done and prefer pragmatic solutions to theoretical ones
● Are a ""full stack"" data person - you know how to work with large, messy datasets, no
matter where or how they are stored OR you are up to figuring it out.
● Know your math but understand that the flashiest solutions usually aren't always the
best
● Have experience with some of the tools we use and are excited to learn the others:
Redshift, MySQL, Hadoop, d3.js, Kinesis, Tableau, SOLR, Elastic Search and, yes, even Excel.
COMPENSATION:
$90-120K + options + 10% bonus + full benefits
HOW TO APPLY:
1. Please email your resume in Word format to amusco@amsolutionsworldwide.com.
2. In the SUBJECT please write ""YOUR NAME - TITLE of this job - LOCATION of this job"".
Upon receipt of your resume -- qualified candidates will be provided more information.
Thank you to all applicants!
Anthony Musco
AM Solutions, LLC
US: (303) 573-6800
CAD: (416) 848-7417
amusco@amsolutionsworldwide.com
www.amsolutionsworldwide.com ",http://newyork.craigslist.org/mnh/sad/5967115345.html
JOB2378488650,Data Engineer,Data Engineer,,,"
As the Data Engineer for this amazing corporate Insurance company, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL, together...
As a data engineer within the exciting, new claims advanced analytics capability, you will be building big data solutions to solve some of the organization’s toughest problems and delivering significant business value. This is a really exciting time to...
Data Engineer - 70,000 Job Description An AWS Partner based in Central London is looking to expand the data side of their business due to growth. They are looking for Data Engineers with significant commercial experience ingesting large quantities of data...
As the Data Engineer for this amazing corporate Insurance company in the City, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL...
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
40'000- 50'000 Pension 8% Technical Progression Healthcare Holidays More Horley, Surrey Are you seeking a new challenge within a rapidly expanding Eco-Energy Tech company where you will be having huge technical autonomy in building a data preform right...
Data Engineer Portsmouth and surrounding areas encouraged to apply, multiple office locations Data Engineer required for established, international business. The business is at the forefront of new technologies working with leading Government organisations...
Data Engineer A brand new role has arisen for an experienced Database / BI Developer to take the next step in their career and transition into a full Data Engineer to work for one of the most recognisable NGO's in London. We are looking for someone with...
Data Engineer Opus are working with an excellent niche software development company in Newcastle. The company is at the forefront of their industry and due to their on-going success are now looking for a Data Engineer to take responsibility for organising...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
A leading Insurance Company are currently recruiting for a Data Engineer to join their dynamic and growing business. They are looking to hire a cross functional, highly tenacious and bright Data Engineer with a passion for functional programming. The ideal...
Data Engineer- 50K Manchester Adria Solutions has an exciting opportunity for a talented Data Engineer to join our rapidly expanding client based near Manchester. The role requires you to work closely with other members of the data team and stakeholders...
We are currently recruiting a highly motivated Data Engineer, for a company who are based in London. The Data Engineer will help develop and maintain the business. The Data Engineer will be responsible for the following; Key responsibilities- - Working...
Vacancy: Data Engineer (INTERVIEW SLOTS 25/06/2020) Skills: Python AND Hadoop (1 Year experience minimum) AND SQL AND Leadership Education : Relevant BSc or MSc: Computer Science, Artificial Intelligence, Mathematics etc (relevant degrees accepted) Location:...
Data Engineer - I am currently recruiting for a Data Engineer based in Bath. The role would be on a permanent basis and is paying 40,000 to 45,000 (There could be flex for the right candidate) PA plus a variety of excellent benefits as well as the flexibility...
Data Engineer - REMOTE WORK If you are a strong Data Engineer, with experience working with Python, R and SQL then this role is ideal. I am working with a large organisation that are market leaders in their respected field. This role will report in to...
Data Engineer London 55,000 - 65,000 Benefits Our client, an exciting RegTech business is looking to recruit for a Data Engineer to join their growing team. The successful candidate will be joining the artificial intelligence team, working on a brand new...
An exciting opportunity for an experienced Data Engineer has arisen in Leeds. After hiring a number of new members of staff at the end of 2019, the organisation are continuing to expand due to winning more projects. Key responsibilites include: Building...
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
Data Engineer London Up to 49,000 A reputable organisation based in London are seeking a talented Data Engineer to design and develop complex and group-wide data solutions. Job Duties - Plan and achieve agile sprint tasks from which the technical solutions...
Data Engineer - I am currently recruiting for a Data Engineer based in Bath. The role would be on a permanent basis and is paying 40,000 to 50,000 (There could be flex for the right candidate) PA plus a variety of excellent benefits as well as the flexibility...
Title: Data Engineer Our client is currently looking for a Data Engineer to play a vital role in the continual development of our digital transformation strategy and earth science analytics. Candidates must have Python, R and SQL. We expect candidates...
Learn more La Fosse Associates are engaged with a non-profit charity in the recruitment of a Data Engineer. Our client is open to speaking to candidates who have studied Python and want to develop their skills in a supportive environment. The successful candidate...
",http://www.reed.co.uk/jobs/data-engineer/39836668
JOB2719252622,Senior Data Engineer,Senior Data Engineer,"At least five years of proficiency on SQL Microsoft stack,Banking or financial sector experience beneficial,Fove years of .Net Language experience,Visualisation and Storyboarding experience,Stats experience,Assist in driving data services strategy across multiple platforms,Building in operation frameworks/processes to take data services to the next level of excellence,Building out of Big Data Platform and consolidating Group Data for provisioning via required channels,Operational/analytical data provisioning and insights into data landscape,Understanding and optimising Data Flow Patterns in order to rationalise data inputs,Shaping of unstructured data acquisition and Realtime Data Integration Patterns,Engagement and shaping Data Initiatives to ensure Strategic Alignment to Group Architecture",,"Job description
Are you looking for a new opportunity in a world-class media environment? If so, a Media Production Company with an International footprint is looking for multi-skilled data engineers to join their dynamic team. They are looking for candidates with the ability to execute on their Data Journey End to End. The business offers a rare opportunity to work on global scale systems in a uniquely flexible and vibrant working environment. This is your chance to up your skill on cutting edge technologies and take your career to the next level!! Don’t miss out on this opportunity. Apply now!
Reference number for this position is DZ47604 which is a permanent position based in Randburg offering a cost to company salary of R1,15mil CTC PA negotiable on experience and ability.
Email Dudley on dudleyz@e-merge.co.za or call him on 011 463 3633 to discuss this and other opportunities.
The time for change is NOW! e-Merge IT recruitment are specialist niche recruiters with a wide range of positions available. We offer researched positions with top companies to strong technical candidates.
Check out our website www.e-merge.co.za for more positions that might be right for you!
Do you have a friend who is a technology specialist? We pay big cash to you if we place a friend that you sent us!
If you haven’t heard from e-Merge IT within two weeks of your application, please consider it unsuccessful for this position.
Requirements
Requirements:
At least five years of proficiency on SQL Microsoft stack
Banking or financial sector experience beneficial
Fove years of .Net Language experience
Visualisation and Storyboarding experience
Stats experience
Big data tools beneficial
Responsibilities:
Assist in driving data services strategy across multiple platforms
Building in operation frameworks/processes to take data services to the next level of excellence
Building out of Big Data Platform and consolidating Group Data for provisioning via required channels
Operational/analytical data provisioning and insights into data landscape
Understanding and optimising Data Flow Patterns in order to rationalise data inputs
Shaping of unstructured data acquisition and Realtime Data Integration Patterns
Engagement and shaping Data Initiatives to ensure Strategic Alignment to Group Architecture
Role would require continuous upskilling on new technologies/patterns/frameworks and market trends
Posted on 03 Dec 07:44
",https://www.bizcommunity.com/Job/196/542/377646.html
JOB3019401729,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-id/details/200188037/ai-ml-search-data-engineer-siri-data
JOB4358524232,Lead Data Engineer,Lead Data Engineer,50+ career categories,"Find a better job, faster!,Hand-screened leads,No ads, scams, junk,Great job search support","
Lead data engineer needed for a full-time opportunity. This position will be remote during the pandemic but is expected to involve travel in the future. Responsible for developing data architecture and performing client organizational reviews.
Job Details
Remote - During Pandemic
Employee
Full-Time
Manager
Yes, a bit
Company name here
Other benefits listed here
Find a better job, faster!
Hand-screened leads
No ads, scams, junk
Great job search support
50+ career categories
Create an Account to Unlock
To find out more about or apply to this Lead Data Engineer job—and other great opportunities like it—become a FlexJobs member today!
With FlexJobs, you'll find the best flexible jobs and fantastic expert resources to support you in your job search. If you have any questions, please feel free to contact us.
",https://www.flexjobs.com/publicjobs/lead-data-engineer-1295986
JOB4439939922,Azure Data Engineer Contract,Azure Data Engineer Contract,,"Performing data discovery on old, out of use legacy systems.,Overseeing the ETL development with Azure Data Factory, writing optimal processes to populate the data warehouse,Strong hands-on experience working in an Azure Cloud system,A history of architecting extensive features of ETL processes,Strong commercial experience developing and optimising ETL processes with Azure Data Factory","
AZURE DATA ENGINEER (CONTRACT)
£400-500 PER DAY, 3 MONTHS
CENTRAL LONDON
A niche start-up Consultancy is looking for an Azure Data Engineer, with strong skill ingesting data from external sources with Azure Data Factory to support their client projects.
THE COMPANY:
This company is a start-up Analytics Consultancy. specialising in providing services to a niche industry. They bring in data from external servers to their own Azure platform in order to perform insightful analytics, adding value to their clients' business.
THE ROLE:
As an Azure Data Engineer you will be responsible for designing and developing ETL processes to bring in data from various external sources to the Azure platform.
In specific, you can expect to be involved in the following:
Performing data discovery on old, out of use legacy systems.
Overseeing the ETL development with Azure Data Factory, writing optimal processes to populate the data warehouse
The provision of data for analysis
YOUR SKILLS AND EXPERIENCE:
The successful Azure Data Engineer will have the following skills and experience:
Strong hands-on experience working in an Azure Cloud system
A history of architecting extensive features of ETL processes
Strong commercial experience developing and optimising ETL processes with Azure Data Factory
Strong experience with the full Microsoft BI Stack (SSIS, SSAS, SSRS)
THE BENEFITS:
The successful Azure Data Engineer will receive £400-500 per day over an initial 3-month contract.
HOW TO APPLY:
Please register your interest by sending your CV to Joseph Pyne via the Apply link on this page.
Reference: 39766889
Bank or payment details should never be provided when applying for a job. For information on how to stay safe in your job search, visit SAFERjobs.
Report this job
",https://www.reed.co.uk/jobs/azure-data-engineer-contract/39766889
JOB4642662913,Apple Music - Software Data Engineer,Apple Music - Software Data Engineer,"Experience in designing, implementing and supporting highly scalable data systems and services in Java and/or Scala,Experience with Hadoop-ecosystem technologies in particular MapReduce, Spark / Spark-SQL / Spark Streaming, Hive, YARN/MR2,Experience building and running large-scale data pipelines, including distributed messaging such as Kafka, data ingest to/from multiple sources to feed batch and near-realtime/streaming compute components,Experience in data-modeling and data-architecture optimized for big data patterns, ie. warehousing concepts; efficient storage and query on HDFS; data security and privacy techniques),Knowledgable about distributed storage and network resources, at the level of hosts, clusters and DCs, to troubleshoot and prevent performance issues",,"This team is more than a group of engineers — it’s a group of music lovers. That passion has made Apple Music the world’s most complete music experience, with over 60 million songs, thousands of playlists, and daily selections from music experts for 115 countries. The team’s data-driven engineers focus relentlessly on the customer experience by running worldwide experiments and analyzing usage and latency, while collaborating with Apple’s product groups. As a result, someone can use the Shazam app to identify an intriguing song in a café in the morning, add it to their playlist from Apple Watch, listen to it through their AirPods on their commute, and share it with their family on HomePod at dinnertime. And there’s more where that came from, because personalization powered by machine learning and music science helps listeners discover more of what they love. Apple Music is a big part of Apple’s business because it’s a big part of people’s lives. Areas of work: macOS/iOS Engineering, Full-Stack Engineering, Front-End Engineering, Back-End Engineering, Quality Engineering, Machine Learning Engineering, Data Science, Data Engineering, Site Reliability Engineering, Commerce Engineering, and Engineering Project Management.
Experience in designing, implementing and supporting highly scalable data systems and services in Java and/or Scala
Experience with Hadoop-ecosystem technologies in particular MapReduce, Spark / Spark-SQL / Spark Streaming, Hive, YARN/MR2
Experience building and running large-scale data pipelines, including distributed messaging such as Kafka, data ingest to/from multiple sources to feed batch and near-realtime/streaming compute components
Experience in data-modeling and data-architecture optimized for big data patterns, ie. warehousing concepts; efficient storage and query on HDFS; data security and privacy techniques)
Knowledgable about distributed storage and network resources, at the level of hosts, clusters and DCs, to troubleshoot and prevent performance issues
Experience with low-latency NoSQL datastores and traditional relational databases is desired
Our Data Engineering team is seeking a hardworking, performance-savvy, engineer to build out the big data platform and services, which power many of these customer features — existing and new. You will be responsible for designing and implementing features that rely on processing and serving very large datasets with an awareness of scalability. This will include crafting systems to model, ingest, process and compute large-scale, mission-critical data across Apple Music. High-throughput and reliability are essential. This is your opportunity to help engineer highly visible global-scale systems with petabytes of data, supporting hundreds of millions of users!
Bachelors degree in Computer Science, or equivalent experience. We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.
",https://jobs.apple.com/en-us/details/200166439/apple-music-software-data-engineer
JOB5389838884,"Data Engineer, People Analytics","Data Engineer, People Analytics","Minimum 5 years of experience in an analytics and data engineering role,BS or MS degree in a quantitative field or equivalent practical experience,Mastery of relational databases (SQL or MySQL),Ability to translate business processes and data into analytics solutions.,A strong foundation in data modeling, including at least 3 years of relevant business or people analytics experience, and a commitment to data governance,Demonstrated ability to manage technical and non-technical stakeholders and drive collaboration,Experience with Python or any scripting language a plus,Experience with Tableau a plus,Desired Attributes,Outstanding written, verbal, and visual communication capabilities,Ability to pivot between widely divergent tasks and subject matter on short notice, and rapidly adapt to varied audiences.,A record of adding value to work outcomes through innovation and an orientation toward continuous refinement and improvement,Highly thorough and detail-oriented",,"Apple’s People Analytics team is accountable for equipping decision-makers with data-driven insights through analytics to make the best decisions about people — individuals, teams, and organizations. This close-knit, highly productive, and well-regarded team is looking for a key player with complementary skills to help deliver on its vision of democratizing talent insights through research and technology.
Minimum 5 years of experience in an analytics and data engineering role
BS or MS degree in a quantitative field or equivalent practical experience
Mastery of relational databases (SQL or MySQL)
Ability to translate business processes and data into analytics solutions.
A strong foundation in data modeling, including at least 3 years of relevant business or people analytics experience, and a commitment to data governance
Demonstrated ability to manage technical and non-technical stakeholders and drive collaboration
Experience with Python or any scripting language a plus
Experience with Tableau a plus
Desired Attributes
Outstanding written, verbal, and visual communication capabilities
Ability to pivot between widely divergent tasks and subject matter on short notice, and rapidly adapt to varied audiences.
A record of adding value to work outcomes through innovation and an orientation toward continuous refinement and improvement
Highly thorough and detail-oriented
A highly collaborative person who is passionate about technology and driven to get things done.
The Sr Data Engineer will play a lead role in designing, developing and scaling Apple’s people analytics database and architecture - HRBI (human resources business intelligence). They will be responsible for driving and managing data source integrations as well as defining load and transformation strategies to make data meaningful for analytics and reporting. This person will also play a key role in assuring quality assurance through peer code reviews. The ideal candidate will be an individual with strong problem solving and analytical skills along with equally strong communication and influencing skills. This highly collaborative role will work with partner teams, vendors and consultants and require to possess the ability to translate complex data and process concepts into scalable analytics solutions that power our visualizations.
",https://jobs.apple.com/en-us/details/200136308/data-engineer-people-analytics
JOB6468708916,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-br/details/200188037/ai-ml-search-data-engineer-siri-data
JOB6523260242,Data Engineer,Data Engineer,,,"
Full-time remote role. He/she will design cutting edge databases and data warehouses. Architect and test scalable systems, software and services. 3+ years of Python and ETL experience and Scrum/agile software development process experience required.
",https://www.flexjobs.com/publicjobs/data-engineer-1291361
JOB7913792601,"AI/ML - Siri Data Engineer, Siri Search, Knowledge & Platform","AI/ML - Siri Data Engineer, Siri Search, Knowledge & Platform","5 years of experience as a Software Engineer,Excellent programming skills - e.g. Python, Go, Java,Excellent problem-solving and analytic skills,Solid computer science and systems foundations; ability to quickly learn new domains,Proven system development skills in UNIX-type OS (e.g. Linux, Mac OS),Experience working with large data sets and pipelines, ideally using the Apache software stack (e.g. Spark, HBase),Experience with continuous integration and continuous development solutions (e.g. Jenkins, etc.),Experience with cloud-native deployment (e.g. Kubernetes),Good communication skills and teamwork,Passion for building great products,Curiosity and desire to learn,The following experience is nice to have, but not required: Data modeling Experience working with search engines Machine learning Natural-language processing",,"
AI/ML - Siri Data Engineer, Siri Search, Knowledge & Platform
Seattle , Washington , United States
Machine Learning and AI
Summary
Posted: Nov 4, 2020
Weekly Hours: 40
Role Number: 200200475
Help us make Siri smarter! We're seeking software engineers and architects to work on improving data workflows for Siri's open domain query understanding. As an expert in developing software to manage large, dynamic data sets, you'll be building platform for data ingestion, cleaning, transformation and evaluation to support a rapidly scaling organization. Key Qualifications
Key Qualifications
5 years of experience as a Software Engineer
Excellent programming skills - e.g. Python, Go, Java
Excellent problem-solving and analytic skills
Solid computer science and systems foundations; ability to quickly learn new domains
Proven system development skills in UNIX-type OS (e.g. Linux, Mac OS)
Experience working with large data sets and pipelines, ideally using the Apache software stack (e.g. Spark, HBase)
Experience with continuous integration and continuous development solutions (e.g. Jenkins, etc.)
Experience with cloud-native deployment (e.g. Kubernetes)
Good communication skills and teamwork
Passion for building great products
Curiosity and desire to learn
Description
Apple is hiring a senior data platform engineer for Siri's Knowledge team. You'll be working at the frontier of AI, crunching massive amounts of data for Siri's knowledge base. In a fast-paced, continuously-integrated environment, you'll design and implement robust, scalable systems capable of processing an ever-growing data set while keeping latency low and quality high. You'll work closely with knowledge extraction engineers to integrate new data, and with engineers from across Siri to deliver data for customer-facing services. Your responsibilities will also include developing tools and tests to ensure quality and help diagnose issues.
Education & Experience
BS or MS in Computer Science or a related field
Additional Requirements
The following experience is nice to have, but not required: Data modeling Experience working with search engines Machine learning Natural-language processing
",http://www.latpro.com/jobs/3760808.html
JOB9035476503,Data Engineer Operations Decision...,Data Engineer Operations Decision...,,,,https://www.avjobs.com/jobs/positions.asp?q=Data+Engineer+Operations+Decision+Science
JOB9966712750,Sr Data Engineer,Sr Data Engineer,"Work with our clients to model their data landscape, obtain data extracts and define secure data exchange approaches;,Plan and execute secure, good practice data integration strategies and approaches;,Acquire, ingest, and process data from multiple sources and systems into Big Data platforms;,Working across different environments and technologies, learning the nuances of each –Amazon Web Services, SQL, NoSQL, and Big Data / Hadoop platforms,Designing, setting up, and running ETL transformations using tools including Informatica PowerCenter, Data Quality, and Informatica Cloud,Create and manage data environments in the Cloud;,Focus on working with our financial services clients;,Collaborate with our data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models;,Keep up to date with Information Security principles to ensure compliant handling and management of client data;,Involved in end-to-end data management for cutting edge Advanced Analytics and Data Science.,A graduate in a relevant subject;,Management consulting experience leading on client-facing projects, including working in close-knit teams,Experience working on projects within the cloud, preferably with AWS,In-house experience within a large financial institution preferred (on topics such as AML),A proven ability in clearly communicating complex solutions,Strong development background with experience in at least one scripting, object oriented or functional programming language, etc. SQL, Python, Java, Scala, C#, R,Data Warehousing experience, building operational ETL data pipelines across a number of sources, and constructing relational and dimensional data models,Distributed Systems experience,Good experience in at least one Database technology: Traditional RDBMS (MS SQL Server, Oracle, MySQL, PostgreSQL), MPP (AWS Redshift, Oracle Exadata, Teradata, IBM Netezza), Distributed Processing (Spark, Hadoop, EMR), NoSQL (MongoDB, DynamoDB, Cassandra, Vertica, Neo4J, Titan),Experience in at least one ETL tool (e.g. Informatica, SAP BODS),The ability to work across structured, semi-structured, and unstructured data, extracting information and identifying linkages across disparate data sets,Excellent interpersonal skills when interacting with clients, both verbally, email, written, and in a clear, timely, and professional manner.,A deep personal motivation to always produce outstanding work for your clients and colleagues,Excel in team collaboration and working with others from diverse skill-sets and backgrounds",," Senior Data Engineer
London
As part of McKinsey & Company Inc UK, QuantumBlack helps our clients use their own data to drive better decisions. With the combination of business experience, expertise in large-scale data analysis, solid software engineering know-how and advanced visualizations, we help our clients to deliver better results. From aerospace to finance to Formula One, we help our clients prototype, develop, and deploy bespoke data science and data visualisation solutions to make better decisions.
We are seeking a Senior Data Engineer who is passionate about data and the opportunity it provides to organisations. You ‘get’ Big Data and Cloud computing for more advanced data processing and Analytics, and are excited about these technologies. You are equally comfortable talking to senior client stakeholders to understand their data as well as designing the ingestion process to store the data locally and preparing it for Data Analytics. You have experience leading client projects and in handling vast amounts of data – working on database design and development, data integration and ingestion, designing ETL architectures using a variety of ETL tools and techniques. You are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled Data Science team. Previous management consulting experience in financial services is preferred ****
Requirements:
Duties and responsibilities:
Work with our clients to model their data landscape, obtain data extracts and define secure data exchange approaches;
Plan and execute secure, good practice data integration strategies and approaches;
Acquire, ingest, and process data from multiple sources and systems into Big Data platforms;
Working across different environments and technologies, learning the nuances of each –Amazon Web Services, SQL, NoSQL, and Big Data / Hadoop platforms
Designing, setting up, and running ETL transformations using tools including Informatica PowerCenter, Data Quality, and Informatica Cloud
Create and manage data environments in the Cloud;
Focus on working with our financial services clients;
Collaborate with our data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models;
Keep up to date with Information Security principles to ensure compliant handling and management of client data;
Involved in end-to-end data management for cutting edge Advanced Analytics and Data Science.
Requirements:
A graduate in a relevant subject;
Management consulting experience leading on client-facing projects, including working in close-knit teams
Experience working on projects within the cloud, preferably with AWS
In-house experience within a large financial institution preferred (on topics such as AML)
A proven ability in clearly communicating complex solutions
Strong development background with experience in at least one scripting, object oriented or functional programming language, etc. SQL, Python, Java, Scala, C#, R
Data Warehousing experience, building operational ETL data pipelines across a number of sources, and constructing relational and dimensional data models
Distributed Systems experience
Good experience in at least one Database technology: Traditional RDBMS (MS SQL Server, Oracle, MySQL, PostgreSQL), MPP (AWS Redshift, Oracle Exadata, Teradata, IBM Netezza), Distributed Processing (Spark, Hadoop, EMR), NoSQL (MongoDB, DynamoDB, Cassandra, Vertica, Neo4J, Titan)
Experience in at least one ETL tool (e.g. Informatica, SAP BODS)
The ability to work across structured, semi-structured, and unstructured data, extracting information and identifying linkages across disparate data sets
Excellent interpersonal skills when interacting with clients, both verbally, email, written, and in a clear, timely, and professional manner.
A deep personal motivation to always produce outstanding work for your clients and colleagues
Excel in team collaboration and working with others from diverse skill-sets and backgrounds
Please apply online attaching your CV and covering letter within 28 days of the first placement of this advert
Benefits:
£60,000 - £70,000 per annum plus allowances / benefits, subject to circumstances and experience
",https://www.indeed.co.uk/job/Senior-Data-Engineer-at-QuantumBlack-in-London-16d2523aa73276af
JOB10100228265,Data Engineer,Data Engineer,"Completed BSc (Computer Science) degree or similar (Software Engineering, Data Science, etc. with experience in software),Two to five years’ experience in Data Engineering (Hadoop and Spark),Data Processing products - Big Query, Redshift, Spectrum, S3, Athena, Kafka, Spark, Storm, Flink, Beam, Presto, Hive,ETL processes and transformations,Cloud experience ideally with Google Cloud Platform,DevOps Stack development experience,Apache-Airflow or other data pipeline tools,Exposure to Scala or Java in context of data processing,Experience and proficiency with Python,Experience in the design and implementation of data flows,Support sophisticated predictive data products by maintaining data science production environments (cloud-based, python), ensuring that the outputs from Data Science models are available and integrated into the system and integrate, coordinate and maintain data flows between various sources of data,Manage and maintain cloud service integrations that perform key data functions by working towards replacing third-party elements of the data pipeline by using open-source tools,Make decisions around the infrastructure, layout and processes of the data warehouse, including working with the engineering team on how to best track and record data following up on data inconsistencies to ensure that it is corrected",,"A data-centred business is on the lookout for a data engineer to join their team. This is an opportunity to work on cutting edge of tech and cloud computing. They are a fun environment with a quality team that is working with some of the biggest and best datasets in the country.
You will be building world-class, scalable data pipelines and warehouses to add real value to customers and drive new product development, both internally and externally.
Requirements:
Completed BSc (Computer Science) degree or similar (Software Engineering, Data Science, etc. with experience in software)
Two to five years’ experience in Data Engineering (Hadoop and Spark)
Data Processing products - Big Query, Redshift, Spectrum, S3, Athena, Kafka, Spark, Storm, Flink, Beam, Presto, Hive
ETL processes and transformations
Cloud experience ideally with Google Cloud Platform
DevOps Stack development experience
Apache-Airflow or other data pipeline tools
Exposure to Scala or Java in context of data processing
Experience and proficiency with Python
Experience in the design and implementation of data flows
Advanced SQL/PostgreSQL/Redshift knowledge
Responsibilities:
Support sophisticated predictive data products by maintaining data science production environments (cloud-based, python), ensuring that the outputs from Data Science models are available and integrated into the system and integrate, coordinate and maintain data flows between various sources of data
Manage and maintain cloud service integrations that perform key data functions by working towards replacing third-party elements of the data pipeline by using open-source tools
Make decisions around the infrastructure, layout and processes of the data warehouse, including working with the engineering team on how to best track and record data following up on data inconsistencies to ensure that it is corrected
Transforming, standardizing and collecting data from various sources
Reference number for this position is LV46312 which is a permanent position based in Johannesburg North offering a salary of up to R900k per annum highly negotiable on experience and ability. Contact Liza on lizavdb@e-merge.co.za or call her on 011 463 3633 to discuss this and other opportunities.
Are you ready for a change of scenery? The e-Merge IT recruitment is a specialist niche recruitment agency. We offer our candidates options so that we can successfully place the right developers with the right companies in the right roles.
Check out the e-Merge website www.e-merge.co.za for more great positions
Do you have a friend who is a developer or technology specialist? We pay cash for successful referrals!
Posted on 25 Jul 10:02
",https://www.bizcommunity.com/Job/196/706/370709.html
JOB10793884501,Data Engineer,Data Engineer,,"Providing efficient ways for data scientists and other team members to access and manipulate data in a timely manner,You will be involved in the decisions about data storage and data models,Highlighting areas of low data quality and technical debt and opportunities for improvement across data quality, technology and process,Vast experience with a variety of databases (SQL, NoSQL etc),Cloud Platforms (AWS or GCP),Golang,Python,Python Libraries,data","
Data Engineer
Contract
London
£500 max daily
I am pleased to be working with a global industry leader with a well recognisable brand who are based out of central London as they search for a new data engineer to work on a contract basis.
The project is a working with a team on a massive innovation solution to provide an analogue industry with a new digital landscape to improve their performance. The team is centred on holding up the principles of a start-up within a global blue chip company. You will be working with some of the most innovative minds in the business and with partners from a variety of backgrounds.
You will be able to show a track record of building, testing, and productionising data pipelines for data science and engineering teams in an Agile environment.
You will also show a level of curiosity to learn about a new industry and its internal challenges.
Being able to lead and liaise with other data engineers and data scientists in a leadership role will be advantageous.
The likely challenges you will face include:
Providing efficient ways for data scientists and other team members to access and manipulate data in a timely manner
You will be involved in the decisions about data storage and data models
Highlighting areas of low data quality and technical debt and opportunities for improvement across data quality, technology and process
You will take part in regular sprint session including demos where you will present your work
Technical skills required:
They are looking for data engineers with experience in the following techs:
Vast experience with a variety of databases (SQL, NoSQL etc)
Cloud Platforms (AWS or GCP)
Golang
Python
Python Libraries
Jupyter Notebooks
If you are feeling ambitious and want to work on an innovative project as a data engineer for a world leading industry and highly recognisable and distinguished brand, then act now, and contact me on the details below.
Reference: *AMC*CBL*Dataeng*101
Start Date: ASAP
Duration: 6 Months
London
Day Rate: Up to £500
Agency: Anson McCade
Contact: Chris Blaney
Reference: 39689157
Bank or payment details should never be provided when applying for a job. For information on how to stay safe in your job search, visit SAFERjobs.
Report this job
",https://www.reed.co.uk/jobs/data-engineer/39689157
JOB10869662520,Senior Data Engineer,Senior Data Engineer,401K,"Location: NY - New York,Job Type: Full Time,Lead architecture design and implementation of next generation cloud BI solution.,Build robust and scalable data integration (ETL) pipelines using SQL, EMR, Python and Spark.,Build and deliver high quality data architecture to support business analysis, data scientists, and customer reporting needs.,Interface with other technology teams to extract, transform, and load data from a wide variety of data sources,Continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for business constituents.,Support, maintain, optimize, upgrade, enhance our current and future state Data Infrastructure (SQL server, AWS, Snowflake, Tableau, Alteryx).,Bachelors Degree in related field,Demonstrated strength in data modeling, ETL development, and Data warehousing,4-6 years of data engineering experience,Experience in working and delivering end-to-end projects independently,Experience with AWS services including S3, Redshift, EMR, Kinesis and RDS preferred,Experience with cloud Data Warehouses such as Snowflake are a plus,Experience with Big Data Technologies (Hadoop, Hive, Hbase, Pig, Spark, etc.),Medical, Dental, and Vision Insurance,Transit Discount Program,401K Plan,Paid Time Off Program,Flexible Spending Accounts,Employee Dining Program,Referral Bonus,Online Training Program,Career Development,Corporate Fitness Discount Programs,Choice of Global Cash Card or Direct Deposit","
Location: NY - New York
Job Type: Full Time
Work it! Here at Shake Shack, we take care of each other first and foremost so that we can make raves for our guests, community, suppliers, and investors. After all, teamwork makes the dream work. We work our buns off, but we play hard too, with a Team Appreciation Day, unlimited meal discounts, volunteer opportunities, and so much more. If you’re looking for a deeply fulfilling, financially rewarding, and really fun career, you’re in the right place.
Sr Data Engineer
The Sr Data Engineer should be an expert with all of the data warehousing technical components (e.g. ETL, Reporting, Data Model), infrastructure (e.g. hardware and software) and their integration. The ideal candidate will be responsible for developing overall architecture and high level design.
Key Responsibilities
Lead architecture design and implementation of next generation cloud BI solution.
Build robust and scalable data integration (ETL) pipelines using SQL, EMR, Python and Spark.
Build and deliver high quality data architecture to support business analysis, data scientists, and customer reporting needs.
Interface with other technology teams to extract, transform, and load data from a wide variety of data sources
Continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for business constituents.
Support, maintain, optimize, upgrade, enhance our current and future state Data Infrastructure (SQL server, AWS, Snowflake, Tableau, Alteryx).
Skills & Knowledge
Bachelors Degree in related field
Demonstrated strength in data modeling, ETL development, and Data warehousing
Experience
4-6 years of data engineering experience
Experience in working and delivering end-to-end projects independently
Experience with AWS services including S3, Redshift, EMR, Kinesis and RDS preferred
Experience with cloud Data Warehouses such as Snowflake are a plus
Experience with Big Data Technologies (Hadoop, Hive, Hbase, Pig, Spark, etc.)
Benefits include:
Medical, Dental, and Vision Insurance
Transit Discount Program
401K Plan
Paid Time Off Program
Flexible Spending Accounts
Employee Dining Program
Referral Bonus
Online Training Program
Career Development
Corporate Fitness Discount Programs
Choice of Global Cash Card or Direct Deposit
About Us
Beginning as a hot dog cart in New York City’s Madison Square Park, Shake Shack was created by Danny Meyer, Founder and CEO of Union Square Hospitality Group and best-selling author of Setting the Table. Shack Fans lined up daily, making the cart a resounding success, and donating all proceeds back to the park beautification efforts. A permanent stand was eventually built…and the rest is Shack history! With our roots in fine dining and giving back to the community, we are committed to high quality food served with a high level of hospitality. Our team members enjoy a positive work environment that is deeply committed to the philosophy they we ""Stand for Something Good.""
Shake Shack is an Equal Opportunity Employer
All qualified applicants will receive consideration for employment without regard to race, color, ancestry, national origin, religion, creed, age (over 40), disability (mental and physical), sex, gender identity, sexual orientation, gender expression, medical condition, genetic information, marital, military and veteran status.
Our company will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of applicable laws.
",https://www.shakeshack.com/job/senior-data-engineer-333199/
JOB14796263596,Senior Data Engineer,Senior Data Engineer,,,,"https://www.computerworld.dk/modules/job/morerandomjobs.php?op=list&start=3&limit=3&jobidsused=677293,703180,704554&layout=cwglassbox"
JOB15504005964,Data Engineer,Data Engineer,,,"
Data Engineer X 2 – Manchester. Our client based near Manchester are currently looking for 2 Data Engineers with Azure experience. The company is currently going through a large digital transformation, they are looking for talented Data specialist to help...
Job Title: Data Engineer Salary: 45,000 to 54,000 plus Benefits Location: Cambridge This is a very rare opportunity for an experienced Data Engineer with a strong background in building Python based data processing pipelines to join a company that are...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
As a data engineer within the exciting, new claims advanced analytics capability, you will be building big data solutions to solve some of the organization’s toughest problems and delivering significant business value. This is a really exciting time to...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Title: Data Engineer Our client is currently looking for a Data Engineer to play a vital role in the continual development of our digital transformation strategy and earth science analytics. Candidates must have Python, R and SQL. We expect candidates...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer - Manchester A growing business based in Manchester City Centre are currently looking for a Data Engineer to help shape their newly formed Data Engineering team and build scalable, reliable and secure cloud datawarehouse solutions and data...
Data Engineer - Python - Permanent Data Idols are working with a well-known client in the e-commerce space who are looking for a Data Engineer to join an existing team. THE ROLE As a Data Engineer, you will be working with the existing Data team to help...
An exciting start up Fintech company has a new opportunity for a Data Engineer where you will play an active part in the success of the company. This role will see you joining a small team where you'll have the opportunity to take responsibility for Data...
Data Engineer Location: Petersfield Salary: 30,000 - 40,000 P/A Hours: Flexible Dynamite Recruitment is delighted to be recruiting a Data Engineer for a global organisation in Petersfield This is an exciting opportunity for an experienced individual to...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer- 50K Manchester Adria Solutions has an exciting opportunity for a talented Data Engineer to join our rapidly expanding client based near Manchester. The role requires you to work closely with other members of the data team and stakeholders...
Data Engineer (12-month Fixed Term Contract) 50,000 - 55,000 We are looking for a Data Engineer to join a market leading business we're representing, based in central London. Working as part of the central Data Science & Analytics team, you will be...
DATA ENGINEER - CURRENTLY REMOTE WORKING LEEDS - CURRENTLY REMOTE WORKING BETWEEN 35,000 - 50,000 BENEFITS BONUS Harnham are partnered with a Financial Services Company to help hire for a Data Engineer within their Business Intelligence team. The team...
DATA ENGINEER - CURRENTLY REMOTE WORKING LEEDS - CURRENTLY REMOTE WORKING BETWEEN 35,000 - 50,000 BENEFITS BONUS Harnham are partnered with a Financial Services Company to help hire for a Data Engineer within their Business Intelligence team. The team...
Data Engineer London 55,000 - 65,000 Benefits Our client, an exciting RegTech business is looking to recruit for a Data Engineer to join their growing team. The successful candidate will be joining the artificial intelligence team, working on a brand new...
Data Engineer - Azure - Data Warehousing - Staffordshire - 50k Hiring remotely Greenfield project Home working I am working with an organisation in Staffordshire who are seeking a Data Engineer to join their growing Data & Analytics team. Data &...
",https://www.reed.co.uk/jobs/data-engineer/40396917
JOB16391347165,Senior Data Engineer for Barstool Sportsbook,Senior Data Engineer for Barstool Sportsbook,,"Design, develop and deploy a big data stack and data processing infrastructure platform,Architect and rearchitect multi-tenant databases to meet the needs of our customer base,Improve data validation and data quality monitoring,Work with client and backend teams to guide events driven designs,Optimize and tune the databases to improve performance and reduce cost,4+ years of experience building large scale, robust data processing pipeline,2+ years of experience coding in Python,Background in API development, with a focus data transformations and data streams,Strong background with building and maintaining automation,Advanced experience with data streaming, ingest, ETL and data warehousing technologies,Strong experience in database schema design, data governance and data modeling,Experience with Spark, Beam, Redshift, Tableau, MySQL, etc.,Experience with AWS, GCP, and/or Azure cloud,Good understanding of data security and encryption,Experience with tools like Airflow, Dagster or DBT","Penn Interactive (PI) is a real-money interactive gaming company headquartered in Philadelphia. As the digital arm to Penn National Gaming (NASDAQ: PENN), the largest regional casino operator in the U.S., we are poised for fast-paced growth in the sports betting and online casino space and are looking for a Sr Data Engineer to join our expanding Sportsbook team!
The Senior Data Engineer works closely with the Director of Engineering in a small, cross-functional team to develop a one-of-a-kind, native sports betting experience. Successful candidates for this role will leverage data from the largest casino chain in the United States to assist in tasks such as affinity, personalization, bonusing, promotions, etc. Previous work in the gaming industry is not important but we do expect you to take the lead in developing a data warehouse and pipeline to enable novel and rewarding data discoveries.
RESPONSIBILITIES:
Design, develop and deploy a big data stack and data processing infrastructure platform
Architect and rearchitect multi-tenant databases to meet the needs of our customer base
Improve data validation and data quality monitoring
Work with client and backend teams to guide events driven designs
Optimize and tune the databases to improve performance and reduce cost
Write and maintain terraform to enable data engineering and science teams to safely deploy tools and services
QUALIFICATION REQUIREMENTS
4+ years of experience building large scale, robust data processing pipeline
2+ years of experience coding in Python
Background in API development, with a focus data transformations and data streams
Strong background with building and maintaining automation
Advanced experience with data streaming, ingest, ETL and data warehousing technologies
Strong experience in database schema design, data governance and data modeling
Experience with Spark, Beam, Redshift, Tableau, MySQL, etc.
Experience with AWS, GCP, and/or Azure cloud
Good understanding of data security and encryption
Ability to work effectively as part of a small team, with strong interpersonal and communication skills
BONUS POINTS
Experience with tools like Airflow, Dagster or DBT
A passion for sports or betting
Penn Interactive is committed to helping our team members live their best, healthy life. We offer unique and competitive benefits that help our employees, through a private exchange which allows our team members the ability to choose from several coverage levels and insurance carriers (both local and national carriers). Along with medical, prescription, dental, and vision coverage, there are also voluntary plans available
Apply Now
",https://technical.ly/job/penn-interactive-senior-data-engineer-for-barstool-sportsbook-66311/
JOB16815978383,Senior Data Engineer,Senior Data Engineer,"5+ years of hands-on experience in business intelligence or IT management role in corporate or consulting setting,Strong development background with experience in at least two scripting, object oriented or functional programming languages: SQL, Python, Java, Scala, C#, R,Client stakeholder engagement and management,Experience leading a work stream and managing small teams on Agile projects,Data Warehousing experience, building operational ETL / ELT pipelines comprised of several sources, and architecting Data Models/Layers for Analytics,Ability to work across structured, semi-structured, and unstructured data, extracting information and identifying linkages across disparate data sets,Experience in multiple Database technologies: Traditional RDBMS (MS SQL Server, Oracle, MySQL, PostgreSQL), MPP (AWS Redshift, Oracle Exadata, Teradata, IBM Netezza), Distributed Processing (Spark, Hadoop, EMR), NoSQL (MongoDB, DynamoDB, Cassandra, Vertica, Neo4J, Titan),Experience developing solutions in Cloud platforms: Amazon Web Services, Microsoft Azure, Google Cloud Platform,Experience generating Insights in the form of reports, KPIs, dashboards or ad-hoc queries; experience with Tableau is a bonus,Ability to thrive in a lively project and consulting setting, often working on different and multiple projects at the same time,Excellent interpersonal skills when interacting with clients, both verbally, email, written, and in a clear, timely, and professional manner,Problem solving and brainstorming solutions to data integration and Analytics challenges,Passion for developing your knowledge and skills in both the technical aspects of the Data Technology industry, and your personal and professional development in work and life",," Qualifications
5+ years of hands-on experience in business intelligence or IT management role in corporate or consulting setting
Strong development background with experience in at least two scripting, object oriented or functional programming languages: SQL, Python, Java, Scala, C#, R
Client stakeholder engagement and management
Experience leading a work stream and managing small teams on Agile projects
Data Warehousing experience, building operational ETL / ELT pipelines comprised of several sources, and architecting Data Models/Layers for Analytics
Ability to work across structured, semi-structured, and unstructured data, extracting information and identifying linkages across disparate data sets
Experience in multiple Database technologies: Traditional RDBMS (MS SQL Server, Oracle, MySQL, PostgreSQL), MPP (AWS Redshift, Oracle Exadata, Teradata, IBM Netezza), Distributed Processing (Spark, Hadoop, EMR), NoSQL (MongoDB, DynamoDB, Cassandra, Vertica, Neo4J, Titan)
Experience developing solutions in Cloud platforms: Amazon Web Services, Microsoft Azure, Google Cloud Platform
Experience generating Insights in the form of reports, KPIs, dashboards or ad-hoc queries; experience with Tableau is a bonus
Ability to thrive in a lively project and consulting setting, often working on different and multiple projects at the same time
Excellent interpersonal skills when interacting with clients, both verbally, email, written, and in a clear, timely, and professional manner
Problem solving and brainstorming solutions to data integration and Analytics challenges
Passion for developing your knowledge and skills in both the technical aspects of the Data Technology industry, and your personal and professional development in work and life
Who You'll Work With You will work in the London Headquarters of QuantumBlack. QuantumBlack help organisations make the most of data, analytics, and visualization to improve asset, operations, and human performance and productivity. You will join over 130 colleagues in London working in a variety of industries at the highest level within global enterprises, alongside McKinsey Analytics with over 800 advanced analytics practitioners. You will be working in cross-functional teams with other members of the Client Services, Engineering, Data Science, and Design teams.
What You'll Do You will help our clients make the most of data, analytics, and visualization to improve asset, operations, and human performance and productivity.
You will architect and create data solutions across multiple technologies (RDBMS, Spark, Hadoop, NoSQL etc.) using a variety of languages (SQL, Python, R, Scala). We will provide comprehensive training to support you working with these technologies / languages. You will work on data analytics and visualisation consulting projects on complex and strategic business problems for large global enterprises.
You will be responsible for acting as the point of contact for our client’s data owners and their domain experts, understanding their data systems and creating an inventory of their data ecosystem. You will model and map client data systems into a templated diagram and define and build data architectures.
You will support data scientists by creating views, queries, data extracts, variables, and features to help their analysis and maintain Information Security (IS) standards in regards to data exchange, storage, and processing. You will develop data exchange and ingestion plans with client IT/Data/IS stakeholders and create cloud and data environments for new projects using a mixture of Amazon Web Services, RDBMS, NoSQL, and Big Data / Hadoop platforms. We will support and help develop you in any of these technologies.
You will also architect and develop operational ETL solutions (using tools like Informatica, Alteryx, Dataiku etc), create Data Quality assessments and produce presentation-ready reports on client data systems, in addition to creating reusable custom scripts, queries, and code commands for ad hoc data processing tasks. You will learn and employ data visualization tools and basic Data Science techniques to analyse data and generate Insights whilst managing and developing Analyst Data Engineers on engagements.
Other jobs you may like
",http://www.indeed.co.uk/job/Senior-Data-Engineer-at-McKinsey-&-Company-in-London-4e131f796bbe328e
JOB17296546681,Data Engineer Jobs,Data Engineer Jobs,,," Sorry, the job you're looking for is no longer being advertised. However, you can still search for similar jobs.
From: Up to £10,000
To:
We are looking for a Data Engineer to join our Clear Review business as we analyse, explore and improve how over 100,000 employees across over 200 companies perform and feel about work. Clear Review is our UK's leading Continuous Performance Management...
See more: Engineer jobs
The data engineer will be responsible for the successful delivery of a variety of software and technology solutions projects. The pace of innovation within RSM is increasing all the time and this has created the need for additional skills within the firm...
See more: Engineer jobs
GCP DATA ENGINEER 400- 500 PER DAY 3 MONTH CONTRACT LONDON BASED As a Data Engineer you will be working heavily with Python/Spark on a GCP platform, creating an automated process to push data into Google Audiences. THE COMPANY: You will be working for...
See more: Engineer jobs
DATA ENGINEER 400- 500 PER DAY 3 MONTH CONTRACT LONDON BASED As a Data Engineer you will be working heavily with Python/Spark on a GCP platform, creating an automated process to push data into Google Audiences. THE COMPANY: You will be working for a start...
See more: Engineer jobs
Are you a passionate and technically rounded Data Engineer, looking for an organisation that will invest in you and pushes you to be the best you can be? Do you want to learn from & work alongside some of the most talented, supportive Data Engineers...
See more: Engineer jobs
DATA ENGINEER LONDON - CURRENTLY FLEXIBLE/REMOTE WORKING UP TO 85K BENEFITS BONUS This is a really exciting position for an experienced senior data engineer to join a rapidly growing start - up founded by leading data experts. They are looking to grow...
See more: Engineer jobs
DATA ENGINEER 400- 500 PER DAY 3 MONTH CONTRACT FULLY REMOTE As a Data Engineer you will have the chance to work for a health care consultancy in analysing local data sets using Python, SQL and Airflow. THE COMPANY: As a Data Engineer, you will be working...
See more: Engineer jobs
DATA ENGINEER 400- 500 PER DAY 3 MONTH CONTRACT LONDON BASED As a Data Engineer you will be working heavily with Python/Spark create APIS on an AWS platform which is connected to Databricks. THE COMPANY: You will be working for a start up within the AI...
See more: Engineer jobs
DATA ENGINEER 70,000 - 85,000 10% BONUS LONDON THE COMPANY: This is a world-renowned insurance business with a range of departments. They've recently been through a transformation to use data more in the business and are looking to bring on a Data Engineer...
See more: Engineer jobs
We are looking for a talented Data Engineer to join our team in Stockport, however due to the pandemic this role will initially start fully remote with a view to return to our offices. You will join us on a full time, permanent basis and in return, you...
See more: Engineer jobs
Senior Data Engineer London Our client is one of the most widely renowned names in British Cyber Security. They are searching for a number of highly skilled Data Engineers with for a role based in their London location with a government client. The role:...
See more: Engineer jobs
DATA ENGINEER LONDON (REMOTE WORKING) UP TO 85,000 Harnham are partnered with an international television network that produces its own unique content. They are looking for a data engineer to join their subscription service and work in tandem with BI and...
See more: Engineer jobs
Data Engineer | Python | SQL | GCP | London | Up to 65,000 Are you an experienced Data Engineer with a real passion for what data can do for a business? Do you enjoy working in a constantly evolving environment where no two days are the same? Method Resourcing...
See more: Engineer jobs
Senior Business Intelligence Engineer - London - 50k- 70k Our client is a prestigious not for profit organisation, providing support to thousands of members across the UK. They are seeking a talented and ambitious BI Data Engineer who has a strong technical...
See more: Engineer jobs
DATA ENGINEER LONDON (REMOTE WORKING) UP TO 75,000 Harnham are partnered with a home furnishing retailer, that has superstores placed all over the UK. They are looking for a data engineer to join their expanding and newly successful team to design and...
See more: Engineer jobs
Data Engineer Our client is a well-established international insurance company, and they are looking for 2 Data Engineers to support the Data & MI team. This is a business facing role within Actuarial & Analytics so excellent communication skills...
See more: Engineer jobs
We're supporting our clients as they adapt to a new world in the wake of COVID-19. We're now recruiting for roles which will help our clients to deliver vital services and to resume business wherever possible. What you'll be doing : Excellent communicational...
See more: Engineer jobs
We're supporting our clients as they adapt to a new world in the wake of COVID-19. We're now recruiting for roles which will help our clients to deliver vital services and to resume business wherever possible. What you'll be doing : Excellent communicational...
See more: Engineer jobs
Data Engineer - 4 week rolling contract - On-site in London/Remote Data Analysis, Data Analytics, Data Modelling, Data Warehouse, Python, ETL, PostgreSQL Data Engineer Up to 450 per day London/Remote Working Immediate start - 4 week rolling contract A...
See more: Engineer jobs
Title: Data Engineer Our client is currently looking for a Data Engineer to play a vital role in the continual development of our digital transformation strategy and earth science analytics. Candidates must have Python, R and SQL. We expect candidates...
See more: Engineer jobs
Data Engineer- South Manchester ""Our Client will be interviewing and onboarding remotely during COVID-19"" Adria Solutions has an exciting opportunity for a talented Data Engineer to join our reputable client based near Manchester. As a Data Engineer you...
See more: Engineer jobs
Are you a Data Engineer who wants to learn, work, and develop with some of the best people in Lisbon? Does collaborate with Machine Learning teams, Data Science teams and Software Engineering teams sound like a good environment to work within as a Data...
See more: Engineer jobs
Data Engineer Copenhagen, Denmark 6 Month Contract 900 DKK Per Hour As a Data Engineer you will be creating and maintaining data pipeline architecture for a leading European home-wares retailer. THE COMPANY: The client is a leading European Home-wares...
See more: Engineer jobs
A London based financial consultancy is on the lookout for a Mid to Senior Level Scala Data Engineer to join their team. The Company The forward thinking and innovative firm is a fast growing financial consultancy working solely within the Financial Services...
See more: Engineer jobs
DATA ENGINEER - REMOTE WORKING 35,000 - 45,000 REMOTE (OFFICE IN LONDON) THE COMPANY: The company are a private equity firm with investments in the fintech, online marketing, insurance and online gaming spaces. They are looking for an experienced ETL developer...
See more: Engineer jobs
Data Engineer is currently required for a 3 month project with a cutting edge start up based in central London. The client are looking for a Data Engineer to help develop out the data platform. The Data Engineer will be joining existing team of Product...
See more: Engineer jobs
Data Engineer | 55,000 - 75,000 AWS | Python| SQL | ETL | Data Pipelines | Glue If you'd like to take your career to the next step then an awesome opportunity to build an environment from the ground up has just become available with an organisation that...
See more: Engineer jobs
",https://www.reed.co.uk/jobs/azure-data-engineer-contract/39766889?source=searchResults
JOB17544056148,Principal Data Engineer,Principal Data Engineer,50+ career categories,"Hand-screened leads,No ads, scams, junk,Great job search support","
Principal Data Engineer
Seeking a data engineer to design a data pipeline, improve data processes, and mentor junior engineers. Need to have at least eight yrs' exp. in a similar role. This is a work-from-home opportunity with benefits.
Job Details
100% Remote
Employee
Full-Time
Experienced
Bachelor's Degree
No specification
Health Insurance, Retirement Planning, Maternity Leave
Company name here
Other benefits listed here
Hand-screened leads
No ads, scams, junk
Great job search support
50+ career categories
Create an Account to Unlock
To find out more about or apply to this Principal Data Engineer job—and other great opportunities like it—become a FlexJobs member today!
With FlexJobs, you'll find the best flexible jobs and fantastic expert resources to support you in your job search. If you have any questions, please feel free to contact us.
",https://www.flexjobs.com/publicjobs/principal-data-engineer-1309951
JOB18751789950,Data Engineer,Data Engineer,,,"
Data Engineer - up to £75k
London
My client is looking for passionate Data Engineers to help build, maintain and support a new cloud based big data platform as part of a large investment plan across data. They are a global company who put lots of investment into training and supporting their staff. This position is for an experienced cloud based Engineers who are looking to join a dedicated team while being exposed to new technologies and existing tools.
Requirements:
- Strong knowledge of AWS
- Hadoop
- Big Data
- Experience of CI/CD
- Jenkins/Bamboo/AWS Code Pipeline/AWS Code Commit
- Ansible, Puppet/Chef
- GIT
-Python
Responsibilities:
* Ensure that data solutions are complimentary and not duplicative.
* Build and maintain high-performance, fault-tolerant, secure and scalable data platform to support multiple data solutions use cases.
* Interface with other technology teams to design and implement robust products, services and capabilities for the data platform making use infrastructure as code and automation.
* Build and support platforms to enable our data engineers and data scientists to build our cloud based big data platform.
* Create patterns, common ways of working, and standardised guidelines to ensure consistency across the organisation.
Benefits:
* Life insurance
* Great Pension scheme
* Insurance discounts
* Cycle to work scheme
If this opportunity interests you, and you believe that you've got what it takes to be a successful candidate, I would be more than happy to arrange a conversation with you to discuss this further.
Reference: 39707048
Bank or payment details should never be provided when applying for a job. For information on how to stay safe in your job search, visit SAFERjobs.
Report this job
",https://www.reed.co.uk/jobs/data-engineer/39707048
JOB18969988425,Senior Data Engineer,Senior Data Engineer,50+ career categories,"Hand-screened leads,No ads, scams, junk,Great job search support","
Senior Data Engineer
A senior data engineer is needed for a full-time, work-from-home position. Will build data pipelines, create API's, and guide junior data engineers. Bachelor's degree and three-plus yrs' exp. in data engineering required.
Job Details
10/16/20
Option for Remote
Employee
Full-Time
Experienced
Bachelor's Degree
No specification
Company name here
Other benefits listed here
Hand-screened leads
No ads, scams, junk
Great job search support
50+ career categories
Create an Account to Unlock
To find out more about or apply to this Senior Data Engineer job—and other great opportunities like it—become a FlexJobs member today!
With FlexJobs, you'll find the best flexible jobs and fantastic expert resources to support you in your job search. If you have any questions, please feel free to contact us.
",https://www.flexjobs.com/publicjobs/senior-data-engineer-1309581
JOB21402708488,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-it/details/200188037/ai-ml-search-data-engineer-siri-data
JOB23062758339,SAP Sybase IQ Data Engineer,SAP Sybase IQ Data Engineer,,"Several years' experience working in SAP Data Services/Sybase IQ with at least two BI projects.,Experience designing ETL solutions,The ability to liaise with the business to gather requirements and create technical documentation.,Experience in data warehouse design and build.","
SAP Data Services * ETL * Data Engineer * SQL * Sybase IQ * Data Warehousing * Business Objects * Data Warehousing * Data Management
SAP Sybase IQ Data Engineer
Leeds
£48,000 - £52,000
This is an excellent role for an experienced SAP Sybase IQ Data Engineer developer to join an excellent Business Intelligence and Data Engineering team who are undertaking a Greenfield Data Warehousing project using agile methodology.
You will work on a range of end to end projects across ETL design, data warehousing, SAP IQ and Datawarehousing
This an excellent role for someone looking for career progression and to develop new techniques and skills. There will be two interviews, the first a telephone screen and the second will be in the head office.
As the Data Engineer you should have:
Several years' experience working in SAP Data Services/Sybase IQ with at least two BI projects.
Experience designing ETL solutions
The ability to liaise with the business to gather requirements and create technical documentation.
Experience in data warehouse design and build.
Excellent communication skills and the capability to interact with business stakeholders at a variety of levels.
",https://www.careerjet.co.uk/clk/de165c7355ffb72fc2d240c33a2656b6.html
JOB25330342753,Data Engineer,Data Engineer,,,"
Data Engineer X 2 – Manchester. Our client based near Manchester are currently looking for 2 Data Engineers with Azure experience. The company is currently going through a large digital transformation, they are looking for talented Data specialist to help...
Job Title: Data Engineer Salary: 45,000 to 54,000 plus Benefits Location: Cambridge This is a very rare opportunity for an experienced Data Engineer with a strong background in building Python based data processing pipelines to join a company that are...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
As a data engineer within the exciting, new claims advanced analytics capability, you will be building big data solutions to solve some of the organization’s toughest problems and delivering significant business value. This is a really exciting time to...
Data Engineer - 70,000 Job Description An AWS Partner based in Central London is looking to expand the data side of their business due to growth. They are looking for Data Engineers with significant commercial experience ingesting large quantities of data...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Title: Data Engineer Our client is currently looking for a Data Engineer to play a vital role in the continual development of our digital transformation strategy and earth science analytics. Candidates must have Python, R and SQL. We expect candidates...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer - Manchester A growing business based in Manchester City Centre are currently looking for a Data Engineer to help shape their newly formed Data Engineering team and build scalable, reliable and secure cloud datawarehouse solutions and data...
Data Engineer - Python - Permanent Data Idols are working with a well-known client in the e-commerce space who are looking for a Data Engineer to join an existing team. THE ROLE As a Data Engineer, you will be working with the existing Data team to help...
An exciting start up Fintech company has a new opportunity for a Data Engineer where you will play an active part in the success of the company. This role will see you joining a small team where you'll have the opportunity to take responsibility for Data...
Data Engineer Location: Petersfield Salary: 30,000 - 40,000 P/A Hours: Flexible Dynamite Recruitment is delighted to be recruiting a Data Engineer for a global organisation in Petersfield This is an exciting opportunity for an experienced individual to...
Job title : Data Engineer Location: London Job type: Permanent Salary: Up to 70,000 per annum Reporting to: Head of Data Engineering Overview A fantastic internet company based in Central London are currently looking for a Data Engineer to come on board...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer- 50K Manchester Adria Solutions has an exciting opportunity for a talented Data Engineer to join our rapidly expanding client based near Manchester. The role requires you to work closely with other members of the data team and stakeholders...
Data Engineer / Data Scientist / Biomedical Informatics / Human Genetics / Python / SQL / R / Oxford / Cambridge / Permanent 60 - 90K (Depending on Experience) Excellent Benefits COVID Safe Interview Process 100% Remote during Covid and up to 50% Post...
Data Engineer London 80,000 - 90,000 Benefits This Data Engineering role will allow you to expand and utilise your skills in a growing team working along side one of the largest data sets in the UK. The Company As a global leader they generate tons of...
Data Engineer (12-month Fixed Term Contract) 50,000 - 55,000 We are looking for a Data Engineer to join a market leading business we're representing, based in central London. Working as part of the central Data Science & Analytics team, you will be...
",https://www.reed.co.uk/jobs/data-engineer/40333447
JOB25601661775,Data Engineer Jobs in Plymouth,Data Engineer Jobs in Plymouth,,,"
Summary This role sits within an agile multi-disciplinary software team. The team carries out full project management, design, development, quality assurance, release management, deployment and operational support of the software solutions we build. This...
See more Engineer jobs in Plymouth ",https://www.reed.co.uk/jobs/data-engineer-jobs-in-plymouth
JOB27439848280,Data Engineer Jobs,Data Engineer Jobs,,,"
DESCRIPTION At Amazon Advertising, we are dedicated to drive measurable outcomes for brand advertisers, agencies, authors, and entrepreneurs. Our ad solutions—including sponsored, display, video, and custom ads—leverage Amazon’s innovations and insights...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
As the Data Engineer for this amazing corporate Insurance company, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL, together...
See more: Engineer jobs
Job Title: Data Engineer Salary: 45,000 to 54,000 plus Benefits Location: Cambridge This is a very rare opportunity for an experienced Data Engineer with a strong background in building Python based data processing pipelines to join a company that are...
See more: Engineer jobs
As the Data Engineer for this amazing corporate Insurance company in the City, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL...
See more: Engineer jobs
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
See more: Engineer jobs
As a data engineer within the exciting, new claims advanced analytics capability, you will be building big data solutions to solve some of the organization’s toughest problems and delivering significant business value. This is a really exciting time to...
See more: Engineer jobs
Data Engineer - 70,000 Job Description An AWS Partner based in Central London is looking to expand the data side of their business due to growth. They are looking for Data Engineers with significant commercial experience ingesting large quantities of data...
See more: Engineer jobs
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
See more: Engineer jobs
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
See more: Engineer jobs
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
Data Engineer - Python - Permanent Data Idols are working with a well-known client in the e-commerce space who are looking for a Data Engineer to join an existing team. THE ROLE As a Data Engineer, you will be working with the existing Data team to help...
See more: Engineer jobs
DATA ENGINEER - TEMPORARILY REMOTE 400- 450 PER DAY 3 MONTH CONTRACT EUROPE BASED As a Data Engineer you will be working heavily with Scala and Spark to improve the quality of data. THE COMPANY: You will be working for dynamic data driven company. As a...
See more: Engineer jobs
Job title : Data Engineer Location: London Job type: Permanent Salary: Up to 70,000 per annum Reporting to: Head of Data Engineering Overview A fantastic internet company based in Central London are currently looking for a Data Engineer to come on board...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
Data Engineer- 50K Manchester Adria Solutions has an exciting opportunity for a talented Data Engineer to join our rapidly expanding client based near Manchester. The role requires you to work closely with other members of the data team and stakeholders...
See more: Engineer jobs
Job title: Data Engineer Location : Zurich. Switzerland Job type : Contract Data Engineer with Hadoop/Apache Sparc Knowledge - - Build a data processing layer based on Hadoop,Spark, Neo4J - Ensure appropriate security processes are integrated with access...
See more: Engineer jobs
Data Engineer- 50K Manchester Adria Solutions has an exciting opportunity for a talented Data Engineer to join our rapidly expanding client based near Manchester. The role requires you to work closely with other members of the data team and stakeholders...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
Data Engineer Location: Petersfield Salary: 30,000 - 40,000 P/A Hours: Flexible Dynamite Recruitment is delighted to be recruiting a Data Engineer for a global organisation in Petersfield This is an exciting opportunity for an experienced individual to...
See more: Engineer jobs
Data Engineer We have had a role come available for a Data Engineer in London. The role will require you to either hold a DV Clearance. Key Experience: Data Analysis experience; Strong SQL skills; Data Processing using ETL tools; Understanding of procurement...
See more: Engineer jobs
",http://www.reed.co.uk/jobs/data-engineer/40062124
JOB27769848643,Senior Data Engineer,Senior Data Engineer,,,"
KnowBe4, Inc. is a high growth information security company. We are the world's largest provider of new-school security awareness training and simulated phishing. KnowBe4 was created to help organizations manage the ongoing problem of social engineering. Tens of thousands of organizations worldwide use KnowBe4's platform to mobilize their end users as a last line of defense and enable them to make better security decisions, every day.
We are ranked #1 best place to work in technology nationwide by Fortune Magazine and have placed #1 or #2 in The Tampa Bay Top Workplaces Survey for the last four years. We also just had our 26th record-setting quarter in a row!
The Senior Data Engineer is responsible for developing, managing and optimizing our data pipelines, architecture, and datasets using Amazon Web Services. He or she will work alongside the developers, data analysts and data scientists to support the organization's data initiatives by evaluating, reviewing, implementing, and building the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
Responsibilities:
* Design and develop data pipelines and ETL processes to connect with various data sources
* Collaborate with Data Architects, Business SMEs, and Data Scientists to design, develop end-to-end data pipeline to meet fast paced organization needs across geographic regions
* Support application programming interfaces (APIs), tools, and third-party products to extract data from SaaS applications
* Extract data from various systems such as Salesforce.com, NetSuite, and our own products to create data models
* Design and maintain enterprise data warehouse models
* Deploy updates and fixes and provide technical support as requested
* Implement standardized, automated operational and quality control processes to deliver accurate and timely data and reporting to meet or exceed SLAs.
* Ensure current and future architecture meets stakeholder needs
* Build and manage large scale data systems and ingestion capabilities and infrastructure
* Research, recommend, and implement methods to ensure data integrity and quality
Minimum Qualifications:
* Bachelor's degree in Computer Science, Engineering or relevant field required
* A minimum of 4 years of proven work experience as a data engineer
* 2+ years of Amazon Web Services (AWS) data related services required
* Strong scripting skills: Python, PySpark
* Strong understanding of data structures and writing complex data analysis queries
* Strong understanding of non-relational data structures and concepts related to BI
* Proven track record of shipping large, complex, data products
Note: An applicant assessment, background check and drug test may be part of your hiring procedure.
No recruitment agencies, please.
","https://www.ziprecruiter.com/c/KnowBe4/Job/Senior-Data-Engineer/-in-Clearwater,FL?ojob=9591d20f21ea153a1f55c12763c09ad5"
JOB28052154931,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-hu/details/200188037/ai-ml-search-data-engineer-siri-data
JOB29475429338,Salesforce Data Engineer,Salesforce Data Engineer,,,"Play a key role within our Philadelphia based engineering team where you will contribute to the design and build of foundational capability across Macquarie Asset Management. As a Salesforce Integration Engineer, you will work alongside a diverse multi-talented team in a fast-paced agile environment.
You will be shaping the technology architecture for a new global Salesforce instance and working collaboratively with various teams across the broader group.
Bringing your Technology expertise, you will be shaping the technology architecture for a new global Salesforce instance and working collaboratively with various teams across the broader group. You core responsibilities will include the uplift of a new global Salesforce instance ensuring compliance to internal and external policies and standards, support feature team development and provide innovative solutions to business needs.
Using your hands-on programming experience in Salesforce, you will be able to contribute to on-going development. You are meticulous, thorough and possess excellent communication skills that allow you to engage through collaboration with stakeholders of all levels.
Your drive to deliver will be required as you provide hands on Salesforce development including APEX, Batch, Integration and Lightning frameworks, developing, maintaining and continuously improving DevOps methods and practices as well providing guidance on quality engineering which includes test class and automation frameworks.
If you have development experience in a large organisation within a complex technology landscape, that includes Salesforce experience with strong understanding of Salesforce data model and data architecture principles this is a fantastic opportunity!
About the Corporate Operations Group
The Corporate Operations Group brings together specialist support services in Digital Transformation & Data, Technology, Market Operations, Human Resources, Business Services, Business Improvement & Strategy, and the Macquarie Group Foundation. The Corporate Operations Group’s purpose is to power the entrepreneurial enterprise.
Our commitment to Diversity and Inclusion
All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, colour, religion, sex, sexual orientation, national origin, age, disability, protected veteran status, genetic information, marital status, gender identity or any other impermissible criterion or circumstance. Macquarie also takes affirmative action in support of its policy to hire and advance in employment of individuals who are minorities, women, protected veterans, and individuals with disabilities.
We recognise that flexibility comes in a variety of forms. Talk to us about what flexibility you need.
Apply Now
",https://technical.ly/job/macquarie-salesforce-data-engineer-66431/
JOB32278829923,Data Engineer,Data Engineer,,,"
Data Engineer X 2 – Manchester. Our client based near Manchester are currently looking for 2 Data Engineers with Azure experience. The company is currently going through a large digital transformation, they are looking for talented Data specialist to help...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Data Engineer - 70,000 Job Description An AWS Partner based in Central London is looking to expand the data side of their business due to growth. They are looking for Data Engineers with significant commercial experience ingesting large quantities of data...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Data Engineer - Python - Permanent Data Idols are working with a well-known client in the e-commerce space who are looking for a Data Engineer to join an existing team. THE ROLE As a Data Engineer, you will be working with the existing Data team to help...
Data Engineer - Manchester A growing business based in Manchester City Centre are currently looking for a Data Engineer to help shape their newly formed Data Engineering team and build scalable, reliable and secure cloud datawarehouse solutions and data...
Job title : Data Engineer Location: London Job type: Permanent Salary: Up to 70,000 per annum Reporting to: Head of Data Engineering Overview A fantastic internet company based in Central London are currently looking for a Data Engineer to come on board...
Data Engineer / Data Scientist / Biomedical Informatics / Human Genetics / Python / SQL / R / Oxford / Cambridge / Permanent 60 - 90K (Depending on Experience) Excellent Benefits COVID Safe Interview Process 100% Remote during Covid and up to 50% Post...
Data Engineer London 80,000 - 90,000 Benefits This Data Engineering role will allow you to expand and utilise your skills in a growing team working along side one of the largest data sets in the UK. The Company As a global leader they generate tons of...
Data Engineer London 55,000 - 65,000 Benefits Our client, an exciting RegTech business is looking to recruit for a Data Engineer to join their growing team. The successful candidate will be joining the artificial intelligence team, working on a brand new...
Recruiting for multiple Data Engineer roles with a global organisation based in Swindon to develop their cloud based platforms and infrastructure. These are permanent opportunities to join a newly created Agile team, offering competitive salaries/benefits...
Data Engineer - Permanent Data Idols are working with a well-known client in the e-commerce space who are looking for a Data Engineer to join an existing team on a permanent basis. THE ROLE As a Data Engineer, you will be working with the existing Data...
Senior Data Enigneer - Permanent Data Idols are working with a well known Technology company who are looking for a Senior Data Engineer to join a cross-functional team. This industry disruptor has been changing the way people interact with an everyday...
DATA ENGINEER - CURRENTLY REMOTE WORKING LONDON, CURRENTLY FLEXIBLE / REMOTE / HOME WORKING BETWEEN 65,000 - 90,000 BENEFITS BONUS Harnham are exclusively partnered with a tech brand looking to hire a Python focused Data Engineer. The client operates within...
DATA ENGINEER - CURRENTLY REMOTE WORKING LONDON, CURRENTLY FLEXIBLE / REMOTE / HOME WORKING BETWEEN 65,000 - 90,000 BENEFITS BONUS Harnham are exclusively partnered with a tech brand looking to hire a Python focused Data Engineer. The client operates within...
DATA ENGINEER ENERGY LONDON BETWEEN 60,000 - 80,000 This vacancy is an excellent opportunity to join an energy trading firm who have recently launched a new data initiative. The role will involve developing a data platform utilising Python, Spark &...
A leading Insurance Company are currently recruiting for a Data Engineer to join their dynamic and growing business. They are looking to hire a cross functional, highly tenacious and bright Data Engineer with a passion for functional programming. The ideal...
Calling all Data Engineers, Wi-Fi Install engineers, Fibre Engineers and Electrical Engineers.? Acorn?is?working in a recruitment partnership with a UK based?IT & Networks solution?provider?to?join?a project in Chartres,?France.?We are?recruiting a...
Site Name: UK - London - Brentford, USA - Pennsylvania - Upper Providence Posted Date: Jun 4 2020 Are you looking for a challenging opportunity to work in an area where cutting edge science meets cutting edge technology with an aim of delivering drugs...
Calling all Data Engineers, Wi-Fi Install engineers, Fibre Engineers and Electrical Engineers. Acorn is working in a recruitment partnership with a UK based IT & Networks solution provider to join a project in Chartres, France. We are recruiting a...
Calling all Data Engineers, Wi-Fi Install engineers, Fibre Engineers and Electrical Engineers.? Acorn?is?working in a recruitment partnership with a UK based?IT and Networks solution?provider?to?join?a project in Chartres,?France.?We are?recruiting a team...
",https://www.reed.co.uk/jobs/data-engineer/40309453
JOB32385191253,Data Engineer,Data Engineer,50+ career categories,"Find a better job, faster!,Hand-screened leads,No ads, scams, junk,Great job search support","
Data Engineer
Full-time job, remote during pandemic. Needs background in coding and experience with large data engineering. Clearly explain data and analytics strengths and weaknesses to stakeholders, develop and maintain strong effective relationships, present data.
Job Details
Remote - During Pandemic
Employee
Flexible Schedule, Full-Time
Experienced
No
Company name here
Other benefits listed here
Find a better job, faster!
Hand-screened leads
No ads, scams, junk
Great job search support
50+ career categories
Create an Account to Unlock
To find out more about or apply to this Data Engineer job—and other great opportunities like it—become a FlexJobs member today!
With FlexJobs, you'll find the best flexible jobs and fantastic expert resources to support you in your job search. If you have any questions, please feel free to contact us.
",https://www.flexjobs.com/publicjobs/data-engineer-1294481
JOB33142112411,Lead Data Engineer,Lead Data Engineer,"Identify data sources that can add value to decision making.,Work with source system owners and analysts to understand source data, e.g. data profiling, definition and mapping.,Design and implement efficient data loads, using traditional structured data ETL techniques.,Design and implement real time and near real time data load solutions, using technologies like data streaming.,Design and implement unstructured data loads, e.g. text speech, images and video.,Design and implement load monitoring tools and procedures and perform continuous monitoring and optimising of loads.,Work with analysts and architect to design and implement effective and efficient data models using appropriate modelling techniques.,Design and implement data warehouse data models.,Design and implement data pipelines for ad hoc, unstructured and other data models.,Design and implement appropriate aggregation data structures that enhance usability of data, e.g. multi-dimensional OLAP structures, summary tables etc.,Design, implement and maintain appropriate indexing on tables to enhance speed of access.,Design and implement data models that support automated decision making and/or further analytics.,Continuously search for data elements from other sources to enhance existing data objects to supplement / enhance context.,Design and implement interfaces for data access, e.g. batch exports, real-time decision API’s etc.,Design and implement interface monitoring and management solutions to ensure availability and accuracy.,Design and implement data monitoring solutions and procedures and continuously monitor and maintain integrity of existing environment, troubleshoot technical and data issues and make appropriate changes where required.,Design and implement meta-data solutions that assist with understanding and managing data.,Work together with business owners, analysts and IT to maintain good data governance.,Work together with business owners, analysts and IT to manage changes to data in the organisation.,Provide technical and data related support to source system teams and external parties with whom we exchange data.,Manage data growth and usage by implementing effective strategies, e.g. archiving and indexing.,Manage systems, technology and tools that enable data management and analytics and liaise with IT infrastructure and IT Operations regarding system and infrastructure management.,Take ownership of own work by delivering high quality work on time.,Show initiative and be pre-active in finding opportunities to improve data and/or processes.,Take ownership of own career development by continuously improving skills, knowledge and the application thereof in designing and implementing solutions.,Positive engagement in team activities and actively contribute ideas to improve team dynamics and performance.,Complex solution and service design and implementation.,Cross functional data and team knowledge gathering and sharing.,Responsible for team activities, team dynamics and performance.,Manage project and task delivery of team.,Multiple stakeholder management (internal and external).,Assist in development of others, e.g. mentoring and knowledge share.,Quality control of other’s work.,Degree in information technology/engineering/mathematics/statistics/actuarial or related discipline,At least 8 years’ experience working in a data, business intelligence or analytics environment,SQL,Data analysis,Data visualisation,Data modelling,Microsoft business intelligence data technologies (SSIS, SSAS, SQL Server),Data warehouse concepts and best practices,Information gathering and problem analysis,Applying professional / specialist / technical expertise,Creating and innovating,Quality & Detail orientation,Planning and organizing,Presenting and Communicating information,Analysing,Leadership",,"Lead Data Engineer
Job description
Capfin is a leading unsecured loan provider with a successful business model supported by great people with a strong culture of innovation and data driven decision making. The purpose of this role is to create business value by leading a team that apply data engineering and data management disciplines to design and build data solutions that enable data driven decision support, in order to optimize business decisions and processes.
Requirements
Key Performance Areas:
Sourcing data
Identify data sources that can add value to decision making.
Work with source system owners and analysts to understand source data, e.g. data profiling, definition and mapping.
Loading data
Design and implement efficient data loads, using traditional structured data ETL techniques.
Design and implement real time and near real time data load solutions, using technologies like data streaming.
Design and implement unstructured data loads, e.g. text speech, images and video.
Design and implement load monitoring tools and procedures and perform continuous monitoring and optimising of loads.
Storing data
Work with analysts and architect to design and implement effective and efficient data models using appropriate modelling techniques.
Design and implement data warehouse data models.
Design and implement data pipelines for ad hoc, unstructured and other data models.
Enhancing data
Design and implement appropriate aggregation data structures that enhance usability of data, e.g. multi-dimensional OLAP structures, summary tables etc.
Design, implement and maintain appropriate indexing on tables to enhance speed of access.
Design and implement data models that support automated decision making and/or further analytics.
Continuously search for data elements from other sources to enhance existing data objects to supplement / enhance context.
Making data available
Design and implement interfaces for data access, e.g. batch exports, real-time decision API’s etc.
Design and implement interface monitoring and management solutions to ensure availability and accuracy.
Managing data
Design and implement data monitoring solutions and procedures and continuously monitor and maintain integrity of existing environment, troubleshoot technical and data issues and make appropriate changes where required.
Design and implement meta-data solutions that assist with understanding and managing data.
Work together with business owners, analysts and IT to maintain good data governance.
Work together with business owners, analysts and IT to manage changes to data in the organisation.
Provide technical and data related support to source system teams and external parties with whom we exchange data.
Manage data growth and usage by implementing effective strategies, e.g. archiving and indexing.
Manage systems, technology and tools that enable data management and analytics and liaise with IT infrastructure and IT Operations regarding system and infrastructure management.
Leadership responsibilities
Take ownership of own work by delivering high quality work on time.
Show initiative and be pre-active in finding opportunities to improve data and/or processes.
Take ownership of own career development by continuously improving skills, knowledge and the application thereof in designing and implementing solutions.
Positive engagement in team activities and actively contribute ideas to improve team dynamics and performance.
Complex solution and service design and implementation.
Cross functional data and team knowledge gathering and sharing.
Responsible for team activities, team dynamics and performance.
Manage project and task delivery of team.
Multiple stakeholder management (internal and external).
Assist in development of others, e.g. mentoring and knowledge share.
Quality control of other’s work.
Qualifications:
Degree in information technology/engineering/mathematics/statistics/actuarial or related discipline
Experience:
At least 8 years’ experience working in a data, business intelligence or analytics environment
Functional Competencies:
SQL
Data analysis
Data visualisation
Data modelling
Microsoft business intelligence data technologies (SSIS, SSAS, SQL Server)
Data warehouse concepts and best practices
Behavioural Competencies:
Information gathering and problem analysis
Applying professional / specialist / technical expertise
Creating and innovating
Quality & Detail orientation
Planning and organizing
Presenting and Communicating information
Analysing
Leadership
The closing date for applications is 9 July 2019.
Posted on 21 Oct 19:21
",https://www.bizcommunity.com/Company/Job.aspx?cid=221357&i=375318
JOB33191172963,Senior Data Engineer,Senior Data Engineer,,,"
Senior Software Engineer with key skills in .net, C#, Kafka, RabbitMQ, Angular and AWS is sought on a fully remote basis by a multi award winning tech innovation organisation based in the Midlands. Due to recent client wins this company are creating space...
Senior Data Engineer - Permanent Data Idols are working with a well known Technology company who are looking for a Senior Data Engineer to join a cross-functional team. This industry disruptor has been changing the way people interact with an everyday...
Senior Process Engineer Salary: DOE Location: Kent A fantastic opportunity is now available for a Senior Process Engineer to join a market leading chemical manufacturer in Kent. During these testing times, the company have been very steady and remain...
Senior DevOps Engineer We are looking for a Senior DevOps Engineer to join an enterprise level tech group who compete with the likes of Microsoft and Mimecast building cloud storage tech at massive scale. The team have recently opened a brand new London...
Senior Linux Engineer - Linux, Redhat, Linux Kernel, Automation, TCP/IP, DNS, Python My London based financial sector client are on the hunt for a Senior Linux Engineer to join their Infrastructure team. They have no preference in previous sectors you...
Role: Senior Software Engineer - Data tech Salary: 70k - 80k equity Location: London Are you an engineer who enjoys solving complex problems? Do you strive to work on the most advanced technology product in London ? Do you want international recognition...
Senior DevOps Engineer We are seeking a Senior DevOps Engineer with experience in scripting, cloud scalability within an AWS environment, optimizing and automating systems and ensuring the overarching reliability of the platform to join a Times Top 20...
Senior Software Engineer - 55k - 75k - Guildford, Surrey Senior Software Engineer required by a market leading software company based in Guildford, Surrey. The company are going through a large growth phase and are looking for exceptional Senior Software...
Senior DevOps Engineer Job Opportunity in Wrexham I am working with a leading business that are on a huge expansion drive now, of whom are seeking to add a Senior DevOps Engineer to their team. You will be working collaboratively with Data Engineers, Data...
Central Oxford software company, lead responsibility for DevOps delivery and execution. Senior DevOps Engineer OxSource is working with a Central Oxford-based software company that require a Senior DevOps Engineer to join their team. Role Profile Siting...
60'000- 75'000 Technical Progression Holiday Pension Job Security Flexibility London Are you a Senior Network engineer certified in Cisco & Juniper and have a background working within an MSP or ISP environment? This is the ultimate opportunity for...
Senior DevOps Engineer Overview: An excellent opportunity has arisen with a global FTSE 250 Financial working on cutting edge projects for a senior DevOps Engineer. Role Responsibilities: ·Transition the on-prem teams into the cloud ·Move to an orchestrated...
Reqiva are working with a well established global manufacturer that create bespoke computer products for multiple industries including Aerospace and Defence. Types of Roles & Responsibilities of a Senior Systems Engineer: Define, build and test small...
Senior Test Engineer Brief Description Are you looking to work in a fast moving, dynamic and evolving business based in Exeter ? As a Senior Software Tester, you will play a leading role in maintaining exceptional product quality levels for this market...
Senior Systems Engineer Scotstoun 43.20ph Ltd 6 month contract Advantage Resourcing are working in partnership with a World Class Defence Organisation based in Glasgow, currently looking to recruit a Systems Engineer subcontractor on an initial 6 month...
On behalf of our client who deliver critical and vital services to the civil and defence sectors, Line Up Group is looking to recruit a Senior Structural Engineer. Role: Senior Structural Engineer Pay: Competitive Contract: Contract Location: Devonport...
Are you the type of Senior Software Engineer that thrives when working in a product focused environment? Do you want to be part of a team that is genuinely passionate about the quality of the code and product that they are producing, making use of industry...
Senior JavaScript Engineer (JavaScript, React.JS, Node) --- Central London --- 60,000- 80,000 pa (salary dep on exp) I have an amazing opportunity at a Leading Global News Media Organisation that should be very exciting to all Senior JavaScript Engineers...
Senior Infrastructure Engineer GBP350 per day 6 month contract Our client is a leading non-profit organization and they are looking for a Senior Infrastructure Engineer to support the team on a contract basis, providing assistance with business and infrastructure...
On behalf of our client who deliver critical and vital services to the civil and defence sectors, Line Up Group is looking to recruit a Senior Mechanical Engineer (Nuclear Process). Role: Senior Mechanical Engineer (Nuclear Process) Pay: Competitive Contract: Contract...
UK WIDE APPLICATIONS WELCOME We are pleased to have been engaged by one of Oxford’s most talked about high-tech start-ups, focusing on an imaging device that will truly change our understanding of what is possible to see with the naked eye. They are currently...
This is a new opportunity as a Senior DevOps Engineer based in Oxford. As a reliability engineer you'll combine your software and systems engineering expertise in coding, system design, integration, deployment and ongoing maintenance, to help build and...
This is an exciting new role for a Senior Software engineer based in Oxford. This client has created and delivered groundbreaking, genome derived health insights to healthcare providers and individuals, through innovative software products. While the development...
Role: Senior Wintel Engineer Location: Portsmouth, Hampshire Type: Permanent Package: Competitive Basic Salary and Benefits Package, plus Training and Development Opportunities Who is STS Defence? STS Defence is a UK based technology and engineering company...
Senior QA Engineer We are looking for a QA Analyst to join the Integrated Solutions Product Team, which designs and develops modern Front Office applications. The Team consists of three work streams: Analysis & Design, then Development and thirdly...
",http://www.reed.co.uk/jobs/senior-engineer/40269996
JOB33678859075,Data Engineer,Data Engineer,"We’re looking for individuals who have proven big data experience, either from an implementation or a data science prospective.,Expert knowledge of at least one big data technology such as Spark, Hadoop, or Elasticsearch.,A strong coding background in either Java, Python or Scala,The desire to learn and code in Scala,Experience in working in an Agile environment,Experience of building data processing pipelines for use in production ""handsoff"" batch systems, including either traditional ETL pipelines and/or analytics pipelines.,Competitive Salary,Company Bonus,Private Healthcare, Life Insurance and Income protection,Pension Scheme with a company contribution of 6% (if you contribute 3%),25 days annual leave (with the option to buy/sell up to 5 days),Amazing working environment,Employee referral scheme,ETL,Scala",,"
Description
Founded in 2016 with only a handful of individuals, Quantexa was built with a purpose that through a greater understanding of context, better decisions can be made. 3 years, 6 locations and 180+ employees later we still believe that today. We connect the dots within our Customers data using dynamic entity resolution and advanced network analytics to create context, empowering businesses to see the bigger picture and drive real value from their data.
Due to the continuous success and high demand from our Customers, we are looking for Data Engineers with a proven track record in big data projects to join the Quantexa family.
What does a Data Engineer role at Quantexa look like?
In order to be a successful data Engineer at Quantexa, you’ll need to be comfortable dealing with both internal and external stakeholders. On a daily basis you'll be you will be managing, transforming and cleansing high volume data, helping our Tier 1 clients solve business problems in the area of fraud, compliance and financial crime.
Being Agile is an integral part to the success we have at Quantexa and having regular team sprints and Scrum meetings with your Projects team is essential. You’ll be working closely with Data Scientists, Business Analysts, Technical Leads, Project Managers and Solutions Architects, with everyone following the same goal of meeting our Clients expectations and delivering a first-class service.
We want our employees to use the latest and leading open source big-data technologies possible. You will be using tools such as Spark, Hadoop, Scala and Elasticsearch, with our platform being hosted on Google cloud (GCP). Our primary language is written in Scala, but don’t worry If that’s not your strongest language or if you haven’t used it before, we make sure that every Quantexan goes through our training academy so they’re comfortable and confident with using our platform.
Requirements
What do I need to have?
We’re looking for individuals who have proven big data experience, either from an implementation or a data science prospective.
Expert knowledge of at least one big data technology such as Spark, Hadoop, or Elasticsearch.
A strong coding background in either Java, Python or Scala
The desire to learn and code in Scala
Experience in working in an Agile environment
Experience of building data processing pipelines for use in production ""handsoff"" batch systems, including either traditional ETL pipelines and/or analytics pipelines.
Passion and drive to grow within one of the UK’s fastest growing Start-ups
Benefits
Why join Quantexa?
We know that just having an excellent glass door rating isn’t enough, so we’ve moved to a brand-new WeWork office and put together a competitive package as a way of saying thank you for all your hard work and dedication.
We offer:
Competitive Salary
Company Bonus
Private Healthcare, Life Insurance and Income protection
Pension Scheme with a company contribution of 6% (if you contribute 3%)
25 days annual leave (with the option to buy/sell up to 5 days)
Amazing working environment
Employee referral scheme
Learning and Developement
",https://www.reed.co.uk/jobs/data-engineer/39680157
JOB33735970137,Specialist - Data Engineer,Specialist - Data Engineer,50+ career categories,"Hand-screened leads,No ads, scams, junk,Great job search support","
Seeking a specialist for a remote option position requiring minimal travel, a BA/BS, ten+ years' relevant experience, and a strong understanding of legacy data systems. Will assist project tasks, collect and analyze data, make recommendations.
Job Details
Option for Remote
Employee
Full-Time
Experienced
Bachelor's Degree
Yes, a bit
Company name here
Other benefits listed here
Hand-screened leads
No ads, scams, junk
Great job search support
50+ career categories
Create an Account to Unlock
To find out more about or apply to this Specialist - Data Engineer job—and other great opportunities like it—become a FlexJobs member today!
With FlexJobs, you'll find the best flexible jobs and fantastic expert resources to support you in your job search. If you have any questions, please feel free to contact us.
",https://www.flexjobs.com/publicjobs/specialist-data-engineer-1303191
JOB34939929426,Most Popular Jobs Similar to Cloud Data Engineer,Most Popular Jobs Similar to Cloud Data Engineer,,,"
Most Popular Cloud Data Engineer Job Categories
",https://www.ziprecruiter.com/Jobs/Cloud-Data-Engineer
JOB35085452274,"Big Data Engineer - Hadoop, SalesForce.com, SQL Server required","Big Data Engineer - Hadoop, SalesForce.com, SQL Server required",,," Big Data Engineer - Hadoop, SalesForce.com, SQL Server required - Berkshire - £550-£600pd
Spargonet Consulting, an IT Services Consultancy, is looking for a Big Data Engineer to help set-up a data lake for one of our customers in the Leisure Industry. This is a green field development opportunity. The ideal candidate will be able to provide thought leadership and architectural guidance. We are looking for an experienced engineer with a proven track record.
Main activities
- Help set up a data lake
- Setup Integration points from various back end systems into the data lake
- Help with the overall Big data strategy, architectural approach and Hadoop eco system tool selection
Mandatory skills :
- Big Data Engineer - Hadoop, SalesForce.com, SQL Server required
- SQL Server (2008 & 2012)
- Web/Call Analytics
- Hadoop/HDFS
- Oozie
- Sqoop
- Kafka
- Flume
- SOAP/ RESTful web services
Desired skills :
- Java
- PIG
- Spark
- Scala
- HBASE
- Cloudera
Working knowledge :
- Good to have travel industry experience
- Good working knowledge of Spark, Hive and Impala would be very beneficial
- A good knowledge of the languages Scala and Java
- Google Analytics
Spargonet Consulting Plc is a leading IT consultancy with over thirty years pedigree and experience of supplying IT services to household name blue chip clients within a range of business sectors.
By joining the personable team at Spargonet, you become a valued member of our personnel with good prospects of a rewarding and challenging opportunity.
All applications welcome for an informal and confidential discussion.
",https://www.careerjet.co.uk/clk/41931dd9e6d0fd5f30205e44441e43d2.html
JOB35262753295,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/hu-hu/details/200188037/ai-ml-search-data-engineer-siri-data
JOB36556954433,Senior Data Engineer - Scala - AWS - Azure - GCP - London,Senior Data Engineer - Scala - AWS - Azure - GCP - London,,,"
Senior Data Engineer - Scala - AWS - Azure - GCP - London You must have experience of working with Scala to be considered for this role This is an opportunity to work for one of the largest, high tech bands in the world. My client are looking for a cutting...
Method Resourcing are really pleased to be working with one of the fastest growing tech brands who are looking for a senior data engineer. They are are championing a transformational data platform that will completely change how data is utilised at the...
Data Engineer - Scala / Python - AWS - Azure - GCP - London This is an opportunity to work for one of the largest, high tech bands in the world. My client are looking for a cutting edge Senior Data Engineer to build a transformational data platform. You'll...
Senior Data Engineer - Permanent Data Idols are working with a well known Technology company who are looking for a Senior Data Engineer to join a cross-functional team. This industry disruptor has been changing the way people interact with an everyday...
Senior Python Engineer (Data) // 60,000 - 90,000 // Weybridge, Surrey Pre-IPO start-up, building genuinely Greenfield platforms from the ground up, MVP through to the final product - Creating own APIs to ingest and data mine throughout the Healthcare world...
C#, Scala, Java A unique opportunity is available for an Enterprise, Software business that are expanding their team due to acquiring new clients and projects, all within the Machine Learning, AI and Data sector. They are looking for a Software Engineer...
SENIOR DATA ENGINEER LONDON, CURRENTLY FLEXIBLE / REMOTE / HOME WORKING UP TO 80,000 BENEFITS BONUS Harnham are partnered with a leading e-commerce company in Central London - this company are building a next-gen data platform from the ground up using...
Big Data Engineer Remote Interview WFH. Are you a data centric technologist seeking complex and interesting systems to apply and enhance your skills, continually learning and working with a range of modern data tools and technologies? You could be joining...
Data Engineer Remote Interview WFH. Are you a data centric technologist seeking complex and interesting systems to apply and enhance your skills, continually learning and working with a range of modern data tools and technologies? You could be joining...
Data Engineer / Senior Data Engineer - Manchester - Multiple Roles Available - Salary DoE - 40,000 - 65,000 An exciting opportunity has arisen for a Data Engineer to join a growing consultancy firm based around the UK who focus on using the latest technologies...
SENIOR DATA ENGINEER - REMOTE WORKING 70-80K BONUS BENEFITS CENTRAL LONDON, CURRENTLY - FLEXIBLE/REMOTE/HOME WORKING THE COMPANY: The company is a leader in its market, and the first of its kind that was formed to disrupt two separate markets and they...
DATA ENGINEER - CURRENTLY REMOTE WORKING LONDON, CURRENTLY FLEXIBLE / REMOTE / HOME WORKING BETWEEN 75,000 - 85,000 BENEFITS BONUS Harnham are exclusively partnered with a tech brand looking to hire a Java focused Data Engineer. The company build advanced...
",https://www.reed.co.uk/jobs/senior-data-engineer-scala/40211497
JOB36719749673,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-vn/details/200188037/ai-ml-search-data-engineer-siri-data
JOB37130447370,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-co/details/200188037/ai-ml-search-data-engineer-siri-data
JOB37145488955,Mlops Data Engineer Staff Jobs,Mlops Data Engineer Staff Jobs,,,,https://www.avjobs.com/jobs/positions.asp?q=MLOps+Data+Engineer+Staff
JOB37896346592,Data Engineer,Data Engineer,Virtual company-sponsored social events,"Develop and maintain developer tooling to support pyspark data pipelines,Implement processes and systems to monitor data quality, ensuring production data is accurate and available for key stakeholders and business processes that depend on it,Develop and maintain data platform components including: data producers and consumers, pipeline architecture, data lake, data warehouse, and Business Intelligence tooling,Collaborate closely with fellow data team members as well as tech and product teams and company leaders,Support continuing increases in data velocity, volume, and complexity,Write unit/integration tests and document work,Experience with or knowledge of Agile Software Development methodologies,Excellent problem solving and troubleshooting skills,Strong SQL and Python development experience,Proven experience with schema design and dimensional data modeling,Practical experience with SQL and NoSQL databases,Practical experience supporting Business Intelligence tooling and third-party systems,Experience designing, building, and maintaining data processing systems,Experience working with MapReduce and Spark clusters,Experience detecting and reporting data quality issues,Familiarity with Docker, CI/CD (such as Jenkins/Circle), AWS,Competitive salary,Health insurance (100% paid for individuals, 75% for families),Primary caregiver 12-week paid leave,401K,Generous vacation policy, plus company holidays,Company equity,Commuter and cell phone benefit,A commitment to an open, inclusive, and diverse work culture,One mental health day per quarter,$100 monthly work-from-home stipend,Tele-mental health services,OneMedical membership, including tele-health services,Increased work flexibility for parents and caretakers,Access to the Axios “Family Fund”, which was created to allow employees to request financial support when facing financial hardship or emergencies,Weekly company-sponsored exercise and meditation classes","Quick take: Axios is a growth-stage startup dedicated to providing trustworthy, award-winning news content in an audience-first format. We’re hiring a Data Engineer to join our growing data team!
Why it matters: As a Data Engineer, this person will collaborate with engineers, analysts, and product managers to drive forward data initiatives across mission-critical Axios products. Our Data team is made of Engineers, Scientists, and Analysts who use data-driven methodologies to inform decisions and strategy, build robust scalable products and identify opportunities for innovation across the company.
Go deeper: This Data Engineer will play a key role in building solutions to problems in an intelligent and nuanced way. In this role, you will make an impact on Axios through the following responsibilities:
Develop and maintain developer tooling to support pyspark data pipelines
Implement processes and systems to monitor data quality, ensuring production data is accurate and available for key stakeholders and business processes that depend on it
Develop and maintain data platform components including: data producers and consumers, pipeline architecture, data lake, data warehouse, and Business Intelligence tooling
Collaborate closely with fellow data team members as well as tech and product teams and company leaders
Support continuing increases in data velocity, volume, and complexity
Write unit/integration tests and document work
Perform data analysis required to troubleshoot data related issues and assist in the resolution of data issues
The details: Ideal candidate should have an entrepreneurial spirit, be highly collaborative, exhibit a passion for building technology products, and have the following qualifications:
Experience with or knowledge of Agile Software Development methodologies
Excellent problem solving and troubleshooting skills
Strong SQL and Python development experience
Proven experience with schema design and dimensional data modeling
Practical experience with SQL and NoSQL databases
Practical experience supporting Business Intelligence tooling and third-party systems
Experience designing, building, and maintaining data processing systems
Experience working with MapReduce and Spark clusters
Experience detecting and reporting data quality issues
Familiarity with Docker, CI/CD (such as Jenkins/Circle), AWS
Experience building data visualizations and dashboards is preferred
Don’t forget:
Competitive salary
Health insurance (100% paid for individuals, 75% for families)
Primary caregiver 12-week paid leave
401K
Generous vacation policy, plus company holidays
Company equity
Commuter and cell phone benefit
A commitment to an open, inclusive, and diverse work culture
Annual learning and development stipend
Additional pandemic-related benefits:
One mental health day per quarter
$100 monthly work-from-home stipend
Tele-mental health services
OneMedical membership, including tele-health services
Increased work flexibility for parents and caretakers
Access to the Axios “Family Fund”, which was created to allow employees to request financial support when facing financial hardship or emergencies
Weekly company-sponsored exercise and meditation classes
Virtual company-sponsored social events
Apply Now
",https://technical.ly/job/axios-data-engineer-67570/
JOB38205486979,"Data Engineer job - LivePerson, Inc. - Remote | Indeed.co.uk","Data Engineer job - LivePerson, Inc. - Remote | Indeed.co.uk","Team player, excellent communication skills","Implement and maintain new services and dashboards leveraging multiple technologies,Build performance reporting for new LivePerson product offerings,Directly deliver reporting enhancement requests within the LivePerson product,Create dynamic API-based tools and reports to drive insight into client performance,Bring a client-facing perspective to an R&D role – transform client feedback into actionable projects and ensure all technical stakeholders are driving toward clients’ business needs.,Proven software development experience within the SaaS industry,Proficiency in Javascript, Node.js, Angular 2+ and HTML/CSS,Experience building large scale web applications in the cloud,Experience with data visualization tools, including MicroStrategy Visual Insights,Advanced Excel user, with proficiency developing in VBA,Familiarity with extracting/transforming data from REST API's,Working knowledge of SQL,Working knowledge of database and table relationships,Working knowledge of Hadoop and Impala,Basic understanding and interest in learning Spark, Python, R or any data science language,Passionate about software development, technology, and data analysis,Strong analysis and design skills,Self-starter with strong motivation and execution capabilities"," Do you have a passion for turning complex data-sets into actionable insights? If so, then LivePerson is looking for you!
LivePerson’s vision is to empower consumers to stop wasting time on hold with 1-800 numbers and instead message their favorite brands just as they do with friends and family. This is all done on our award-winning mobile and online messaging platform, LiveEngage. More than 18,000 businesses -- including Microsoft, Virgin Atlantic, The Home Depot, Citibank, IBM, Adobe, and ½ of the Global Fortune 500 telecoms and commercial banks -- choose LivePerson because of our unparalleled intelligence, security and scalability demanded by the most recognizable global brands.
Our more than 1,000 employees across 13 global offices live by our core values of “Be an Owner” and “Help Others” and are connected by our strong company culture. Headquartered in New York City, we have offices in Atlanta, London, Reading (UK), Paris, Melbourne, Milan, Tokyo, Mannheim, Berlin, Amsterdam and a world-class tech hub in Tel Aviv. (NASDAQ: LPSN)
What YWill You Own?
Implement and maintain new services and dashboards leveraging multiple technologies
Build performance reporting for new LivePerson product offerings
Directly deliver reporting enhancement requests within the LivePerson product
Create dynamic API-based tools and reports to drive insight into client performance
Bring a client-facing perspective to an R&D role – transform client feedback into actionable projects and ensure all technical stakeholders are driving toward clients’ business needs.
What Do You Need for Success?
Proven software development experience within the SaaS industry
Proficiency in Javascript, Node.js, Angular 2+ and HTML/CSS
Experience building large scale web applications in the cloud
Experience with data visualization tools, including MicroStrategy Visual Insights
Advanced Excel user, with proficiency developing in VBA
Familiarity with extracting/transforming data from REST API's
Working knowledge of SQL
Working knowledge of database and table relationships
Working knowledge of Hadoop and Impala
Basic understanding and interest in learning Spark, Python, R or any data science language
Passionate about software development, technology, and data analysis
Strong analysis and design skills
Self-starter with strong motivation and execution capabilities
Team player, excellent communication skills
",https://www.indeed.co.uk/job/Data-Engineer-at-LivePerson-in-Remote-b452f9a81b7a4908
JOB38351526765,Data Engineer Jobs,Data Engineer Jobs,,,"
DESCRIPTION At Amazon Advertising, we are dedicated to drive measurable outcomes for brand advertisers, agencies, authors, and entrepreneurs. Our ad solutions—including sponsored, display, video, and custom ads—leverage Amazon’s innovations and insights...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
As the Data Engineer for this amazing corporate Insurance company, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL, together...
See more: Engineer jobs
As a data engineer within the exciting, new claims advanced analytics capability, you will be building big data solutions to solve some of the organization’s toughest problems and delivering significant business value. This is a really exciting time to...
See more: Engineer jobs
Data Engineer - 70,000 Job Description An AWS Partner based in Central London is looking to expand the data side of their business due to growth. They are looking for Data Engineers with significant commercial experience ingesting large quantities of data...
See more: Engineer jobs
As the Data Engineer for this amazing corporate Insurance company in the City, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
DATA ENGINEER - TEMPORARILY REMOTE 400- 450 PER DAY 3 MONTH CONTRACT EUROPE BASED As a Data Engineer you will be working heavily with Scala and Spark to improve the quality of data. THE COMPANY: You will be working for dynamic data driven company. As a...
See more: Engineer jobs
40'000- 50'000 Pension 8% Technical Progression Healthcare Holidays More Horley, Surrey Are you seeking a new challenge within a rapidly expanding Eco-Energy Tech company where you will be having huge technical autonomy in building a data preform right...
See more: Engineer jobs
Role: Data Engineer Client: Government agency (BPSS will be required) Location: Glasgow Duration: 8 Months Rate: 400 per day (outside IR35) Note: The office is based in Glasgow city centre. It is expected that the consultant would be available for physical...
See more: Engineer jobs
Data Engineer Opus are working with an excellent niche software development company in Newcastle. The company is at the forefront of their industry and due to their on-going success are now looking for a Data Engineer to take responsibility for organising...
See more: Engineer jobs
A leading Insurance Company are currently recruiting for a Data Engineer to join their dynamic and growing business. They are looking to hire a cross functional, highly tenacious and bright Data Engineer with a passion for functional programming. The ideal...
See more: Engineer jobs
Data Engineer - 6 months - Ware - Hertfordshire Global FMCG is looking for an experienced Data Engineer who will play a pivotal role in operationalizing data and analytics initiatives for digital business initiatives. The bulk of the data engineer's work...
See more: Engineer jobs
Data Engineer Portsmouth and surrounding areas encouraged to apply, multiple office locations Data Engineer required for established, international business. The business is at the forefront of new technologies working with leading Government organisations...
See more: Engineer jobs
Data Engineer A brand new role has arisen for an experienced Database / BI Developer to take the next step in their career and transition into a full Data Engineer to work for one of the most recognisable NGO's in London. We are looking for someone with...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
Data Engineer- 50K Manchester Adria Solutions has an exciting opportunity for a talented Data Engineer to join our rapidly expanding client based near Manchester. The role requires you to work closely with other members of the data team and stakeholders...
See more: Engineer jobs
We are currently recruiting a highly motivated Data Engineer, for a company who are based in London. The Data Engineer will help develop and maintain the business. The Data Engineer will be responsible for the following; Key responsibilities- - Working...
See more: Engineer jobs
Data Engineer - I am currently recruiting for a Data Engineer based in Bath. The role would be on a permanent basis and is paying 40,000 to 45,000 (There could be flex for the right candidate) PA plus a variety of excellent benefits as well as the flexibility...
See more: Engineer jobs
Data Engineer - London - 550-600 per day - 6 month contract SearchData is currently looking to recruit a Data Engineer to work on a cutting-edge DWH project in the financial services industry. As the Data Engineer your role will be to take a leadership...
See more: Engineer jobs
An exciting opportunity for an experienced Data Engineer has arisen in Leeds. After hiring a number of new members of staff at the end of 2019, the organisation are continuing to expand due to winning more projects. Key responsibilites include: Building...
See more: Engineer jobs
Data Engineer - REMOTE WORK If you are a strong Data Engineer, with experience working with Python, R and SQL then this role is ideal. I am working with a large organisation that are market leaders in their respected field. This role will report in to...
See more: Engineer jobs
Data Engineer London 55,000 - 65,000 Benefits Our client, an exciting RegTech business is looking to recruit for a Data Engineer to join their growing team. The successful candidate will be joining the artificial intelligence team, working on a brand new...
See more: Engineer jobs
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
See more: Engineer jobs
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
See more: Engineer jobs
",http://www.reed.co.uk/jobs/data-engineer/39947657
JOB38993657005,"Data Engineer, Analytics","Data Engineer, Analytics","Development experience with at least two different database platforms, such as Teradata, Oracle, or MS SQL.,Minimum of 5 years experience designing, developing, and testing ETL interfaces aligned with defined requirements.,Exposure to Business Intelligence tools such as Business Objects, Informatica, SSRS, Cognos, MicroStrategy, Tableau, QlikView, SpotFire, etc.,Experience tuning ETL processes to ensure performance and reliability.,MDM experience.,Competitive salary with performance based bonus opportunities,Single and Family Health Insurance plans, including Dental coverage,Short-Term and Long-Term disability,Matching 401(k),Competitive Paid Time Off,Training and Certification opportunities eligible for expense reimbursement,Team building and social activities","Design, develop, document, and test ETL solutions using industry standard tools.,Participate in requirements gathering sessions with business and technical staff to distill technical requirements from business requests.,Partner with clients to fully understand business philosophy and IT Strategy; recommend process improvements to increase efficiency and reliability in ETL development.,Present ETL documentation and designs to team members and convey complex information in a clear and concise manner.,Extract data from multiple sources, integrate disparate data into a common data model, and integrate data into a target database, application, or file using efficient ETL processes.","CapTech is an award-winning national management technology-consulting firm with an enterprising, entrepreneurial environment. We have achieved four straight years ranked in the Top 10 of Consulting Magazine’s Best Firms to Work For, including a #5 ranking overall in 2015. Additionally, we placed 28th within the Vault Consulting 50 for the second year in a row, including a #5 ranking in work/life balance.
At CapTech you’ll experience a flat organizational structure with access to constant learning -- where your career path isn’t set in stone, and you have unlimited potential for growth. CapTech is based upon a culture of mutual respect. We look for, and hire the best. The creatively innovative, the technically insightful, the driven, the self-managed, the value conscious, the caring, and the gracious person – these are all qualities that we look for along with a love and a passion for the work that we do.
The Data Engineer, Analytics role falls into the Data Management & Business Intelligence practice area at CapTech, through which our consultants provide a broad spectrum of services to help our clients define and implement a strategy to deliver lasting and mission-critical information capabilities. Our Data Integration consultants bridge the gap between the business and IT side of companies. By partnering with clients to fully understand both their business philosophy and IT strategy, CapTech consultants maintain the vision that data integration should be built to help the organization make better decisions by providing the right data at the right time.
Specific responsibilities for the Data Integration Developer - ETL position include:
Design, develop, document, and test ETL solutions using industry standard tools.
Participate in requirements gathering sessions with business and technical staff to distill technical requirements from business requests.
Partner with clients to fully understand business philosophy and IT Strategy; recommend process improvements to increase efficiency and reliability in ETL development.
Present ETL documentation and designs to team members and convey complex information in a clear and concise manner.
Extract data from multiple sources, integrate disparate data into a common data model, and integrate data into a target database, application, or file using efficient ETL processes.
Collaborate with Quality Assurance resources to debug ETL development and ensure the timely delivery of products.
Specific qualifications for the Data Engineer, Analytics position include:
Development experience with at least two different database platforms, such as Teradata, Oracle, or MS SQL.
Minimum of 5 years experience designing, developing, and testing ETL interfaces aligned with defined requirements.
Exposure to Business Intelligence tools such as Business Objects, Informatica, SSRS, Cognos, MicroStrategy, Tableau, QlikView, SpotFire, etc.
Experience tuning ETL processes to ensure performance and reliability.
MDM experience.
Strong SQL skills.
We offer challenging and impactful jobs with professional career paths. All CapTechers can keep their hands on technology no matter what position they hold. Our employees find their work exciting and rewarding in a culture that filled with opportunities to have fun along the way.
At CapTech we offer a competitive and comprehensive benefits package including, but not limited to:
Competitive salary with performance based bonus opportunities
Single and Family Health Insurance plans, including Dental coverage
Short-Term and Long-Term disability
Matching 401(k)
Competitive Paid Time Off
Training and Certification opportunities eligible for expense reimbursement
Team building and social activities
Mentor program to help you develop your career
At this time, CapTech cannot transfer nor sponsor a work visa for this position. Applicants must be authorized to work for any employer in the United States without visa sponsorship.
Candidates must be eligible to work in the U.S. for any employer.
CapTech is an equal opportunity employer.
CapTech is a Drug-Free work place.
Candidates must have the ability to work at CapTech’s client locations.
All positions include the possibility of travel.
",https://www.smartrecruiters.com/CapTechConsulting/95456814-data-engineer-analytics
JOB38993657005,"Data Engineer, Analytics","Data Engineer, Analytics","Development experience with at least two different database platforms, such as Teradata, Oracle, or MS SQL.,Minimum of 5 years experience designing, developing, and testing ETL interfaces aligned with defined requirements.,Exposure to Business Intelligence tools such as Business Objects, Informatica, SSRS, Cognos, MicroStrategy, Tableau, QlikView, SpotFire, etc.,Experience tuning ETL processes to ensure performance and reliability.,MDM experience.,Competitive salary with performance based bonus opportunities,Single and Family Health Insurance plans, including Dental coverage,Short-Term and Long-Term disability,Matching 401(k),Competitive Paid Time Off,Training and Certification opportunities eligible for expense reimbursement,Team building and social activities","Design, develop, document, and test ETL solutions using industry standard tools.,Participate in requirements gathering sessions with business and technical staff to distill technical requirements from business requests.,Partner with clients to fully understand business philosophy and IT Strategy; recommend process improvements to increase efficiency and reliability in ETL development.,Present ETL documentation and designs to team members and convey complex information in a clear and concise manner.,Extract data from multiple sources, integrate disparate data into a common data model, and integrate data into a target database, application, or file using efficient ETL processes.","CapTech is an award-winning national management technology-consulting firm with an enterprising, entrepreneurial environment. We have achieved four straight years ranked in the Top 10 of Consulting Magazine’s Best Firms to Work For, including a #5 ranking overall in 2015. Additionally, we placed 28th within the Vault Consulting 50 for the second year in a row, including a #5 ranking in work/life balance.
At CapTech you’ll experience a flat organizational structure with access to constant learning -- where your career path isn’t set in stone, and you have unlimited potential for growth. CapTech is based upon a culture of mutual respect. We look for, and hire the best. The creatively innovative, the technically insightful, the driven, the self-managed, the value conscious, the caring, and the gracious person – these are all qualities that we look for along with a love and a passion for the work that we do.
The Data Engineer, Analytics role falls into the Data Management & Business Intelligence practice area at CapTech, through which our consultants provide a broad spectrum of services to help our clients define and implement a strategy to deliver lasting and mission-critical information capabilities. Our Data Integration consultants bridge the gap between the business and IT side of companies. By partnering with clients to fully understand both their business philosophy and IT strategy, CapTech consultants maintain the vision that data integration should be built to help the organization make better decisions by providing the right data at the right time.
Specific responsibilities for the Data Integration Developer - ETL position include:
Design, develop, document, and test ETL solutions using industry standard tools.
Participate in requirements gathering sessions with business and technical staff to distill technical requirements from business requests.
Partner with clients to fully understand business philosophy and IT Strategy; recommend process improvements to increase efficiency and reliability in ETL development.
Present ETL documentation and designs to team members and convey complex information in a clear and concise manner.
Extract data from multiple sources, integrate disparate data into a common data model, and integrate data into a target database, application, or file using efficient ETL processes.
Collaborate with Quality Assurance resources to debug ETL development and ensure the timely delivery of products.
Specific qualifications for the Data Engineer, Analytics position include:
Development experience with at least two different database platforms, such as Teradata, Oracle, or MS SQL.
Minimum of 5 years experience designing, developing, and testing ETL interfaces aligned with defined requirements.
Exposure to Business Intelligence tools such as Business Objects, Informatica, SSRS, Cognos, MicroStrategy, Tableau, QlikView, SpotFire, etc.
Experience tuning ETL processes to ensure performance and reliability.
MDM experience.
Strong SQL skills.
We offer challenging and impactful jobs with professional career paths. All CapTechers can keep their hands on technology no matter what position they hold. Our employees find their work exciting and rewarding in a culture that filled with opportunities to have fun along the way.
At CapTech we offer a competitive and comprehensive benefits package including, but not limited to:
Competitive salary with performance based bonus opportunities
Single and Family Health Insurance plans, including Dental coverage
Short-Term and Long-Term disability
Matching 401(k)
Competitive Paid Time Off
Training and Certification opportunities eligible for expense reimbursement
Team building and social activities
Mentor program to help you develop your career
At this time, CapTech cannot transfer nor sponsor a work visa for this position. Applicants must be authorized to work for any employer in the United States without visa sponsorship.
Candidates must be eligible to work in the U.S. for any employer.
CapTech is an equal opportunity employer.
CapTech is a Drug-Free work place.
Candidates must have the ability to work at CapTech’s client locations.
All positions include the possibility of travel.
",https://www.smartrecruiters.com/CapTechConsulting/95456814-data-engineer-analytics
JOB39005517719,Big Data Engineer,Big Data Engineer,"Experience with Spark, Google Big Query, Redis, Amazon Aurora, Dynamo DB, Kinesis or Riak.","Strong software development skills,Solid PHP frameworks knowledge (Symfony is nice to have),Solid Python experience,Ability to work fast, quickly get up to speed with existing code, and learn new concepts easily,Experience and passion for Big Data,Great problem solving skills,Ability to work in a team environment.,Facility to learn new technologies,Background in SQL/PostgreSQL,Experience with Big Data architectures and technologies (more than 1TB of data) and BI solutions"," Big Data Engineer
Our client create amazing games and are positioned in the top rankings of both iOS and android that are played and loved by over 50 million fans all over the world.
As a Data Engineer you will contribute to build the architecture that is currently able to handle 50K events per second, it’s 30TB of compressed data in size and processes more than 1000 different kpi every night per game.
You will work closely with other awesome developers and data scientists to make their BI tools and architecture the best in the industry.
You Are:
Professional, passionate about video games, problem solver, proactive, team worker, rigorous and data oriented. You are smart, creative and practical at the same time and you have the ability to work fast, quickly get up to speed with existing code, and learn new concepts easily.
You also have:
Strong software development skills
Solid PHP frameworks knowledge (Symfony is nice to have)
Solid Python experience
Ability to work fast, quickly get up to speed with existing code, and learn new concepts easily
Experience and passion for Big Data
Great problem solving skills
Ability to work in a team environment.
Facility to learn new technologies
Background in SQL/PostgreSQL
Experience with Big Data architectures and technologies (more than 1TB of data) and BI solutions
Experience with Spark, Google Big Query, Redis, Amazon Aurora, Dynamo DB, Kinesis or Riak.
Please contact Cassandra Donnelly on 01279 871330 cassandra@interactiveselection.com if you are interested in this position. Please forward your CV in a Word format. View Many More Interactive Selection Jobs.
We are an equal opportunities recruitment agency that values diversity and does not discriminate. We encourage clients to welcome applicants from all backgrounds
",https://www.indeed.co.uk/job/Big-Data-Engineer-at-Interactive-Selection-in-United-Kingdom-2ac9cfee55ade293
JOB39925350562,Data Engineer,Data Engineer,"Completed BSc (Computer Science) degree or similar (Software Engineering, Data Science, etc. with experience in software),Two to five years’ experience in Data Engineering (Hadoop and Spark),Data Processing products - Big Query, Redshift, Spectrum, S3, Athena, Kafka, Spark, Storm, Flink, Beam, Presto, Hive,ETL processes and transformations,Cloud experience ideally with Google Cloud Platform,DevOps Stack development experience,Apache-Airflow or other data pipeline tools,Exposure to Scala or Java in context of data processing,Experience and proficiency with Python,Experience in the design and implementation of data flows,Support sophisticated predictive data products by maintaining data science production environments (cloud-based, python), ensuring that the outputs from Data Science models are available and integrated into the system and integrate, coordinate and maintain data flows between various sources of data,Manage and maintain cloud service integrations that perform key data functions by working towards replacing third-party elements of the data pipeline by using open-source tools,Make decisions around the infrastructure, layout and processes of the data warehouse, including working with the engineering team on how to best track and record data,following up on data inconsistencies to ensure that it is corrected",,"A data-centred business is on the lookout for a data engineer to join their team. This is an opportunity to work on cutting edge of tech and cloud computing. They are a fun environment with a quality team that is working with some of the biggest and best datasets in the country.
You will be building world-class, scalable data pipelines and warehouses to add real value to customers and drive new product development, both internally and externally.
Requirements:
Completed BSc (Computer Science) degree or similar (Software Engineering, Data Science, etc. with experience in software)
Two to five years’ experience in Data Engineering (Hadoop and Spark)
Data Processing products - Big Query, Redshift, Spectrum, S3, Athena, Kafka, Spark, Storm, Flink, Beam, Presto, Hive
ETL processes and transformations
Cloud experience ideally with Google Cloud Platform
DevOps Stack development experience
Apache-Airflow or other data pipeline tools
Exposure to Scala or Java in context of data processing
Experience and proficiency with Python
Experience in the design and implementation of data flows
Advanced SQL/PostgreSQL/Redshift knowledge
Responsibilities:
Support sophisticated predictive data products by maintaining data science production environments (cloud-based, python), ensuring that the outputs from Data Science models are available and integrated into the system and integrate, coordinate and maintain data flows between various sources of data
Manage and maintain cloud service integrations that perform key data functions by working towards replacing third-party elements of the data pipeline by using open-source tools
Make decisions around the infrastructure, layout and processes of the data warehouse, including working with the engineering team on how to best track and record data
following up on data inconsistencies to ensure that it is corrected
Transforming, standardising and collecting data from various sources
Reference number for this position is LV46312 which is a permanent position based in Johannesburg North offering a salary of up to R900k per annum highly negotiable on experience and ability. Contact Liza on lizavdb@e-merge.co.za or call her on 011 463 3633 to discuss this and other opportunities.
Are you ready for a change of scenery? The e-Merge IT recruitment is a specialist niche recruitment agency. We offer our candidates options so that we can successfully place the right developers with the right companies in the right roles.
Check out the e-Merge website www.e-merge.co.za for more great positions
Do you have a friend who is a developer or technology specialist? We pay cash for successful referrals!
Posted on 25 Jul 10:03
",https://www.bizcommunity.com/Job/196/662/370710.html
JOB40636936399,Data Engineer,Data Engineer,Machine learning and statistical analysis,"Creation and maintenance of reporting and analytics infrastructure,Full lifecycle of Performance Hub architectures, for the creation of data set processes used in modelling, mining, acquisition, and verification,Solid command of common scripting languages and tools,Skills to constantly improve data quality and quantity by leveraging and improving data analytics systems,Provide a link between the business and the solution providers within the context of functional alignment,Identify and communicate risks and issues as they arise,Travel to Site, on average 1 trips per month of 2 to 3 days,In-depth knowledge of SQL, Data warehousing, ETL tools, Hadoop-Based analytics,Coding skills across Python and Tibco Spotfire,Data modelling across OT and IT datasets,A solid background in business requirements gathering (use cases) and agile delivery,Excellent interpersonal skills and the ability to work well and effectively with a range of business and project stakeholders.,Ability to question, challenge and collaboratively find better ways of working,Excellent communication and presentation skills,Motivated individual with the ability to make decisions and take direction.,Mining or resource industry experience or ability to transfer skill set into mining,Business analyst skills,Esri Insight and Akumen","
Data Engineer with Strong business analyst and people skills. Experienced in working across Operational and Information Technology.
Adelaide
We have an immediately requirement for an experienced Data Engineer with exceptional communicational skills and ability to hit the ground running.
Responsibilities will include but not limited too;
Creation and maintenance of reporting and analytics infrastructure
Full lifecycle of Performance Hub architectures, for the creation of data set processes used in modelling, mining, acquisition, and verification
Solid command of common scripting languages and tools
Abilities needed:
Skills to constantly improve data quality and quantity by leveraging and improving data analytics systems
Provide a link between the business and the solution providers within the context of functional alignment
Identify and communicate risks and issues as they arise
Travel to Site, on average 1 trips per month of 2 to 3 days
Mandatory requirements:
In-depth knowledge of SQL, Data warehousing, ETL tools, Hadoop-Based analytics
Coding skills across Python and Tibco Spotfire
Data modelling across OT and IT datasets
A solid background in business requirements gathering (use cases) and agile delivery
Excellent interpersonal skills and the ability to work well and effectively with a range of business and project stakeholders.
Ability to question, challenge and collaboratively find better ways of working
Excellent communication and presentation skills
Motivated individual with the ability to make decisions and take direction.
Highly Desirable
Mining or resource industry experience or ability to transfer skill set into mining
Business analyst skills
Esri Insight and Akumen
Machine learning and statistical analysis
To be considered for the role click the 'Apply' button or for more information about this and other opportunities please contact Simone Yearsley on 08 74220613. Please quote our job reference number: 200172870.
Reference Number: 200172870_1
Contact Details:
How to Apply?
Click on the link below
Click here for more information about this job
",https://www.computerworld.co.nz/jobs/view/31841/data-engineer/
JOB42631338818,Data Engineer,Data Engineer,,,"
Data Engineer X 2 – Manchester. Our client based near Manchester are currently looking for 2 Data Engineers with Azure experience. The company is currently going through a large digital transformation, they are looking for talented Data specialist to help...
Job Title: Data Engineer Salary: 45,000 to 54,000 plus Benefits Location: Cambridge This is a very rare opportunity for an experienced Data Engineer with a strong background in building Python based data processing pipelines to join a company that are...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
As a data engineer within the exciting, new claims advanced analytics capability, you will be building big data solutions to solve some of the organization’s toughest problems and delivering significant business value. This is a really exciting time to...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Title: Data Engineer Our client is currently looking for a Data Engineer to play a vital role in the continual development of our digital transformation strategy and earth science analytics. Candidates must have Python, R and SQL. We expect candidates...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer - Python - Permanent Data Idols are working with a well-known client in the e-commerce space who are looking for a Data Engineer to join an existing team. THE ROLE As a Data Engineer, you will be working with the existing Data team to help...
Data Engineer - Manchester A growing business based in Manchester City Centre are currently looking for a Data Engineer to help shape their newly formed Data Engineering team and build scalable, reliable and secure cloud datawarehouse solutions and data...
An exciting start up Fintech company has a new opportunity for a Data Engineer where you will play an active part in the success of the company. This role will see you joining a small team where you'll have the opportunity to take responsibility for Data...
Data Engineer Location: Petersfield Salary: 30,000 - 40,000 P/A Hours: Flexible Dynamite Recruitment is delighted to be recruiting a Data Engineer for a global organisation in Petersfield This is an exciting opportunity for an experienced individual to...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer- 50K Manchester Adria Solutions has an exciting opportunity for a talented Data Engineer to join our rapidly expanding client based near Manchester. The role requires you to work closely with other members of the data team and stakeholders...
Data Engineer (12-month Fixed Term Contract) 50,000 - 55,000 We are looking for a Data Engineer to join a market leading business we're representing, based in central London. Working as part of the central Data Science & Analytics team, you will be...
DATA ENGINEER - CURRENTLY REMOTE WORKING LEEDS - CURRENTLY REMOTE WORKING BETWEEN 35,000 - 50,000 BENEFITS BONUS Harnham are partnered with a Financial Services Company to help hire for a Data Engineer within their Business Intelligence team. The team...
DATA ENGINEER - CURRENTLY REMOTE WORKING LEEDS - CURRENTLY REMOTE WORKING BETWEEN 35,000 - 50,000 BENEFITS BONUS Harnham are partnered with a Financial Services Company to help hire for a Data Engineer within their Business Intelligence team. The team...
Data Engineer London 55,000 - 65,000 Benefits Our client, an exciting RegTech business is looking to recruit for a Data Engineer to join their growing team. The successful candidate will be joining the artificial intelligence team, working on a brand new...
Data Engineer - Azure - Data Warehousing - Staffordshire - 50k Hiring remotely Greenfield project Home working I am working with an organisation in Staffordshire who are seeking a Data Engineer to join their growing Data & Analytics team. Data &...
",https://www.reed.co.uk/jobs/data-engineer/40396668
JOB43742767619,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-za/details/200188037/ai-ml-search-data-engineer-siri-data
JOB43816409929,Data Engineer,Data Engineer,,,"
Data Engineer X 2 – Manchester. Our client based near Manchester are currently looking for 2 Data Engineers with Azure experience. The company is currently going through a large digital transformation, they are looking for talented Data specialist to help...
Job Title: Data Engineer Salary: 45,000 to 54,000 plus Benefits Location: Cambridge This is a very rare opportunity for an experienced Data Engineer with a strong background in building Python based data processing pipelines to join a company that are...
",https://www.reed.co.uk/jobs/data-engineer/40297684
JOB45579382291,Mission Data Engineer Sr Stf,Mission Data Engineer Sr Stf,,,,https://www.avjobs.com/jobs/positions.asp?q=Mission+Data+Engineer+Sr+Stf
JOB47967021581,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-eg/details/200188037/ai-ml-search-data-engineer-siri-data
JOB48594397741,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-lt/details/200188037/ai-ml-search-data-engineer-siri-data
JOB50503762761,3M HIS Data Engineer,3M HIS Data Engineer,,,"
Job Description: Data Engineer Collaborate with Innovative 3Mers Around the World Choosing where to start and grow your career has a major impact on your professional and personal life, so it?s equally important you know that the company that you choose to work at, and its leaders, will support and guide you. With a diversity of people, global locations, technologies and products, 3M is a place where you can collaborate with 93,000 other curious, creative 3Mers. ?3M?s culture is driven by curious, spirited and collaborative people who are constantly asking ?What if??
And the many talents of 3Mers around the globe have me incredibly excited about what?s to come next.? ? Kristen Ludgate, senior vice president of Human Resources at 3M This position provides an opportunity to transition from other private, public, government or military environments to a 3M career.
*The Impact You?ll Make in this Role As a(n) you will have the opportunity to tap into your curiosity and collaborate with some of the most innovative and diverse people around the world. Here, you will make an impact by: Designing, coding, debugging, and testing, ETL modules and related data structures in support of the 3M HIS Healthcare Data Pipeline Building high-quality, innovative, and fully performing features that comply with 3M's coding standards and technical design Contributing to an Agile team, to build data pipeline enhancements, automated tests, and automated deployments that meet the requirements defined by the Product Owner *Your Skills and Expertise To set you up for success in this role from day one, 3M is looking for candidates who must have the following qualifications: Possess a Bachelor?s degree or higher (completed and verified prior to start) from an accredited institution OR High School Diploma/GED or higher from an accredited institution and a minimum of?five (5) years software development experience in lieu of a bachelor?s degree Two (2) years development experience with object oriented programming, such as Java, C#, C++ or Python (Course work and internships considered) Two?(2) years data warehousing experience with technologies such as MySQL, MS SQL Server, AWS RDS, AWS Aurora, AWS DynamoDB or Oracle (Course work and internships considered) Additional qualifications that could help you succeed even further in this role include: Healthcare Data and X12 standards AWS Glue Spark/Distributed processing Continuous Integration/Continuous Deployment Agile/Scrum Travel: May include up to 10% domestic Relocation Assistance: Not authorized Location: Albany, NY Supporting Your Well-being 3M offers many programs to help you live your best life ? both physically and financially.
To ensure competitive pay and benefits, 3M regularly benchmarks with other companies that are comparable in size and scope. Resources for You For more details on what happens before, during and after the interview process, check out the Insights for Candidates page at 3M.com/careers. Learn more about 3M?s creative solutions to the world?s problems at www.3M.com or on Twitter @3M.
3M is an equal opportunity employer. 3M will not discriminate against any applicant for employment on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, or veteran status. Please note: your application may not be considered if you do not provide your education and work history, either by: 1) uploading a resume, or 2) entering the information into the application fields directly.
3M Global Terms of Use and Privacy Statement Carefully read these Terms of Use before using this website. Your access to and use of this website and application for a job at 3M are conditioned on your acceptance and compliance with these terms. Please access the linked document by clicking here, select the country where you are applying for employment, and review.
Before submitting your application you will be asked to confirm your agreement with the terms.
","https://www.ziprecruiter.com/c/3M/Job/3M-HIS-Data-Engineer/-in-Albany,NY?ojob=5b8e25d9bf783fbe650e97eaee178d6c"
JOB51110407722,Mid Level Data Engineer,Mid Level Data Engineer,,,,https://www.avjobs.com/jobs/positions.asp?q=Mid+Level+Data+Engineer
JOB51803904858,Data Engineer Jobs,Data Engineer Jobs,,,"
DESCRIPTION At Amazon Advertising, we are dedicated to drive measurable outcomes for brand advertisers, agencies, authors, and entrepreneurs. Our ad solutions—including sponsored, display, video, and custom ads—leverage Amazon’s innovations and insights...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
As the Data Engineer for this amazing corporate Insurance company, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL, together...
See more: Engineer jobs
As a data engineer within the exciting, new claims advanced analytics capability, you will be building big data solutions to solve some of the organization’s toughest problems and delivering significant business value. This is a really exciting time to...
See more: Engineer jobs
Data Engineer - 70,000 Job Description An AWS Partner based in Central London is looking to expand the data side of their business due to growth. They are looking for Data Engineers with significant commercial experience ingesting large quantities of data...
See more: Engineer jobs
As the Data Engineer for this amazing corporate Insurance company in the City, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
DATA ENGINEER - TEMPORARILY REMOTE 400- 450 PER DAY 3 MONTH CONTRACT EUROPE BASED As a Data Engineer you will be working heavily with Scala and Spark to improve the quality of data. THE COMPANY: You will be working for dynamic data driven company. As a...
See more: Engineer jobs
40'000- 50'000 Pension 8% Technical Progression Healthcare Holidays More Horley, Surrey Are you seeking a new challenge within a rapidly expanding Eco-Energy Tech company where you will be having huge technical autonomy in building a data preform right...
See more: Engineer jobs
Role: Data Engineer Client: Government agency (BPSS will be required) Location: Glasgow Duration: 8 Months Rate: 400 per day (outside IR35) Note: The office is based in Glasgow city centre. It is expected that the consultant would be available for physical...
See more: Engineer jobs
A leading Insurance Company are currently recruiting for a Data Engineer to join their dynamic and growing business. They are looking to hire a cross functional, highly tenacious and bright Data Engineer with a passion for functional programming. The ideal...
See more: Engineer jobs
Data Engineer - 6 months - Ware - Hertfordshire Global FMCG is looking for an experienced Data Engineer who will play a pivotal role in operationalizing data and analytics initiatives for digital business initiatives. The bulk of the data engineer's work...
See more: Engineer jobs
Data Engineer - I am currently recruiting for a Data Engineer based in Bath. The role would be on a permanent basis and is paying 40,000 to 45,000 (There could be flex for the right candidate) PA plus a variety of excellent benefits as well as the flexibility...
See more: Engineer jobs
An exciting opportunity for an experienced Data Engineer has arisen in Leeds. After hiring a number of new members of staff at the end of 2019, the organisation are continuing to expand due to winning more projects. Key responsibilites include: Building...
See more: Engineer jobs
Data Engineer Portsmouth and surrounding areas encouraged to apply, multiple office locations Data Engineer required for established, international business. The business is at the forefront of new technologies working with leading Government organisations...
See more: Engineer jobs
Data Engineer A brand new role has arisen for an experienced Database / BI Developer to take the next step in their career and transition into a full Data Engineer to work for one of the most recognisable NGO's in London. We are looking for someone with...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
Data Engineer- 50K Manchester Adria Solutions has an exciting opportunity for a talented Data Engineer to join our rapidly expanding client based near Manchester. The role requires you to work closely with other members of the data team and stakeholders...
See more: Engineer jobs
We are currently recruiting a highly motivated Data Engineer, for a company who are based in London. The Data Engineer will help develop and maintain the business. The Data Engineer will be responsible for the following; Key responsibilities- - Working...
See more: Engineer jobs
Data Engineer - REMOTE WORK If you are a strong Data Engineer, with experience working with Python, R and SQL then this role is ideal. I am working with a large organisation that are market leaders in their respected field. This role will report in to...
See more: Engineer jobs
Data Engineer London 55,000 - 65,000 Benefits Our client, an exciting RegTech business is looking to recruit for a Data Engineer to join their growing team. The successful candidate will be joining the artificial intelligence team, working on a brand new...
See more: Engineer jobs
Title: Data Engineer Our client is currently looking for a Data Engineer to play a vital role in the continual development of our digital transformation strategy and earth science analytics. Candidates must have Python, R and SQL. We expect candidates...
See more: Engineer jobs
Learn more
La Fosse Associates are engaged with a non-profit charity in the recruitment of a Data Engineer. Our client is open to speaking to candidates who have studied Python and want to develop their skills in a supportive environment. The successful candidate...
See more: Engineer jobs
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
See more: Engineer jobs
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
See more: Engineer jobs
",http://www.reed.co.uk/jobs/data-engineer/39954446
JOB52537625959,Data Engineer II,Data Engineer II,50+ career categories,"Find a better job, faster!,Hand-screened leads,No ads, scams, junk,Great job search support","
Contract job. Needs a bachelor's degree and two years' work related experience. Build a strong intuitive understanding of the problem domain, select and transform features, integrate data from multiple sources and enhance data collection procedures.
Job Details
No Remote Work Option
Freelance
Experienced
Bachelor's Degree
No
Company name here
Other benefits listed here
Find a better job, faster!
Hand-screened leads
No ads, scams, junk
Great job search support
50+ career categories
Create an Account to Unlock
To find out more about or apply to this Data Engineer II job—and other great opportunities like it—become a FlexJobs member today!
With FlexJobs, you'll find the best flexible jobs and fantastic expert resources to support you in your job search. If you have any questions, please feel free to contact us.
",https://www.flexjobs.com/publicjobs/data-engineer-ii-1179614
JOB52693850975,Data Engineer Jobs,Data Engineer Jobs,,,"
DESCRIPTION At Amazon Advertising, we are dedicated to drive measurable outcomes for brand advertisers, agencies, authors, and entrepreneurs. Our ad solutions—including sponsored, display, video, and custom ads—leverage Amazon’s innovations and insights...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
As the Data Engineer for this amazing corporate Insurance company, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL, together...
See more: Engineer jobs
As a data engineer within the exciting, new claims advanced analytics capability, you will be building big data solutions to solve some of the organization’s toughest problems and delivering significant business value. This is a really exciting time to...
See more: Engineer jobs
Data Engineer - 70,000 Job Description An AWS Partner based in Central London is looking to expand the data side of their business due to growth. They are looking for Data Engineers with significant commercial experience ingesting large quantities of data...
See more: Engineer jobs
As the Data Engineer for this amazing corporate Insurance company in the City, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL...
See more: Engineer jobs
DATA ENGINEER - TEMPORARILY REMOTE 400- 450 PER DAY 3 MONTH CONTRACT EUROPE BASED As a Data Engineer you will be working heavily with Scala and Spark to improve the quality of data. THE COMPANY: You will be working for dynamic data driven company. As a...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
40'000- 50'000 Pension 8% Technical Progression Healthcare Holidays More Horley, Surrey Are you seeking a new challenge within a rapidly expanding Eco-Energy Tech company where you will be having huge technical autonomy in building a data preform right...
See more: Engineer jobs
Role: Data Engineer Client: Government agency (BPSS will be required) Location: Glasgow Duration: 8 Months Rate: 400 per day (outside IR35) Note: The office is based in Glasgow city centre. It is expected that the consultant would be available for physical...
See more: Engineer jobs
A leading Insurance Company are currently recruiting for a Data Engineer to join their dynamic and growing business. They are looking to hire a cross functional, highly tenacious and bright Data Engineer with a passion for functional programming. The ideal...
See more: Engineer jobs
Data Engineer - 6 months - Ware - Hertfordshire Global FMCG is looking for an experienced Data Engineer who will play a pivotal role in operationalizing data and analytics initiatives for digital business initiatives. The bulk of the data engineer's work...
See more: Engineer jobs
Data Engineer - I am currently recruiting for a Data Engineer based in Bath. The role would be on a permanent basis and is paying 40,000 to 45,000 (There could be flex for the right candidate) PA plus a variety of excellent benefits as well as the flexibility...
See more: Engineer jobs
An exciting opportunity for an experienced Data Engineer has arisen in Leeds. After hiring a number of new members of staff at the end of 2019, the organisation are continuing to expand due to winning more projects. Key responsibilites include: Building...
See more: Engineer jobs
Data Engineer Portsmouth and surrounding areas encouraged to apply, multiple office locations Data Engineer required for established, international business. The business is at the forefront of new technologies working with leading Government organisations...
See more: Engineer jobs
Data Engineer A brand new role has arisen for an experienced Database / BI Developer to take the next step in their career and transition into a full Data Engineer to work for one of the most recognisable NGO's in London. We are looking for someone with...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
Data Engineer- 50K Manchester Adria Solutions has an exciting opportunity for a talented Data Engineer to join our rapidly expanding client based near Manchester. The role requires you to work closely with other members of the data team and stakeholders...
See more: Engineer jobs
Vacancy: Data Engineer (INTERVIEW SLOTS 25/06/2020) Skills: Python AND Hadoop (1 Year experience minimum) AND SQL AND Leadership Education : Relevant BSc or MSc: Computer Science, Artificial Intelligence, Mathematics etc (relevant degrees accepted) Location:...
See more: Engineer jobs
Data Engineer - REMOTE WORK If you are a strong Data Engineer, with experience working with Python, R and SQL then this role is ideal. I am working with a large organisation that are market leaders in their respected field. This role will report in to...
See more: Engineer jobs
Data Engineer London 55,000 - 65,000 Benefits Our client, an exciting RegTech business is looking to recruit for a Data Engineer to join their growing team. The successful candidate will be joining the artificial intelligence team, working on a brand new...
See more: Engineer jobs
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
See more: Engineer jobs
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
See more: Engineer jobs
Job Description AWS DATA ENGINEER - 6 MONTHS - LONDON - OUTSIDE IR35 Key Skills Experience with functional programming and distributed systems Exposure with streaming technologies, preferably Kafka Experience with Amazon AWS platform (Athena, S3, DynamoDB...
See more: Engineer jobs
Our client in Guildford is looking for a Data Engineer to integrate data and generate models that enable their data scientists to build and assess a multitude of analytical use cases designed to optimise human decisions and manual processes across their...
See more: Engineer jobs
A large consultancy business in London is looking for a Data Engineer to integrate data and generate models that enable their data scientists to build and assess a multitude of analytical use cases designed to optimise human decisions and manual processes...
See more: Engineer jobs
Data Engineer London Up to 49,000 A reputable organisation based in London are seeking a talented Data Engineer to design and develop complex and group-wide data solutions. Job Duties - Plan and achieve agile sprint tasks from which the technical solutions...
See more: Engineer jobs
",http://www.reed.co.uk/jobs/data-engineer/39927363
JOB53172282005,Data Engineer,Data Engineer,"5+ years experience building traditional data warehouse solutions, are knowledgeable about data modeling, data access, and data storage techniques.,You understand standard methodologies for ETL, and are proficient in debugging and optimizing pipelines.,You can easily transition from one ETL tool set e.g., Informatica to Kettle to more programmatic approaches such as Python/SQL or Spark/Scala,Extensive Experience with SQL and understanding of NoSQL solutions,You have significant coding experience in Java, Python and want to apply those skills to processing big data.,5+ years experience with object-oriented design, coding and testing patterns as well as experience in engineering open source software platforms and large-scale data infrastructures.,You have an understanding of distributed systems, NoSQL solutions such as Redshift or BigQuery.,Familiar with Google Cloud or other cloud provider products and servers,You are able to work in teams and collaborate with others to clarify requirements,You have a Bachelor’s degree or Master’s in information Technology or relevant discipline.,Experience with automation, build tools, release engineering,Bonus: Experience with Spark/Scala, distributed data systems and MPP databases","Every few months, we have a “hack week” that gives our developers the opportunity to explore ideas that might not otherwise make it on the product roadmap.,We are committed to career development. We offer a formal mentoring program as well as tuition reimbursement. We have frequent panel discussions and talks by industry leaders (Sheryl Sandberg, Melinda Gates and Ta-Nahesi Coates are a few recent examples).,We believe diversity fuels innovation and creativity, and we have a variety of employee groups dedicated to fostering a diverse and inclusive workplace.,We offer a generous parental leave policy, which was recently expanded in response to employee feedback. Birth mothers receive 16 weeks fully paid, adoptive parents and birth fathers receive 10 weeks fully paid. Similarly, we offer competitive health and dental insurance, as well as 401k matching.,Implement complex data projects with a focus on collecting, parsing, analyzing and visualizing large sets of data to turn information into insights across multiple platforms.,Build fault tolerant, self-healing, adaptive and highly accurate ETL platforms.,Design and develop the data model(s) for the Data Warehouse, Data Marts or NoSQL solutions which will be vetted by the team and or guided by the Senior Data Solutions Architect.,Responsible for data administration of warehouse solutions.,Take ownership of the warehouse solutions, troubleshoot issues, and provide production support.,Document processes and standard operating procedures for processes.,Generate reports using a variety of reporting tools such as Business Objects, Tableau, Pentaho.,Work with team of developers who are transitioning current in-house data warehouse solution to Google Cloud platform.","The New York Times is seeking a creative, passionate, and experienced data engineer to join the Data Warehouse team. In this role, you will be instrumental in building critical ETL applications to surface data and insights across the company.
Who are we?
Our team collaborates with data analysts, data scientists, product, marketing and finance to develop state-of-the-art data solutions used for analysis and reporting. We are focused on innovation around increasing our digital subscriber base, understanding the lifecycle of subscribers and as well as retaining our valuable print subscriber base. Currently, the team is re-examining our subscription and financial data warehouses and figuring out the best approach for integration into our Google Cloud Platform.
Who are we looking for?
We’re looking for an excellent hands-on developer who is skilled in solving data warehouse problems using traditional ETL tools but also has experience building applications in languages like Python, Java, or Scala and is excited to phase into big data work on a platform like Google Cloud & BigQuery. You have a strong understanding of dimensional data warehouse data models. You are comfortable sitting with engineers, business owners, data analysts and able to own and shape a subject area to move the business forward. We’re looking for someone who is innovative, loves solving data problems, can present their solution to the team and take it to all the way to production. You should have an attention to detail, capable of analyzing downstream effects of data architectures, reporting processes and potential impact to business owners. Overall you take great pride and ownership of your work.
You are passionate about the New York Times and believe in it’s mission. You’ll have the opportunity to participate in modernizing approaches to ingest, move, process, store and expose consumer datasets to surface meaningful data to our internal business partners. You will improve and maintain data that are used by our executives and diverse sets of teams across the company. You are excited about data and motivated to learn new technologies. You enjoy being part of team who are creative developers and are well-versed in building data-driven solutions and are using state-of-the-art technologies such as Spark/Scala and BigQuery. Above all we have fun, work hard and and we take our responsibilities very seriously.
Every few months, we have a “hack week” that gives our developers the opportunity to explore ideas that might not otherwise make it on the product roadmap.
We are committed to career development. We offer a formal mentoring program as well as tuition reimbursement. We have frequent panel discussions and talks by industry leaders (Sheryl Sandberg, Melinda Gates and Ta-Nahesi Coates are a few recent examples).
We believe diversity fuels innovation and creativity, and we have a variety of employee groups dedicated to fostering a diverse and inclusive workplace.
We offer a generous parental leave policy, which was recently expanded in response to employee feedback. Birth mothers receive 16 weeks fully paid, adoptive parents and birth fathers receive 10 weeks fully paid. Similarly, we offer competitive health and dental insurance, as well as 401k matching.
Salary commensurate with experience.
Responsibilities
Implement complex data projects with a focus on collecting, parsing, analyzing and visualizing large sets of data to turn information into insights across multiple platforms.
Build fault tolerant, self-healing, adaptive and highly accurate ETL platforms.
Design and develop the data model(s) for the Data Warehouse, Data Marts or NoSQL solutions which will be vetted by the team and or guided by the Senior Data Solutions Architect.
Responsible for data administration of warehouse solutions.
Take ownership of the warehouse solutions, troubleshoot issues, and provide production support.
Document processes and standard operating procedures for processes.
Generate reports using a variety of reporting tools such as Business Objects, Tableau, Pentaho.
Work with team of developers who are transitioning current in-house data warehouse solution to Google Cloud platform.
Qualifications
5+ years experience building traditional data warehouse solutions, are knowledgeable about data modeling, data access, and data storage techniques.
You understand standard methodologies for ETL, and are proficient in debugging and optimizing pipelines.
You can easily transition from one ETL tool set e.g., Informatica to Kettle to more programmatic approaches such as Python/SQL or Spark/Scala
Extensive Experience with SQL and understanding of NoSQL solutions
You have significant coding experience in Java, Python and want to apply those skills to processing big data.
5+ years experience with object-oriented design, coding and testing patterns as well as experience in engineering open source software platforms and large-scale data infrastructures.
You have an understanding of distributed systems, NoSQL solutions such as Redshift or BigQuery.
Familiar with Google Cloud or other cloud provider products and servers
You are able to work in teams and collaborate with others to clarify requirements
You have a Bachelor’s degree or Master’s in information Technology or relevant discipline.
Experience with automation, build tools, release engineering
Bonus: Experience with Spark/Scala, distributed data systems and MPP databases
#LI-SL1
If interested, send us a resume at digitaljobs@nytimes.com
The New York Times is an Equal Opportunity Employer and does not discriminate on the basis of an individual's sex, age, race, color, creed, national origin, alienage, religion, marital status, pregnancy, sexual orientation or affectional preference, gender identity and expression, disability, genetic trait or predisposition, carrier status, citizenship, veteran or military status and other personal characteristics protected by law. All applications will receive consideration for employment without regard to legally protected characteristics.
",http://www.nytco.com/careers/technology/data-engineer/
JOB53189552652,"AI/ML - Sr Data Engineer, Siri Data","AI/ML - Sr Data Engineer, Siri Data","You have excellent written and verbal communication skills.,You are tenacious, relentless, & determined.,You are curious: always learning new technologies, rapidly synthesizing new information, and understanding “the why” before “the what.”,You are self-directed and capable of operating amid ambiguity.,You are poised and display excellent judgment in prioritizing across difficult tradeoffs.,You are pragmatic: not letting “the perfect” be the enemy of “the good.”",,"Would you like to play a critical part in the next revolution of human-computer interaction? Would you like to contribute to the advancement of a product that is globally redefining how humans use voice to relate to technology? The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within Siri Data, the mission of Siri data engineering is to build the scalable & high quality data sets that curate the data required to give our customers their voice. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream analytical & product consumers.
You have excellent written and verbal communication skills.
You are tenacious, relentless, & determined.
You are curious: always learning new technologies, rapidly synthesizing new information, and understanding “the why” before “the what.”
You are self-directed and capable of operating amid ambiguity.
You are poised and display excellent judgment in prioritizing across difficult tradeoffs.
You are pragmatic: not letting “the perfect” be the enemy of “the good.”
You are humble, continually growing in self-awareness and possessing a growth mindset.
WHAT WILL FILL YOUR DAYS: - Moving between understanding the open & unanswered questions about Siri; to defining new metrics and filters; to specifying new logging necessary with the high-level goal of using data to improve Siri. - Designing, creating, and maintaining data pipelines that populate a petabyte scale data warehouse. - Working with data infrastructure teams providing input to improve our platform. - Working with data producing teams to specify requirements and to transparently provide rapid feedback. - Partnering with your teammates across Siri data to answer questions, to provide support, and to innovate in taking our data warehouse to the next level.
- Surprise us! Many will have an MS or BS in CS, Engineering, Math, Statistics, or a related field OR equivalent practical experience in data engineering. - 4+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, Flink, Kafka, etc.) for building efficient & large-scale data pipelines. - Software Engineering proficiency in at least one high-level programming language (Java, Scala, Python or equivalent). - Experience required in building batch data processing pipelines curating data for data science consumers. - Experience strongly preferred building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others.
",https://jobs.apple.com/en-us/details/200111028/ai-ml-sr-data-engineer-siri-data
JOB53282319775,"Senior Data Engineer, Online","Senior Data Engineer, Online","BA/BS Degree in Computer Science, any Engineering discipline, Statistics, Information Systems or another quantitative field.",Apply strong technical skills in a data engineering team building industry-leading technology,"
POSITION PURPOSE
As the Data Engineer within Online Analytics & BI, you will be responsible for development of the workflow orchestration & ETL pipelines within marketing's analytics and data science platforms. You will ensure that the data pipeline infrastructure meets the analysis, reporting, and data science needs of the marketing organization.
This position calls for top technical talent to implement continued design, development and optimization of the marketing data pipelines & data prep infrastructure built on cutting-edge cloud technologies.
Additional Roles & Responsibilities
Apply strong technical skills in a data engineering team building industry-leading technology
Embrace an active team role to help design, implement, and launch efficient and reliable data pipelines moving data across a number of platforms including Data Warehouse, online caches and real-time systems.
Create data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Deploy workflow orchestration and demonstrate expertise in data modeling, ETL development, and data warehousing
Build industry-leading tools to increase productivity of Data Analysts, Data Scientists and Marketers
Help Marketing organization to become a 100% data-driven organization by building a next generation data platform that brings accurate and timely data to the Marketers
Validate Data Engineering business data elements, organizational and business intelligence architecture designs for engineering functional areas from Dashboards, Data Lakes, Data Operations, ML - AI, and upstream/downstream intake and output processes
MAJOR TASKS, RESPONSIBILITIES AND KEY ACCOUNTABILITIES
50%-Design and develop robust, user friendly applications, reports and dashboards using BI tools like MicroStrategy and SAS
25%-Partner with leaders to identify needs and gather requirements. Provide solutions by building tools, reports and predictive models. Automate reporting as needed
25%-Research and document best practices and standards for using our BI tools. Provide insight on industry trends
NATURE AND SCOPE
Position reports to Sr Manager or Manager, Online Business Intelligence.
Position has no direct reports.
ENVIRONMENTAL JOB REQUIREMENTS
Environment:
Located in a comfortable indoor area. Any unpleasant condition
Travel:
Typically requires overnight travel less than 10% of the time.
Additional Environmental Job Requirements:
MINIMUM QUALIFICATIONS
Must be eighteen years of age or older.
Must be legally permitted to work in the United States.
Additional Minimum Qualifications:
Education Required: The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.
Years of Relevant Work Experience: 3 years
Physical Requirements:
Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.
Additional Qualifications:
Preferred Qualifications:
BA/BS Degree in Computer Science, any Engineering discipline, Statistics, Information Systems or another quantitative field.
4+ years of industry experience in data engineering, data science, or related field with a track record of manipulating, processing, and extracting value from large datasets
Experience building and managing data pipelines and repositories in cloud environments such as Google Cloud, Microsoft Azure or AWS
Experience in Airflow is a must
Experience extracting/cleansing data and generating insights from large transactional data sets using Spark SQL, SQL, Python, and PySpark on cloud
Experience with optimizing Spark pipelines on Dataproc, Databricks or similar technologies.
Strong verbal and written communications skills at all levels; ability to communicate complex customer behavior information to both functional partners and Executive Leadership
Open to idea exploration with strong problem-solving/analytical abilities
Demonstrated strength in creating partnerships and in building relationships with other functions and associates within the organization
Knowledge, Skills, Abilities and Competencies:
Strong decision making and problem solving skills
Proficiency in Microsoft Excel and Access
Ability to lead and manage cross functionally
Strong organizational, analytical and customer service skills
We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
",https://www.careerbliss.com/jobs/detail/552490740/
JOB53375654778,Data Engineer,Data Engineer,,"Use technology such as Spark, Kafka and SQS to build large scale real time and batch data pipelines.,Help implement cloud technologies such as AWS, Azure or GCP.,Program in at least one of the following languages - Java, Scala or Python.,Proven experience in data development in a big data/ Hadoop and cloud data warehouse using SQL or SQL based ETL capabilities.,Have a deep understanding of the processes, skills and technologies which are needed to deliver complex development solutions for a business.,Understand and have experience working with a variety of delivery methods, such as Agile, Waterfall and Scrum.,Experience developing in the cloud with AWS or Snowflake.,Work in one of the most data rich businesses in the UK.,Competitive bonus.,Discount across brands.","
DATA ENGINEER £45,000- 55,000 + BONUS + COMPETITIVE BONUS
CENTRAL LONDON
Are you looking to join one of the largest retailers, with one of the most visited websites in the UK as a Data Engineer where you will be working on huge data sets in a serverless environment? You will be using the latest technology solutions and have the opportunity to make a real impact within your squad due to a highly collaborative culture.
THE COMPANY:
As one of the largest retailers in the UK with multiple sub-brands you will be working in a data rich environment across a wide variety of projects. You will help deliver solutions to millions of customers across the UK and provide real value both to customers and stakeholders within the business.
THE ROLE:
You will be joining a team of highly experienced and passionate data engineers and architects to undertake data transformation and solution development. You will be working with a wide range of tools across a mix of Big Data, Cloud and open source platforms.
In specific, you can expect to be involved in the following:
Use technology such as Spark, Kafka and SQS to build large scale real time and batch data pipelines.
Help implement cloud technologies such as AWS, Azure or GCP.
Program in at least one of the following languages - Java, Scala or Python.
Work as part of an Agile squad to deliver solutions in a flexible manner.
YOUR SKILLS AND EXPERIENCE:
The successful Data Engineer will have the following skills and experience:
Proven experience in data development in a big data/ Hadoop and cloud data warehouse using SQL or SQL based ETL capabilities.
Have a deep understanding of the processes, skills and technologies which are needed to deliver complex development solutions for a business.
Understand and have experience working with a variety of delivery methods, such as Agile, Waterfall and Scrum.
Experience developing in the cloud with AWS or Snowflake.
Understand the process of developing data stores and data warehouses and have hands on experience in doing so in a previous role.
THE BENEFITS:
Work in one of the most data rich businesses in the UK.
Competitive bonus.
Discount across brands.
Competitive benefits.
HOW TO APPLY:
Please register your interest by sending your CV to Lillie via the Apply link on this page.
",https://www.reed.co.uk/jobs/data-engineer/39677514
JOB53446637499,Data Engineer | London,Data Engineer | London,,,"
As a SQL Developer in our Technology department you will have experience in the design, development, delivery, optimisation and troubleshooting of data solutions, primarily delivered on Microsoft SQL Server and Azure SQL Database.
Alongside you’ll have exposure to SDLC and an understanding of how data solutions are built, deployed and tested through CI/CD automation.
You will be enthusiastic and keen to expand your data engineering skills to deliver outstanding solutions to high-usage, high-availability business problems.
This role offers exposure to new and exciting NoSQL data stores and since these stores are accessed using .net and .net core SDKs, an understanding of iterative languages such as C# or java would be very advantageous.
This is a great opportunity to work collaboratively alongside our existing team of talented Solution Architects, and Software and Data Engineers to implement the optimum data solutions to business problems, ensuring every solution meets the non-functional requirements defined by the business. Our mission is to delivery grade A data solutions and we can only do that with the right people and a collaborative culture. We expect you to grow as an individual and we will provide the tools and mentoring to help accomplish your career aspirations.
What you’ll be doing:
· Working within a team or team(s) of software engineers, you will bring a depth of database development understanding. You will participate in the planning, best practice implementation and delivery of micro-services which are dependent on low latency, highly available and distributed data stores.
· Ensuring that data engineering is an integral part of the development process, following the same practices of source control, build, automated testing, versioning and deployment.
· Helping to identify potential performance issues, bottlenecks and pain points and recommend ways to mitigate or resolve them.
· Engineering approaches for storing, transforming, transporting, synchronising, archiving and securing data.
We would like an individual who:
· Understands the importance of a good team dynamic, is a very capable communicator and comfortable receiving feedback.
· Utilises their experience in order to help teams resolve and overcome technical challenges.
· Is self-motivated and inquisitive with a desire to endlessly improve and take their skills to the next level.
· Has at least 1 year experience with an iterative coding language such as C#, javascript, etc.
· At least 3 years experience working with Microsoft SQL Server or equivalent RDBMS with an understanding of
o Stored Procedures / Functions / Triggers / Views
o Transaction isolation levels
o Indexing
o Query plans and optimisation
Desirable skills:
· Microsoft Azure SQL Database
· Exposure to an enterprise system running in Azure
· Cosmos DB / Mongo DB or equivalent NoSQL data store
· OLTP database design
· Object orientated programming
For more information about this role please contact our Talent Partner, Vashma Bolton, on Vashma.Bolton@ASOS.com
#LI-VB1
",https://www.indeed.co.uk/job/Data-Engineer-London-at-ASOS-in-United-Kingdom-ecf0aeeb71ed1cbb
JOB53795027240,Data Engineer,Data Engineer,,,"
First People Solutions are working on behalf of a leading building support services provider who are looking for experienced Data Cabling Engineers to join their team in London.
The main duties will include but is not limited to:
Data Cabling - Installation of Cat5E, Cat6, Cat6a. Testing cabling using Fluke DTX & DSX.
Fibre Cabling - Installation of fibre cabling. Ability to test fibre cabling using Fluke DTX & DSZ using multimode/single mode tester.
Voice Cabling - Ability to terminate/jumpering voice cabling within 237A Krone strips. Ability to test fibre cabling using Fluke DTX & DSZ data tester
Cabinet & Containment - Ability to install data cabinets & carry out containment.
General - Knowledge of Krone, Systimax, Brand-Rex etc
You must have the ability to work to your own initiative and be able to successfully complete tasks within given timescales. You must have a ECS Grade Card and hold a full clean driving licence.
If interested in the position please apply by attaching your CV or contact Rebecca on 0141 270 5130.
",https://www.totaljobs.com/job/data-engineer/first-people-solutions-job75164590
JOB54010862410,Data Engineer Jobs,Data Engineer Jobs,,,"
DESCRIPTION At Amazon Advertising, we are dedicated to drive measurable outcomes for brand advertisers, agencies, authors, and entrepreneurs. Our ad solutions—including sponsored, display, video, and custom ads—leverage Amazon’s innovations and insights...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
As the Data Engineer for this amazing corporate Insurance company, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL, together...
See more: Engineer jobs
As a data engineer within the exciting, new claims advanced analytics capability, you will be building big data solutions to solve some of the organization’s toughest problems and delivering significant business value. This is a really exciting time to...
See more: Engineer jobs
Data Engineer - 70,000 Job Description An AWS Partner based in Central London is looking to expand the data side of their business due to growth. They are looking for Data Engineers with significant commercial experience ingesting large quantities of data...
See more: Engineer jobs
As the Data Engineer for this amazing corporate Insurance company in the City, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
DATA ENGINEER - TEMPORARILY REMOTE 400- 450 PER DAY 3 MONTH CONTRACT EUROPE BASED As a Data Engineer you will be working heavily with Scala and Spark to improve the quality of data. THE COMPANY: You will be working for dynamic data driven company. As a...
See more: Engineer jobs
40'000- 50'000 Pension 8% Technical Progression Healthcare Holidays More Horley, Surrey Are you seeking a new challenge within a rapidly expanding Eco-Energy Tech company where you will be having huge technical autonomy in building a data preform right...
See more: Engineer jobs
Data Engineer Portsmouth and surrounding areas encouraged to apply, multiple office locations Data Engineer required for established, international business. The business is at the forefront of new technologies working with leading Government organisations...
See more: Engineer jobs
Data Engineer A brand new role has arisen for an experienced Database / BI Developer to take the next step in their career and transition into a full Data Engineer to work for one of the most recognisable NGO's in London. We are looking for someone with...
See more: Engineer jobs
Role: Data Engineer Client: Government agency (BPSS will be required) Location: Glasgow Duration: 8 Months Rate: 400 per day (outside IR35) Note: The office is based in Glasgow city centre. It is expected that the consultant would be available for physical...
See more: Engineer jobs
Data Engineer Opus are working with an excellent niche software development company in Newcastle. The company is at the forefront of their industry and due to their on-going success are now looking for a Data Engineer to take responsibility for organising...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
A leading Insurance Company are currently recruiting for a Data Engineer to join their dynamic and growing business. They are looking to hire a cross functional, highly tenacious and bright Data Engineer with a passion for functional programming. The ideal...
See more: Engineer jobs
Data Engineer- 50K Manchester Adria Solutions has an exciting opportunity for a talented Data Engineer to join our rapidly expanding client based near Manchester. The role requires you to work closely with other members of the data team and stakeholders...
See more: Engineer jobs
Data Engineer - 6 months - Ware - Hertfordshire Global FMCG is looking for an experienced Data Engineer who will play a pivotal role in operationalizing data and analytics initiatives for digital business initiatives. The bulk of the data engineer's work...
See more: Engineer jobs
We are currently recruiting a highly motivated Data Engineer, for a company who are based in London. The Data Engineer will help develop and maintain the business. The Data Engineer will be responsible for the following; Key responsibilities- - Working...
See more: Engineer jobs
Data Engineer - I am currently recruiting for a Data Engineer based in Bath. The role would be on a permanent basis and is paying 40,000 to 45,000 (There could be flex for the right candidate) PA plus a variety of excellent benefits as well as the flexibility...
See more: Engineer jobs
Data Engineer - London - 550-600 per day - 6 month contract SearchData is currently looking to recruit a Data Engineer to work on a cutting-edge DWH project in the financial services industry. As the Data Engineer your role will be to take a leadership...
See more: Engineer jobs
Data Engineer - REMOTE WORK If you are a strong Data Engineer, with experience working with Python, R and SQL then this role is ideal. I am working with a large organisation that are market leaders in their respected field. This role will report in to...
See more: Engineer jobs
Data Engineer London 55,000 - 65,000 Benefits Our client, an exciting RegTech business is looking to recruit for a Data Engineer to join their growing team. The successful candidate will be joining the artificial intelligence team, working on a brand new...
See more: Engineer jobs
An exciting opportunity for an experienced Data Engineer has arisen in Leeds. After hiring a number of new members of staff at the end of 2019, the organisation are continuing to expand due to winning more projects. Key responsibilites include: Building...
See more: Engineer jobs
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
See more: Engineer jobs
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
See more: Engineer jobs
",http://www.reed.co.uk/jobs/data-engineer/39871572
JOB55367195477,"Big Data Engineer, Python, Opensource, Apache, Storm","Big Data Engineer, Python, Opensource, Apache, Storm",,,"
My Client who is a Gaming/Streaming Tech company based in London
is looking for a Big Data Engineer/Developer for a 6 month contract up to £600/day.
The ideal candidate should be well versed in:
-Big Data
-Opensource
-AWS
-Python
-Apache
-Storm
-Kafka
-Scala
My client is looking for someone who can start within 2-3 weeks from now.
Do get in contact if you see this role to be a fit for you.
Reference: 32993967
Bank or payment details should not be provided when applying for a job. reed.co.uk is not responsible for any external website content. All applications should be made via the 'Apply now' button.
Report this job
",https://www.careerjet.co.uk/clk/1712552c8911c66f52d64c2799f5a11c.html
JOB56765560704,Big Data Engineer Consultant,Big Data Engineer Consultant,,," Big Data Engineer Consultant
Location: Lo
ndon/Other UK Location
Salary: £43,000- £55,000
Closing Date: 28 /0 8/2017
Introduction:
The digital revolution is changing everything. It’s everywhere – transforming how we work and play. Are you reacting to the disruption each day or are you leading the way as a digital disrupter? Accenture Digital is driving these exciting changes and bringing them to life across 40 industries in more than 120 countries. At the forefront of digital, you’ll create it, own it and make it a reality for our clients. Join us and become an integral part of our experienced digital team with the credibility, expertise and insight our clients depend on.
Accenture Digital is powered by three practices – Analytics, Interactive, and Mobility. As part of our Analytics practice, you’ll help businesses deliver insight-driven outcomes in entirely new ways.
Accenture Analytics supports clients to turn information into action by driving technology-enabled business insights, creating a ""decision making environment"" embracing social media, cloud, mobility, big data and legacy environments. We deliver and run the information strategy, architecture and governance that enable a ""single source of the truth"", empowering our clients to analyze that data for smarter decision making, actions and outcomes.
We invite you to learn more at: https://www.accenture.com/gb-en/understanding-data-analysis
What responsibilities will you have? · Designing and implementing modern, scalable data pipelines for our clients leveraging Hadoop, NoSQL, Apache open source and emerging technologies, covering on-premise and cloud-based deployment patterns
· Providing advisory services and thought leadership on the selection and deployment of commercial and open source tools to process streaming, micro-batch and low latency workloads
· Designing and implementing data access patterns and data pipelines on Hadoop and NoSQL platforms leveraging agile, DevOps, continuous integration and continuous delivery approaches
· Provide innovative design and deployment approaches that leverage the best of innovations in in-memory processing, agile delivery, automated testing, containerisation etc. to enhance the speed and flexibility of testing analytics hypotheses and apply machine learning at scale
· Working closely with technology partners, Accenture Technology Labs and Innovation centres to incubate emerging technologies and build prototypes/demos to enhance our data engineering codebases and frameworks
· Supporting hackathons which allow us to work with publicly available data and open source tools to create new data engineering patterns and codebases
· Mentoring the next wave of data engineers and providing your skills and experience to enable clients to modernise their existing data pipelines
",https://www.indeed.co.uk/job/Big-Data-Engineer-Consultant-at-Accenture-in-United-Kingdom-66340ba93d8878e0
JOB57919429469,Senior Data Engineer,Senior Data Engineer,,,"
DESCRIPTION Senior Data Engineer Amazon Fashion is a fast moving innovative team that is revolutionizing the future of online Fashion retail to become each customer’s most loved fashion destination. We are looking for candidates that are passionate about...
DESCRIPTION Amazon’s Inventory Prediction and Entitlement (IPE) team, based in Cambridge, U.K. is looking for passionate, hard-working, and talented individuals to join our fast paced, stimulating environment to help invent the future of business ownership...
DESCRIPTION Amazon’s Inventory Prediction and Entitlement (IPE) team, based in Cambridge, U.K. is looking for passionate, hard-working, and talented individuals to join our fast paced, stimulating environment to help invent the future of business ownership...
DESCRIPTION Although this job is posted in London, the real location is CAMBRIDGE, UK. Amazon’s Inventory Prediction and Entitlement (IPE) team, based in Cambridge, U.K. is looking for passionate, hard-working, and talented individuals to join our fast...
DESCRIPTION Love data? Love music? The Amazon Music team is looking for a brilliant, creative, and passionate professional to join our Business Intelligence team. The responsibilities include developing self-serve and automated tools that improve the efficiency...
AstraZeneca is a global biopharmaceutical business that focuses on the discovery, development and commercialisation of prescription medicines for some of the world's most serious diseases. Our growth platforms are doing deeply well, and the impact of our...
AstraZeneca is a global biopharmaceutical business that focuses on the discovery, development and commercialisation of prescription medicines for some of the world's most serious diseases. Our growth platforms are doing deeply well, and the impact of our...
AstraZeneca is a global biopharmaceutical business that focuses on the discovery, development and commercialisation of prescription medicines for some of the world's most serious diseases. At AstraZeneca, we're proud to have a workplace culture that inspires...
X4 Technology are currently working on a remote Senior QA Engineer position with a London based financial services organisation. Due to the growth of the company they are looking for a Senior QA Engineer to help build on existing testing services used...
Infrastructure Engineer / 2nd Line Support - Cambridgeshire - ITIL, Service Desk, Virtualisation 25-27,500 training package Concept IT are looking for an experienced Infrastructure / 2nd Line Support Engineer to join a well-established and growing IT solutions...
I amrecruiting for an Visualisation Engineer / Technical Reporter to join my client's newly established team based in Liverpool on a full-time and permanent basis. This role is at the centre of a period of transformation, helping conceive, create and publicise...
Lead Data & Analytics Engineer – Cambridge Job Description The Lead Data Engineer will have a technical background across the full BI stack but will also have experience leading teams of senior developers. The Lead Data Engineer will work very closely...
An international leading broadcast media technology organisation is seeking an experienced Infrastructure Engineer to support and provide technical solutions for internal infrastructure and technical project solutions. You will be the senior technical...
We are looking for a motivated and high-achieving Software Engineer based in London to join the team on our vision to optimise every business on the planet. This is a full-time placement with significant opportunities for personal development. We offer...
DESCRIPTION Are you an experienced Business Intelligence Engineer with a strong work ethic? If yes, this opportunity will appeal to you. At Amazon, we're working to be the most customer-centric company on earth. To get there, we need exceptionally talented...
We are delighted to offer the below opportunity for a SENIOR IT ENGINEER ( 35-40K) to join my client located in Hitchin, Hertfordshire. This opportunity will suit a strong infrastructure engineer who brings knowledge/experience as a real all-rounder...
Junior DevOps Engineer Job based in Wrexham I am working with a leading business that are on a huge expansion drive now, of whom are seeking to add a Junior DevOps Engineer to their team. You will be working collaboratively with Data Engineers, Data Scientists...
Job Title: Air Quality Engineer/Service Manager Location: Near Stansted, Essex - Could be Home Based Salary: c. 35,000 Term : Permanent Our client specialises in ambient air quality, providing top class equipment and services to customers worldwide. 2020...
SENIOR SOFTWARE ENGINEER - DV CLEARED BRAND NEW PERMANENT JOB OPPORTUNITY AVAILABLE WITHIN A GLOBALLY LEADING DEFENCE COMPANY FOR A SENIOR SOFTWARE ENGINEER Permanent job opportunity for a Senior Software Engineer Globally leading defence / cyber security...
Senior Application Support Engineer - Linux, Postgres, Apache, Jenkins - Liverpool - 40,000 The Role Are you an Application Support Engineer who is looking for the next step in your career? Do you want to work for a market leading entertainment company...
Application Support Engineer required by leading Software Application Company based in North Wales, about 30 minutes from Chester. As a Support Engineer you will earn a salary up to 28K Benefits and will be working on a 24x7 basis to ensure that Incidents...
CAD Engineer required working on a large scale Shipping/Marine project. The project is to re-engineer a large vessel. The CAD Engineer will be responsible for all modelling and drawings completed alongside the Senior Engineer and Project Manager Previous...
Senior Service Desk Engineer is required to join a leading company, providing internal IT support, from their head office based in central Bournemouth. The role of a Senior Service Desk Engineer would be to work within their service desk environment which...
DESCRIPTION Come and be a part of Amazon's amazing growth story Are you looking for an opportunity to solve deep technical problems and build innovative solutions in a fast-paced environment working with smart, passionate software developers? Do you want...
Electrical Design Engineer Up to 45,000 London Seeking a Electrical Design Engineer to join a Building Services Engineering consultancy in their London office during their fastest period of growth to date. You will be joining a strong team of engineers...
",http://www.reed.co.uk/jobs/senior-data-engineer/40360468
JOB57956633951,Principal Oracle Data Engineer,Principal Oracle Data Engineer,50+ career categories,"Hand-screened leads,No ads, scams, junk,Great job search support","
Principal Oracle Data Engineer
Remote position will be responsible for installation, configuration, maintenance/tuning of database systems, hands-on participation/facilitation of full life cycle implementation, and develop solutions. Need hands-on experience.
Job Details
Option for Remote
Employee
Full-Time
Entry-Level
Yes, a bit
Company name here
Other benefits listed here
Hand-screened leads
No ads, scams, junk
Great job search support
50+ career categories
Create an Account to Unlock
To find out more about or apply to this Principal Oracle Data Engineer job—and other great opportunities like it—become a FlexJobs member today!
With FlexJobs, you'll find the best flexible jobs and fantastic expert resources to support you in your job search. If you have any questions, please feel free to contact us.
",https://www.flexjobs.com/publicjobs/principal-oracle-data-engineer-1314307
JOB59026267006,Data Engineer Jobs,Data Engineer Jobs,,,"
DESCRIPTION At Amazon Advertising, we are dedicated to drive measurable outcomes for brand advertisers, agencies, authors, and entrepreneurs. Our ad solutions—including sponsored, display, video, and custom ads—leverage Amazon’s innovations and insights...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
As the Data Engineer for this amazing corporate Insurance company, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL, together...
See more: Engineer jobs
As a data engineer within the exciting, new claims advanced analytics capability, you will be building big data solutions to solve some of the organization’s toughest problems and delivering significant business value. This is a really exciting time to...
See more: Engineer jobs
Data Engineer - 70,000 Job Description An AWS Partner based in Central London is looking to expand the data side of their business due to growth. They are looking for Data Engineers with significant commercial experience ingesting large quantities of data...
See more: Engineer jobs
As the Data Engineer for this amazing corporate Insurance company in the City, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
DATA ENGINEER - TEMPORARILY REMOTE 400- 450 PER DAY 3 MONTH CONTRACT EUROPE BASED As a Data Engineer you will be working heavily with Scala and Spark to improve the quality of data. THE COMPANY: You will be working for dynamic data driven company. As a...
See more: Engineer jobs
40'000- 50'000 Pension 8% Technical Progression Healthcare Holidays More Horley, Surrey Are you seeking a new challenge within a rapidly expanding Eco-Energy Tech company where you will be having huge technical autonomy in building a data preform right...
See more: Engineer jobs
Data Engineer Portsmouth and surrounding areas encouraged to apply, multiple office locations Data Engineer required for established, international business. The business is at the forefront of new technologies working with leading Government organisations...
See more: Engineer jobs
Data Engineer A brand new role has arisen for an experienced Database / BI Developer to take the next step in their career and transition into a full Data Engineer to work for one of the most recognisable NGO's in London. We are looking for someone with...
See more: Engineer jobs
Role: Data Engineer Client: Government agency (BPSS will be required) Location: Glasgow Duration: 8 Months Rate: 400 per day (outside IR35) Note: The office is based in Glasgow city centre. It is expected that the consultant would be available for physical...
See more: Engineer jobs
Data Engineer Opus are working with an excellent niche software development company in Newcastle. The company is at the forefront of their industry and due to their on-going success are now looking for a Data Engineer to take responsibility for organising...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
A leading Insurance Company are currently recruiting for a Data Engineer to join their dynamic and growing business. They are looking to hire a cross functional, highly tenacious and bright Data Engineer with a passion for functional programming. The ideal...
See more: Engineer jobs
Data Engineer- 50K Manchester Adria Solutions has an exciting opportunity for a talented Data Engineer to join our rapidly expanding client based near Manchester. The role requires you to work closely with other members of the data team and stakeholders...
See more: Engineer jobs
Data Engineer - 6 months - Ware - Hertfordshire Global FMCG is looking for an experienced Data Engineer who will play a pivotal role in operationalizing data and analytics initiatives for digital business initiatives. The bulk of the data engineer's work...
See more: Engineer jobs
We are currently recruiting a highly motivated Data Engineer, for a company who are based in London. The Data Engineer will help develop and maintain the business. The Data Engineer will be responsible for the following; Key responsibilities- - Working...
See more: Engineer jobs
Data Engineer - I am currently recruiting for a Data Engineer based in Bath. The role would be on a permanent basis and is paying 40,000 to 45,000 (There could be flex for the right candidate) PA plus a variety of excellent benefits as well as the flexibility...
See more: Engineer jobs
Data Engineer - London - 550-600 per day - 6 month contract SearchData is currently looking to recruit a Data Engineer to work on a cutting-edge DWH project in the financial services industry. As the Data Engineer your role will be to take a leadership...
See more: Engineer jobs
Data Engineer - REMOTE WORK If you are a strong Data Engineer, with experience working with Python, R and SQL then this role is ideal. I am working with a large organisation that are market leaders in their respected field. This role will report in to...
See more: Engineer jobs
Data Engineer London 55,000 - 65,000 Benefits Our client, an exciting RegTech business is looking to recruit for a Data Engineer to join their growing team. The successful candidate will be joining the artificial intelligence team, working on a brand new...
See more: Engineer jobs
An exciting opportunity for an experienced Data Engineer has arisen in Leeds. After hiring a number of new members of staff at the end of 2019, the organisation are continuing to expand due to winning more projects. Key responsibilites include: Building...
See more: Engineer jobs
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
See more: Engineer jobs
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
See more: Engineer jobs
",http://www.reed.co.uk/jobs/data-engineer/39893440
JOB60189832995,"Senior Data Engineer (Snowflake, Python)","Senior Data Engineer (Snowflake, Python)",,,,https://www.splunk.com/en_us/careers/jobs/senior-data-engineer-15946.html
JOB62546684465,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/da-dk/details/200188037/ai-ml-search-data-engineer-siri-data
JOB62706428428,Sr. Data Engineer - Health Technologies,Sr. Data Engineer - Health Technologies,"Experience with software engineering frameworks,Excellent coding skills in Python, experience with JVM languages such as Java, Scala,Web Service APIs (e.g. AWS, REST, GraphQL),Data Format SDKs (e.g. Protobuf),Designing and maintaining databases (e.g. Postgres, Apache Parquet),Distributed processing and job scheduling frameworks (e.g. Spark, Hadoop, Airflow, Oozie),Version control frameworks (e.g. Git, virtualenv),macOS/iOS/watchOS development is a nice to have (e.g. Objective-C, Swift),:Familiarity with best practices for information security, including safe harbor privacy principles for sensitive data,You will thrive in our fast-paced environment if you are highly organized and able to multitask.,Flexible thinking, adaptability to change and comfort with ambiguity are hallmarks of successful people on our team.,We look forward to witnessing your excellent communication and interpersonal skills during the interview process.,A proven ability to work seamlessly with others is required to acclimate quickly to our culture.",,"Sr. Data Engineer - Health Technologies
The Health Technologies Team conceives and proves out innovative and exciting technology for Apple’s future products and features in health. We are seeking a highly capable Sr. Data Engineer - Health Technologies to join a multi-disciplinary team. Successful candidates will be able to integrate with our research study leads, data scientists and engineers to develop and support effective data analysis and machine learning workflows.
Experience with software engineering frameworks
Excellent coding skills in Python, experience with JVM languages such as Java, Scala
Web Service APIs (e.g. AWS, REST, GraphQL)
Data Format SDKs (e.g. Protobuf)
Designing and maintaining databases (e.g. Postgres, Apache Parquet)
Distributed processing and job scheduling frameworks (e.g. Spark, Hadoop, Airflow, Oozie)
Version control frameworks (e.g. Git, virtualenv)
macOS/iOS/watchOS development is a nice to have (e.g. Objective-C, Swift)
:Familiarity with best practices for information security, including safe harbor privacy principles for sensitive data
:Experience with biomedical sensors/platforms for measuring physiological signals in the health, wellness and/or fitness realms. Experience with documenting turnkey pipelines for both technical and nontechnical audiences
In this role, you will be expected to: *Work closely with team members and study staff to design, build, launch, document and maintain systems for storing, aggregating, and analyzing large amounts of data *Process, troubleshoot, and clean incoming data from human studies *Script and automate data ingestion and transformation pipelines, with hooks for QA, auditing, redaction, and compliance checks per data management specifications *Create and populate databases with existing and incoming clinical/physiological data *Architect data models and create tools to harmonize disparate data sources *Incorporate and comply with regulations as they pertain to electronic and clinical data and databases
You will thrive in our fast-paced environment if you are highly organized and able to multitask.
Flexible thinking, adaptability to change and comfort with ambiguity are hallmarks of successful people on our team.
We look forward to witnessing your excellent communication and interpersonal skills during the interview process.
A proven ability to work seamlessly with others is required to acclimate quickly to our culture.
We highly value your analytical mind and problem-solving skills, and expect a stellar attention to detail.
",https://jobs.apple.com/en-us/details/200268880/sr-data-engineer-health-technologies
JOB65047219576,Lead Data Engineer,Lead Data Engineer,50+ career categories,"Find a better job, faster!,Hand-screened leads,No ads, scams, junk,Great job search support","
The lead data engineer will help design a strategic data platform, implement data infrastructure, create run books, and advise on data best practices. Seven years' data engineering or similar experience required. Related degree preferred. Remote position.
Job Details
100% Remote
Employee
Full-Time
Experienced
No specification
Company name here
Other benefits listed here
Find a better job, faster!
Hand-screened leads
No ads, scams, junk
Great job search support
50+ career categories
Create an Account to Unlock
To find out more about or apply to this Lead Data Engineer job—and other great opportunities like it—become a FlexJobs member today!
With FlexJobs, you'll find the best flexible jobs and fantastic expert resources to support you in your job search. If you have any questions, please feel free to contact us.
",https://www.flexjobs.com/publicjobs/lead-data-engineer-1283097
JOB65657652039,Most Popular Types of Data Engineer Jobs,Most Popular Types of Data Engineer Jobs,,,"
What Does a Data Engineer Do?
The job duties of a data engineer involve helping with the development of systems, software, and infrastructure used to process, store and analyze data. Your responsibilities in this career include working to install data management software. Your employer may expect you to perform maintenance and install updates to all software and systems that they use for data acquisition, management, and analysis. Data engineers also analyze existing data systems to find ways to improve efficiency and accessibility. You then suggest upgrades or changes based on your assessment.
More about Data Engineer Jobs
",https://www.ziprecruiter.com/Jobs/Data-Engineer
JOB66193992215,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-nl/details/200188037/ai-ml-search-data-engineer-siri-data
JOB66626247495,Data Engineer,Data Engineer,,,"
Data Engineer X 2 – Manchester. Our client based near Manchester are currently looking for 2 Data Engineers with Azure experience. The company is currently going through a large digital transformation, they are looking for talented Data specialist to help...
Job Title: Data Engineer Salary: 45,000 to 54,000 plus Benefits Location: Cambridge This is a very rare opportunity for an experienced Data Engineer with a strong background in building Python based data processing pipelines to join a company that are...
",https://www.reed.co.uk/jobs/data-engineer/40249964
JOB66937714577,SQL Developer / Data Engineer - E-Commerce,SQL Developer / Data Engineer - E-Commerce,,," As a SQL Developer in our Technology department you will have experience in the design, development, delivery, optimisation and troubleshooting of data solutions, primarily delivered on Microsoft SQL Server and Azure SQL Database.
Alongside you’ll have exposure to SDLC and an understanding of how data solutions are built, deployed and tested through CI/CD automation.
You will be enthusiastic and keen to expand your data engineering skills to deliver outstanding solutions to high-usage, high-availability business problems.
This role offers exposure to new and exciting NoSQL data stores and since these stores are accessed using .net and .net core SDKs, an understanding of iterative languages such as C# or java would be very advantageous.
This is a great opportunity to work collaboratively alongside our existing team of talented Solution Architects, and Software and Data Engineers to implement the optimum data solutions to business problems, ensuring every solution meets the non-functional requirements defined by the business. Our mission is to delivery grade A data solutions and we can only do that with the right people and a collaborative culture. We expect you to grow as an individual and we will provide the tools and mentoring to help accomplish your career aspirations.
What you’ll be doing:
· Working within a team or team(s) of software engineers, you will bring a depth of database development understanding. You will participate in the planning, best practice implementation and delivery of micro-services which are dependent on low latency, highly available and distributed data stores.
· Ensuring that data engineering is an integral part of the development process, following the same practices of source control, build, automated testing, versioning and deployment.
· Helping to identify potential performance issues, bottlenecks and pain points and recommend ways to mitigate or resolve them.
· Engineering approaches for storing, transforming, transporting, synchronising, archiving and securing data.
We would like an individual who:
· Understands the importance of a good team dynamic, is a very capable communicator and comfortable receiving feedback.
· Utilises their experience in order to help teams resolve and overcome technical challenges.
· Is self-motivated and inquisitive with a desire to endlessly improve and take their skills to the next level.
· Has at least 1 year experience with an iterative coding language such as C#, javascript, etc.
· At least 3 years experience working with Microsoft SQL Server or equivalent RDBMS with an understanding of
o Stored Procedures / Functions / Triggers / Views
o Transaction isolation levels
o Indexing
o Query plans and optimisation
Desirable skills:
· Microsoft Azure SQL Database
· Exposure to an enterprise system running in Azure
· Cosmos DB / Mongo DB or equivalent NoSQL data store
· OLTP database design
· Object orientated programming
For more information about this role please contact our Talent Partner, Vashma Bolton, on Vashma.Bolton@ASOS.com
#LI-VB1
",https://www.indeed.co.uk/job/SQL-Developer-at-ASOS-in-United-Kingdom-ecf0aeeb71ed1cbb
JOB67407342375,EY looking for Data Engineer with 2-4 year experience,EY looking for Data Engineer with 2-4 year experience,"Experience in areas such as data-driven statistical modeling, discriminative methods, feature extraction and analysis, supervised learning.","Conduct advanced statistical analysis to provide actionable insights, identify trends, and measure performance,Use data-mining techniques to collect and compile data from a wide variety of data repositories.,Build learning systems that monitor data flows and react to changes in customer preferences and business objectives,Build high-performance predictive and prescriptive algorithms using cutting-edge statistical techniques (e.g. neural networks).,Research new machine learning solutions to complex business problems,Collaborate with engineers to implement and deploy scalable solutions,Provide thought leadership by researching best practices, conducting experiments, and collaborating with industry leader,Use data visualization tools to develop visuals that can be used to effectively communicate technical findings to a non-technical audience,Teach data science concepts to more junior members of the team,PhD with 1-2 years of experience or Masters with 3-4 years of experience in Data Science, Computer Science, Engineering, Statistics, or related field.,Strong background in machine learning and statistics (Deep Learning and Bayesian statistics is a plus),Prototyping Expertise: quick to build proofs-of-concept involving data munging, scripting and analysis.,Solid foundation in data structures and algorithms,Hands on experience building models with deep learning frameworks like MXNet, Tensorflow, Caffe, Torch, Theano or similar.,Experience processing massive amounts of structured and unstructured data using Spark/SQL/Hive/Impala/HBase.,Proficiency in Python for numerical/statistical programming (including Numpy, Pandas, and Scikit-learn),Experience with natural language processing,Experience using Cloud computing (AWS/Azure/GCP),Experience with Java, Scala, Python etc.,Experience working with large data sets and distributed computing tools a plus (Map/Reduce, Hadoop, Hive, Spark)","
EY looking for Data Engineer with 2-4 year experience
Application Period: May 17, 2018 - June 29, 2018
Contact: To apply, visit link below.
EY's people in more than 150 countries are committed to operating with integrity, quality and professionalism in the provision of audit, tax, transaction and advisory services. We strive to help all of our people achieve their professional and personal goals through an inclusive environment that values everyone's contributions, appreciates diversity of thought, fosters growth, and provides continuous opportunities for development. Recognized as one of Canada's top employers, EY continually strives to be a great place to work.
Our IT Advisory Analytics practice works collaboratively with our clients to enhance their ability to use and interpret data, and develop their own enhanced information management capabilities to support better decision making, along with regulatory compliance within their business. Our clients need the vision to articulate the big picture and the precision to see the smallest of details.
Information and intelligence are the assets which enable this, and our Analytics practice provides innovative approaches to unlocking this information, solving many of our clients’ biggest challenges. We are working to integrate this capability into all Advisory service offerings and assists clients to leverage data as an asset throughout its business processes.
We are looking for someone to:
Conduct advanced statistical analysis to provide actionable insights, identify trends, and measure performance
Use data-mining techniques to collect and compile data from a wide variety of data repositories.
Build learning systems that monitor data flows and react to changes in customer preferences and business objectives
Build high-performance predictive and prescriptive algorithms using cutting-edge statistical techniques (e.g. neural networks).
Research new machine learning solutions to complex business problems
Collaborate with engineers to implement and deploy scalable solutions
Provide thought leadership by researching best practices, conducting experiments, and collaborating with industry leader
Use data visualization tools to develop visuals that can be used to effectively communicate technical findings to a non-technical audience
Teach data science concepts to more junior members of the team
We are looking for someone with:
PhD with 1-2 years of experience or Masters with 3-4 years of experience in Data Science, Computer Science, Engineering, Statistics, or related field.
Strong background in machine learning and statistics (Deep Learning and Bayesian statistics is a plus)
Prototyping Expertise: quick to build proofs-of-concept involving data munging, scripting and analysis.
Solid foundation in data structures and algorithms
Hands on experience building models with deep learning frameworks like MXNet, Tensorflow, Caffe, Torch, Theano or similar.
Experience processing massive amounts of structured and unstructured data using Spark/SQL/Hive/Impala/HBase.
Proficiency in Python for numerical/statistical programming (including Numpy, Pandas, and Scikit-learn)
Experience with natural language processing
Experience using Cloud computing (AWS/Azure/GCP)
Experience with Java, Scala, Python etc.
Experience working with large data sets and distributed computing tools a plus (Map/Reduce, Hadoop, Hive, Spark)
Experience in areas such as data-driven statistical modeling, discriminative methods, feature extraction and analysis, supervised learning.
If you think you can meet the challenges of a focused consulting organisation, understand how to grow and lead in a large practice and work in the most complex of sectors our Analytics team is looking forward to hearing from you.
To apply, click https://eygbl.referrals.selectminds.com/experienced-opportunities/jobs/senior-consultant-–-data-analytics-25321
EY is committed to inclusiveness, equity and accessibility. We encourage all qualified candidates to apply.
",https://www.cs.mcgill.ca/postings/184
JOB68828324130,Data Engineer,Data Engineer,,,"
Data Engineer
21 - 25 years experience in South Africa
",http://www.infomine.com/careers/jobs/data-engineer_1782320/
JOB69641143151,"41 Data Engineer Manager Jobs in Amherst, MA","41 Data Engineer Manager Jobs in Amherst, MA",,, ,"https://www.ziprecruiter.com/Jobs/Data-Engineer-Manager/-in-Amherst,MA"
JOB70090633412,Senior Data Engineer,Senior Data Engineer,"Possess a bachelor's degree in Computer Science, Applied Mathematics, Engineering, or any other technology related field.","Responsible for the maintenance, improvement, cleaning, and manipulation of data in the business's operational and analytics databases.,Identification and discovery of complex data sets that align to defined use cases,Contribute to the development of data aggregation and metrics calculations,Selecting and integrating any Big Data tools and frameworks,Implementing ETL process,Monitoring performance and advising any necessary infrastructure changes,Defining data retention policies,Define and builds the data pipelines that will enable faster, better, data-informed decision-making within the business.,At least 3 years of working experience as a database engineering support personnel or a database engineering administrator within a fast-paced a complex business setting.,You will also have experience in defining and building data roadmaps, Spark, NoSQL databases, Big Data ML toolkits and good knowledge of Big Data querying tools,Demonstrate experience working with large and complex data sets as well as experience analyzing volumes of data,Experience in the creation and debugging of databases critical to the business's mission. You will have a strong working and conceptual knowledge of building and maintaining physical and logical data models and experience with Tableau, Qlik or other toolsets,Preferable experience with monitoring, disaster recovery, backup, automated testing, automated schema migration, and continuous deployment.,High level of business and commercial acumen with a demonstrated ability to interpret business requirements and deliver outputs that align with business improvement objectives.,High quality written and oral communication skills including presentation skills,Telecommunications Industry experience","
Fantastic opportunity to work close to home and work on large complex datasets. Clayton location
Melbourne
Clayton location
Contract to 15th December 2017
Your accountabilities include:
Responsible for the maintenance, improvement, cleaning, and manipulation of data in the business's operational and analytics databases.
Identification and discovery of complex data sets that align to defined use cases
Contribute to the development of data aggregation and metrics calculations
Selecting and integrating any Big Data tools and frameworks
Implementing ETL process
Monitoring performance and advising any necessary infrastructure changes
Defining data retention policies
Define and builds the data pipelines that will enable faster, better, data-informed decision-making within the business.
You will have the following skills and experience:
At least 3 years of working experience as a database engineering support personnel or a database engineering administrator within a fast-paced a complex business setting.
You will also have experience in defining and building data roadmaps, Spark, NoSQL databases, Big Data ML toolkits and good knowledge of Big Data querying tools
Demonstrate experience working with large and complex data sets as well as experience analyzing volumes of data
Experience in the creation and debugging of databases critical to the business's mission. You will have a strong working and conceptual knowledge of building and maintaining physical and logical data models and experience with Tableau, Qlik or other toolsets
Preferable experience with monitoring, disaster recovery, backup, automated testing, automated schema migration, and continuous deployment.
High level of business and commercial acumen with a demonstrated ability to interpret business requirements and deliver outputs that align with business improvement objectives.
High quality written and oral communication skills including presentation skills
Telecommunications Industry experience
Possess a bachelor's degree in Computer Science, Applied Mathematics, Engineering, or any other technology related field.
To be considered for the role click the 'Apply' button or for more information about this and other opportunities please contact Jo-Ann Lim on 03 86804321. Please quote our job reference number: 200167951.
Reference Number: 200167951_2
Contact Details:
How to Apply?
Click on the link below
Click here for more information about this job
",https://www.computerworld.co.nz/jobs/view/24136/senior-data-engineer/
JOB70405200706,Data Engineer,Data Engineer,,,"
We are currently looking for a Senior Data Engineer who will be responsible for designing and developing data processing and data persistence software components for solutions, which handle data at scale. You will be working in agile teams, Lead Data Engineers providing strong development leadership for team members and take responsibility for the quality of the codebase as well as the match to user needs.
Experience we would like to see
* Software development experience with distributed data storage and processing technologies including Hadoop and Spark and using JVM languages.
* Experience of leading the development of substantial components for large-scale data processing solutions, taking responsibility for non-functional needs of ETL/ELT data processing pipelines such as robustness, performance and security.
* Develop including the design, code, test defect resolution and operational readiness, and includes setting the standards for these activities.
* Coaching and mentoring experience in data development disciplines with the ability to gain the respect of a junior team.
Other useful experience
* Software development experience with Cloudera’s distribution of Apache Hadoop and with Python.
* Experience of data visualisation and data complex data transformations, including ETL tools such as Talend.
* Able to productionise machine learning algorithms.
* Understanding of text processing including Natural Language Processing.
* Experience with steaming and event-processing architectures including technologies such as Kafka and change-data-capture products.
* Data modelling experience with data storage technology, such as document, graph, log stores and other non-relational platforms.
* Open source contributor
As an industry leading, nationwide Marketing, Digital, Analytics, IT and Design recruitment agency, we are continually receiving new assignments to work on, so keep a close eye on our website, Facebook, LinkedIn and Twitter pages for a full list of current permanent and interim opportunities as well as marketplace news and fun stuff.
Forward Role is operating as an employment agency.
Reference: 39666415
Bank or payment details should never be provided when applying for a job. For information on how to stay safe in your job search, visit SAFERjobs.
Report this job
",https://www.reed.co.uk/jobs/data-engineer/39666415
JOB70544117224,AVAILABLE POSITIONS Principal Data Engineer,AVAILABLE POSITIONS Principal Data Engineer,Work with cool people and impact millions of daily players!,"Build and own multi PB-scale data platform.,Design, code, and develop new features/fix bugs/enhancements to systems and data pipelines (ETLs) while adhering to the SLA.,Follow engineering best methodologies towards ensuring performance, reliability, scalability, and measurability.,Collaborate with other Software Engineers, ML Engineers, Data Scientists, and other stakeholders, taking on learning and leadership opportunities that will arise every single day.,Mentor junior engineers in the team to level them up.,Raise the bar on sustainable engineering by improving best practices, producing best in class of code, documentation, testing and monitoring.,Bachelor’s degree in Computer Science, or a related technical discipline (or equivalent).,7+ years of strong data engineering design/development experience in building massively large scale distributed data platforms/products.,Advanced coding expertise in SQL & Python/JVM-based language.,Expert in heterogeneous data storage systems (relational, NoSQL, in-memory etc).,Deep knowledge of data modeling, lineage, access and its governance.,Excellent skills in AWS services like Redshift, Kinesis, Lambda, EMR, EKS/ECS etc.,Wide exposure to open source software, frameworks and broader cutting edge technologies (Airflow, Spark, Druid etc).,Familiar with infrastructure provisioning tools (e.g Terraform, Chef),Consistent proven ability to deliver work on time with attention to quality.,Excellent written and spoken communication skills and ability to work effectively with others in a team environment.,Work in a studio that has complete P&L ownership of games,Competitive salary, discretionary annual bonus scheme and Zynga RSUs,Full medical, accident as well as life insurance benefits,Catered breakfast, lunch and evening snacks,Child care facilities for women employees and discounted facilities for male employees,Well stocked pantry,Generous Paid Maternity/Paternity leave,Employee Assistance Programs,Active Employee Resource Groups – Women at Zynga,Frequent employee events,Additional leave options for most employees,Flexible working hours on many teams,Casual dress every single day","
We are seeking top engineering talent to join our creative, dynamic, and highly driven team. Zynga’s mission is to “Connect the World through Games” by building a truly social experience that makes the world a better place. The ideal candidate will have a devotion to software craftsmanship, an unwavering commitment to quality, and the desire to have their work seen by tens of millions of people worldwide.
The Analytics Engineering team is responsible for all things data at Zynga. We own the full game and player data pipeline – from ingestion to storage to driving insights and analytics. As a Principal Data Engineer, you will be responsible for the software design and development of quality services and products to support the Analytics needs of our games. In this role, you will be part of our Central Technology group focusing on advanced technology developments for building scalable data infrastructure and end-to-end services which can be leveraged by the various games. We are a 120+ organization servicing 1500 others across 13 global locations.
Your responsibilities will include
Build and own multi PB-scale data platform.
Design, code, and develop new features/fix bugs/enhancements to systems and data pipelines (ETLs) while adhering to the SLA.
Follow engineering best methodologies towards ensuring performance, reliability, scalability, and measurability.
Collaborate with other Software Engineers, ML Engineers, Data Scientists, and other stakeholders, taking on learning and leadership opportunities that will arise every single day.
Mentor junior engineers in the team to level them up.
Raise the bar on sustainable engineering by improving best practices, producing best in class of code, documentation, testing and monitoring.
Bachelor’s degree in Computer Science, or a related technical discipline (or equivalent).
7+ years of strong data engineering design/development experience in building massively large scale distributed data platforms/products.
Advanced coding expertise in SQL & Python/JVM-based language.
Expert in heterogeneous data storage systems (relational, NoSQL, in-memory etc).
Deep knowledge of data modeling, lineage, access and its governance.
Excellent skills in AWS services like Redshift, Kinesis, Lambda, EMR, EKS/ECS etc.
Wide exposure to open source software, frameworks and broader cutting edge technologies (Airflow, Spark, Druid etc).
Familiar with infrastructure provisioning tools (e.g Terraform, Chef)
Consistent proven ability to deliver work on time with attention to quality.
Excellent written and spoken communication skills and ability to work effectively with others in a team environment.
What we offer you:
Work in a studio that has complete P&L ownership of games
Competitive salary, discretionary annual bonus scheme and Zynga RSUs
Full medical, accident as well as life insurance benefits
Catered breakfast, lunch and evening snacks
Child care facilities for women employees and discounted facilities for male employees
Well stocked pantry
Generous Paid Maternity/Paternity leave
Employee Assistance Programs
Active Employee Resource Groups – Women at Zynga
Frequent employee events
Additional leave options for most employees
Flexible working hours on many teams
Casual dress every single day
Work with cool people and impact millions of daily players!
#LI-HK1
Careers region: India
Careers location: Bengaluru, India
Careers Type: Full-Time
",https://www.zynga.com/?p=3001
JOB70580329340,Data Engineer,Data Engineer,,"Engineer,Data Engineer","
The following job is no longer available:
Data Engineer
Data Engineer - up to 75k London My client is looking for passionate Data Engineers to help build, maintain and support a new cloud based big data platform as part of a large investment plan across data. They are a global company who put lots of investment...
My client is an extremely prestigeous, market leading Data Consultancy with offices throughout the UK. They work with some of the biggest names in the Financial Services industry. They are an agile, client focused consultancy. My client are looking for...
We are currently looking for a Senior Data Engineer who will be responsible for designing and developing data processing and data persistence software components for solutions, which handle data at scale. You will be working in agile teams, Lead Data Engineers...
Data Engineer - Central London - Consultancy 50,000 - 90,000 (Dependent on experience) Immediate Start Dates (January 2020) This Client has an immediate requirement to hire x4 Data Engineers , to join their growing team based in Central London. Due to...
Data Engineer London 3 months 400- 450 per day An opportunity for a Data Engineer has arisen within a growing customer analytics agency with one of their financial services clients. As a Data Engineer you will be working as part of a fluid and dynamic...
DATA ENGINEER 65,000 - 85,000 BENEFITS LONDON Are you a data engineer looking forward to working with one of the largest telecommunications company Globally? Would you like to work with large data sets and use the latest tools and technology? Are you looking...
Data Engineer 3 Months 350- 425 Greater London New Data Engineer role for a growing Customer Engagement Agency to work along side Insight Analysts within a Customer Retention project. THE COMPANY This fast-expanding Consultancy are looking for a Data Engineer...
Data Engineer London 40,000 - 90,000 Benefits This Data Engineer role will allow you to expand and utilise your skills in a growing team working along side one of the largest data sets in the UK. The Company As a global leader they generate tons of data...
DATA ENGINEER UP TO 100,000 LONDON THE COMPANY This leading telecoms company are making data their priority. They're building a huge new data platform in GCP and are ready to start using advanced data science to inform all their business decisions. You'll...
DATA ENGINEER London 375- 450 Inside IR35 Are you looking for a new and exciting contract for a growing online Auction Platform company? THE COMPANY This online Auction Platform company are looking to grow rapidly in the following months to compete against...
THE COMPANY Leading telecommunication company who are looking to improve their Data Engineering function. My client is looking for a data engineer to join their team of world class engineers and Data Scientists to build end-to-end applications that make...
THE COMPANY Leading telecommunication company who are looking to improve their Data Engineering function. My client is looking for a data engineer to join their team of world class engineers and Data Scientists to build end-to-end applications that make...
THE COMPANY Leading telecommunication company who are looking to improve their Data Engineering function. My client is looking for a data engineer to join their team of world class engineers and Data Scientists to build end-to-end applications that make...
THE COMPANY Leading telecommunication company who are looking to improve their Data Engineering function. My client is looking for a data engineer to join their team of world class engineers and Data Scientists to build end-to-end applications that make...
THE COMPANY Leading telecommunication company who are looking to improve their Data Engineering function. My client is looking for a data engineer to join their team of world class engineers and Data Scientists to build end-to-end applications that make...
Data Engineer Central London Data-driven organisation If you have a passion for Big Data, with an interest in keeping up to date with modern, cutting-edge technologies, read on: This London-based company have just released a Data Engineer position, with...
THE COMPANY Leading telecommunication company who are looking to improve their Data Engineering function. My client is looking for a data engineer to join their team of world class engineers and Data Scientists to build end-to-end applications that make...
THE COMPANY Leading telecommunication company who are looking to improve their Data Engineering function. My client is looking for a data engineer to join their team of world class engineers and Data Scientists to build end-to-end applications that make...
THE COMPANY Leading telecommunication company who are looking to improve their Data Engineering function. My client is looking for a data engineer to join their team of world class engineers and Data Scientists to build end-to-end applications that make...
THE COMPANY This group is one of the largest retailers in the UK, they are also a leading Digital retailer. They are looking for a hands on Data Engineer who will work within a team who use the latest technology solutions. Technologies in their stack include...
Data Engineer - London, permanent, 60k to 75k/annum My client, finance and leasing organisation, is looking for a Data Engineer to join our development team on high profile projects. The candidate should be able to demonstrate experience of building Oracle...
Scale-up Tech Firm Greenfield design and build. Architect data infrastructure for a cloud-native company. Great engineering culture, tech stack and family atmosphere. This scale-up technology firm is growing rapidly through both organic growth and acquisition...
We are looking for an experienced Data Engineer to join the development team for a global media agency to support and deliver on a growing range of machine learning applications. They work directly with various business units across the entire group and...
Role- Data Engineer Location- Farringdon Salary- up to 80,000 Fancy working with a truly revolutionary company? With a company that is taking marketing analytics to the next level, using AI and Machine learning technology? This data centric company is...
Job Title: Data Engineer Contract Length: 3 Months Rolling Start Date: Immediate Description: You will be involved with a GCP migration project and may be required to travel to Europe when needed. AWS/Azure experience will be considered for these requirements...
",https://www.reed.co.uk/jobs/data-engineer/39594628
JOB72034523986,Data Engineer Jobs,Data Engineer Jobs,,," Sorry, the job you're looking for is no longer being advertised. However, you can still search for similar jobs.
From: Up to £10,000
To:
We are looking for a Data Engineer to join our Clear Review business as we analyse, explore and improve how over 100,000 employees across over 200 companies perform and feel about work. Clear Review is our UK's leading Continuous Performance Management...
See more: Engineer jobs
The data engineer will be responsible for the successful delivery of a variety of software and technology solutions projects. The pace of innovation within RSM is increasing all the time and this has created the need for additional skills within the firm...
See more: Engineer jobs
GCP DATA ENGINEER 400- 500 PER DAY 3 MONTH CONTRACT LONDON BASED As a Data Engineer you will be working heavily with Python/Spark on a GCP platform, creating an automated process to push data into Google Audiences. THE COMPANY: You will be working for...
See more: Engineer jobs
DATA ENGINEER 400- 500 PER DAY 3 MONTH CONTRACT LONDON BASED As a Data Engineer you will be working heavily with Python/Spark on a GCP platform, creating an automated process to push data into Google Audiences. THE COMPANY: You will be working for a start...
See more: Engineer jobs
Are you a passionate and technically rounded Data Engineer, looking for an organisation that will invest in you and pushes you to be the best you can be? Do you want to learn from & work alongside some of the most talented, supportive Data Engineers...
See more: Engineer jobs
DATA ENGINEER LONDON - CURRENTLY FLEXIBLE/REMOTE WORKING UP TO 85K BENEFITS BONUS This is a really exciting position for an experienced senior data engineer to join a rapidly growing start - up founded by leading data experts. They are looking to grow...
See more: Engineer jobs
DATA ENGINEER 400- 500 PER DAY 3 MONTH CONTRACT FULLY REMOTE As a Data Engineer you will have the chance to work for a health care consultancy in analysing local data sets using Python, SQL and Airflow. THE COMPANY: As a Data Engineer, you will be working...
See more: Engineer jobs
DATA ENGINEER 400- 500 PER DAY 3 MONTH CONTRACT LONDON BASED As a Data Engineer you will be working heavily with Python/Spark create APIS on an AWS platform which is connected to Databricks. THE COMPANY: You will be working for a start up within the AI...
See more: Engineer jobs
DATA ENGINEER 70,000 - 85,000 10% BONUS LONDON THE COMPANY: This is a world-renowned insurance business with a range of departments. They've recently been through a transformation to use data more in the business and are looking to bring on a Data Engineer...
See more: Engineer jobs
We are looking for a talented Data Engineer to join our team in Stockport, however due to the pandemic this role will initially start fully remote with a view to return to our offices. You will join us on a full time, permanent basis and in return, you...
See more: Engineer jobs
Senior Data Engineer London Our client is one of the most widely renowned names in British Cyber Security. They are searching for a number of highly skilled Data Engineers with for a role based in their London location with a government client. The role:...
See more: Engineer jobs
DATA ENGINEER LONDON (REMOTE WORKING) UP TO 85,000 Harnham are partnered with an international television network that produces its own unique content. They are looking for a data engineer to join their subscription service and work in tandem with BI and...
See more: Engineer jobs
Data Engineer | Python | SQL | GCP | London | Up to 65,000 Are you an experienced Data Engineer with a real passion for what data can do for a business? Do you enjoy working in a constantly evolving environment where no two days are the same? Method Resourcing...
See more: Engineer jobs
Senior Business Intelligence Engineer - London - 50k- 70k Our client is a prestigious not for profit organisation, providing support to thousands of members across the UK. They are seeking a talented and ambitious BI Data Engineer who has a strong technical...
See more: Engineer jobs
DATA ENGINEER LONDON (REMOTE WORKING) UP TO 75,000 Harnham are partnered with a home furnishing retailer, that has superstores placed all over the UK. They are looking for a data engineer to join their expanding and newly successful team to design and...
See more: Engineer jobs
Data Engineer Our client is a well-established international insurance company, and they are looking for 2 Data Engineers to support the Data & MI team. This is a business facing role within Actuarial & Analytics so excellent communication skills...
See more: Engineer jobs
We're supporting our clients as they adapt to a new world in the wake of COVID-19. We're now recruiting for roles which will help our clients to deliver vital services and to resume business wherever possible. What you'll be doing : Excellent communicational...
See more: Engineer jobs
We're supporting our clients as they adapt to a new world in the wake of COVID-19. We're now recruiting for roles which will help our clients to deliver vital services and to resume business wherever possible. What you'll be doing : Excellent communicational...
See more: Engineer jobs
Data Engineer - 4 week rolling contract - On-site in London/Remote Data Analysis, Data Analytics, Data Modelling, Data Warehouse, Python, ETL, PostgreSQL Data Engineer Up to 450 per day London/Remote Working Immediate start - 4 week rolling contract A...
See more: Engineer jobs
Title: Data Engineer Our client is currently looking for a Data Engineer to play a vital role in the continual development of our digital transformation strategy and earth science analytics. Candidates must have Python, R and SQL. We expect candidates...
See more: Engineer jobs
Data Engineer- South Manchester ""Our Client will be interviewing and onboarding remotely during COVID-19"" Adria Solutions has an exciting opportunity for a talented Data Engineer to join our reputable client based near Manchester. As a Data Engineer you...
See more: Engineer jobs
Are you a Data Engineer who wants to learn, work, and develop with some of the best people in Lisbon? Does collaborate with Machine Learning teams, Data Science teams and Software Engineering teams sound like a good environment to work within as a Data...
See more: Engineer jobs
Data Engineer Copenhagen, Denmark 6 Month Contract 900 DKK Per Hour As a Data Engineer you will be creating and maintaining data pipeline architecture for a leading European home-wares retailer. THE COMPANY: The client is a leading European Home-wares...
See more: Engineer jobs
A London based financial consultancy is on the lookout for a Mid to Senior Level Scala Data Engineer to join their team. The Company The forward thinking and innovative firm is a fast growing financial consultancy working solely within the Financial Services...
See more: Engineer jobs
DATA ENGINEER - REMOTE WORKING 35,000 - 45,000 REMOTE (OFFICE IN LONDON) THE COMPANY: The company are a private equity firm with investments in the fintech, online marketing, insurance and online gaming spaces. They are looking for an experienced ETL developer...
See more: Engineer jobs
Data Engineer is currently required for a 3 month project with a cutting edge start up based in central London. The client are looking for a Data Engineer to help develop out the data platform. The Data Engineer will be joining existing team of Product...
See more: Engineer jobs
Data Engineer | 55,000 - 75,000 AWS | Python| SQL | ETL | Data Pipelines | Glue If you'd like to take your career to the next step then an awesome opportunity to build an environment from the ground up has just become available with an organisation that...
See more: Engineer jobs
",https://www.reed.co.uk/jobs/spark-data-engineer-with-databricks-experience-required-3-6-months-leeds/39764632?source=searchResults
JOB74043038268,Data Engineer,Data Engineer,,,"
Job Description:
The candidate will primarily work virtually from a home-office with occasional in-person meetings as necessary. Preference for candidate to be located in the Mid-Atlantic states (NC, SC, VA).
Position Summary:
As a Data Engineer for the American Red Cross, you will be part of a Data Management team that is modernizing and transforming our data and reporting capabilities across multiple verticals including Biomedical Services by implementing a new modernized data architecture.
The Data Engineer will design and develop highly scalable and extensible data platforms which enable collection, storage, distribution, modeling, and analysis of large data sets from numerous channels. This position requires an innovative software engineer who is passionate about data & data quality. The ideal candidate will possess strong data management and API integration experience and the ability to develop scalable data pipelines that make data management and analytics/reporting faster, more insightful, and more efficient.
Responsibilities:
• Develop, test, document and maintain scalable data pipelines.
• Build out new data integrations including APIs to support continuing increases in data volume and complexity.
• Establish and follow data governance processes and guidelines to ensure data availability, usability, consistency, integrity, and security.
• Build and implement scalable solutions that align to our data governance standards and architectural road map for data integrations, data storage, reporting, and analytic solutions.
• Collaborate with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization.
• Design and develop data integrations and a data quality framework. Write unit/integration/functional tests and document work.
• Design, implement, and automate deployment of our distributed system for collecting and processing streaming events from multiple sources
• Perform data analysis required to troubleshoot data-related issues and assist in the resolution of data issues.
• Serve as tech lead when needed.
Qualifications:
• Education: 4-year college degree or equivalent combination of education and experience. Prefer academic backgrounds in in Computer Science, Mathematics, Statistics, or related technical field.
• 7-10 years of relevant work experience in analytics, data engineering, business intelligence or related field.
• Experience with or knowledge of Agile software development methodologies.
• Experience using SQL queries as well as writing and optimizing SQL queries in a business environment with large-scale, complex datasets.
• Experience developing integrations across multiple systems and APIs.
• Experience creating ETL and/or ELT jobs.
• Excellent problem solving and troubleshooting skills.
• Process oriented with great documentation skills.
• Proficient with coding in Python.
• Experience with AWS technologies (e.g. Redshift, RDS, S3, EMR, EC2, Kinesis) is a plus.
• Experience with data warehouse technologies is a plus.
• Experience designing data schemas and operating SQL/NoSQL database systems is a plus.
• Experience with Big Data tools like Spark, Hadoop, Kafka, etc. is a plus.
*LI-EH1
IND123
Apply now! Joining our team will provide you with the opportunity to make a difference every day.
The American Red Cross is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law.
The American Red Cross is a diverse nonprofit organization offering its employee's professional development and growth opportunities, a competitive salary, comprehensive benefits, and a collaborative team spirit environment. To be considered for this position, please visit www.redcross.org/jobs to apply.
To view the EEOC Summary of Rights, click here: Summary of Rights
",https://www.gettinghired.com/job-details/277280/data-engineer/
JOB74578418228,Cloud Data Engineer,Cloud Data Engineer,,"DevOps and Agile Delivery and SLC methodologies adjusted for infrastructure service delivery and integration with Abbott DevOps organizations.,Uses Infrastructure as Code tools (e.g. Terraform and Packer) and techniques to deliver re-usable storage services for public and private cloud.,Implements Continuous Integration and Continuous Delivery pipelines for the deployment of application and infrastructure stacks.,Establishes data governance and security,Optimize cloud storage for security, cost and availability.,Automate cloud operations tasks including backups and restores,Responsible for compliance to applicable Corporate and Divisional Policies and procedures.,Serve as a technical expert for public cloud storage offerings and uses within Abbott,Evaluate and recommend new software, utilities and tools.,Sets the strategy for implementing new technologies.,Develops service implementation scripts, and provides top level support of IT solutions aligned with customer's business objectives and other infrastructure technology disciplines within BTS-IS.,Nurtures relationships with key suppliers of cloud technologies to keep abreast of emerging technologies, ensure solution stability, optimal pricing, and influences their product direction to align with Abbott.,This position reports directly to the Director of Hosting in BTS.,The position is accountable for internal cost recovery mechanisms,This position is a technical contact representing the infrastructure hosting / cloud area to partner with all other Abbott IT and business organizations and key external service providers.,Accountable for awareness of technology trends and the determination/execution of global strategies that satisfy the business-critical reliance that Abbott is increasingly placing on its infrastructure to host applications.,3+ years Cloud Experience,Experience implementing PostgreSQL and MySQL,Experience managing data storage solutions (blob, managed disk, NFS) in AWS and Azure,Bachelor's Degree preferred in a technology or management discipline","
Abbott is a global healthcare leader that helps people live more fully at all stages of life. Our portfolio of life-changing technologies spans the spectrum of healthcare, with leading businesses and products in diagnostics, medical devices, nutritionals and branded generic medicines. Our 103,000 colleagues serve people in more than 160 countries.
Primary Job Functions
Designs and delivers public-cloud specific storage solutions based on the business need. Implements proper security protocols to secure and categorize data in the public cloud. Partners with Cloud Engineers as part of the overall cloud ecosystem and solution. Conversion of databases from on-prem to cloud PaaS offerings.
Core Job Responsibilities
DevOps and Agile Delivery and SLC methodologies adjusted for infrastructure service delivery and integration with Abbott DevOps organizations.
Uses Infrastructure as Code tools (e.g. Terraform and Packer) and techniques to deliver re-usable storage services for public and private cloud.
Implements Continuous Integration and Continuous Delivery pipelines for the deployment of application and infrastructure stacks.
Establishes data governance and security
Optimize cloud storage for security, cost and availability.
Automate cloud operations tasks including backups and restores
Responsible for compliance to applicable Corporate and Divisional Policies and procedures.
Serve as a technical expert for public cloud storage offerings and uses within Abbott
Evaluate and recommend new software, utilities and tools.
Sets the strategy for implementing new technologies.
Develops service implementation scripts, and provides top level support of IT solutions aligned with customer's business objectives and other infrastructure technology disciplines within BTS-IS.
Nurtures relationships with key suppliers of cloud technologies to keep abreast of emerging technologies, ensure solution stability, optimal pricing, and influences their product direction to align with Abbott.
Proactively asses the effectiveness of standards, methodologies and processes; driving change as appropriate for continuous improvement.
Position Accountability/Scope
This position reports directly to the Director of Hosting in BTS.
The position is accountable for internal cost recovery mechanisms
This position is a technical contact representing the infrastructure hosting / cloud area to partner with all other Abbott IT and business organizations and key external service providers.
Accountable for awareness of technology trends and the determination/execution of global strategies that satisfy the business-critical reliance that Abbott is increasingly placing on its infrastructure to host applications.
Directly impacts the operation and profitability of every division through their reliance on the cloud infrastructure to host Abbott's Enterprise and Business critical applications globally.
Core Job Requirments
3+ years Cloud Experience
Experience implementing PostgreSQL and MySQL
Experience managing data storage solutions (blob, managed disk, NFS) in AWS and Azure
Experience with Azure Files
Minimum Experience/Training Required
Bachelor's Degree preferred in a technology or management discipline
5+ years of overall IT experience
",https://www.gettinghired.com/job-details/276399/cloud-data-engineer/
JOB74830133317,Data Engineer – Mid/Senior – Full Time at Alta,Data Engineer – Mid/Senior – Full Time at Alta,"5+ years within a software engineering role, preferably on the data analysis side,2+ years experience building production systems on a major cloud provider (AWS preferred),Strong database knowledge (SQL / NoSQL),Experience manipulating data, building data pipelines, and automating dashboards,Experience implementing data logging from production code,Ability to translate ambiguous and complex requirements into clear data deliverables,Strong problem-solving skills using quantitative and statistical approach,Very strong passion and understanding of data architectures and best-practices of devops to deliver faster and more reliable outcomes,Experience in agile delivery methodologies,Experience with real-time and live data sources,Strong communication skills to present findings to non technical stakeholders,Proficiency in a Software Engineering language of your choice (C#, Python, Java, C++, etc…),Experience in C# and .NET Core,REST API design experience,Kubernetes and containerised workloads,Good understanding of CI/CD principles",,"
Programmers located Anywhere.
Background
After our recent successful launch on Oculus Quest, we’re looking to grow the team! We need a talented Data Engineer to help us understand why our users spend thousands of hours in our game, and help us figure out where they should go next. We’ve got a game that’s already pretty good, but we’re looking for people who can help us make it great.
Team/Company
Alta is a Sydney-based Virtual Reality startup. Since 2016 we have worked on the multiplayer game A Township Tale, and have grown from the 3 founding members to over a dozen passionate developers. At Alta, each team member wears multiple hats and is committed to our overall mission in developing a groundbreaking VR experience for players worldwide.
We are now fully remote and have several team members in different time zones. We are a very tight knit team and finding a great team fit is just as important to us and finding the right skillset.
The role
As a Data Engineer, you will be expanding and working with our analytics system to give meaningful insights into the way the company operates. You will be reporting to senior members to make very high level decisions on the future of the game and structure of development. We need someone who can take ownership of their work and work unsupervised to achieve the mission. You will need to be self motivated to deep dive into any datasets we have or talk to the other developers in order to capture other metrics we currently don’t have. You will need to be capable of providing insights into various metrics such as users retention rates, why they churn at particular points in their lifetime and which are the most used features within the game. Ideally you are someone that enjoys and understands the ways video games connect us and can put that knowledge to use in making meaningful changes to our product.
Requirements
5+ years within a software engineering role, preferably on the data analysis side
2+ years experience building production systems on a major cloud provider (AWS preferred)
Strong database knowledge (SQL / NoSQL)
Experience manipulating data, building data pipelines, and automating dashboards
Experience implementing data logging from production code
Ability to translate ambiguous and complex requirements into clear data deliverables
Strong problem-solving skills using quantitative and statistical approach
Very strong passion and understanding of data architectures and best-practices of devops to deliver faster and more reliable outcomes
Experience in agile delivery methodologies
Experience with real-time and live data sources
Strong communication skills to present findings to non technical stakeholders
Proficiency in a Software Engineering language of your choice (C#, Python, Java, C++, etc…)
Bonus skills
Experience in C# and .NET Core
REST API design experience
Kubernetes and containerised workloads
Good understanding of CI/CD principles
If you are looking to start your journey at a company at the forefront of exciting new technology, this job is for you. At Alta you will see the impact you make daily and have a chance to be part of a company that is growing rapidly. You will get a competitive salary and a work environment where your actions can make a real impact.
To Apply
",https://www.indiedb.com/jobs/data-engineer-midsenior-full-time
JOB75777431803,Mid-Level SQL Server Data Engineer,Mid-Level SQL Server Data Engineer,,,"Mid-Level SQL Server Data Engineer
The job you tried to view is no longer active on the site.
MKS Instruments Inc.
MKS Instruments Inc.
MKS Instruments
Thorlabs, Inc.
Florida Atlantic University
Nikon Research Corporation of America
",https://www.optics.org/jobs/5375985
JOB78682172946,Senior Geospatial Data Engineer...,Senior Geospatial Data Engineer...,,,,https://www.avjobs.com/jobs/positions.asp?q=Senior+Geospatial+Data+Engineer
JOB78797101604,Data Engineer - Big Data,Data Engineer - Big Data,,"At least 2 years relevant experience,Minimum 1 years of hands-on experience in Big Data Eco System (Hadoop, Hive, and MapReduce),Minimum 1 year of hands-on experience in Spark core,Minimum 1 years of hands-on programming experience in core Python or Java,Minimum 1 year of hands-on experience in HBase or Cassandra","
Introduction
At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.
Your Role and Responsibilities
The position of the Data Engineer plays a key role in the development and deployment of innovative big data platforms for advanced analytics and data processing. The Data Engineer defines and builds the data pipelines that will enable faster, better, data-informed decision-making within the business. Develops applications on Big Data and Cognitive technologies including API development. Expected to have traditional Application Development background along with knowledge of Analytics libraries, open-source Natural Language Processing, statistical and big data computing libraries. Strong technical abilities to understand, design, write and debug complex code.
CAREER GROWTH
Our goal is to be essential to the world, which starts with our people. Company wide we kicked off an internal talent strategy program called Go Organic. At our core, we are committed to believing and investing in our workforce through:
Skill development: helping our employees grow their foundational skills
Finding the dream job at IBM: navigating our company with the potential for many careers by channeling an employee's strengths and career aspirations
Diversity of people: Diversity of thought driving collective innovation
In 2015, Go Organic filled approximately 50% of our open positions with internal talent that were promoted into the role.
CORPORATE CITIZENSHIP
With an employee population of 375,000 in over 170 countries, amazingly we connect, collaborate, and care. IBMers drive a corporate culture of shared responsibility. We love grand challenges and everyday improvements for our company and for the world. We care about each other, our clients, and the communities we live, work, and play in! gbscicbr
Required Technical and Professional Expertise
At least 2 years relevant experience
Minimum 1 years of hands-on experience in Big Data Eco System (Hadoop, Hive, and MapReduce)
Minimum 1 year of hands-on experience in Spark core
Minimum 1 years of hands-on programming experience in core Python or Java
Minimum 1 year of hands-on experience in HBase or Cassandra
Preferred Technical and Professional Expertise
• Minimum 1 year of hands-on experience with RDBMS, DW/DM, NoSQL databases
• Minimum 1 year of hands-on experience with Pig, Yarn and Oozie
• Minimum 1 year of hands-on experience with Spark SQL and Spark Streaming
• Minimum 1 year of hands-on experience with Scala, C/C++, Perl, Kafka, or Golang
• Minimum 1 year of hands-on experience with building Docker containers
• Minimum 1 year of hands-on experience with CI/CD using tools such as Gradle or Jenkins or BitBucket""
• Minimum 1 year of hands-on experience with Cloud Platforms (AWS, Google, Red Hat or Azure)
About Business Unit
IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.
Your Life @ IBM
What matters to you when you're looking for your next career challenge?
Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities - where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust - where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.
Impact. Inclusion. Infinite Experiences. Do your best work ever.
About IBM
IBM's greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.
Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.
Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
",https://www.gettinghired.com/job-details/251667/data-engineer-big-data/
JOB78834926433,Experienced Data Engineer,Experienced Data Engineer,"Proficient at designing, accessing, and maintaining data stores, data feeds, and data processing tools: RDBMS, NoSQL, APIs, Kafka, Apache Spark, ELK stack,Experience with AWS services: EC2, S3, Lambda, Glue, Athena, Redshift, etc.,Proven experience deploying machine learning algorithms to production as a Data Engineer, Machine Learning Engineer, or similar role,Proficiency using GitHub, Docker, Luigi/Airflow, Jenkins, Terraform,Proficient in Python, shell scripting, Java (a plus), familiar with BI tools (e.g., Power BI, AWS QuickSight, Tableu, etc.),Proficient at writing high-quality and scalable code and integrating with version control systems,Knowledge of statistical and data mining techniques including model evaluation/validation,Enthusiasm for big data and translating data into actionable insights and demonstrable experience with big data technologies (with structured and unstructured data),Proficient at building robust data pipelines and delivering reliable data services to stakeholders,Ability to work in a complex, fast-paced environment while maintaining a high degree of accuracy and professionalism,Excellent interpersonal, verbal and written communication skills,Agile project development experience is a plus,Experience leading successful data engineering projects and operationalizing machine learning algorithms,BS (required, 5+ years of experience) or Master's degree (preferred, 3+ years of experience) in computer science, applied mathematics, engineering, operations research, or a related field","Develop and administer standards for architecting and working with data management systems, as well as for deploying, monitoring, and maintaining machine learning models,Ensure analytics systems meet business requirements and implement industry best practices,Develop processes and tools to monitor and analyze model performance and data quality,Build the infrastructure required for optimal ETL from a wide variety of data sources using SQL databases and AWS 'big data' services,Extract, integrate, and analyze data from heterogeneous mix of data sources to support create insights and recommendations to internal stakeholders,Collaborate with data scientists and stakeholders from across the business (Sales, Strategy, Finance, Technology, and Business Development) to develop new information services to optimise business operations,Create and maintain optimal data pipeline architecture,Work with data scientists and business stakeholders to develop, refine, and maintain statistical and machine learning models,Productionize machine learning models and other data science products (e.g., A/B tests) to optimise business operations,Recommend and implement different ways to constantly improve data reliability, quality, and disaster recovery procedures,Identify, design, and implement internal process improvements: automating manual process, optimizing data delivery, redesigning infrastructure for greater scalability, etc.,Create tools to improve access and confidence in data so that internal users can make data-driven decisions,Mentor data science and tech team members","
Description
Position at Dominion Enterprises
PrimeStreet seeks an Experienced Data Engineer to join one of the fastest growing companies in Coastal Virginia. This position will be completely remote, with some required travel to our office in Norfolk, VA.
In the past year, PrimeStreet has grown over 500%. Our growth is enabled by our culture, which encourages individual development, embraces an inclusive environment, rewards innovative excellence, and supports our community. PrimeStreet is independently owned by Dominion Enterprises, a company with a rich heritage and a bold entrepreneurial mission.
The role will apply analytic rigor to develop and maintain the data and analytic infrastructure to support business intelligence (BI) reporting, predictive models, and strategic analyses. The successful candidate will be an experienced professional with strong technical skills and excellent business acumen. This position has a strong potential for advancement within the company. The ideal candidate has 2-5 years of experience building data pipelines in support of BI and advanced analytics product, plus demonstrable professional experience productionizing machine learning models to optimise business operations. The Experienced Data Engineer will collaborate with the Prime Street data science team members and serve as the leader of data engineering efforts for our growing analytics team. The Experienced Data Engineer will report directly to the Director of Data Science.
Responsibilities:
Develop and administer standards for architecting and working with data management systems, as well as for deploying, monitoring, and maintaining machine learning models
Ensure analytics systems meet business requirements and implement industry best practices
Develop processes and tools to monitor and analyze model performance and data quality
Build the infrastructure required for optimal ETL from a wide variety of data sources using SQL databases and AWS 'big data' services
Extract, integrate, and analyze data from heterogeneous mix of data sources to support create insights and recommendations to internal stakeholders
Collaborate with data scientists and stakeholders from across the business (Sales, Strategy, Finance, Technology, and Business Development) to develop new information services to optimise business operations
Create and maintain optimal data pipeline architecture
Work with data scientists and business stakeholders to develop, refine, and maintain statistical and machine learning models
Productionize machine learning models and other data science products (e.g., A/B tests) to optimise business operations
Recommend and implement different ways to constantly improve data reliability, quality, and disaster recovery procedures
Identify, design, and implement internal process improvements: automating manual process, optimizing data delivery, redesigning infrastructure for greater scalability, etc.
Create tools to improve access and confidence in data so that internal users can make data-driven decisions
Mentor data science and tech team members
Qualifications:
Proficient at designing, accessing, and maintaining data stores, data feeds, and data processing tools: RDBMS, NoSQL, APIs, Kafka, Apache Spark, ELK stack
Experience with AWS services: EC2, S3, Lambda, Glue, Athena, Redshift, etc.
Proven experience deploying machine learning algorithms to production as a Data Engineer, Machine Learning Engineer, or similar role
Proficiency using GitHub, Docker, Luigi/Airflow, Jenkins, Terraform
Proficient in Python, shell scripting, Java (a plus), familiar with BI tools (e.g., Power BI, AWS QuickSight, Tableu, etc.)
Proficient at writing high-quality and scalable code and integrating with version control systems
Knowledge of statistical and data mining techniques including model evaluation/validation
Enthusiasm for big data and translating data into actionable insights and demonstrable experience with big data technologies (with structured and unstructured data)
Proficient at building robust data pipelines and delivering reliable data services to stakeholders
Ability to work in a complex, fast-paced environment while maintaining a high degree of accuracy and professionalism
Excellent interpersonal, verbal and written communication skills
Agile project development experience is a plus
Experience leading successful data engineering projects and operationalizing machine learning algorithms
BS (required, 5+ years of experience) or Master's degree (preferred, 3+ years of experience) in computer science, applied mathematics, engineering, operations research, or a related field
About DE
Dominion Enterprises (DE) is a leading digital marketing and software services company offering client solutions across multiple business verticals. Our customers rely on our B2B cloud SaaS solutions to establish their online and mobile brands, generate leads, and manage customer relationships through our Homes.com, Dominion Dealer Solutions, Dominion Business Solutions / DX1, Travel Media and Franchise and Business Opportunity divisions. Our B2C web and mobile applications include Homes.com, HotelCoupons.com, FranchiseOpportunities.com, FranchiseGator.com, Franchise.com, and BusinessBroker.net.
About 2,000 employees reside and work in our Norfolk, VA home office and in offices across the U.S. Our employees will tell you about our collaborative, innovative, team-oriented work environment, excellent career enrichment opportunities, community service opportunities, competitive earnings, and a comprehensive benefits package that includes a generous 401(k). DE is an equal opportunity employer and supports a diverse workforce. DE is a drug-testing employer.
","https://www.ziprecruiter.com/c/Dominion-Enterprises/Job/Experienced-Data-Engineer/-in-Dallas,TX?ojob=ee819187ec0e19fb84e1a57b70640d71"
JOB80901945227,IBM Watson Stack & Big Data Engineer,IBM Watson Stack & Big Data Engineer,,"Evaluate cognitive application requirements and make architectural recommendations for implementation, deployment and provisioning of Watson services and applications on IBM Bluemix,Provide expertise in identification of cognitive use cases that bring significant business value, development of use cases from proof of concept to enterprise-wide implementation and integration of cognitive computing services within an existing application environment,Work alongside the engineering teams and align with all aspects of day to day delivery in an Agile or DevOps environment,You will work with clients to identify Cognitive Computing strategies, options and roadmaps,Internally, you will help identify improved ways of working, mentor junior architects and lead on business development opportunities,Experience in a software engineering/development background (in Java or C# or other COTS Products).,Designing and deploying scalable, highly available, and fault tolerant systems on IBM Bluemix or other cloud platforms (AWS, Azure),Significant experience designing the architecture for Big Data and data science platforms including Hadoop, Spark, data warehouses, NoSQL or graph databases,Knowledge, experience and practical application of Natural Language Processing, Information Retrieval, Semantic Technologies, Big Data or Machine Learning,Development experience and expertise with the Watson Data Platform, Data Science Experience (DSX) and Watson APIs and services including Knowledge Studio, Natural Language Understanding, Speech-to-text and Visual Recognition,Designing analytical data stores for enterprise-wide performance management and data visualisation applications,Architecting optimal cognitive computing solutions based on Watson services from user requirements,Experience in data architecture and designing logical data models,Workshop facilitation, client communication and presentation of cognitive computing concepts to non-technical audiences,Understand, implement, and automate security controls, governance processes, and compliance validation,Understanding of how cognitive computing technology can automate and enhance operational business processes,Experience of DevOps type operations – use of source control (GitHub, Stash), Build tools (Puppet, Jenkins, etc), continuous integration, test driven development (i.e. Cucumber, Lettuce etc),Identifying and defining requirements for a Watson application,Deploying hybrid systems with on-premise and Bluemix components,Providing best practices for building secure and reliable applications on the Bluemix platform,Hadoop administration, set up , security and tuning,Data ingestion,Kafka, Flume, Spark"," now Location Whilst you may have any of our UK offices as a base location, you must be fully flexible in terms of assignment location, as these roles may involve periods of time away from home during the week at short notice.
Who you'll be working with The Big Data Analytics team is part of the Insights and Data Global Practice and has seen strong growth and continued success across a variety of projects and sectors. We continue to grow and need to add to our talented team. We very much try to encourage a ‘leave your grade at the door’ mentality so everyone feels comfortable contributing to our innovation. We also have a great sense of community, we encourage sharing of ideas, we sponsor meet ups for your peers and have a large calendar of social events throughout the year.
If you are keen on working on some truly cutting edge programmes, learning new technologies and techniques and joining a team with like minded big data architects, engineers and analysts, then click the link below and apply now.
The focus of your role We are looking to bring in a Big Data Engineer who is an experienced practitioner in IBM Watson Stack. If you join us, you would be involved with the full life cycle of designing and delivering cognitive computing platforms to support modern analytical data science and AI solutions utilising the IBM Watson product set. Our projects are varied, sometimes you may be asked to help define a client’s data transformation roadmap, other times you may be rolling your sleeves up and creating some innovative solution for a complex problem.
What you'll do
You will work within a Big Data engineering team or an analytics function to:
Evaluate cognitive application requirements and make architectural recommendations for implementation, deployment and provisioning of Watson services and applications on IBM Bluemix
Provide expertise in identification of cognitive use cases that bring significant business value, development of use cases from proof of concept to enterprise-wide implementation and integration of cognitive computing services within an existing application environment
Work alongside the engineering teams and align with all aspects of day to day delivery in an Agile or DevOps environment
You will work with clients to identify Cognitive Computing strategies, options and roadmaps
Internally, you will help identify improved ways of working, mentor junior architects and lead on business development opportunities
What you'll bring If you can demonstrate some or all of these characteristics then we’d really like to talk to you -
Experience in a software engineering/development background (in Java or C# or other COTS Products).
Designing and deploying scalable, highly available, and fault tolerant systems on IBM Bluemix or other cloud platforms (AWS, Azure)
Significant experience designing the architecture for Big Data and data science platforms including Hadoop, Spark, data warehouses, NoSQL or graph databases
Knowledge, experience and practical application of Natural Language Processing, Information Retrieval, Semantic Technologies, Big Data or Machine Learning
Development experience and expertise with the Watson Data Platform, Data Science Experience (DSX) and Watson APIs and services including Knowledge Studio, Natural Language Understanding, Speech-to-text and Visual Recognition
Designing analytical data stores for enterprise-wide performance management and data visualisation applications
Architecting optimal cognitive computing solutions based on Watson services from user requirements
Experience in data architecture and designing logical data models
Workshop facilitation, client communication and presentation of cognitive computing concepts to non-technical audiences
Understand, implement, and automate security controls, governance processes, and compliance validation
Understanding of how cognitive computing technology can automate and enhance operational business processes
Any Experience of:
Experience of DevOps type operations – use of source control (GitHub, Stash), Build tools (Puppet, Jenkins, etc), continuous integration, test driven development (i.e. Cucumber, Lettuce etc)
Identifying and defining requirements for a Watson application
Deploying hybrid systems with on-premise and Bluemix components
Providing best practices for building secure and reliable applications on the Bluemix platform
Familiarity of the Hadoop ecosystem (Cloudera, Hortonworks, IBM, AWS, MicroSoft & Google)
Hadoop administration, set up , security and tuning
Data ingestion
Kafka, Flume, Spark
SQL on Hadoop tools
What we'll offer you Professional development. Accelerated career progression. An environment that encourages entrepreneurial spirit. It’s all on offer at Capgemini. And although collaboration is at the core of the way we work, we also recognise individual needs with a flexible benefits package you can tailor to suit you.
Why we're different At Capgemini, we help organisations across the world become more agile, more competitive and more successful. Smart, tailored, often-groundbreaking technical solutions to complex problems are the norm. But so, too, is a culture that’s as collaborative as it is forward thinking. Working closely with each other, and with our clients, we get under the skin of businesses and to the heart of their goals. You will too.
Capgemini is proud to represent nearly 130 nationalities and its cultural diversity. Our holistic definition of diversity extends beyond gender, gender identity, sexual orientation, disability, ethnicity, race, age and religion. Capgemini views diversity as everything that makes us who we are as an organization, including our social background, our experiences in life and work, our communication styles and even our personality. These dimensions contribute to the type of diversity we value the most: diversity of thought.
We want to make sure that we find the right people to work in our teams, and we know that working full-time isn’t necessarily right for everyone. So we’d love to hear from you if you feel you’re a great fit for this role, and would like to work flexibly. As an example, some of our team members work four days a week, but travel across the UK during their working days. Or you might prefer to work three days a week (in a job share scenario) with travel limited to Greater London. If you are the right person for this role, we’ll find the right working approach for you.
Find out more and apply
Other jobs you may like
Java Developer Agile Java (Senior) Data
Client Server - London
6 days ago
Data Architect - BI, MDM, Data Warehousing, O...
Logic Engagements - London
9 days ago
DevOps Platform engineer
Capita IT Resourcing - Oldham
3 days ago
Senior Software Engineer - Stafford
Orion Electrotech - Stafford
30+ days ago
Software Test Engineer (Embedded / Firmware)
Innovative Technology Ltd - Manchester
14 days ago
",http://www.indeed.co.uk/job/IBM-Watson-Stack-Big-Data-Engineer-at-Capgemini-in-United-Kingdom-f36d6646cdc82d08
JOB82129475827,DATA ENGINEER/SYSTEMS ENGINEER,DATA ENGINEER/SYSTEMS ENGINEER,Advanced degree in systems or electrical engineering or equivalent experience in systems engineering,"Advance the development of the optical read/write drive for Folio Photonics’ DataFilm DiscTM,Hands-on engineering of the data storage system consisting of Folio’s DataFilm DiscTM and associated read/write drive as well as integration into customers’ multidisc library,Signal processing and data engineering for optical data.,Integration of drive with data storage system,Display strong interpersonal skills to work with our cross-functional engineering and executive teams,Management opportunity for appropriately qualified candidates","
DATA ENGINEER/SYSTEMS ENGINEER
Employer Description
Folio Photonics is a dynamic startup company focused on developing a multi-terabyte multilayer fluorescent optical disc with a decades long shelf- life, small environmental footprint, and low total cost of ownership. This represents a significant and much needed breakthrough for the archival and nearline data storage industry. Folio technology's benefits include: lowest industry price per gigabyte; lower datacenter costs by reducing electricity required to spin disks and cool space; reduced rates of re-archiving previously archived data, and giving users fast access to more data for analysis, trend spotting, and informed decision making. Our team is composed of talented individuals that work to bring this technology to market.
We seek an experienced individual in engineering management whose area of technical expertise is in data engineering. This engineering manager will oversee the development of the optical drive/tester and its optical pickup unit (OPU) for the drive needed to read and write data on our multilayer optical disc, and will work with the company’s Chief Technology Officer (CTO) to help manage the overall product development projects. Engineering duties will include development of the media and drive systems as well as integration into multidisc data storage systems. If you are a talented engineering manager/systems engineer with desire to help lead a dynamic start-up company, this position is for you.
Job Duties:
Advance the development of the optical read/write drive for Folio Photonics’ DataFilm DiscTM
Hands-on engineering of the data storage system consisting of Folio’s DataFilm DiscTM and associated read/write drive as well as integration into customers’ multidisc library
Signal processing and data engineering for optical data.
Integration of drive with data storage system
Display strong interpersonal skills to work with our cross-functional engineering and executive teams
Management opportunity for appropriately qualified candidates
Job Requirements
Advanced degree in systems or electrical engineering or equivalent experience in systems engineering
",https://optics.org/jobs/5374348
JOB82478033417,"Data Engineer, Retail Business Intelligence","Data Engineer, Retail Business Intelligence","Advanced SQL knowledge,7+ years of data extraction experience,Should be proficient in writing advanced SQL and tuning SQL code,Semantic layer (ESL) development experience with relational databases such as Oracle/Teradata/Vertica/Hadoop desired,Experience with data induction and validation against source systems,Experience working in Capital Projects a plus, including writing requirements and executing UAT,Expert at normalizing data for reporting,Strong analytical skills; should have the ability to evaluate, analyze and present data to answer business questions,Experience with data visualization tools (e.g.: Tableau) a plus,Familiarity with Finance, Operations, Retail Contact Center data desired,Desire for end-to-end ownership of work,Flexibility to balance directional changes and ability to support multiple deadline-specific projects while maintaining day-to-day business support,Ability to deal with ambiguity,Proactive, driven individual who is comfortable working in a global, matrixed, fast-paced environment",,"The people here at Apple don’t just build products — we craft the kind of wonder that’s revolutionized entire industries. It’s the diversity of those people and their ideas that supports the innovation that runs through everything we do, from amazing technology to industry-leading environmental efforts. Join Apple and help us leave the world better than we found it. Do you love problem solving and thinking beyond an obvious solution? Do you thrive in ambiguity and teams where little guidance fuels your creativity? The Retail Business Intelligence group is looking for a Data Info Analyst / Data Engineer to define, develop and maintain easy-to-query certified datasets and reporting tools that will support downstream dashboards and analysis. Acting as the data SME for multiple subject areas, your tasks will include working closely with IT and downstream customers to drive for optimal data collection and delivery throughout ongoing projects. A passion to understand the process of data creation, from the source systems to reporting objects is critical.
Advanced SQL knowledge
7+ years of data extraction experience
Should be proficient in writing advanced SQL and tuning SQL code
Semantic layer (ESL) development experience with relational databases such as Oracle/Teradata/Vertica/Hadoop desired
Experience with data induction and validation against source systems
Experience working in Capital Projects a plus, including writing requirements and executing UAT
Expert at normalizing data for reporting
Strong analytical skills; should have the ability to evaluate, analyze and present data to answer business questions
Experience with data visualization tools (e.g.: Tableau) a plus
Familiarity with Finance, Operations, Retail Contact Center data desired
Desire for end-to-end ownership of work
Flexibility to balance directional changes and ability to support multiple deadline-specific projects while maintaining day-to-day business support
Ability to deal with ambiguity
Proactive, driven individual who is comfortable working in a global, matrixed, fast-paced environment
Ability to build effective relationships in a multi-functional team environment
Working in a centralized organization, this position plays a substantial role in defining how data is structured, organized and evaluated for consistent understanding and interpretation. A key success factor for this role is the ability to understand diverse partner needs, dive deep into the data, analyze complex elements in a multi-dimensional fashion and deliver significant insights to senior management and business partners in a comprehensive and persuasive manner. You will: - Engage in business initiatives and capital projects to ensure the planned impact of changes will be measurable. - Execute unit integration and UAT (user acceptance testing) to support system implementations and upgrades. - Define how data is structured, organized and interpreted by building certified datasets for consistent analytics and reporting. - Develop web reports and analytical tools. - Provide consultation and training to users of analytical tools and data sets. - Define, build and deploy relevant metrics and perform ad hoc analyses.
",https://jobs.apple.com/en-us/details/200118204/data-engineer-retail-business-intelligence
JOB82605828625,"AI/ML - Sr Data Engineer, Siri Data","AI/ML - Sr Data Engineer, Siri Data","You have excellent written and verbal communication skills.,You are tenacious, relentless, & determined.,You are curious: always learning new technologies, rapidly synthesizing new information, and understanding “the why” before “the what.”,You are self-directed and capable of operating amid ambiguity.,You are poised and display excellent judgment in prioritizing across difficult tradeoffs.,You are pragmatic: not letting “the perfect” be the enemy of “the good.”",,"Would you like to play a critical part in the next revolution of human-computer interaction? Would you like to contribute to the advancement of a product that is globally redefining how humans use voice to relate to technology? The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within Siri Data, the mission of Siri data engineering is to build the scalable & high quality data sets that curate the data required to give our customers their voice. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream analytical & product consumers.
You have excellent written and verbal communication skills.
You are tenacious, relentless, & determined.
You are curious: always learning new technologies, rapidly synthesizing new information, and understanding “the why” before “the what.”
You are self-directed and capable of operating amid ambiguity.
You are poised and display excellent judgment in prioritizing across difficult tradeoffs.
You are pragmatic: not letting “the perfect” be the enemy of “the good.”
You are humble, continually growing in self-awareness and possessing a growth mindset.
Moving between understanding the open & unanswered questions about Siri; to defining new metrics and filters; to specifying new logging necessary with the high-level goal of using data to improve Siri. Designing, creating, and maintaining data pipelines that populate a petabyte scale data warehouse. Working with data infrastructure teams providing input to improve our platform. Working with data producing teams to specify requirements and to transparently provide rapid feedback. Partnering with your teammates across Siri data to answer questions, to provide support, and to innovate in taking our data warehouse to the next level.
Surprise us! Many will have an MS or BS in CS, Engineering, Math, Statistics, or a related field OR equivalent practical experience in data engineering. 4+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, Flink, Kafka, etc.) for building efficient & large-scale data pipelines. Software Engineering proficiency in at least one high-level programming language (Java, Scala, Python or equivalent). Experience required in building batch data processing pipelines curating data for data science consumers. Experience strongly preferred building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others.
",https://jobs.apple.com/en-us/details/200128489/ai-ml-sr-data-engineer-siri-data
JOB83471745866,Data Engineer / Data Engineer with Programming language experience/ Software Engineer /Software d...,Data Engineer / Data Engineer with Programming language experience/ Software Engineer /Software d...,,,"
Company Description
Infotree's approach to every employee and customer is based around making a positive impact. We focus on over-servicing, continuous improvement and a high-quality culture. We're passionate about making successful matches for our employees and customers across the globe. Infotree prides itself in our proven track record and innovative culture with 100% focus on the employees and customers
ONLY W2
If interested, Please directly reach out to me at [email protected] or 734-928-2457.
Title: Software Dev Engineer II
Duration: 12+ Months
Location: Seattle, WA
Description:
As a Software Development visionary, are you working on new technologies, surrounded by disruptive problem solvers, or working with game-changers? We are. our team is leading the way in delivering Big Data solutions. The only question is; ""will you come along for the ride?""
Description:
The Client Data Products and Platforms team is currently looking for talented and highly motivated Software Development Engineers with a heavy programming and analysis background. As part of this team, you will be responsible for the delivery of solutions on top of the Big Data platforms implementation and will be playing a key role in this huge technology pivot. You will not only help train our existing staff making the leap over to our new technologies, but you will also empower the team to approach problems differently. These solutions drive business value from powering the most critical business decisions to powering how the site behaves through various avenues of personalization. This entails working with the delivery team and business partners to flesh out requirements, complete solution design, development and ultimate delivery to the end consumers.
Responsibilities:
You will understand business rules; define and develop applications/ architecture, perform source to target data mapping, design, review, implement and optimize Data Engineering and ETL processes.
You will actively be involved in reviews on development and test specifications. Perform data analysis, provide development/QA support for existing systems, and troubleshoot data and/or system issues within the Data Warehouse environment as well as upstream systems, as needed.
You will drive investigations across the organizations and deliver resolution of technical, procedural, and/or operational issues to completion and ensure customer satisfaction.
You will develop test plans/cases, conditions and scenarios in support of ongoing business system applications and infrastructure.
You will provide timely and appropriate communication to business owners, business partners, and users on issue status and resolution.
Qualifications:
Strong Background in Data warehousing principles, architecture and its implementation in large environments.
Experience in data engineering applications and products in AWS or any cloud provider.
Data engineering/ETL Design and Development knowledge using Hadoop or Spark
Experience with AWS (Dynamo DB, Lambda, or S3).
Hands-on experience on programming (Java, Python, or Scala), and to perform data/file manipulation using Shell scripting.
Experience using no-SQL technologies and Big Data platforms - strong development skills around Hadoop, Hive, Map Reduce.
Hands-on experience using Database procedural languages such as SQL, PL/SQL, T-SQL;
Hands-on experience with test practices and processes; test automation, test coverage and user acceptance testing.
Exposure to Object-oriented design, distributed computing, performance/scalability tuning, advanced data structures and algorithms, real time analytics and large scale data processing.
Exposure to ETL Development tools such as Airflow, SSIS, SSRS, DataServices.
Experience working in Agile/SCRUM model.
Core Competencies:
Ability to design multi-platform solutions.
Excellent collaboration with customers, including crisp and compelling verbal and written communication.
Excellent problem solving and analytical skills.
Ability and desire to work in a fast-paced environment and stay motivated/flexible.
Ability to work cross functionally to resolve technical, procedural, and operational issues.
Education and Work Experience:
MS/ME/BS/BE/B Tech degree in Computer Science, related technical field, or equivalent work experience.
5+ years of experience in data warehouse technologies.
Many Thanks & Warm Regards,
Kajal Verma
Technical Recruiter
(: 734-928-2457
Infotree Global Solutions
*: [email protected]
https://www.infotreeglobal.com
Additional Information
All your information will be kept confidential according to EEO guidelines.
Responsibilities: ONLY W2 If interested, Please directly reach out to me at [email protected] or 734-928-2457. Title: Software Dev Engineer II Duration: 12+ Months Location: Seattle, WA Description: As a Software Development visionary, are you working on new technologies, surrounded by disruptive problem solvers, or working with game-changers? We are. our team is leading the way in delivering Big Data solutions. The only question is; ""will you come along for the ride?"" Description: The Client Data Products and Platforms team is currently looking for talented and highly motivated Software Development Engineers with a heavy programming and analysis background. As part of this team, you will be responsible for the delivery of solutions on top of the Big Data platforms implementation and will be playing a key role in this huge technology pivot. You will not only help train our existing staff making the leap over to our new technologies, but you will also empower the team to approach problems differently. These solutions drive business value from powering the most critical business decisions to powering how the site behaves through various avenues of personalization. This entails working with the delivery team and business partners to flesh out requirements, complete solution design, development and ultimate delivery to the end consumers. Responsibilities: You will understand business rules; define and develop applications/ architecture, perform source to target data mapping, design, review, implement and optimize Data Engineering and ETL processes. You will actively be involved in reviews on development and test specifications. Perform data analysis, provide development/QA support for existing systems, and troubleshoot data and/or system issues within the Data Warehouse environment as well as upstream systems, as needed. You will drive investigations across the organizations and deliver resolution of technical, procedural, and/or operational issues to completion and ensure customer satisfaction. You will develop test plans/cases, conditions and scenarios in support of ongoing business system applications and infrastructure. You will provide timely and appropriate communication to business owners, business partners, and users on issue status and resolution. Qualifications: Strong Background in Data warehousing principles, architecture and its implementation in large environments. Experience in data engineering applications and products in AWS or any cloud provider. Data engineering/ETL Design and Development knowledge using Hadoop or Spark Experience with AWS (Dynamo DB, Lambda, or S3). Hands-on experience on programming (Java, Python, or Scala), and to perform data/file manipulation using Shell scripting. Experience using no-SQL technologies and Big Data platforms - strong development skills around Hadoop, Hive, Map Reduce. Hands-on experience using Database procedural languages such as SQL, PL/SQL, T-SQL; Hands-on experience with test practices and processes; test automation, test coverage and user acceptance testing. Exposure to Object-oriented design, distributed computing, performance/scalability tuning, advanced data structures and algorithms, real time analytics and large scale data processing. Exposure to ETL Development tools such as Airflow, SSIS, SSRS, DataServices. Experience working in Agile/SCRUM model. Core Competencies: Ability to design multi-platform solutions. Excellent collaboration with customers, including crisp and compelling verbal and written communication. Excellent problem solving and analytical skills. Ability and desire to work in a fast-paced environment and stay motivated/flexible. Ability to work cross functionally to resolve technical, procedural, and operational issues. Education and Work Experience: MS/ME/BS/BE/B Tech degree in Computer Science, related technical field, or equivalent work experience. 5+ years of experience in data warehouse technologies. Many Thanks & Warm Regards, Kajal Verma Technical Recruiter (: 734-928-2457 Infotree Global Solutions *: [email protected] https://www.infotreeglobal.com
","https://www.ziprecruiter.com/c/Infotree-Service-Inc/Job/Data-Engineer-Data-Engineer-with-Programming-language-experience-Software-Engineer-Software-d.../-in-Seattle,WA?ojob=bd9d23b6dde61fc298a4db023e1d0ef5"
JOB83966658207,Data Engineer - Snowflake / Stitch / Fivetran,Data Engineer - Snowflake / Stitch / Fivetran,,Project Type: One-time project,"Data Engineer - Snowflake / Stitch / Fivetran
We are Matador Labs, an automotive company based in Montreal. The Lead Data Architect/Engineer will help Matador build technology that can sync/stItch data from different sources together.
The end goal is to bring a customer data platform that utilizes etl tool's (like stitch & fivetran) that will allow the users of matador to connect various sources and destinations through the matador platform. Our current warehouse is build around Snowflake.
Experience with tools such as: segment, stitch, fivetran and other analytics tool is a must!
- Have 7 to 10 years of experience in the development, transformation and operation of databases
- Complete command of SQL language (preferably on SQL Server), SSIS tool and ETL processes
- Ability to integrate new data sources by working with IT engineers.
- Solid knowledge in the design, construction and maintenance of a data warehouse
- Experience with Windows Server and Task Scheduler.
- Experience in an inventory environment (an important asset)
- Experience in reporting and visualization with Power Bi and / or Tableau (an asset)
- Experience with AWS or Snowflake (an asset).
Project Type: One-time project
Skills and Expertise
Activity on this job
",https://www.upwork.com/job/Lead-Data-Architect-Engineer_~012685dc9e36c4b15b/
JOB85073156629,Data Engineer,Data Engineer,"Bachelor's or Master's degree in Computer Science or related technical field or equivalent professional experience,Greater than 3 years of experience,Safety & Quality First,Valuing Ethics, Integrity & Diversity,Passion for Serving Our Customers Globally,Dedication to Each Other Through Servant Leadership,Creating Value for Shareholders, Customers and Employees,Consistently Delivering Our Commitments.,Competitive Salary,Comprehensive Health, Wellness and Income Protection Benefits,401(k) Savings Plan with Company Match,Paid Vacations and Holidays,Opportunities for Flexible Work Arrangements,Educational Reimbursement Program,Employee Referral Program","Assist with creation of data schemas, stored procedures, data pipelines, and views,Help build and maintain technical solutions required for optimal ingestion, transformation, and loading of data from a wide variety of data sources and large, complex data sets,Collaborate across roles to embrace best practices in reporting and analysis, including data integrity, test design, validation, and documentation,Ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy,Build and automate actionable reports,Collaborate with data analysts, data scientists, and stakeholders during design discussions to uncover more detailed business requirements related to data engineering,Develop strong hypotheses, independently solve problems, and share actionable insights with engineering","
Job Responsibilities
Are you interested in being part of an innovative team that supports Westinghouse's mission to provide clean energy solutions? At Westinghouse, we recognize that our employees are our most valuable asset and we seek to identify, attract and recruit the most qualified talent while recognizing and encouraging the value of diversity in the global workplace.
If this sounds like an environment you would thrive in, we have an exciting opportunity for a Data Engineer.
Your Day-to-Day:
Assist with creation of data schemas, stored procedures, data pipelines, and views
Help build and maintain technical solutions required for optimal ingestion, transformation, and loading of data from a wide variety of data sources and large, complex data sets
Collaborate across roles to embrace best practices in reporting and analysis, including data integrity, test design, validation, and documentation
Ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Build and automate actionable reports
Collaborate with data analysts, data scientists, and stakeholders during design discussions to uncover more detailed business requirements related to data engineering
Develop strong hypotheses, independently solve problems, and share actionable insights with engineering
Partner and develop strong relationships with cross-functional teams
Minimum Requirements
Who You Are:
As a successful candidate, you will bring the following to the team:
Bachelor's or Master's degree in Computer Science or related technical field or equivalent professional experience
Greater than 3 years of experience
Experience with Azure products; Data Factory or Databricks is required
Education Level
Bachelors Degree, Masters Degree
Years of Experience
3+ Years
Benefits
""Why Westinghouse?
Westinghouse Electric Company is the global nuclear energy industry's first choice for safe, clean, and efficient energy solutions. We enable our delivery of this vision by living our value system:
Safety & Quality First
Valuing Ethics, Integrity & Diversity
Passion for Serving Our Customers Globally
Dedication to Each Other Through Servant Leadership
Creating Value for Shareholders, Customers and Employees
Consistently Delivering Our Commitments.
Westinghouse offers competitive benefits to all our employees around the globe to keep them healthy and enhance their well-being. In the U.S. the following are representative of what we offer:
Competitive Salary
Comprehensive Health, Wellness and Income Protection Benefits
401(k) Savings Plan with Company Match
Paid Vacations and Holidays
Opportunities for Flexible Work Arrangements
Educational Reimbursement Program
Employee Referral Program
While our Global Headquarters are located in Cranberry Township, PA, we have over 9,000 employees working at locations in 19 different countries. You can learn more by visiting link http://www.westinghousenuclear.com./careers/
EOE of Minorities / Females / Vets / Disability.
Keep in mind that only applications completed and submitted via the Westinghouse Careers website will be considered. You can submit your completed application, and also explore other available options, using the following link: link http://www.westinghousenuclear.com/careers/
Get connected with Westinghouse on social media:
Twitter | Facebook | LinkedIn| YouTube
Notice
Employment opportunities for positions in the United States may require use of information which is subject to the export control regulations of the United States. Hiring decisions for such positions are required by law to be made in compliance with these regulations. Applicants for employment opportunities in other countries must be able to meet the comparable export control requirements of that country and of the United States.
",https://www.gettinghired.com/job-details/251837/data-engineer/
JOB86540855866,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-fi/details/200188037/ai-ml-search-data-engineer-siri-data
JOB86632114726,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-fr/details/200188037/ai-ml-search-data-engineer-siri-data
JOB86688115219,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-us/details/200188037/ai-ml-search-data-engineer-siri-data
JOB86745684800,Data Engineer,Data Engineer,,"Use technology such as Spark, Kafka and SQS to build large scale real time and batch data pipelines.,Help implement cloud technologies such as AWS, Azure or GCP.,Program in at least one of the following languages - Java, Scala or Python.,Proven experience in data development in a big data/ Hadoop and cloud data warehouse using SQL or SQL based ETL capabilities.,Have a deep understanding of the processes, skills and technologies which are needed to deliver complex development solutions for a business.,Understand and have experience working with a variety of delivery methods, such as Agile, Waterfall and Scrum.,Experience developing in the cloud with AWS or Snowflake.,Work in one of the most data rich businesses in the UK.,Competitive bonus.,Discount across brands.","
DATA ENGINEER £45,000- 55,000 + BONUS + COMPETITIVE BONUS
CENTRAL LONDON
Are you looking to join one of the largest retailers, with one of the most visited websites in the UK as a Data Engineer where you will be working on huge data sets in a serverless environment? You will be using the latest technology solutions and have the opportunity to make a real impact within your squad due to a highly collaborative culture.
THE COMPANY:
As one of the largest retailers in the UK with multiple sub-brands you will be working in a data rich environment across a wide variety of projects. You will help deliver solutions to millions of customers across the UK and provide real value both to customers and stakeholders within the business.
THE ROLE:
You will be joining a team of highly experienced and passionate data engineers and architects to undertake data transformation and solution development. You will be working with a wide range of tools across a mix of Big Data, Cloud and open source platforms.
In specific, you can expect to be involved in the following:
Use technology such as Spark, Kafka and SQS to build large scale real time and batch data pipelines.
Help implement cloud technologies such as AWS, Azure or GCP.
Program in at least one of the following languages - Java, Scala or Python.
Work as part of an Agile squad to deliver solutions in a flexible manner.
YOUR SKILLS AND EXPERIENCE:
The successful Data Engineer will have the following skills and experience:
Proven experience in data development in a big data/ Hadoop and cloud data warehouse using SQL or SQL based ETL capabilities.
Have a deep understanding of the processes, skills and technologies which are needed to deliver complex development solutions for a business.
Understand and have experience working with a variety of delivery methods, such as Agile, Waterfall and Scrum.
Experience developing in the cloud with AWS or Snowflake.
Understand the process of developing data stores and data warehouses and have hands on experience in doing so in a previous role.
THE BENEFITS:
Work in one of the most data rich businesses in the UK.
Competitive bonus.
Discount across brands.
Competitive benefits.
HOW TO APPLY:
Please register your interest by sending your CV to Lillie via the Apply link on this page.
",https://www.reed.co.uk/jobs/data-engineer/39765557
JOB87232715745,"ELT Data Engineer (Talend, Datastage), Banking and Financial Services","ELT Data Engineer (Talend, Datastage), Banking and Financial Services",,DataStage,"
Meet our professionals
Canada-That's CGI
Position Description
We are a global IT and business consulting services leader, and after 40 years, we're still growing! Join Canada's largest IT Company in our Global Wealth and Banking Services Division in Toronto.
CGI supports our members’ career aspirations, offering learning initiatives and provides access to our global health and wellness program. We also offer competitive compensation and benefits such as our share purchase plan, a profit sharing program, flexible schedules that guarantee a good work-life balance!
Innovation, technology and service delivery are our focus. Our goal is to ensure our clients remain ahead of the competition. We provide a full spectrum of services from Business Consulting and Systems Integration to Managed Services and IP Solutions that are transforming our clients’ operations and helping them to succeed.
Your future duties and responsibilities
As a Data Engineer, you will design, develops, tests, implements, and maintains complex ELT functions, user defined functions and complex queries for custom solutions with limited direction.
Leads and coordinates code/peer review of focused development work to ensure it aligns to the business and technical requirements.
• Collaborate with Product Owners and Analysts to understand business requirements and define technical solutions.
• Design, develop, maintain and take ownership of code.
• Design reusable components, user defined functions.
Required qualifications to be successful in this role
• Minimum 5 years+ of related experience in Data Engineering.
• Education: College/Bachelor in Computer Science and or related discipline. Recent relevant technical certification an asset.
• Experience and knowledge of data architecture and concepts of relational and dimensional databases
• Experience with enterprise application architecture and enterprise integration patterns.
• Ability to implement re-usable data-integration/ETL code in an enterprise data-warehouse environment.
• Perform complex applications programming activities. Code, test, debug, document, maintain, and modify complex applications program as required.
• Examine and solve the performance bottlenecks in the ETL processes.
• Demonstrates good understanding of the Software Development Life Cycle.
• Proficiency in ETL tools - specifically Talend or DataStage.
• Strong SQL skills.
• Must have an experience working in Data Lake environment with Hive, Beeline expertise preferred.
• Previous experience of working in an Agile Development environment.
• Ability to work well in a challenging environment.
• Strong troubleshooting skills.
• Excellent writing skills, oral communication skills, strong process skills, and leadership ability.
• Ability to multi-task and prioritize under minimal supervision.
What you can expect from us
Build your career with us.
It is an extraordinary time to be in business. As digital transformation continues to accelerate, CGI is at the center of this change—supporting our clients’ digital journeys and offering our professionals exciting career opportunities.
At CGI, our success comes from the talent and commitment of our professionals. As one team, we share the challenges and rewards that come from growing our company, which reinforces our culture of ownership. All of our professionals benefit from the value we collectively create.
Be part of building one of the largest independent technology and business services firms in the world.
Learn more about CGI at www.cgi.com.
No unsolicited agency referrals please.
CGI is an equal opportunity employer. In addition, CGI is committed to providing accommodations for people with disabilities in accordance with provincial legislation. Please let us know if you require a reasonable accommodation due to a disability during any aspect of the recruitment process and we will work with you to address your needs.
",https://www.cgi.com/polska/en/careers-search/J1020-2795/elt-data-engineer-talend-datastage-banking-and-financial-services
JOB87709944166,Data Engineer Intern,Data Engineer Intern,,,"
Company/Organization: EPAM Systems, Inc
Description:
Data Engineer interns at EPAM Systems, Inc are integrated into our data warehousing team as part of our regular agile cadence. The data engineer intern works with our data warehouse and BI tools to provide business reporting and analysis capabilities to our customers.
The Role
Data Engineer Intern will work closely during this internship with their Agile team of other engineers, QA, and product owners to design and implement features through a variety of technologies. Data Engineer Interns are expected to participate in writing/reading code of a variety of languages and paradigms, gathering and organizing product requirements, testing theirs and their peers software, both automated and manually. Data Engineer Interns are mentored while gaining domain and technical knowledge during this internship.
Essential Functions:
* Participate in agile processes.
* Develop, test and refactor SQL Reports.
* Develop online dashboards.
* Work closely with Client Success and Data System & Reporting teams.
* Collaborate in a distributed team environment.
* Build SQL Queries.
Qualifications:
* Currently attending university for Computer Science or related field.
* Java programming skills.
* Firm understanding of data structures and algorithms.
* Familiarity with relational database concepts.
* Willingness to be mentored and grow.
* Excellent verbal and written communication skills.
* Keen eye for detail.
* Undying passion for data quality.
* Summer internship only.
* MA or RI candidates only.
Paid Internship Info:
$24/Hr
Hours:
9AM-3PM Mon-Fri
Length/Availability:
12 weeks
Start Date:
09/24/2018
End Date:
09/14/2018, 11/29/2018
Deadline: Additional Info:
All applicants must successfully complete a thorough medical and psychological exam, a polygraph interview and an extensive background investigation. US citizenship is required.
Tags: More Internships in California: ",http://www.internweb.com/internship/CA/30004/20299/int/
JOB88101055003,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-mo/details/200188037/ai-ml-search-data-engineer-siri-data
JOB88200135528,"19,054 Lead Data Engineer Jobs","19,054 Lead Data Engineer Jobs",,,,https://www.ziprecruiter.com/Jobs/Lead-Data-Engineer
JOB88857369426,"Data Engineer (Green Card Holders only) 130,000","Data Engineer (Green Card Holders only) 130,000",Python,"Leverage company data to drive business outcomes.,Play a role in their analytics team developing data-driven solutions, taking ownership for driving client Growth.,Develop and maintain global data models by analysing use cases and applications and across all other brands.,Design and develop scalable data ingestion frameworks to transform a variety of
large data sets.,Own end-to-end delivery of raw and trained data sets to and from brand cloud environments.,Integrate with data platform architecture by building applications using open-source frameworks such as Apache Spark, containerized applications (i.e. Kubernetes), and Apache Airflow.,Build and maintain data integration utilities, data scheduling and monitoring capabilities, source-to-target mappings and data lineage trees.,Implement and manage production support processes around data lifecycle, data quality, coding utilities, storage, reporting and other data integration points.,Maintain system performance by identifying and resolving production and application development problems; calculating optimum values for parameters; evaluating, integrating and installing new releases; performing routine maintenance; and answering user questions.","
Our client is looking for a data engineer to add to their growing team. They are making this investment to help optimise their digital channels and technology innovations with a goal of creating competitive advantages for their businesses around the globe. They are looking for a solid engineer who brings modern ideas from previous experiences and is keen to tackle new challenges in their business.
They are looking for a candidate who enjoys working with modern data integration frameworks, big data and cloud technologies. Candidates must be competent with data programming languages ie, Python and SQL. The data engineer will build a variety of data pipelines and models to support advanced AI/ML analytics projects - with the intent of lifting the customer exp and driving revenues with profit growth for their businesses internationally.
Job Duties
As a Data Engineer, you will:
Leverage company data to drive business outcomes.
Play a role in their analytics team developing data-driven solutions, taking ownership for driving client Growth.
Develop and maintain global data models by analysing use cases and applications and across all other brands.
Design and develop scalable data ingestion frameworks to transform a variety of
large data sets.
Own end-to-end delivery of raw and trained data sets to and from brand cloud environments.
Integrate with data platform architecture by building applications using open-source frameworks such as Apache Spark, containerized applications (i.e. Kubernetes), and Apache Airflow.
Build and maintain data integration utilities, data scheduling and monitoring capabilities, source-to-target mappings and data lineage trees.
Implement and manage production support processes around data lifecycle, data quality, coding utilities, storage, reporting and other data integration points.
Maintain system performance by identifying and resolving production and application development problems; calculating optimum values for parameters; evaluating, integrating and installing new releases; performing routine maintenance; and answering user questions.
Lead technical teams and projects to deliver projects and accomplish business and
IT objectives.
Skills and Qualifications
Airflow
Data Warehousing
Amazon Web Services
Snowflake
Data Models
Kubernetes
Apache Spark
SQL
Python
Reference: 39744167
Bank or payment details should never be provided when applying for a job. For information on how to stay safe in your job search, visit SAFERjobs.
Report this job
Not quite what you are looking for? Try these similar searches
",https://www.reed.co.uk/jobs/data-engineer-green-card-holders-only-130000/39744167
JOB88978270763,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-in/details/200188037/ai-ml-search-data-engineer-siri-data
JOB89541192217,"AI/ML - Sr Data Engineer, Siri Data","AI/ML - Sr Data Engineer, Siri Data","You have excellent written and verbal communication skills.,You are tenacious, relentless, & determined,You are curious: always learning new technologies, rapidly synthesizing new information, and understanding “the why” before “the what.”,You are self-directed and capable of operating amid ambiguity.,You are poised and display excellent judgment in prioritizing across difficult tradeoffs.,You are pragmatic: not letting “the perfect” be the enemy of “the good.”",,"AI/ML - Sr Data Engineer, Siri Data
Summary
Would you like to play a critical part in the next revolution of human-computer interaction? Would you like to contribute to the advancement of a product that is globally redefining how humans use voice to relate to technology? The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within Siri Data, the mission of Siri data engineering is to build the scalable & high quality data sets that curate the data required to give our customers their voice. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream analytical & product consumers.
You have excellent written and verbal communication skills.
You are tenacious, relentless, & determined
You are curious: always learning new technologies, rapidly synthesizing new information, and understanding “the why” before “the what.”
You are self-directed and capable of operating amid ambiguity.
You are poised and display excellent judgment in prioritizing across difficult tradeoffs.
You are pragmatic: not letting “the perfect” be the enemy of “the good.”
You are humble, continually growing in self-awareness and possessing a growth mindset
Moving between understanding the open & unanswered questions about Siri; to defining new metrics and filters; to specifying new logging necessary with the high-level goal of using data to improve Siri. Designing, creating, and maintaining data pipelines that populate a petabyte scale data warehouse. Working with data infrastructure teams providing input to improve our platform. Working with data producing teams to specify requirements and to transparently provide rapid feedback. Partnering with your teammates across Siri data to answer questions, to provide support, and to innovate in taking our data warehouse to the next level.
Surprise us! Many will have an MS or BS in CS, Engineering, Math, Statistics, or a related field OR equivalent practical experience in data engineering. 4+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, Flink, Kafka, etc.) for building efficient & large-scale data pipelines. Software Engineering proficiency in at least one high-level programming language (Java, Scala, Python or equivalent). Experience required in building batch data processing pipelines curating data for data science consumers. Experience strongly preferred building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others.
",https://jobs.apple.com/en-us/details/200088405/ai-ml-sr-data-engineer-siri-data
JOB90375924261,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-se/details/200188037/ai-ml-search-data-engineer-siri-data
JOB90467494433,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-ng/details/200188037/ai-ml-search-data-engineer-siri-data
JOB90728524327,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-hk/details/200188037/ai-ml-search-data-engineer-siri-data
JOB91002664843,Big Data Engineer,Big Data Engineer,"BSc or MSc in Computer Science or related field (or equivalent experience),Strong analytical, learning and problem solving skills with personal interest in subjects such as math/statistics, machine learning, AI and analytics,Solid knowledge of data structures, algorithms and Unix/Linux,Proficient in Scala, Java and SQL,Strong experience with Apache Spark 2.0,Experience working in an Agile environment using TDD and Continuous Integration,Experience refactoring code with scale and production in mind,Familiar with Git, Python, JavaScript, HTML and CSS,Proficient understanding of distributed computing principles,Proficiency with Hadoop v2, MapReduce, HDFS,Good knowledge of Big Data querying tools, such as Pig, Hive, and Impala,Experience with integration of data from multiple data sources,Experience with NoSQL databases, such as HBase, Cassandra, MongoDB,Knowledge of various ETL techniques and frameworks,Experience with Big Data ML toolkits, such as Mahout, SparkML, or H2O,Experience with Cloudera/MapR/Hortonworks,Management of Hadoop cluster, with all included services,Experience with building stream-processing systems, using solutions such as Storm or Spark-Streaming,Good understanding of Lambda Architecture, along with its advantages and drawbacks,Experience with various messaging systems, such as Kafka or RabbitMQ","Working in a cross-functional team – alongside talented Engineers and Data Scientists,Building scalable and high-performant code,Mentoring less experienced colleagues within the team,Implementing ETL process – including cohorts building and ETL routines customisation,Monitoring cluster (Spark/Hadoop) performance,Working in an Agile Environment,Refactoring and moving our current libraries and scripts to Scala/Java,Enforcing coding standards and best practices,Working in a geographically dispersed team,Working in an environment with a significant number of unknowns – both technically and functionally"," You will be working in a team of highly talented Engineers and Data Scientists. Your main responsibility will be to write highly performant / scalable code that will run on top of our Big Data platform (Spark/Hive/Impala/Hadoop). Also, you will be working closely with the Data Science team to support them in the ETL process (including the cohorts building efforts).
Responsibilities
Working in a cross-functional team – alongside talented Engineers and Data Scientists
Building scalable and high-performant code
Mentoring less experienced colleagues within the team
Implementing ETL process – including cohorts building and ETL routines customisation
Monitoring cluster (Spark/Hadoop) performance
Working in an Agile Environment
Refactoring and moving our current libraries and scripts to Scala/Java
Enforcing coding standards and best practices
Working in a geographically dispersed team
Working in an environment with a significant number of unknowns – both technically and functionally
Skills and Qualifications
Essential
BSc or MSc in Computer Science or related field (or equivalent experience)
Strong analytical, learning and problem solving skills with personal interest in subjects such as math/statistics, machine learning, AI and analytics
Solid knowledge of data structures, algorithms and Unix/Linux
Proficient in Scala, Java and SQL
Strong experience with Apache Spark 2.0
Experience working in an Agile environment using TDD and Continuous Integration
Experience refactoring code with scale and production in mind
Familiar with Git, Python, JavaScript, HTML and CSS
Proficient understanding of distributed computing principles
Proficiency with Hadoop v2, MapReduce, HDFS
Good knowledge of Big Data querying tools, such as Pig, Hive, and Impala
Experience with integration of data from multiple data sources
Experience with NoSQL databases, such as HBase, Cassandra, MongoDB
Knowledge of various ETL techniques and frameworks
Experience with Big Data ML toolkits, such as Mahout, SparkML, or H2O
Experience with Cloudera/MapR/Hortonworks
Desirable
Management of Hadoop cluster, with all included services
Experience with building stream-processing systems, using solutions such as Storm or Spark-Streaming
Good understanding of Lambda Architecture, along with its advantages and drawbacks
Experience with various messaging systems, such as Kafka or RabbitMQ
",https://www.indeed.co.uk/job/Big-Data-Engineer-at-QuintilesIMS-in-London-5290741f02009334
JOB91600244034,Lead Data Engineer,Lead Data Engineer,50+ career categories,"Find a better job, faster!,Hand-screened leads,No ads, scams, junk,Great job search support","
Seeking a lead engineer for a currently remote position responsible for assessing client needs, implementing data models, writing code, performing verifications, overseeing teams, assisting projects, and more. Must have strong leadership ability.
Job Details
Remote - During Pandemic
Employee
Full-Time
Manager
No specification
Company name here
Other benefits listed here
Find a better job, faster!
Hand-screened leads
No ads, scams, junk
Great job search support
50+ career categories
Create an Account to Unlock
To find out more about or apply to this Lead Data Engineer job—and other great opportunities like it—become a FlexJobs member today!
With FlexJobs, you'll find the best flexible jobs and fantastic expert resources to support you in your job search. If you have any questions, please feel free to contact us.
",https://www.flexjobs.com/publicjobs/lead-data-engineer-1295982
JOB93001505642,Data Engineer,Data Engineer,,,"
Data Engineer - 70,000 Job Description An AWS Partner based in Central London is looking to expand the data side of their business due to growth. They are looking for Data Engineers with significant commercial experience ingesting large quantities of data...
Job title : Data Engineer Location: London Job type: Permanent Salary: Up to 70,000 per annum Reporting to: Head of Data Engineering Overview A fantastic internet company based in Central London are currently looking for a Data Engineer to come on board...
Data Engineer / Data Scientist / Biomedical Informatics / Human Genetics / Python / SQL / R / Oxford / Cambridge / Permanent 60 - 90K (Depending on Experience) Excellent Benefits COVID Safe Interview Process 100% Remote during Covid and up to 50% Post...
Data Engineer London 80,000 - 90,000 Benefits This Data Engineering role will allow you to expand and utilise your skills in a growing team working along side one of the largest data sets in the UK. The Company As a global leader they generate tons of...
Data Engineer - Permanent Data Idols are working with a well-known client in the e-commerce space who are looking for a Data Engineer to join an existing team on a permanent basis. THE ROLE As a Data Engineer, you will be working with the existing Data...
Senior Data Enigneer - Permanent Data Idols are working with a well known Technology company who are looking for a Senior Data Engineer to join a cross-functional team. This industry disruptor has been changing the way people interact with an everyday...
DATA ENGINEER ENERGY LONDON BETWEEN 60,000 - 80,000 This vacancy is an excellent opportunity to join an energy trading firm who have recently launched a new data initiative. The role will involve developing a data platform utilising Python, Spark &...
Site Name: UK - London - Brentford, USA - Pennsylvania - Upper Providence Posted Date: Jun 4 2020 Are you looking for a challenging opportunity to work in an area where cutting edge science meets cutting edge technology with an aim of delivering drugs...
Site Name: UK - London - Brentford, USA - North Carolina - Research Triangle Park, USA - Pennsylvania - Philadelphia Posted Date: Mar 17 2020 Data Engineer is accountable for developing and delivering cloud-based data ingestion solutions across the Pharma...
LEAD DATA ENGINEER LONDON, CURRENTLY FLEXIBLE / REMOTE / HOME WORKING UP TO 100,000 BENEFITS BONUS Harnham are partnered with an exciting tech scale up based in Central London. They are looking for an experienced data engineer to lead the build of a greenfield...
Senior Data Engineer - Permanent Data Idols are working with a well known Technology company who are looking for a Senior Data Engineer to join a cross-functional team. This industry disruptor has been changing the way people interact with an everyday...
Senior Data Enigneer - Permanent Data Idols are working with a well known Technology company who are looking for a Senior Data Engineer to join a cross-functional team. This industry disruptor has been changing the way people interact with an everyday...
THE COMPANY Leading telecommunication company who are looking to improve their Data Engineering function. My client is looking for a data engineer to join their team of world class engineers and Data Scientists to build end-to-end applications that make...
Our client, a global travel company require a Digital Data Engineer with strong GCP/ Big Query skills to join their analytics engineering team. Your Role You will be responsible for developing reporting infrastructure and providing actionable reporting...
Python Data Engineer, Oxford or remote, 65k to 75k Avanti Recruitment is working with a successful SAAS provider in the finance domain, to recruit a Python Data Engineer who will excel in a modern DevOps environment. Main areas of expertise are Python...
Data Engineer Quantitative Trading - London One of the world's leading online CFD and financial spread betting providers is looking for a talented Data Engineer to join their business in London and support Data Science team. ROLE AND RESPONSIBILITIES -...
Data Engineer We are currently partnering with an exciting scale up business who are looking to hire a Data Engineer. Working closely with the Data Scientist's, they need someone to help build their algorithm set and take design ideas through to production...
DEVOPS ENGINEER - DATA LONDON, CURRENTLY FLEXIBLE / REMOTE / HOME WORKING UP TO 75,000 BENEFITS BONUS Harnham are partnered with one of the leaders in renewable energy initiatives and energy traders in the World. This company have been going through a...
Big Data Engineer - Permanent Data Idols are working with a well-known client in the Fintech industry. They are looking for a Big Data Engineer to join an existing data team. You will be helping build end to end applications that make use of large volumes...
A leading insurtech company are seeking a PhD Data Engineer to join their python engineering team to implement and optimise ETL pipelines for a data lake project. Essential skills required for the PhD Data Engineer: PhD in computer science (or relevant...
INSPIRE SUCCESSFUL DECISIONS Azure Data Engineer Location: Flexible As Kantar Worldpanel shifts from legacy production systems to the cloud, we are looking to appoint an Azure Data Engineer as part of our PRISM Factory team whose role is to develop, maintain...
Data Engineer - Python - Permanent Data Idols are working with a well-known client in the e-commerce space who are looking for a Data Engineer to join an existing team. THE ROLE As a Data Engineer, you will be working with the existing Data team to help...
Data Engineer - Python - Permanent Data Idols are working with a well-known client in the e-commerce space who are looking for a Data Engineer to join an existing team. THE ROLE As a Data Engineer, you will be working with the existing Data team to help...
DATA ENGINEER - DATA LONDON, CURRENTLY FLEXIBLE / REMOTE / HOME WORKING UP TO 75,000 BENEFITS BONUS Harnham are partnered with one of the leaders in renewable energy initiatives and energy traders in the World. This company have been going through a data...
Python Software Engineer / Developer (PostgreSQL) Remote Interview. Are you a bright, motivated Python Software Engineer looking to work on complex, data centric systems whilst continually learning and gaining valuable knowledge of financial trading systems?...
",https://www.reed.co.uk/jobs/data-engineer/40231664
JOB93090317148,Modeling Data Engineer,Modeling Data Engineer,,,"
State Farm's PC Actuarial Underwriting and Modeling Department is seeking a Modeling Data Engineer with experience in data andor application development to work in a dynamic and growing technical unit with emerging technologies. We have a growing and evolving infrastructure of predictive models that support State Farm's insurance pricing and underwriting decisions. We are looking for innovative individuals who are self-starters and like being part of a team to develop and implement creative solutions.
Working within PC Actuarial Underwriting and Modeling Department, agile product teams have autonomy to drive outcomes that provide meaningful business value directly to department customers. Locations Bloomington, IL Atlanta, GA Dallas, TX Responsibilities Include bull Represent PC Actuarial and Underwriting and Modeling needs in projects relating to data capture, storage, movement sourcing to our analytic environments bull Research, facilitate the work, and implement the resolution of data-related issues bull Understanding of Development practices and design within relational databases applications bull Understanding of Development practices and design within big data environments applications (Hadoop, AWS) using a variety of tools bull Maintain and develop custom ETL pipelines to construct and aggregate data used for research, modeling, andor model monitoring projects bull Performs data collection activities for research projects and special requests bull Resolves data issues bull Awareness of work status and timelines, and ability to adjust priorities Technical Knowledge Experience Desired bull Programming skills, particularly with Python, SQL, andor Spark bull Bachelor's degree in Computer Science, Information Technology or related field, or relevant work experience bull Experience with Cloud based technologies Experience working with large data sets is preferred. Other Helpful Skills bull Ability to work in an Agile work environment bull Property Casualty insurance knowledge bull R, SAS, or Clojure programming skills Key Job Family Responsibilities bull Demonstrates up-to-date expertise in data engineering practices and provides solutions for the identification, acquisition, cleansing, profiling, and ETL (extracting, transformation, and loading) of data used in data science discovery and deployment solutions bull Provides data pipeline solutions for the development, implementation, execution, validation, monitoring, and improvement of data science solutions bull Develops intelligent data management and pipelines solutions for reusability bull Establishes business domain knowledge for existing State Farm data sources and investigates, recommends, and initiates acquisition of new data resources from internal and external open and vendor data sources for model building, training, and deployment bull Conforms with State Farms strategic analytic data related policies, environments, and direction bull Understands the basics of machine learning models in order to optimize data science solutions bull Identifies critical and emerging technologies, techniques, tools, data sources, and platforms in the data engineering field, including cloud-based solutions, that will support and extend quantitative analytic deployment solutions Desired Competencies bull Ability to adapt quickly to changing timelines bull Critical Thinking bull Independent troubleshooting abilities bull Initiative bull Learning agilitydesire to learn new tools bull Quality and Attention to Detail bull Teamwork bull TechnicalFunctional Expertise Please provide a copy of your unofficial transcript with your application.
Incumbency Period There is a 24-month incumbency period for any lateral job movements (which must be met before the employee is eligible to post for other opportunities) and a 12-month incumbency employee and does not create an employment contract, nor contractual rights. LI-MT1 SFARMPandoLogic. Keywords: Data Engineer, Location: Bloomington, IL - 61701
","https://www.ziprecruiter.com/c/State-Farm/Job/Modeling-Data-Engineer/-in-Bloomington,IL?ojob=96f4550af262aed6552ac1daf968a0da"
JOB93243632136,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-il/details/200188037/ai-ml-search-data-engineer-siri-data
JOB95404723567,Associate Data Engineer,Associate Data Engineer,,,"
Optional WFH job for candidate who will design, develop, and administer ETL production processes, perform data verification and validation and translate concepts and developments into an automated production process. BA/BS degree and 1 year SQL exp. req.
",https://www.flexjobs.com/publicjobs/associate-data-engineer-1312134
JOB96336184162,IT Data Engineer,IT Data Engineer,,,"
IT Data Engineerat Stitch Fix(View all jobs)
San Francisco, CA
About the Team
Our team is made up of bright, kind and motivated people from varied backgrounds, who built and scaled organizations like Airbnb, Shutterfly, Oracle, Google and Netflix. Cross-functional partnerships are deeply meaningful to us and are how we've built up immense trust with the people running the business. We focus on high-value products that solve clearly identified problems but are designed in a sustainable way so that value continues to deliver in the long term.
About the Role
We are looking for a Data Engineer for the Insights team, which focuses on delivering solutions that enable our finance team to be successful. You will partner with Engineering, Finance, IT, People & Culture (HR) and other teams to understand their requirements, synthesize them, and work with the IT team to build global scalable solutions.
You will design and configure end-to-end solutions-not just features-by developing an understanding of how Stitch Fix works, and collaborating with business partners to define product requirements, plans, and deliverables. Your commitment to applying technology to business challenges in clean & innovative ways will make you a trusted advisor to your partners and their teams. You will own programs and projects, and will impact the business in a tangible, visible way.
In this role as a Data Engineer, you will lead the implementation, design, configuration, and maintenance of an enterprise data warehouse. You'll work with our Data Architect to make decisions and implement the infrastructure necessary to the management of our custom build financial accounting hub and rules engine. This role will involve building infrastructure to allow data to flow between our engineering & enterprise systems and enable better decision-making throughout our business. The right candidate for this role will have experience in combining open-source and commercial technologies, as well as being comfortable building or buying components to create an enterprise-wide solution.You have experience working on large, cross-functional teams and are an expert in data warehouses, business intelligence systems, and ERP/transactional systems like Oracle Cloud Financials, Anaplan, Essbase.
You're excited about this opportunity because you will... Data Engineering
+ Be responsible for architecting our next gen Data Processing applications and reporting systems/Engine through Python, SQL, Talend, Tableau. Redshift and Big data tools - Hadoop, Hive, HDFS, etc. Relational SQL and NoSQL databases
+ Craft optimal data processing architecture and systems for new data and ETL pipelines and drive the recommendation for improvements and modifications to existing data and ETL pipelines
+ Help to evangelize high quality data engineering practices towards building data infrastructure, pipelines at scale and foster the next-gen State of Art Data Warehouse
+ Design and build robust data integrations within our data platform and between the engineering systems to enable touchless data processing.
+ Evangelize our reporting platform to embrace new initiative like prescriptive modeling, Self-Serve analytics and machine learning through data engineering solutions
+ Drive internal process improvements and automating manual processes for data quality and SLA management
Reporting & BI
+ Build rich, interactive, and Executive-facing dashboards to track the progress of the business and its highest priority initiatives
+ Analyze large data sets to identify, evaluate and prioritize new opportunities to grow and optimize the business through analytics, financial modeling, and business case development
+ Identify key business levers, establish cause and effect, perform analyses, and communicate key findings to various partners to facilitate data-directed decision-making
+ Work closely with business partners to develop OKRs, build operating dashboards, and manage performance and reporting to key stakeholders
Partnership
+ Develop an understanding of Stitch Fix's current state management reporting processes to facilitate future state recommendations
+ Collaborate with business partners at all levels to facilitate issues resolution, troubleshoot functional application issues, develop solutions to support business needs, and help determine opportunities to leverage current analytical application capabilities
+ Build effective partnerships across teams
+ Develop innovation strategies, processes, and best practices; drives the execution of multiple business plans and projects and ensures business needs are being met.
We're excited about you because...
+ You build strong relationships and partnerships.You love people, processes and technologies. You love to interact with Finance and IT to build solutions that empower Finance to be immensely productive.
+ You have deep respect for your craft. You are a data expert. You live and breathe data. You get excited about data warehouses, new technologies around data, data analysis and data engineering.
+ You are proficient in implementing and executing SOX controls, program change management functions and SOX recertifications. You have led a team of systems analysts, integration developers, QA engineers and data analysts to provide an end-to-end solution using our ERP applications.
+ You have exceptional communication skills. You have the ability to develop and communicate the program objectives, inspire and motivate staff, and maintain alignment with the business strategy. You have excellent verbal and written communication skills, including the ability to explain and ""sell"" the program goals and objectives to the business, as well as technical leadership.
+ You have amazing qualifications. You have more than 5+ years of industry experience.You have demonstrated success in managing complex and/or large scale global projects.
+ You are respectful, empathetic, and humble.We want you to take your work seriously and be open to personal and professional growth. However you can also have a lot of fun doing your work. Successful people show everyone respect and consideration.
You'll love working at Stitch Fix because we...
+ Are a successful, vibrant, fast-growing company
+ Are a technologically and data-driven business.
+ Are at the forefront of tech and fashion, redefining shopping for the next generation.
+ Are passionate about our clients and live/breathe the client experience.
+ Get to be creative every day.
+ Have a smart, experienced, and diverse leadership team that wants to do it right & is open to new ideas.
+ Believe in autonomy & taking initiative.
+ Have sunny offices in downtown San Francisco, CA
+ Offer transparent, equitable, and competitive compensation based on your level to help eliminate bias in salaries, as well as equity and comprehensive health benefits.
+ Are serious about our commitment to life-work balance, and have generous parental leave policies.
About Stitch FixStitch Fix is an online personal style service for men and women combining art and science to disrupt and redefine the retail industry. We're the first fashion retailer to blend expert styling, proprietary technology, and unique product to deliver a refined and deeply personalized shopping experience. We leverage vast amounts of client data to make decisions throughout the company. All of this results in a simple, powerful offering to our customers and a successful, growing business. We believe we are only scratching the surface of our opportunity, and we're looking for incredible people to contribute! We'd love for you to help us carry on the trend.
","https://www.ziprecruiter.com/c/Stitch-Fix/Job/IT-Data-Engineer/-in-San-Francisco,CA?ojob=ab4c79e8e2bc5865429370e649f30631"
JOB96752222391,Senior Data Engineer,Senior Data Engineer,"Identify data sources that can add value to decision making.,Work with source system owners and analysts to understand source data, e.g. data profiling, definition and mapping.,Design and implement efficient data loads, using traditional structured data ETL techniques.,Design and implement real time and near real time data load solutions, using technologies like data streaming.,Design and implement unstructured data loads, e.g. text speech, images and video.,Design and implement load monitoring tools and procedures and perform continuous monitoring and optimising of loads.,Work with analysts and architect to design and implement effective and efficient data models using appropriate modelling techniques.,Design and implement data warehouse data models.,Design and implement data pipelines for ad hoc, unstructured and other data models.,Design and implement appropriate aggregation data structures that enhance usability of data, e.g. multi-dimensional OLAP structures, summary tables etc.,Design, implement and maintain appropriate indexing on tables to enhance speed of access.,Design and implement data models that support automated decision making and/or further analytics.,Continuously search for data elements from other sources to enhance existing data objects to supplement / enhance context.,Design and implement interfaces for data access, e.g. batch exports, real-time decision API’s etc.,Design and implement interface monitoring and management solutions to ensure availability and accuracy.,Monitor and maintain integrity of existing environment, troubleshoot technical and data issues and make appropriate changes where required.,Implement meta-data solutions that assist with understanding and managing data.,Work together with business owners, analysts and IT to maintain good data governance.,Provide technical and data related support to source system teams and external parties with whom we exchange data.,Manage data growth and usage by designing and implementing effective strategies, e.g. archiving and indexing.,Manage systems, technology and tools that enable data management and analytics.,Take ownership of own work by delivering high quality work on time.,Show initiative and be pre-active in finding opportunities to improve data and/or processes.,Take ownership of own career development by continuously improving skills, knowledge and the application thereof in designing and implementing solutions.,Positive engagement in team activities and actively contribute ideas to improve team dynamics and performance.,Stakeholder management (internal and external).,Assist in development of others, e.g. mentoring and knowledge share.,Quality control of other’s work.,Degree in information technology / mathematics / engineering / actuarial science or related discipline.,At least 5+ years in a technical data role, preferably in a formal data, data warehouse or business intelligence environment.,SQL,Data analysis,Data visualisation,Data modelling,Microsoft business intelligence data technologies (SSIS, SSAS, SQL Server),Data warehouse concepts and best practices,Financial services knowledge, specifically personal or unsecured loans,Business process monitoring and optimising,Microsoft business intelligence visualisation technologies (SSRS, Power BI),IT infrastructure, e.g. storage, networking, servers, security,Unstructured data experience,Information gathering and problem analysis,Applying professional / specialist / technical expertise,Creating and innovating,Quality & Detail orientation,Analysing",,"Senior Data Engineer
Job description
Capfin is a leading unsecured loan provider with a successful business model supported by great people with a strong culture of innovation and data driven decision making. The purpose of this role is to create business value by applying data engineering and data management disciplines to design and build data solutions that enable data driven decision support, in order to optimize business decisions and processes, as well as train and mentor more junior team members.
Requirements
Key Performance Areas:
Sourcing data
Identify data sources that can add value to decision making.
Work with source system owners and analysts to understand source data, e.g. data profiling, definition and mapping.
Loading data
Design and implement efficient data loads, using traditional structured data ETL techniques.
Design and implement real time and near real time data load solutions, using technologies like data streaming.
Design and implement unstructured data loads, e.g. text speech, images and video.
Design and implement load monitoring tools and procedures and perform continuous monitoring and optimising of loads.
Storing data
Work with analysts and architect to design and implement effective and efficient data models using appropriate modelling techniques.
Design and implement data warehouse data models.
Design and implement data pipelines for ad hoc, unstructured and other data models.
Enhancing data
Design and implement appropriate aggregation data structures that enhance usability of data, e.g. multi-dimensional OLAP structures, summary tables etc.
Design, implement and maintain appropriate indexing on tables to enhance speed of access.
Design and implement data models that support automated decision making and/or further analytics.
Continuously search for data elements from other sources to enhance existing data objects to supplement / enhance context.
Making data available
Design and implement interfaces for data access, e.g. batch exports, real-time decision API’s etc.
Design and implement interface monitoring and management solutions to ensure availability and accuracy.
Managing data
Monitor and maintain integrity of existing environment, troubleshoot technical and data issues and make appropriate changes where required.
Implement meta-data solutions that assist with understanding and managing data.
Work together with business owners, analysts and IT to maintain good data governance.
Provide technical and data related support to source system teams and external parties with whom we exchange data.
Manage data growth and usage by designing and implementing effective strategies, e.g. archiving and indexing.
Manage systems, technology and tools that enable data management and analytics.
Leadership responsibilities
Take ownership of own work by delivering high quality work on time.
Show initiative and be pre-active in finding opportunities to improve data and/or processes.
Take ownership of own career development by continuously improving skills, knowledge and the application thereof in designing and implementing solutions.
Positive engagement in team activities and actively contribute ideas to improve team dynamics and performance.
Stakeholder management (internal and external).
Assist in development of others, e.g. mentoring and knowledge share.
Quality control of other’s work.
Qualifications:
Degree in information technology / mathematics / engineering / actuarial science or related discipline.
Experience:
At least 5+ years in a technical data role, preferably in a formal data, data warehouse or business intelligence environment.
Functional Competencies:
SQL
Data analysis
Data visualisation
Data modelling
Microsoft business intelligence data technologies (SSIS, SSAS, SQL Server)
Data warehouse concepts and best practices
Financial services knowledge, specifically personal or unsecured loans
Business process monitoring and optimising
Microsoft business intelligence visualisation technologies (SSRS, Power BI)
IT infrastructure, e.g. storage, networking, servers, security
Unstructured data experience
Behavioural Competencies:
Information gathering and problem analysis
Applying professional / specialist / technical expertise
Creating and innovating
Quality & Detail orientation
Analysing
Posted on 06 Sep 12:34
",https://www.bizcommunity.com/Company/Job.aspx?cid=221357&i=373060
JOB96761699142,Senior Micro Service Data Engineer,Senior Micro Service Data Engineer,,Engineer,"
The following job is no longer available:
Senior Data Engineer
MARIONETE's leading Big Data, IoT, DLT and Data Science consultancy is looking for a lead developer with proven technical architecture experience and banking knowledge. Do you search for a new and exciting place to work with intellectual stimulation, personal...
Senior Software Engineer / Developer (C 11 Backend Real-time Optimisation). Would you like to take ownership of diverse, highly technical projects in a work culture that is defined by progression and continuous learning? Leading global investment management...
C Developer / Senior Software Engineer (C 11 Real-time Optimisation)Remote Process WFH. Are you a senior C Developer who wants to remain hands-on, working on complex and technically challenging systems? Join this hugely profitable algorithmic trading company...
Software Engineer / C Developer (Real-time C Linux). Remote Interview Are you a senior C Software Engineer who wants to remain hands-on, working on complex and technically challenging financial systems? Join this hugely profitable algorithmic trading company...
Job Role: Senior DevOps Engineer - City of London - 500- 600 per day The Company: An established company are looking to recruit a DevOps Engineer to join the team The Role: You will be tasked with designing, implementing and managing the companies Cloud...
Senior Machine Learning Engineer - currently working from home London Up to 120,000- 130,000 Harnham have just partnered with a unicorn company in Central London who are building out a machine learning capability to focus on customer behaviour and safety...
Senior AWS DevOps Engineer - Contract Our client, a leading player in their field are on the look out for 2 x Senior DevOps Engineers to come on board to assist in building highly resilient, scalable and performant AWS infrastructure in an automated and...
Java Developer / Senior Software Engineer (Data Privacy Data SQL Hadoop) Remote Interview. Would you like to help solve one of society's most urgent issues around personal data privacy and protection, working alongside extremely talented Java software...
Security Engineer (Architect / Consultant) Pudsey / 2-3 days remote working 6 months Happy to discuss day rate Role Summary: There is now an opportunity to be involved with the secure deployment of cutting edge banking Cyber technologies. Main Responsibilities...
Senior Network Engineer (Ultra Low Latency Data Centre CCIE) Remote Interview. Ultra Low Latency Network technologist sought by algorithmic trading company to work on complex and interesting systems as part of a global team. You'll be based in modern,...
Role: Data and Process Automation Engineer Location: West London Client: Global Ecommerce Duration: Initially 6 Months Rate: 450 per day Looking for an expert Data and Process Automation Engineer for a Global Ecommerce company in London. This is a high...
Snr Full Stack Engineer (JavaScript/Python/AWS) – London 500 per day – 6 month FTC My client a leading news publisher is looking for a more traditional Senior Full-Stack Software Engineer for a 6 month FTC, to manage and work alongside an established team...
Lead Java Engineer - Big Data/Kafka ALL interview process done remotely and remote on-boarding. Lead Java Engineer - Big Data/Kafka. An international leader in cloud messaging services (500 employees) for top-tier financial organisations are taking part...
Lead Java Engineer - Big Data/Devops ALL interview process done remotely and remote on-boarding. Lead Java Engineer - Big Data/DevOps. An international leader in cloud messaging services (500 employees) for top-tier financial organisations are taking part...
C Software Engineer / Developer (C 14 17 20 Python Template Metaprogramming). Would you like to be challenged, working on complex algorithmic trading systems as part of a small, extremely talented engineering team where you will directly impact the bottom...
IT Talent are representing a global Ecommerce organisation in London with over 150 million users worldwide. We are recruiting for an expert Data and Process Automation Engineer on an initial 6 month contract basis. This is a high impact role within our...
Senior AWS DevOps Engineer - Contract Our client, a leading player in their field are on the look out for 2 x Senior DevOps Engineers to come on board to assist in building highly resilient, scalable and performant AWS infrastructure in an automated and...
Python Software Engineer / Developer (Linux CI/CD Automation) Remote Interview. Are you a senior Python Software Engineer who wants to remain hands-on, working on complex and technically challenging systems? Join this hugely profitable algorithmic trading...
Senior Software Developer / C Engineer (UNIX Linux TCP/IP C/C Latency) Remote Interview. Would you like to work on intellectually and technically challenging projects and gain valuable knowledge of financial trading systems as part of a supportive Agile...
Python Developer / Engineer (Linux CI/CD Automation). Are you a senior Python Developer who wants to remain hands-on, working on complex and technically challenging systems? Join this hugely profitable algorithmic trading company and collaborate with quant...
Swift Engineer Swift Engineer London - Our challenger financial services client is looking for a Senior Swift engineer with a solid background of Analysis, Design, and spec writing for Swift Solutions. You will have been involved with the installation...
Swift Engineer Swift Engineer London - Our challenger financial services client is looking for a Senior Swift engineer with a solid background of Analysis, Design, and spec writing for Swift Solutions. You will have been involved with the installation...
Engineering Lead (M&E) 6 month contract 575 per day based in central London Inside scope IR35 This post is to lead on a number of engineering infrastructure and associated workstreams under direction from the Design Director and alongside the other...
Artificial Intelligence (AI) Engineer - Insight & Data Services - Permanent Salary guideline: 60,000 - 120,000 pa (DOE) Benefits, pension up to 6% contributory, Health Insurance, Life Assurance etc. Base Location: London - UK wide Our client is a global...
Senior Scala Engineer (Cats / Scalaz, Http4s, Circe and Doobie) - Broadcasting - London Rate: 500 - 550 per day Duration: 6 months We are looking for a Scala engineer to work within a cross-functional team to deliver software that meets the clients Online's...
",https://www.reed.co.uk/jobs/senior-data-engineer/39711681
JOB96847715193,Senior Data Engineer,Senior Data Engineer,,,"
DESCRIPTION Senior Data Engineer Amazon Fashion is a fast moving innovative team that is revolutionizing the future of online Fashion retail to become each customer’s most loved fashion destination. We are looking for candidates that are passionate about...
Senior Data Engineer - Manchester A large organisation based in Manchester are currently looking for a Senior Data Engineer to lead and participate on a wide range of initiatives to transform the data and information landscape across the business. The...
DESCRIPTION Amazon’s Inventory Prediction and Entitlement (IPE) team, based in Cambridge, U.K. is looking for passionate, hard-working, and talented individuals to join our fast paced, stimulating environment to help invent the future of business ownership...
DESCRIPTION Although this job is posted in London, the real location is CAMBRIDGE, UK. Amazon’s Inventory Prediction and Entitlement (IPE) team, based in Cambridge, U.K. is looking for passionate, hard-working, and talented individuals to join our fast...
Senior Data Engineer REF: JA26 Salary: 55,000 to 65,000 dependent on experience Location: Manchester Job Type: Permanent, Full Time Job Section: Professional Services Experience: 2 years Contact: Joel Ambrose An opportunity to work with some of the internet’s...
Data Engineer / Senior Data Engineer - Manchester - Multiple Roles Available - Salary DoE - 40,000 - 65,000 An exciting opportunity has arisen for a Data Engineer to join a growing consultancy firm based around the UK who focus on using the latest technologies...
Data Engineer We are currently partnering with an exciting scale up business who are looking to hire a Data Engineer. Working closely with the Data Scientist's, they need someone to help build their algorithm set and take design ideas through to production...
DESCRIPTION Love data? Love music? The Amazon Music team is looking for a brilliant, creative, and passionate professional to join our Business Intelligence team. The responsibilities include developing self-serve and automated tools that improve the efficiency...
AstraZeneca is a global biopharmaceutical business that focuses on the discovery, development and commercialisation of prescription medicines for some of the world's most serious diseases. Our growth platforms are doing deeply well, and the impact of our...
Senior Data & BI Developer / Engineer - BI platforms, database and data warehouse infrastructure - Microsoft, SQL, Azure - Poole - a design, develop build role to help transform data infrastructure and BI platforms In this business critical role you...
Senior Data Engineer - Nationwide charity: as the technical Data / BI SME on a business-critical data strategy (embracing SQL BI, Python, Cloud tech, Big Data, Data Science), you will be reporting directly to the Head of IT and working closely with key...
Senior Data Enigneer - Permanent Data Idols are working with a well known Technology company who are looking for a Senior Data Engineer to join a cross-functional team. This industry disruptor has been changing the way people interact with an everyday...
Senior Mechanical Design Engineer 45,000 - 55,000 package London Mission Critical Engineering Division of a Global Engineering Consultancy are presently undertaking the design and delivery of several major data centre developments in the UK, Europe and...
Senior Electrical Design Engineer - Frankfurt - To €70K Accommodation, Flights and Living expenses I'm working with a large, global main contractor who specialise in the design of complex projects such as data centres, hospitals and industrial projects...
X4 Technology are currently working on a remote Senior QA Engineer position with a London based financial services organisation. Due to the growth of the company they are looking for a Senior QA Engineer to help build on existing testing services used...
Senior Electrical Design Engineer 45,000 - 55,000 package London Mission Critical Engineering Division of a Global Engineering Consultancy are presently undertaking the design and delivery of several major data centre developments in the UK, Europe and...
Data Engineer - Python - Leeds We are looking for a Data Engineer with a solid fundamental basis in Python to join an up-and-coming software consultancy based in Leeds, to work on a combination of public and private sector projects. You will be working...
Infrastructure Engineer / 2nd Line Support - Cambridgeshire - ITIL, Service Desk, Virtualisation 25-27,500 training package Concept IT are looking for an experienced Infrastructure / 2nd Line Support Engineer to join a well-established and growing IT solutions...
Senior Software Engineer | Python | Django OxSource is currently on the lookout for a Senior Software Engineer to join a growing start-up based in Central Oxford. Role Profile As a Software Engineer, you will join an experienced team where you will help...
Lead Data & Analytics Engineer – Cambridge Job Description The Lead Data Engineer will have a technical background across the full BI stack but will also have experience leading teams of senior developers. The Lead Data Engineer will work very closely...
A leading global bank based in the City are currently looking for an experienced Network Engineer to come in and join the vast IT team. The client is a global institution, who are a market leader with operations covering global financial markets. This...
Senior DevOps Engineer Job Opportunity in Wrexham I am working with a leading business that are on a huge expansion drive now, of whom are seeking to add a Senior DevOps Engineer to their team. You will be working collaboratively with Data Engineers, Data...
Senior O365 Engineer/Office 365 Specialist/Infrastructure Engineer/Infrastructure Specialist/Senior Windows Engineer/Office 365 Engineer/Unified Communications Engineer/Unified Communications Analyst/Unified Communications Specialist Type - Permanent Salary...
Would you like to work on a product that helps life-changing treatments? We are currently looking for skilled Developers to help drive our product suite forward. Senior Software Engineer The software development team are responsible for the research, development...
We have an opportunity available for a highly motivated Principal Engineer to join our Technology & Design department . You will be based in Southampton working a full time permanent basis and in return, you will receive a competitive salary of 54...
",https://www.reed.co.uk/jobs/senior-data-engineer/40396036
JOB97523903001,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-at/details/200188037/ai-ml-search-data-engineer-siri-data
JOB97785725937,Data Engineer - Java,Data Engineer - Java,,"Working knowledge of data warehousing concepts (change data capture, ETL, data marts etc.),Experience building data marts/BI applications for specific business areas from multiple data sources like files, API's, messaging streams (Kafka, Kinesis etc),Experience with using data and analytics technologies/services eg. Redshift, S3, RDS, BigQuery etc. or comparable technologies.,Programming languages - Java, Python, node.js,Creating ETL pipelines for Data processing workloads for change data capture, set based data transformations, data movement between AWS services,Implementing,optimising and administering cloud based parallel processing/in-memory/columnar relational databases eg. BigQuery, Redshift etc.,Ability to setup and configure ETL frameworks like Airflow using Java/Python,Events/Stream parallel data processing solutions like Spark on AWS or similar technology,Implemented data processing using Hadoop/Hbase/Hive,Implemented AWS Security rules/policies for communication between AWS Services and securing PII data stored, transferred or processed on them.,Working with NoSQL databases eg. Cassandra, DynamoDB","
Data Engineer - Java - Contract
A global leading media client a looking for a Data Engineer to join their London team.
As the project is in its very early stages, you will be involved in architectural decisions as well as the direct implementation of the defined services. You will help shape the project direction and be using continuous deployment within a genuinely agile team who are striving to deliver quality products with realistic timescales. You will also be encouraged to explore new technologies and approaches that best fit the problems.
The ideal candidate would have a strong working experience of architecting and implementing data processing pipelines on a combination of one or more cloud based data storage and processing systems; working experience with AWS services like S3, EMR (using Hive, Spark etc.) and good knowledge of using Java and Python.
Background
Working knowledge of data warehousing concepts (change data capture, ETL, data marts etc.)
Experience building data marts/BI applications for specific business areas from multiple data sources like files, API's, messaging streams (Kafka, Kinesis etc)
Experience with using data and analytics technologies/services eg. Redshift, S3, RDS, BigQuery etc. or comparable technologies.
Skills Required
Programming languages - Java, Python, node.js
Creating ETL pipelines for Data processing workloads for change data capture, set based data transformations, data movement between AWS services
Implementing,optimising and administering cloud based parallel processing/in-memory/columnar relational databases eg. BigQuery, Redshift etc.
Ability to setup and configure ETL frameworks like Airflow using Java/Python
Events/Stream parallel data processing solutions like Spark on AWS or similar technology
Implemented data processing using Hadoop/Hbase/Hive
Implemented AWS Security rules/policies for communication between AWS Services and securing PII data stored, transferred or processed on them.
Working with NoSQL databases eg. Cassandra, DynamoDB
Data manipulation languages - SQL, Python
This vacancy is being advertised by Oliver Bernard Ltd. The services advertised by Oliver Bernard Ltd are those of an Employment Agency.
",https://www.careerjet.co.uk/clk/96264542f1d41e08b9570e46896b8741.html
JOB98735748205,Data engineer job description sample,Data engineer job description sample,"Knowledge of best practices and IT operations in an always-up, always-available service,Experience with or knowledge of Agile Software Development methodologies,Excellent problem solving and troubleshooting skills,Process oriented with great documentation skills,Excellent oral and written communication skills with a keen sense of customer service,BS or MS degree in Computer Science or a related technical field,4+ years of Python or Java development experience,4+ years of SQL experience (No-SQL experience is a plus),4+ years of experience with schema design and dimensional data modeling,Ability in managing and communicating data warehouse plans to internal clients,Experience designing, building, and maintaining data processing systems,Experience working with either a Map Reduce or an MPP system on any size/scale","Develops and maintains scalable data pipelines and builds out new API integrations to support continuing increases in data volume and complexity.,Collaborates with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization.,Implements processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.,Writes unit/integration tests, contributes to engineering wiki, and documents work.,Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues.,Works closely with a team of frontend and backend engineers, product managers, and analysts.,Defines company data assets (data models), spark, sparkSQL, and hiveSQL jobs to populate data models.,Designs data integrations and data quality framework.,Designs and evaluates open source and vendor tools for data lineage.,Works closely with all business units and engineering teams to develop strategy for long term data platform architecture.","
This data engineer job description sample is your launching pad to create the ideal posting to attract the best, most qualified candidates. Just build in the specific job duties and requirements of your position to the structure and organization of this outline, and you’ll turn those candidates into applicants. Check out our data engineer job listings for more ideas on how to fill out your description.
Data Engineer
[Intro Paragraph] Kick off your data engineer job description by introducing prospective applicants to your company, corporate culture, and working environment. This is your chance to let prospective engineers know what you have to offer new hires and set your posting apart from the rest by catering your recruiting pitch to the ideal candidate.
Data Engineer Job Responsibilities:
Develops and maintains scalable data pipelines and builds out new API integrations to support continuing increases in data volume and complexity.
Collaborates with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization.
Implements processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Writes unit/integration tests, contributes to engineering wiki, and documents work.
Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues.
Works closely with a team of frontend and backend engineers, product managers, and analysts.
Defines company data assets (data models), spark, sparkSQL, and hiveSQL jobs to populate data models.
Designs data integrations and data quality framework.
Designs and evaluates open source and vendor tools for data lineage.
Works closely with all business units and engineering teams to develop strategy for long term data platform architecture.
[Work Hours & Benefits] Job seekers also want to know about your working hours and benefits. The best performing job descriptions inform future data engineers about the availability of flexible hours, work from home options, or other telecommuting opportunities. They also don’t forget highlight unique office perks and benefits they offer, like conference sponsorships, continuing education credits, or paid time off.
Data Engineer Qualifications / Skills:
Knowledge of best practices and IT operations in an always-up, always-available service
Experience with or knowledge of Agile Software Development methodologies
Excellent problem solving and troubleshooting skills
Process oriented with great documentation skills
Excellent oral and written communication skills with a keen sense of customer service
Education, Experience, and Licensing Requirements:
BS or MS degree in Computer Science or a related technical field
4+ years of Python or Java development experience
4+ years of SQL experience (No-SQL experience is a plus)
4+ years of experience with schema design and dimensional data modeling
Ability in managing and communicating data warehouse plans to internal clients
Experience designing, building, and maintaining data processing systems
Experience working with either a Map Reduce or an MPP system on any size/scale
[Call to Action] You’ve attracted some eyeballs on your job description, but how do you get the applications in your inbox? With a compelling call to action that lets engineers know exactly how to apply and encourages them to do so. Advise job seekers to apply via this listing or to contact your HR department directly, and include any other application requirements.
Ready to post your perfect data engineer job description?
Great. Now, let Monster job ads put you in the driver’s seat when it comes to finding the right hire. Our range of monthly plans can be customized for any size company or job search. You’ll even get access to Monster Studios, which lets you create video job descriptions, at no additional charge. Plus, you can cancel at any time.Get started right now!
",https://hiring.monster.com/employer-resources/job-description-templates/data-engineer-job-description-sample/
JOB100256619330,Data Engineer,Data Engineer,,,"
Data Engineer X 2 – Manchester. Our client based near Manchester are currently looking for 2 Data Engineers with Azure experience. The company is currently going through a large digital transformation, they are looking for talented Data specialist to help...
Job Title: Data Engineer Salary: 45,000 to 54,000 plus Benefits Location: Cambridge This is a very rare opportunity for an experienced Data Engineer with a strong background in building Python based data processing pipelines to join a company that are...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Title: Data Engineer Our client is currently looking for a Data Engineer to play a vital role in the continual development of our digital transformation strategy and earth science analytics. Candidates must have Python, R and SQL. We expect candidates...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer - Manchester A growing business based in Manchester City Centre are currently looking for a Data Engineer to help shape their newly formed Data Engineering team and build scalable, reliable and secure cloud datawarehouse solutions and data...
Data Engineer - Python - Permanent Data Idols are working with a well-known client in the e-commerce space who are looking for a Data Engineer to join an existing team. THE ROLE As a Data Engineer, you will be working with the existing Data team to help...
An exciting start up Fintech company has a new opportunity for a Data Engineer where you will play an active part in the success of the company. This role will see you joining a small team where you'll have the opportunity to take responsibility for Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer- 50K Manchester Adria Solutions has an exciting opportunity for a talented Data Engineer to join our rapidly expanding client based near Manchester. The role requires you to work closely with other members of the data team and stakeholders...
Data Engineer (12-month Fixed Term Contract) 50,000 - 55,000 We are looking for a Data Engineer to join a market leading business we're representing, based in central London. Working as part of the central Data Science & Analytics team, you will be...
DATA ENGINEER - CURRENTLY REMOTE WORKING LEEDS - CURRENTLY REMOTE WORKING BETWEEN 35,000 - 50,000 BENEFITS BONUS Harnham are partnered with a Financial Services Company to help hire for a Data Engineer within their Business Intelligence team. The team...
DATA ENGINEER - CURRENTLY REMOTE WORKING LEEDS - CURRENTLY REMOTE WORKING BETWEEN 35,000 - 50,000 BENEFITS BONUS Harnham are partnered with a Financial Services Company to help hire for a Data Engineer within their Business Intelligence team. The team...
Data Engineer London 55,000 - 65,000 Benefits Our client, an exciting RegTech business is looking to recruit for a Data Engineer to join their growing team. The successful candidate will be joining the artificial intelligence team, working on a brand new...
Data Engineer - Azure - Data Warehousing - Staffordshire - 50k Hiring remotely Greenfield project Home working I am working with an organisation in Staffordshire who are seeking a Data Engineer to join their growing Data & Analytics team. Data &...
Recruiting for multiple Data Engineer roles with a global organisation based in Swindon to develop their cloud based platforms and infrastructure. These are permanent opportunities to join a newly created Agile team, offering competitive salaries/benefits...
Data Engineer London Up to 49,000 A reputable organisation based in London are seeking a talented Data Engineer to design and develop complex and group-wide data solutions. Job Duties - Plan and achieve agile sprint tasks from which the technical solutions...
",https://www.reed.co.uk/jobs/data-engineer/40293457
JOB100490861114,Data Engineer,Data Engineer,"Bachelor's or Master's degree in Computer Science or related technical field or equivalent professional experience,Greater than 3 years of experience,Safety & Quality First,Valuing Ethics, Integrity & Diversity,Passion for Serving Our Customers Globally,Dedication to Each Other Through Servant Leadership,Creating Value for Shareholders, Customers and Employees,Consistently Delivering Our Commitments.,Competitive Salary,Comprehensive Health, Wellness and Income Protection Benefits,401(k) Savings Plan with Company Match,Paid Vacations and Holidays,Opportunities for Flexible Work Arrangements,Educational Reimbursement Program,Employee Referral Program","Assist with creation of data schemas, stored procedures, data pipelines, and views,Help build and maintain technical solutions required for optimal ingestion, transformation, and loading of data from a wide variety of data sources and large, complex data sets,Collaborate across roles to embrace best practices in reporting and analysis, including data integrity, test design, validation, and documentation,Ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy,Build and automate actionable reports,Collaborate with data analysts, data scientists, and stakeholders during design discussions to uncover more detailed business requirements related to data engineering,Develop strong hypotheses, independently solve problems, and share actionable insights with engineering","
Job Responsibilities
Are you interested in being part of an innovative team that supports Westinghouse's mission to provide clean energy solutions? At Westinghouse, we recognize that our employees are our most valuable asset and we seek to identify, attract and recruit the most qualified talent while recognizing and encouraging the value of diversity in the global workplace.
If this sounds like an environment you would thrive in, we have an exciting opportunity for a Data Engineer.
Your Day-to-Day:
Assist with creation of data schemas, stored procedures, data pipelines, and views
Help build and maintain technical solutions required for optimal ingestion, transformation, and loading of data from a wide variety of data sources and large, complex data sets
Collaborate across roles to embrace best practices in reporting and analysis, including data integrity, test design, validation, and documentation
Ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Build and automate actionable reports
Collaborate with data analysts, data scientists, and stakeholders during design discussions to uncover more detailed business requirements related to data engineering
Develop strong hypotheses, independently solve problems, and share actionable insights with engineering
Partner and develop strong relationships with cross-functional teams
Minimum Requirements
Who You Are:
As a successful candidate, you will bring the following to the team:
Bachelor's or Master's degree in Computer Science or related technical field or equivalent professional experience
Greater than 3 years of experience
Experience with Azure products; Data Factory or Databricks is required
Education Level
Bachelors Degree, Masters Degree
Years of Experience
3+ Years
Benefits
""Why Westinghouse?
Westinghouse Electric Company is the global nuclear energy industry's first choice for safe, clean, and efficient energy solutions. We enable our delivery of this vision by living our value system:
Safety & Quality First
Valuing Ethics, Integrity & Diversity
Passion for Serving Our Customers Globally
Dedication to Each Other Through Servant Leadership
Creating Value for Shareholders, Customers and Employees
Consistently Delivering Our Commitments.
Westinghouse offers competitive benefits to all our employees around the globe to keep them healthy and enhance their well-being. In the U.S. the following are representative of what we offer:
Competitive Salary
Comprehensive Health, Wellness and Income Protection Benefits
401(k) Savings Plan with Company Match
Paid Vacations and Holidays
Opportunities for Flexible Work Arrangements
Educational Reimbursement Program
Employee Referral Program
While our Global Headquarters are located in Cranberry Township, PA, we have over 9,000 employees working at locations in 19 different countries. You can learn more by visiting link http://www.westinghousenuclear.com./careers/
EOE of Minorities / Females / Vets / Disability.
Keep in mind that only applications completed and submitted via the Westinghouse Careers website will be considered. You can submit your completed application, and also explore other available options, using the following link: link http://www.westinghousenuclear.com/careers/
Get connected with Westinghouse on social media:
Twitter | Facebook | LinkedIn| YouTube
Notice
Employment opportunities for positions in the United States may require use of information which is subject to the export control regulations of the United States. Hiring decisions for such positions are required by law to be made in compliance with these regulations. Applicants for employment opportunities in other countries must be able to meet the comparable export control requirements of that country and of the United States.
",https://www.gettinghired.com/job-details/251837/data-engineer/url
JOB101769053035,Senior Data Engineer - Remote consulting position (Full-time W2),Senior Data Engineer - Remote consulting position (Full-time W2),"Architect and build data pipelines,Architect and implement data warehouse structure and table schemas,Develop data models to enable end users to effectively analyze data,Optimize and tune data warehouse for query performance and analytical workloads,Identify, troubleshoot and resolve data quality issues,Write complex SQL queries for data analysis,Design and maintain robust data reporting and visualization tools based on requirements,Develop integrations from BI tools to third party productivity applications,5+ years of engineering experience,Expert in SQL, preferably across a number of dialects (we commonly write Snowflake, Redshift/PostgreSQL, MySQL, SQL Server),Experience developing software code in one or more programming languages (Python, Java, Scala, Ruby),Experience managing database or data warehouse technologies (bonus for Redshift and/or Snowflake),Experience implementing ETL tools (Bonus for Stitch, Fivetran or Matillion),Understanding of data analytics ecosystem. Experience with one or more relevant tools (Spark, Kafka, AWS Glue, Amazon Kinesis, Sqoop, Flume, Flink),Experience with implementing Business Intelligence tools (Bonus for Looker),Experience developing data pipelines from scratch",,"
Are you excited to work on cutting edge technologies to solve interesting data challenges? Join the Bytecode IO team as a senior data engineering expert for an opportunity to work with a team of smart, passionate consultants helping a wide range of clients unlock the value of their data.
The ideal candidate will work independently with minimal guidance, take the lead on deciding the best course of action for specific projects and clients - while being exposed to interesting cutting edge technologies.
You can work from anywhere (within the US) and shape your work schedule to meet both your professional and personal goals.
In this position you’ll be responsible for interfacing directly with clients to understand their needs as you architect and deploy end-to-end technology stacks. The ideal team member will have extensive hands-on experience with designing, developing and operating data technologies in the Amazon Web Services or Google Cloud Platform ecosystem such as Redshift, Kinesis, Glue, EMR, Athena, BigQuery, Cloud Dataflow, or Cloud Pub/Sub.
Role Requirements
Architect and build data pipelines
Architect and implement data warehouse structure and table schemas
Develop data models to enable end users to effectively analyze data
Optimize and tune data warehouse for query performance and analytical workloads
Identify, troubleshoot and resolve data quality issues
Write complex SQL queries for data analysis
Design and maintain robust data reporting and visualization tools based on requirements
Develop integrations from BI tools to third party productivity applications
Teach technical data modeling concepts to a variety of audiences, including developers, data architects, business users, and IT professionals
Who you are and what you have done
5+ years of engineering experience
Expert in SQL, preferably across a number of dialects (we commonly write Snowflake, Redshift/PostgreSQL, MySQL, SQL Server)
Experience developing software code in one or more programming languages (Python, Java, Scala, Ruby)
Experience managing database or data warehouse technologies (bonus for Redshift and/or Snowflake)
Experience implementing ETL tools (Bonus for Stitch, Fivetran or Matillion)
Understanding of data analytics ecosystem. Experience with one or more relevant tools (Spark, Kafka, AWS Glue, Amazon Kinesis, Sqoop, Flume, Flink)
Experience with implementing Business Intelligence tools (Bonus for Looker)
Experience developing data pipelines from scratch
Experience presenting complex topics to non-technical audiences
","https://www.ziprecruiter.com/c/Bytecode-IO/Job/Senior-Data-Engineer-Remote-consulting-position-(Full-time-W2)/-in-Remote,OR?jid=DQc84811b248ea853de16907517156a0ab"
JOB101811260756,Data Engineer,Data Engineer,,"Find a better job, faster!,Hand-screened leads,No ads, scams, junk,Great job search support,50+ career categories","
Data Engineer
Full-time role with remote option. He/she will build distributed pipelines and tools and develop a summary data platform. Bachelor's degree and 5+ years' healthcare data experience required. Must be able to design relational data structures.
Job Details
10/26/20
Option for Remote
Employee
Full-Time
Experienced
Bachelor's Degree
No specification
Pre-tax commuter benefits, Paid gym membership
Health Insurance
Company name here
Other benefits listed here
Find a better job, faster!
Hand-screened leads
No ads, scams, junk
Great job search support
50+ career categories
Create an Account to Unlock
To find out more about or apply to this Data Engineer job—and other great opportunities like it—become a FlexJobs member today!
With FlexJobs, you'll find the best flexible jobs and fantastic expert resources to support you in your job search. If you have any questions, please feel free to contact us.
Get new job postings, the latest job search tips, trends, news, and exclusive promotions!
",https://www.flexjobs.com/publicjobs/data-engineer-1312968
JOB101872236420,DATA ENGINEER,DATA ENGINEER,,,"
Job title: DATA ENGINEER
Department: Analytics
Line manager: Head of
analytics
Position type:
Permanent, full time
About us
MADE.COM is a UK-based
online retailer of designer furniture and home accessories, founded in 2010.
Our mission is to make great design accessible to everybody and so we do
things slightly differently from other retailers; we cut out the expensive
middle-men and produce original design at an affordable price.
What you’ll be doing :
Working
in agile team of analysts to deliver effective data solutions. This means
working on a variety of projects from supply chain optimisation to customer
analytics.
You
will manage data for the analytics team. You will be designing, developing
and maintaining backend of our analytics solutions to increase data
availability. This will include designing the reporting schemas, data
profiling, building data processes with ETL tools or programming in Python/R.
Lead
data quality initiatives. Collaborate with other teams on data quality,
provide recommendations for changes, manage monitoring tools and metrics.
Document
and promote conventions. You will support the team effort in maintaining data
dictionaries and promote conventions in development.
Manage
release process. You will help to manage release processes for our BI system
and Data Warehouse. You will also collaborate with IT on change management to
make sure that any changes in infrastructure are coordinated with our
development process.
What you’ll need:
2
years experience of ETL tools in data
warehousing environment.
Hands
on experience of schema design and dimensional data modeling.
2
years experience with programming languages (Python, R)
Proficiency
in different flavors of SQL and data APIs.
Experience
of cloud technologies including AWS.
Experience
working in a continuous automation / deployment / delivery environment
What we offer:
An
award winning, fast-paced, creative and fun office environment in Soho
Great
opportunities to make the role your own and get involved with exciting
projects
Access to the leaders of one of the UK’s most innovative retailers
Generous
employee benefits package including private healthcare
Regular
social events
",http://www.indeed.co.uk/job/Data-Engineer-at-Made-in-United-Kingdom-b8c805d563769aa9
JOB103722315295,Data Engineer IT Applications,Data Engineer IT Applications,,,,https://www.avjobs.com/jobs/positions.asp?q=Data+Engineer+IT+Applications
JOB104610084335,Senior Data Engineer (Bellevue),Senior Data Engineer (Bellevue),,," Senior Data Engineer
As a well-funded start-up, we can offer a very competitive comp package - salary, stock options and full benefits.
Overview:
We are looking for a Data Engineer to join our team. In this role you will be responsible for preparing the data to be made more easily accessible to our team of Data Scientists. You will be overseeing the integrity of the data. You will be integrating data from various resources, managing the data, writing complex queries, and optimizing the performance of the data infrastructure. You will use a variety of big data skills and tools, ETL, and data warehousing. You will be designing and building reliable, easy to use data pipelines and data systems. You will roll out new tools and features on existing big data storage, processing, and machine learning systems. And you will work closely with others across departments.
Qualifications:
1) BS Degree in CS, Math, or related.
2) Experienced in Postgres, T-SQL, MySQL, etc.
3) Exposure to AWS development and operations experience (EMR, s3, data pipelines, etc.) and Amazon Redshift data warehouse.
4) Experienced in Apache systems such as Kafka, Spark, Storm, Zookeeper, etc.
5) Proficient in data structures, algorithms, programming languages, distributed systems, and information retrieval.
6) Experienced building large-scale data pipeline and ETL tooling.
7) Understanding of both streaming and batch data processing tools.
8) Big Data experience; knowledge of both schema-based and unstructured data.
",http://seattle.craigslist.org/est/sof/5966951198.html
JOB105456134676,"Data Engineer, Health Strategic Initiatives","Data Engineer, Health Strategic Initiatives","Workflow scheduling/orchestration such as Airflow or Oozie,Big data warehousing (RDB or MPP DB) such as Oracle, Teradata, Postgress, Hive,Strong Python programming skills with an understanding of data analytics, linear algebra, and ML libraries such as Numpy, Scipy,Experience with query APIs using JSON, ProtocolBuffers, or XML",,"Be at the forefront of the fight to improve health outcomes. Join the Health Strategic Initiatives (HSI) team as we explore novel ways to motivate and coach users to adopt healthier lifestyles. Our mission is to work with internal and external partners to deliver custom applications and campaigns to encourage, motivate, and reward our users to live their best healthy lives. We will develop cutting-edge ML pipelines to learn user behavior and how best to modify it in the areas of activity, sleep, nutrition, and wellness. As a data engineer, you will play a key role in architecting, implementing, and managing big data pipelines, ML and analytic functions, and experimentation frameworks.
Workflow scheduling/orchestration such as Airflow or Oozie
Big data warehousing (RDB or MPP DB) such as Oracle, Teradata, Postgress, Hive
Strong Python programming skills with an understanding of data analytics, linear algebra, and ML libraries such as Numpy, Scipy
Experience with query APIs using JSON, ProtocolBuffers, or XML
ML model deployment, serving, and performance monitoring
",https://jobs.apple.com/en-us/details/200164542/data-engineer-health-strategic-initiatives
JOB105977686531,Sr. Health Sensing Data Engineer,Sr. Health Sensing Data Engineer,"Strong software development skills, with a proficiency in both Object Oriented and Functional Python required,Demonstrated skill and experience using PySpark and SparkSQL,Familiarity with cloud-based, distributed systems such as blob storage, elastic compute and virtual instances,Familiarity with Software Development Life Cycles and the tools and methodologies that support them such as git, continuous integration, issue tracking, code reviews, quality assurance processes and scheduling.,Supporting data collection, curation and data provenance when working with machine learning models.,Exposure to Signal Processing and low level data collection,Experience with statistical inference methods for scientific experimentation,Experience with Scala,____________________________________________________________________,We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.,Apple’s most important resource, our soul, is our people. Apple benefits help further the well-being of our employees and their families in meaningful ways. No matter where you work at Apple, you can take advantage of our health and wellness resources and time-away programmes. We’re proud to provide stock grants to employees at all levels of the company, and we also give employees the option to buy Apple stock at a discount — both offer everyone at Apple the chance to share in the company’s success. You’ll discover many more benefits of working at Apple, such as programmes that match your charitable contributions, reimburse you for continuing your education and give you special employee pricing on Apple products.,Apple benefits programmes vary by country and are subject to eligibility requirements. Apple is committed to working with and providing reasonable accommodation to applicants with physical and mental disabilities. Apple is a drug-free workplace.",,"Our team is growing! Here is your opportunity to come and join an exciting engineering team responsible for building next-generation health sensors and features. The Human Interface Devices team is looking for hardworking and passionate engineers with expertise in data pipelines to support health study engineering. This is an integral role where you will help design, develop, and support high quality, scalable data platforms and applications that enable health sensors and health features for Apple hardware.
Strong software development skills, with a proficiency in both Object Oriented and Functional Python required
Demonstrated skill and experience using PySpark and SparkSQL
Familiarity with cloud-based, distributed systems such as blob storage, elastic compute and virtual instances
Familiarity with Software Development Life Cycles and the tools and methodologies that support them such as git, continuous integration, issue tracking, code reviews, quality assurance processes and scheduling.
Pro-active communicator and collaborator, comfortable working within a distributed team
As a Senior Data Engineer, in this central role you will: - Facilitate the engineering of large scale Human Interface Device studies involving the Apple Watch and iPhone - Be directly responsible for the health study data collection and processing pipelines - Work with the Data Engineering team to develop general use tooling - Collaborate with Algorithm Engineering on data collection, processing, and distribution - Collaborate with Quality Engineering and Study Operations to design and implement frameworks to enable pipeline validation, monitoring and study management. Your work will directly impact the development of health-related features across multiple Apple hardware platforms.
Supporting data collection, curation and data provenance when working with machine learning models.
Exposure to Signal Processing and low level data collection
Experience with statistical inference methods for scientific experimentation
Experience with Scala
____________________________________________________________________
We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.
Apple’s most important resource, our soul, is our people. Apple benefits help further the well-being of our employees and their families in meaningful ways. No matter where you work at Apple, you can take advantage of our health and wellness resources and time-away programmes. We’re proud to provide stock grants to employees at all levels of the company, and we also give employees the option to buy Apple stock at a discount — both offer everyone at Apple the chance to share in the company’s success. You’ll discover many more benefits of working at Apple, such as programmes that match your charitable contributions, reimburse you for continuing your education and give you special employee pricing on Apple products.
Apple benefits programmes vary by country and are subject to eligibility requirements. Apple is committed to working with and providing reasonable accommodation to applicants with physical and mental disabilities. Apple is a drug-free workplace.
Apple is an equal opportunity employer that is committed to inclusion and diversity. We take affirmative action to ensure equal opportunity for all applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, Veteran status, or other legally protected characteristics.
",https://jobs.apple.com/en-us/details/200164794/sr-health-sensing-data-engineer
JOB106699656565,Lead Data Engineer,Lead Data Engineer,,"Find a better job, faster!,Hand-screened leads,No ads, scams, junk,Great job search support,50+ career categories","
Lead Data Engineer
Lead data engineer needed for a full-time opportunity. This is a remote position. Will be responsible for implementing processes and infrastructure. Experience with SPARK, Linux, Unix, AWS, SQL, and Redshift required. Compensation $120k-$160k yearly.
Job Details
100% Remote
Employee
Full-Time
Manager
No specification
120,000.00 USD / Annually
Company name here
Other benefits listed here
Find a better job, faster!
Hand-screened leads
No ads, scams, junk
Great job search support
50+ career categories
Create an Account to Unlock
To find out more about or apply to this Lead Data Engineer job—and other great opportunities like it—become a FlexJobs member today!
With FlexJobs, you'll find the best flexible jobs and fantastic expert resources to support you in your job search. If you have any questions, please feel free to contact us.
Get new job postings, the latest job search tips, trends, news, and exclusive promotions!
",https://www.flexjobs.com/publicjobs/lead-data-engineer-1252713
JOB106827589039,Data Engineer,Data Engineer,"Bachelor's degree in computer science, information systems, related field,3+ years in Data Engineering in an AWS environment developing ETL tools,3+ years practical hands-on work experience with data systems,3-5 years practical, demonstrable, hands-on work experience with SQL reading/writing/database management skills,Experience in one or more of the following: Python, Java, Scala, R,Sharp attention to detail with the ability to effectively prioritize and execute multiple tasks,Excellent problem solving skills,Ability to communicate effectively with stakeholders and peers,Experience working with relational, NoSQL, and columnar data stores,Familiarity with AWS, AWS Lambda, S3, Redshift, MongoDB, Graph Databases, Azure, and other cloud based technologies,Contribute to the development of a newly established data warehouse ecosystem,Communicate effectively and define requirements from a wide range of different teams,Translate business requests into database design and execution,Work closely with domain experts to understand the source systems of the data,Build robust and scalable interfaces, ETL programs, and data pipelines,Develop and maintain data dictionary for published data sources,Develop and improve data release and testing processes,Create and manage data sources and integrate with numerous APIs,Ability to identify and resolve performance issues,Operate in an open source and cloud based environment that includes: AWS, Redshift, Python, R, Hadoop, Spark, and other technologies,Work with structured and unstructured data,Competitive wages including performance bonuses,Medical/Dental/Life/Disability insurance,Paid time off,401k with employer match,Employer funded retirement plan,Health Savings Account/Medical and Dependent Care Flexible Spending Accounts,Wellness Program,Membership to the TPC Sawgrass",,"
Qualifications:
Bachelor's degree in computer science, information systems, related field
3+ years in Data Engineering in an AWS environment developing ETL tools
3+ years practical hands-on work experience with data systems
3-5 years practical, demonstrable, hands-on work experience with SQL reading/writing/database management skills
Experience in one or more of the following: Python, Java, Scala, R
Sharp attention to detail with the ability to effectively prioritize and execute multiple tasks
Excellent problem solving skills
Ability to communicate effectively with stakeholders and peers
Experience working with relational, NoSQL, and columnar data stores
Familiarity with AWS, AWS Lambda, S3, Redshift, MongoDB, Graph Databases, Azure, and other cloud based technologies
Responsibilities:
Contribute to the development of a newly established data warehouse ecosystem
Communicate effectively and define requirements from a wide range of different teams
Translate business requests into database design and execution
Work closely with domain experts to understand the source systems of the data
Build robust and scalable interfaces, ETL programs, and data pipelines
Develop and maintain data dictionary for published data sources
Develop and improve data release and testing processes
Create and manage data sources and integrate with numerous APIs
Ability to identify and resolve performance issues
Operate in an open source and cloud based environment that includes: AWS, Redshift, Python, R, Hadoop, Spark, and other technologies
Work with structured and unstructured data
Our benefits include:
Competitive wages including performance bonuses
Medical/Dental/Life/Disability insurance
Paid time off
401k with employer match
Employer funded retirement plan
Health Savings Account/Medical and Dependent Care Flexible Spending Accounts
Wellness Program
Membership to the TPC Sawgrass
EOE/DFW
",https://www.sportsbusinessdaily.com/careerlink/Jobs/2520-Data-Engineer
JOB107596491268,Data Engineer - Customer Analytics Platform,Data Engineer - Customer Analytics Platform,"Proficient in SQL and programming (Python preferred),Experience with MPP databases preferred,6+ years of experience in data engineering and ETL pipeline development.,3+ years of Spark development.,6+ years of experience in Big Data Technologies (Hadoop, MapReduce, Hive etc…). Spark experience preferred.",,"Imagine what you could do here. At Apple, new ideas have a way of becoming great products, services, and customer experiences very quickly. Bring passion and dedication to your job and there's no telling what you could accomplish. The Product Marketing Customer Analytics team is seeking a data engineer to support customer analytics with advanced, scalable and robust architecture, tools, data products, and critical data pipelines that are optimized for rapid business intelligence, data analysis, and data science.
Proficient in SQL and programming (Python preferred)
Experience with MPP databases preferred
6+ years of experience in data engineering and ETL pipeline development.
3+ years of Spark development.
6+ years of experience in Big Data Technologies (Hadoop, MapReduce, Hive etc…). Spark experience preferred.
Experience on Kubernetes, Docker preferred.
Technical Experience in designing, developing, and managing a highly optimized, flexible, and scalable data platform for customer analytics. Experience building a connected low latency data platform (highly distributed, scalable with high availability), and stitching together various large and disparate data sources for data analysis. Deep experience in Big Data, Cloud and programming. Deep experience in developing custom ETL frameworks and developing robust, low latency and fault tolerant data pipelines dealing with very high volumes. Deep experience with relational databases and data warehouses (preferably MPP system such as Teradata), and optimizing SQL statements on large data set. Deploy inclusive data quality checks to ensure high quality of data Problem Solving Structured thinking with ability to easily break down ambiguous problems and propose impactful data modeling designs. Project Management / Product Design Significant experience managing data engineering projects through all phases, including requirements, ETL, data quality assessments, and data exploration. Communication Strong documentation and technical writing skills. Attention to detail and effective verbal/written communication skills. Environment / Culture Can work effectively on sometimes ambiguous data and constructs within a fast changing environment, tight deadlines and priority changes.
",https://jobs.apple.com/en-us/details/200109510/data-engineer-customer-analytics-platform
JOB107783232365,Data Engineer Jobs,Data Engineer Jobs,,,"
DESCRIPTION At Amazon Advertising, we are dedicated to drive measurable outcomes for brand advertisers, agencies, authors, and entrepreneurs. Our ad solutions—including sponsored, display, video, and custom ads—leverage Amazon’s innovations and insights...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
As the Data Engineer for this amazing corporate Insurance company, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL, together...
See more: Engineer jobs
As a data engineer within the exciting, new claims advanced analytics capability, you will be building big data solutions to solve some of the organization’s toughest problems and delivering significant business value. This is a really exciting time to...
See more: Engineer jobs
Data Engineer - 70,000 Job Description An AWS Partner based in Central London is looking to expand the data side of their business due to growth. They are looking for Data Engineers with significant commercial experience ingesting large quantities of data...
See more: Engineer jobs
As the Data Engineer for this amazing corporate Insurance company in the City, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
DATA ENGINEER - TEMPORARILY REMOTE 400- 450 PER DAY 3 MONTH CONTRACT EUROPE BASED As a Data Engineer you will be working heavily with Scala and Spark to improve the quality of data. THE COMPANY: You will be working for dynamic data driven company. As a...
See more: Engineer jobs
40'000- 50'000 Pension 8% Technical Progression Healthcare Holidays More Horley, Surrey Are you seeking a new challenge within a rapidly expanding Eco-Energy Tech company where you will be having huge technical autonomy in building a data preform right...
See more: Engineer jobs
Role: Data Engineer Client: Government agency (BPSS will be required) Location: Glasgow Duration: 8 Months Rate: 400 per day (outside IR35) Note: The office is based in Glasgow city centre. It is expected that the consultant would be available for physical...
See more: Engineer jobs
Data Engineer Opus are working with an excellent niche software development company in Newcastle. The company is at the forefront of their industry and due to their on-going success are now looking for a Data Engineer to take responsibility for organising...
See more: Engineer jobs
A leading Insurance Company are currently recruiting for a Data Engineer to join their dynamic and growing business. They are looking to hire a cross functional, highly tenacious and bright Data Engineer with a passion for functional programming. The ideal...
See more: Engineer jobs
Data Engineer - 6 months - Ware - Hertfordshire Global FMCG is looking for an experienced Data Engineer who will play a pivotal role in operationalizing data and analytics initiatives for digital business initiatives. The bulk of the data engineer's work...
See more: Engineer jobs
Data Engineer Portsmouth and surrounding areas encouraged to apply, multiple office locations Data Engineer required for established, international business. The business is at the forefront of new technologies working with leading Government organisations...
See more: Engineer jobs
Data Engineer A brand new role has arisen for an experienced Database / BI Developer to take the next step in their career and transition into a full Data Engineer to work for one of the most recognisable NGO's in London. We are looking for someone with...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
Data Engineer- 50K Manchester Adria Solutions has an exciting opportunity for a talented Data Engineer to join our rapidly expanding client based near Manchester. The role requires you to work closely with other members of the data team and stakeholders...
See more: Engineer jobs
We are currently recruiting a highly motivated Data Engineer, for a company who are based in London. The Data Engineer will help develop and maintain the business. The Data Engineer will be responsible for the following; Key responsibilities- - Working...
See more: Engineer jobs
Data Engineer - I am currently recruiting for a Data Engineer based in Bath. The role would be on a permanent basis and is paying 40,000 to 45,000 (There could be flex for the right candidate) PA plus a variety of excellent benefits as well as the flexibility...
See more: Engineer jobs
Data Engineer - London - 550-600 per day - 6 month contract SearchData is currently looking to recruit a Data Engineer to work on a cutting-edge DWH project in the financial services industry. As the Data Engineer your role will be to take a leadership...
See more: Engineer jobs
An exciting opportunity for an experienced Data Engineer has arisen in Leeds. After hiring a number of new members of staff at the end of 2019, the organisation are continuing to expand due to winning more projects. Key responsibilites include: Building...
See more: Engineer jobs
Data Engineer - REMOTE WORK If you are a strong Data Engineer, with experience working with Python, R and SQL then this role is ideal. I am working with a large organisation that are market leaders in their respected field. This role will report in to...
See more: Engineer jobs
Data Engineer London 55,000 - 65,000 Benefits Our client, an exciting RegTech business is looking to recruit for a Data Engineer to join their growing team. The successful candidate will be joining the artificial intelligence team, working on a brand new...
See more: Engineer jobs
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
See more: Engineer jobs
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
See more: Engineer jobs
",http://www.reed.co.uk/jobs/data-engineer/39851455
JOB108195758247,Data Engineer – Hadoop,Data Engineer – Hadoop,"Data Engineer,Five to seven years’ experience with big data tools: Hadoop, Spark, Kafka,Five to seven years’ experience SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases,Five to seven years' strong analytic skills related to working with unstructured datasets,Experience with AWS cloud services: EC2, EMR, RDS, Redshift,Full SQL Stack (SSIS, SSAS, SSRS),Degree: Information Technology",,"Our client is a firm believer in technical innovation. To help them guarantee exceptional client service and leading edge financial solutions, they are looking for an experienced Data Engineer with Big Data experience to join their growing team. Their digital footprint reflects their commitment to the latest solutions within a uniquely flexible and vibrant working culture.
You will build scalable infrastructure for supporting the delivery of clear business insights from raw data sources; with a focus on collecting, managing, analysing, visualising data and developing analytical solutions.
Requirements:
Data Engineer
Five to seven years’ experience with big data tools: Hadoop, Spark, Kafka
Five to seven years’ experience SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases
Five to seven years' strong analytic skills related to working with unstructured datasets
Experience with AWS cloud services: EC2, EMR, RDS, Redshift
Full SQL Stack (SSIS, SSAS, SSRS)
ETL (must have)
Qualifications:
Degree: Information Technology
The reference Number for this position is LV45748. It’s a permanent position based in JHB, the salary is negotiable based on experience. Contact Liza on target=""_blank"">lizavdb@e-merge.co.za or call her on 011 463 3633 to discuss this and other opportunities.
Are you ready for a change of scenery? The e-Merge IT recruitment is a specialist niche recruitment agency. We offer our candidates options so that we can successfully place the right developers with the right companies in the right roles. Check out the e-Merge website for more great positions.
Do you have a friend who is a developer or technology specialist? We pay cash for successful *referrals! https://www.e-merge.co.za/careers/referralprogramme/
Posted on 02 Jul 09:40
",https://www.bizcommunity.com/Job/196/662/369262.html
JOB108690057752,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-tw/details/200188037/ai-ml-search-data-engineer-siri-data
JOB109263841809,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/es-co/details/200188037/ai-ml-search-data-engineer-siri-data
JOB109842897752,Data Engineer-4 Months-Remote-£500/Day Inside IR35,Data Engineer-4 Months-Remote-£500/Day Inside IR35,,,"
We are seeking a Senior Network Engineer for our public sector client to work on a remote basis on a 2-month contract with the potential to extend paying between 450 - 550 per day depending on experience. This role is deemed to be inside IR35. Key Skills...
Commercial Manager-6 Months-London- 600/Day Inside IR35 We are seeking a Commercial Manager to work in Consumables, & Equipment for our client based in London. This is an initial 6 month contract paying up to 600/Day Inside IR35. This role is remote...
Data Engineer-4 Months-Remote- 500/Day Inside IR35 We are seeking a Data Engineer for our client on a remote basis. This is an initial contract running until March 2021 paying up to 500/Day Inside IR35. This role is inside IR35 - Due to the service of...
Splunk SME-5 Months-Remote- 600/Day Inside IR35 We are seeking a Splunk SME for our Government client on a remote basis. This is an initial 5 month contract paying up to 600/Day Inside IR35. This role is inside IR35 - Due to the service of the role this...
Java Developer-4 Months-Remote- 550/Day Inside IR35 We are seeking a Java Developer for our Government client on a remote basis. This is an initial 4 month contract paying up to 550/Day Inside IR35. This role is inside IR35 - Due to the service of the...
BI Developer-6 Months-Remote- 600/Day Inside IR35 We are seeking a BI Developer for our Government client on a remote basis. This is an initial 12 month contract paying up to 600/Day Inside IR35. This role is inside IR35 - Due to the service of the role...
Project Manager-4 Months-Corsham- 467/Day Inside IR35 We are seeking a Project Manager for our Government client based in Corsham. This is an initial contract running until March 2021, paying up to 467/Day Inside IR35. This role is inside IR35 - Due to...
Senior User Researcher-5 Months-Remote- 587/Day Inside IR35 We are seeking a Senior User Researcher for our Government client on a remote basis. This is an initial 5 month contract, paying up to 587/Day Inside IR35. This role is inside IR35 - Due to the...
Service Desk Manager-4 Months-Corsham - 521/Day Inside IR35 We are seeking a Service Desk Manager for our Government client based in Corsham. This is an initial contract running until March 2021 paying up to 521/Day Inside IR35. Please note, this is an...
Wintel Engineer-4 Months-Corsham- 506/Day Inside IR35 We are seeking a 3rd Line Wintel Engineer for our Government client based in Corsham. This is an initial contract running until March 2021, paying up to 506/Day Inside IR35. Please note, this is an...
Senior Technical Architect-3 Months-Remote- 600/Day Inside IR35 We are seeking a Senior Technical Architect for our NHS client. This role is home based. This is an initial contract running until March 2021, paying up to 600/Day Inside IR35. This role is...
Project Manager-12 Month- Dungeness- 480/Day Inside IR35 We are seeking a Project Manager for our client based in Dungeness. This is an initial contract running until December 2021, paying up to 480/Day Inside IR35. Please note this is a site based role...
Power Apps Developer-12 Months-Remote- 600/Day Inside IR35 We are seeking a Power Apps Developer for our Government client on a remote basis. This is an initial 12 month contract paying up to 600/Day Inside IR35. This role is inside IR35 - Due to the service...
SQL Developer / SQL / T-SQL / SSIS / Financial Services / Mixture of Remote & Warwickshire / 6 month contract / 400 - 460 per day Inside IR35. One of our leading clients is looking to recruit a SQL Developer. Location - Likely to be remote based but...
SQL Developer / SQL / T-SQL / SSIS / SSAS / SSMS / POWERBI / MS Azure / Financial Services / Mixture of Remote & Warwickshire / 6 month contract / 400 - 460 per day Inside IR35. One of our leading clients is looking to recruit a SQL Developer. Location...
Test Automation Engineer - 440 per day (inside IR35) - Initially Remote Test Automation Engineer 440 per day inside IR35 February 2021 - June 2021 Initially Remote - Manchester Site The QA Analyst will work closely with the Developer and DevOps resource...
Programme Manager - Clinical Trials & Pharma / 550 per day Inside IR35 / 4 month contract / Home based Your new role Programme Manager - Clinical Trials / Pharma What you'll need to succeed You will need past experience working on clinical trials /...
Major Incident Manager / MIM / ITIL / Service Delivery / IT Infrastructure / Remote based initially and then a mixture of Remote / Warwickshire based, 450-500 per day Inside IR35. One of our leading clients is looking to recruit a Major Incident Manager...
Senior Frontend Developer-6 Months-Blackpool- 500/Day Inside IR35 We are seeking a Senior Front End Developer for our Government client based in Blackpool. This is ian initial 6 month contract paying up to 500/Day Inside IR35. This role is remote for the...
Scrum Master / Agile / Scrum Ceremonies / Working on large change programmes / Stakeholder Management / Sprint Processes / Initially remote based and then mixture of remote and Warwickshire, 6 month contract, 500-550 per day Inside IR35. One of our leading...
SCRUM Master / Agile / SCRUM Ceremonies / Working on large change programmes / Stakeholder Management / Sprint Processes / Initially remote based and then mixture of remote and Warwickshire, 6 month contract, 500-550 per day Inside IR35. One of our leading...
Technical Solution Architect - contract until March 2021 - up to 700p/day (inside ir35) - remote working Your new company Hays are partnering with a large government department, to recruit for a Technical solution Architect on a contract basis until the...
SQL Developer/ Financial Sector / West Midlands / 6 month contract / 400- 460 per day Inside IR35 One of our leading clients in the market is looking to recruit x2 SQL Developers, Location - West Midlands Duration - 6 months Day Rate - 400-460 per day...
UX Designer / Lead UX Designer / User Experience / EU / Digital / Web / Websites One of our leading clients is looking to recruit a UX Designer. Location - initially remote and then mixture of remote and Warwickshire Duration - 6 months Day rate - 450-500...
Information Architect / Data Architect / Data Mapping / Data Architecture / TOGAF / Digital / Portal / Data Catalogues / Remote based initially moving to a mixture of remote and Warwickshire. 6 month contract, Inside IR35, 550-650 per day. One of our leading...
",https://www.reed.co.uk/jobs/data-engineer-remote-450-500-day-inside-ir35/41281377
JOB111634039617,Data Scientist / Data Engineer,Data Scientist / Data Engineer,"Seeks a challenge and gets things done.,Math/Stats/Machine Learning background.,Data modeling / SQL / NoSQL database experience.","Use a combination of financial market data, social media data, the AuCoDe controversy score engine, and customer supplied data to infer insights into stock price movements.","
Position Overview
This role is perfect for an entrepreneurial self-starter who loves data, finding signal among the noise, and presenting results for practical consumption. On the flip side, you also love building the foundational processes and systems to receive, store, transform and make the data usable.
You will be our first hire and work directly with the founders as we move the company forward.
Essential Responsibilities
Use a combination of financial market data, social media data, the AuCoDe controversy score engine, and customer supplied data to infer insights into stock price movements.
Build/organize systems and processes to manage market, social media and customer data.
Present results in graphically informative ways for internal and external consumption.
Collaborate with founders to understand customer needs and formulate solutions.
Integrate novel research from our partner lab at UMass Amherst directly into our products.
Requirements
Seeks a challenge and gets things done.
At least one of:
Math/Stats/Machine Learning background.
FinTech work experience.
Working Python skillset.
U.S. Work Authorization. Unfortunately we cannot sponsor visas at this stage.
Desired but not Required
Data modeling / SQL / NoSQL database experience.
R, Java, SAS or other data centric programming language experience.
Experience creating visualizations with software like Jupyter, Tableau, Spotfire, Power BI, etc.
Investment/Quant experience.
",https://www.ziprecruiter.com/jobs/aucode-15aafb36/data-scientist-data-engineer-7b1e47cc
JOB111927854804,Data Engineer in Geosciences Domain,Data Engineer in Geosciences Domain,,"Maintaining, improving, and developing databases,Developing data pipelines from sensor input to shared output,Supporting the development of dashboards and automated reports,Supporting the deployment and development of sensors,Master’s degree in computer sciences, information technology, or similar; or a Master’s degree in geosciences with strong programming skills,At least 3 years of relevant work experience in data engineering,Experienced user of databases and dashboard software,Hands-on understanding of machine learning applications and algorithms,Excellent proficiency in an open-source programming language (e.g. Python),Bonuspoints for experience with Azure, PostGIS, Grafana and/or DataIKU,Proficiency in geographic information systems (GIS),Experience with remote sensing and telemetry is a plus,Structured worker with a curious and critical mindset,Comfortable with a high level of autonomy,Enjoys structuring work for yourself and others,Excited about working on back-end systems and being the hero behind the scenes,Enjoys sharing knowledge with team members (and building capacity in the team and with partners),Able to deal with uncertainty, changes in scope, and ambiguity,Enjoys learning and developing new skills and tools","
MISSION TO METRICS
The mission of The Ocean Cleanup is to develop advanced technologies to rid the world’s oceans of plastic. To do so, we design, develop, and deploy cleanup systems to stop plastic from reaching our oceans by intercepting it in rivers. As a Data Engineer, you will be responsible for designing technical solutions to collect, store, and share data that come from models, field campaigns, sensors, and apps from around the world. Together with the data scientist and river survey engineers, you provide the team with real-time data on our plastic extraction operations and plastic emitting rivers.
“The Data and Monitoring team supports the development of our plastic interception technologies and measures their performance. To support future river deployments, we collect data on the spatial and temporal behavior of plastic in these rivers and provide all relevant data. We conduct fieldwork and develop and deploy sensors, apps, and dashboards to provide actionable information to other teams in the organization. We collaborate with universities across the globe to gather the best understanding of plastic emitting rivers. If you are a structured person who combines data engineering skills with a hands-on mentality, then this is the opportunity for you.” – Lourens Meijer, Head of Data & Monitoring
RESPONSIBILITIES
The Ocean Cleanup currently operates Interceptors in several countries and is seeking to expand rapidly in the next years. The Data and Monitoring team identifies suitable deployment locations and measures the performance of existing operations. Various types of data (continuous, real-time, periodical, through apps, sensors e.g.) are collected. It is the responsibility of the Data Engineer to structure and store these raw data to allow and support analysis and visualization. The Data Engineer facilitates the deployment of sensors and necessary tools and participates in projects that require data analysis or collection.
Your responsibilities include:
Maintaining, improving, and developing databases
Developing data pipelines from sensor input to shared output
Supporting the development of dashboards and automated reports
Supporting the deployment and development of sensors
Structuring raw data, assisting in data analyses
PROFESSIONAL QUALIFICATIONS
Master’s degree in computer sciences, information technology, or similar; or a Master’s degree in geosciences with strong programming skills
At least 3 years of relevant work experience in data engineering
Experienced user of databases and dashboard software
Hands-on understanding of machine learning applications and algorithms
Excellent proficiency in an open-source programming language (e.g. Python)
Bonuspoints for experience with Azure, PostGIS, Grafana and/or DataIKU
Proficiency in geographic information systems (GIS)
Experience with remote sensing and telemetry is a plus
Fluent in English
PERSONAL QUALIFICATIONS
Structured worker with a curious and critical mindset
Comfortable with a high level of autonomy
Enjoys structuring work for yourself and others
Excited about working on back-end systems and being the hero behind the scenes
Enjoys sharing knowledge with team members (and building capacity in the team and with partners)
Able to deal with uncertainty, changes in scope, and ambiguity
Enjoys learning and developing new skills and tools
Intrinsic motivation to work on our ambitious and meaningful goal
Starting from:
ASAP
Work permit needed:
A valid European Union work permit is highly preferred for this position. However, feel free to send an open application so we can contact you if an opportunity arises in your country.
",https://theoceancleanup.com/careers/jobs/data-engineer-geosciences/
JOB112735738379,Data Engineer,Data Engineer,"This position requires a Computer Science, Bioinformatics, or related degree; 5+ years' experience in data movement, data wrangling and delivery of data or analytics pipelines,Experience implementing and maintaining, data or analytic pipelines.,Experience with Big Data technologies, Cloud-based offerings (Microsoft Azure, GCP, AWS, etc), and corresponding tools.,Experience with data movement and management in the Pharmaceutical industry or related scientific fields.,Experience with the core components of the Hadoop stack including HDFS and Apache Spark, ideally a Cloudera based stack,Background and experience in LIMS systems, Next Generation Sequencing (NGS) workflows, Cloud computing and HPC systems.,Understanding of diverse ‘omic data types including RNA-Seq, DNA-Seq, Chip-Seq, WES, WGS, ATAC-seq, microbiome, proteomic, metabolomic data etc. from different sources.,Familiarity with data mining, machine learning and artificial intelligence techniques,Proven ability to contribute to development projects.,Operating at pace and agile decision-making - using evidence and applying judgement to balance pace, rigour and risk.,Committed to delivering high quality results, overcoming challenges, focusing on what matters, execution.,Continuously looking for opportunities to learn, build skills and share learning.,Sustaining energy and well-being.,Building strong relationships and collaboration, honest and open conversations.","Partner with data teams to implement pipeline designs to support R&D strategy and conceptual data flows,Partner with the metadata leads to translate conceptual data models into physical database/tables optimized for data analytics in RDIP using established environments and tools,Assist the design, build, test and maintenance of data acquisition and processing pipelines including but not limited to the creation/maintenance of appropriate artifacts,Ensure the preservation of data integrity from source to target state including but not limited to the acquisition of appropriate metadata and the incorporation of appropriate QC checks into the pipelines,Support the use and growth of the Data Engineering DataOps environment, influence strategy and roadmap for the curation toolset, work with R&D and Tech to prioritize enhancements,Provide Tier 3 support for production pipelines,Support DCS and broader R&D in self-service/exploratory efforts,Influence vendor roadmaps, work with R&D and Tech to prioritize DataOps enhancements, and onboard these tools or enhancements,Ensure the quality consistency and availability of guidance documentation of end users of the tools to support high quality outputs,Extend current pipelines to support clinical biomarkers,Assess GxP readiness as it related to the upstream data pipelines and develop a plan for addressing any gaps","
This job has expired
Are you looking for a challenging opportunity to work in an area where cutting edge science meets cutting edge technology with an aim of delivering drugs to patients in need? If so, this Data Engineer role could be an exciting opportunity to explore.
The Data & Compute Delivery (DCD) Data Engineering team is a crucial component of the environment and are responsible for delivery of data pipelines populating and maintaining data for scientific use in HPCs, Cloud and the R&D Information Platform (RDIP).
We are looking for a passionate and enthusiastic individual who will contribute to the strategy for data movement in a variety of scientific areas by working closely with people who are involved in the generation, handling and consumption of such data that includes Data & Computational Science (DCS), R&D Tech, different vendors and the larger R&D organization. The data engineer needs to be able to apply technologies in a DataOps environment to solve big data problems and to develop innovative big data solutions based on defined business requirements. The successful candidate must be able to learn and work independently, lead or assist with pipeline development efforts and collaborate effectively with co-workers.
This role will provide YOU the opportunity to lead key activities to progress YOUR career, these responsibilities include some of the following:
Partner with data teams to implement pipeline designs to support R&D strategy and conceptual data flows
Partner with the metadata leads to translate conceptual data models into physical database/tables optimized for data analytics in RDIP using established environments and tools
Assist the design, build, test and maintenance of data acquisition and processing pipelines including but not limited to the creation/maintenance of appropriate artifacts
Ensure the preservation of data integrity from source to target state including but not limited to the acquisition of appropriate metadata and the incorporation of appropriate QC checks into the pipelines
Support the use and growth of the Data Engineering DataOps environment, influence strategy and roadmap for the curation toolset, work with R&D and Tech to prioritize enhancements
Provide Tier 3 support for production pipelines
Support DCS and broader R&D in self-service/exploratory efforts
Influence vendor roadmaps, work with R&D and Tech to prioritize DataOps enhancements, and onboard these tools or enhancements
Ensure the quality consistency and availability of guidance documentation of end users of the tools to support high quality outputs
Extend current pipelines to support clinical biomarkers
Assess GxP readiness as it related to the upstream data pipelines and develop a plan for addressing any gaps
Provide Tier 3 support/administration of DNA Nexus bioinformatics system
Why you?
Basic Qualifications:
We are looking for professionals with these required skills to achieve our goals:
This position requires a Computer Science, Bioinformatics, or related degree; 5+ years' experience in data movement, data wrangling and delivery of data or analytics pipelines
Experience implementing and maintaining, data or analytic pipelines.
Experience with Big Data technologies, Cloud-based offerings (Microsoft Azure, GCP, AWS, etc), and corresponding tools.
Experience with open source software, bioinformatics tools and languages such as SQL, R, Perl, Python, Java, and ETL tools.
Preferred Qualifications:
If you have the following characteristics, it would be a plus:
Experience with data movement and management in the Pharmaceutical industry or related scientific fields.
Experience with the core components of the Hadoop stack including HDFS and Apache Spark, ideally a Cloudera based stack
Background and experience in LIMS systems, Next Generation Sequencing (NGS) workflows, Cloud computing and HPC systems.
Understanding of diverse ‘omic data types including RNA-Seq, DNA-Seq, Chip-Seq, WES, WGS, ATAC-seq, microbiome, proteomic, metabolomic data etc. from different sources.
Familiarity with data mining, machine learning and artificial intelligence techniques
Proven ability to contribute to development projects.
Strong interpersonal skills and effective communication of complex concepts to stake holders with wide range of expertise.
Why GSK?
Our values and expectationsare at the heart of everything we do and form an important part of our culture. These include Patient focus, Transparency, Respect, Integrity along with Courage, Accountability, Development, and Teamwork. As GSK focuses on our values and expectations and a culture of innovation, performance, and trust, the successful candidate will demonstrate the following capabilities:
Operating at pace and agile decision-making - using evidence and applying judgement to balance pace, rigour and risk.
Committed to delivering high quality results, overcoming challenges, focusing on what matters, execution.
Continuously looking for opportunities to learn, build skills and share learning.
Sustaining energy and well-being.
Building strong relationships and collaboration, honest and open conversations.
Budgeting and cost-consciousness
*LI-GSK
If you require an accommodation or other assistance to apply for a job at GSK, please contact the GSK Service Centre at 1-877-694-7547 (US Toll Free) or +1 801 567 5155 (outside US).
GSK is an Equal Opportunity Employer and, in the US, we adhere to Affirmative Action principles. This ensures that all qualified applicants will receive equal consideration for employment without regard to race, color, national origin, religion, sex, pregnancy, marital status, sexual orientation, gender identity/expression, age, disability, genetic information, military service, covered/protected veteran status or any other federal, state or local protected class.
Important notice to Employment businesses/ Agencies
GSK does not accept referrals from employment businesses and/or employment agencies in respect of the vacancies posted on this site. All employment businesses/agencies are required to contact GSK's commercial and general procurement/human resources department to obtain prior written authorization before referring any candidates to GSK. The obtaining of prior written authorization is a condition precedent to any agreement (verbal or written) between the employment business/ agency and GSK. In the absence of such written authorization being obtained any actions undertaken by the employment business/agency shall be deemed to have been performed without the consent or contractual agreement of GSK. GSK shall therefore not be liable for any fees arising from such actions or any fees arising from any referrals by employment businesses/agencies in respect of the vacancies posted on this site.
Please note that if you are a US Licensed Healthcare Professional or Healthcare Professional as defined by the laws of the state issuing your license, GSK may be required to capture and report expenses GSK incurs, on your behalf, in the event you are afforded an interview for employment. This capture of applicable transfers of value is necessary to ensure GSK's compliance to all federal and state US Transparency requirements. For more information, please visit GSK's Transparency Reporting For the Record site.
",https://www.gettinghired.com/job-details/1635384/data-engineer/
JOB113481669460,Data Engineer Jobs,Data Engineer Jobs,,,"
Data Engineer Role Two data engineers are required to support the head of architecture and data engineering.? The head of data architecture and engineering will be delivering a data approach for which includes building a data platform for the firm in order...
See more: Engineer jobs
We are looking for a Data Engineer to join our Clear Review business as we analyse, explore and improve how over 100,000 employees across over 200 companies perform and feel about work. Clear Review is our UK's leading Continuous Performance Management...
See more: Engineer jobs
DATA ENGINEER LONDON - CURRENTLY FLEXIBLE/REMOTE WORKING UP TO 85K BENEFITS BONUS This is a really exciting position for an experienced senior data engineer to join a rapidly growing start - up founded by leading data experts. They are looking to grow...
See more: Engineer jobs
DATA ENGINEER 400- 500 PER DAY 3 MONTH CONTRACT LONDON BASED As a Data Engineer you will be working heavily with Python/Spark create APIS on an AWS platform which is connected to Databricks. THE COMPANY: You will be working for a start up within the AI...
See more: Engineer jobs
DATA ENGINEER 70,000 - 85,000 10% BONUS LONDON THE COMPANY: This is a world-renowned insurance business with a range of departments. They've recently been through a transformation to use data more in the business and are looking to bring on a Data Engineer...
See more: Engineer jobs
Data Engineer | Python | SQL | GCP | London | Up to 65,000 Are you an experienced Data Engineer with a real passion for what data can do for a business? Do you enjoy working in a constantly evolving environment where no two days are the same? Method Resourcing...
See more: Engineer jobs
GCP DATA ENGINEER 400- 500 PER DAY 3 MONTH CONTRACT LONDON BASED As a Data Engineer you will be working heavily with Python/Spark on a GCP platform, creating an automated process to push data into Google Audiences. THE COMPANY: You will be working for...
See more: Engineer jobs
DATA ENGINEER 400- 500 PER DAY 3 MONTH CONTRACT LONDON BASED As a Data Engineer you will be working heavily with Python/Spark on a GCP platform, creating an automated process to push data into Google Audiences. THE COMPANY: You will be working for a start...
See more: Engineer jobs
Are you a passionate and technically rounded Data Engineer, looking for an organisation that will invest in you and pushes you to be the best you can be? Do you want to learn from & work alongside some of the most talented, supportive Data Engineers...
See more: Engineer jobs
DATA ENGINEER 400- 500 PER DAY 3 MONTH CONTRACT FULLY REMOTE As a Data Engineer you will have the chance to work for a health care consultancy in analysing local data sets using Python, SQL and Airflow. THE COMPANY: As a Data Engineer, you will be working...
See more: Engineer jobs
DATA ENGINEER LONDON (REMOTE WORKING) UP TO 75,000 Harnham are partnered with a home furnishing retailer, that has superstores placed all over the UK. They are looking for a data engineer to join their expanding and newly successful team to design and...
See more: Engineer jobs
Data Engineer Role Two data engineers are required to support the head of architecture and data engineering.? The head of data architecture and engineering will be delivering a data approach for which includes building a data platform for the firm in order...
See more: Engineer jobs
DATA ENGINEER LONDON (REMOTE WORKING) UP TO 85,000 Harnham are partnered with an international television network that produces its own unique content. They are looking for a data engineer to join their subscription service and work in tandem with BI and...
See more: Engineer jobs
Senior Business Intelligence Engineer - London - 50k- 70k Our client is a prestigious not for profit organisation, providing support to thousands of members across the UK. They are seeking a talented and ambitious BI Data Engineer who has a strong technical...
See more: Engineer jobs
We are looking for a talented Data Engineer to join our team in Stockport, however due to the pandemic this role will initially start fully remote with a view to return to our offices. You will join us on a full time, permanent basis and in return, you...
See more: Engineer jobs
Data Engineer Our client is a well-established international insurance company, and they are looking for 2 Data Engineers to support the Data & MI team. This is a business facing role within Actuarial & Analytics so excellent communication skills...
See more: Engineer jobs
We're supporting our clients as they adapt to a new world in the wake of COVID-19. We're now recruiting for roles which will help our clients to deliver vital services and to resume business wherever possible. What you'll be doing : Excellent communicational...
See more: Engineer jobs
We're supporting our clients as they adapt to a new world in the wake of COVID-19. We're now recruiting for roles which will help our clients to deliver vital services and to resume business wherever possible. What you'll be doing : Excellent communicational...
See more: Engineer jobs
Data Engineer | 350- 450 per day | Berkshire | 6 Months Role: Data Engineer Day Rate: 400- 500 per day Type: Contract Location: Bristol My client based in Bristol have an urgent requirement for a Data Engineer on a 6 month contract. The daily rate on offer...
See more: Engineer jobs
Title: Data Engineer Our client is currently looking for a Data Engineer to play a vital role in the continual development of our digital transformation strategy and earth science analytics. Candidates must have Python, R and SQL. We expect candidates...
See more: Engineer jobs
Data Engineer - Python - Permanent Data Idols are working with a well-known client in the e-commerce space who are looking for a Data Engineer to join an existing team. THE ROLE As a Data Engineer, you will be working with the existing Data team to help...
See more: Engineer jobs
Data Engineer - Permanent - London Data Idols are working with a well-known client in the e-commerce space who are looking for a Data Engineer to join an existing team based in London. THE ROLE As a Data Engineer, you will be working with the existing...
See more: Engineer jobs
Data Engineer Espoo, Finland 90 EUR Per Hour 4 Months As a Data Engineer you will be developing automation for cloud-based data pipelines to aid this growing tech company to provide a streamlined customer retail experience. You will be deploying both existing...
See more: Engineer jobs
One of Europe’s fastest growing FinTech companies, are looking for a Data Engineer to join their growing team on a permanent basis. The Company This is an exciting time to join a fast growing award winning company within the financial services space. To...
See more: Engineer jobs
Data Engineer Are you a Data Engineer with prior experience in Big Query and Python? If so, you now have the opportunity to work for one of the most prestigious Cyber Security organisations in the United Kingdom. This role will provide you the opportunity...
See more: Engineer jobs
Data Engineer, Uxbridge, 40-55K 10% bonus bens. You must be an experienced Data Engineer and have a deep understanding of data technologies and strong software engineering expertise, along with a deep interest in data analytics, machine learning and AI...
See more: Engineer jobs
Data Engineer – Manchester – 50K - 60K Interviewing and onboarding for this role will be going ahead remotely while Covid-19 restrictions are in place. Adria Solutions has an exciting opportunity for an experienced Data Engineer to join a well-established...
See more: Engineer jobs
",https://www.reed.co.uk/jobs/data-engineer/40454836?source=searchResults
JOB113578066103,Lead Data Engineer,Lead Data Engineer,"Identify data sources that can add value to decision making.,Work with source system owners and analysts to understand source data, e.g. data profiling, definition and mapping.,Design and implement efficient data loads, using traditional structured data ETL techniques.,Design and implement real time and near real time data load solutions, using technologies like data streaming.,Design and implement unstructured data loads, e.g. text speech, images and video.,Design and implement load monitoring tools and procedures and perform continuous monitoring and optimising of loads.,Work with analysts and architect to design and implement effective and efficient data models using appropriate modelling techniques.,Design and implement data warehouse data models.,Design and implement data pipelines for ad hoc, unstructured and other data models.,Design and implement appropriate aggregation data structures that enhance usability of data, e.g. multi-dimensional OLAP structures, summary tables etc.,Design, implement and maintain appropriate indexing on tables to enhance speed of access.,Design and implement data models that support automated decision making and/or further analytics.,Continuously search for data elements from other sources to enhance existing data objects to supplement / enhance context.,Design and implement interfaces for data access, e.g. batch exports, real-time decision API’s etc.,Design and implement interface monitoring and management solutions to ensure availability and accuracy.,Design and implement data monitoring solutions and procedures and continuously monitor and maintain integrity of existing environment, troubleshoot technical and data issues and make appropriate changes where required.,Design and implement meta-data solutions that assist with understanding and managing data.,Work together with business owners, analysts and IT to maintain good data governance.,Work together with business owners, analysts and IT to manage changes to data in the organisation.,Provide technical and data related support to source system teams and external parties with whom we exchange data.,Manage data growth and usage by implementing effective strategies, e.g. archiving and indexing.,Manage systems, technology and tools that enable data management and analytics and liaise with IT infrastructure and IT Operations regarding system and infrastructure management.,Take ownership of own work by delivering high quality work on time.,Show initiative and be pre-active in finding opportunities to improve data and/or processes.,Take ownership of own career development by continuously improving skills, knowledge and the application thereof in designing and implementing solutions.,Positive engagement in team activities and actively contribute ideas to improve team dynamics and performance.,Complex solution and service design and implementation.,Cross functional data and team knowledge gathering and sharing.,Responsible for team activities, team dynamics and performance.,Manage project and task delivery of team.,Multiple stakeholder management (internal and external).,Assist in development of others, e.g. mentoring and knowledge share.,Quality control of other’s work.,Degree in information technology/engineering/mathematics/statistics/actuarial or related discipline,At least 8 years’ experience working in a data, business intelligence or analytics environment,SQL,Data analysis,Data visualisation,Data modelling,Microsoft business intelligence data technologies (SSIS, SSAS, SQL Server),Data warehouse concepts and best practices,Information gathering and problem analysis,Applying professional / specialist / technical expertise,Creating and innovating,Quality & Detail orientation,Planning and organizing,Presenting and Communicating information,Analysing,Leadership",,"Lead Data Engineer
Job description
Capfin is a leading unsecured loan provider with a successful business model supported by great people with a strong culture of innovation and data driven decision making. The purpose of this role is to create business value by leading a team that apply data engineering and data management disciplines to design and build data solutions that enable data driven decision support, in order to optimize business decisions and processes.
Requirements
Key Performance Areas:
Sourcing data
Identify data sources that can add value to decision making.
Work with source system owners and analysts to understand source data, e.g. data profiling, definition and mapping.
Loading data
Design and implement efficient data loads, using traditional structured data ETL techniques.
Design and implement real time and near real time data load solutions, using technologies like data streaming.
Design and implement unstructured data loads, e.g. text speech, images and video.
Design and implement load monitoring tools and procedures and perform continuous monitoring and optimising of loads.
Storing data
Work with analysts and architect to design and implement effective and efficient data models using appropriate modelling techniques.
Design and implement data warehouse data models.
Design and implement data pipelines for ad hoc, unstructured and other data models.
Enhancing data
Design and implement appropriate aggregation data structures that enhance usability of data, e.g. multi-dimensional OLAP structures, summary tables etc.
Design, implement and maintain appropriate indexing on tables to enhance speed of access.
Design and implement data models that support automated decision making and/or further analytics.
Continuously search for data elements from other sources to enhance existing data objects to supplement / enhance context.
Making data available
Design and implement interfaces for data access, e.g. batch exports, real-time decision API’s etc.
Design and implement interface monitoring and management solutions to ensure availability and accuracy.
Managing data
Design and implement data monitoring solutions and procedures and continuously monitor and maintain integrity of existing environment, troubleshoot technical and data issues and make appropriate changes where required.
Design and implement meta-data solutions that assist with understanding and managing data.
Work together with business owners, analysts and IT to maintain good data governance.
Work together with business owners, analysts and IT to manage changes to data in the organisation.
Provide technical and data related support to source system teams and external parties with whom we exchange data.
Manage data growth and usage by implementing effective strategies, e.g. archiving and indexing.
Manage systems, technology and tools that enable data management and analytics and liaise with IT infrastructure and IT Operations regarding system and infrastructure management.
Leadership responsibilities
Take ownership of own work by delivering high quality work on time.
Show initiative and be pre-active in finding opportunities to improve data and/or processes.
Take ownership of own career development by continuously improving skills, knowledge and the application thereof in designing and implementing solutions.
Positive engagement in team activities and actively contribute ideas to improve team dynamics and performance.
Complex solution and service design and implementation.
Cross functional data and team knowledge gathering and sharing.
Responsible for team activities, team dynamics and performance.
Manage project and task delivery of team.
Multiple stakeholder management (internal and external).
Assist in development of others, e.g. mentoring and knowledge share.
Quality control of other’s work.
Qualifications:
Degree in information technology/engineering/mathematics/statistics/actuarial or related discipline
Experience:
At least 8 years’ experience working in a data, business intelligence or analytics environment
Functional Competencies:
SQL
Data analysis
Data visualisation
Data modelling
Microsoft business intelligence data technologies (SSIS, SSAS, SQL Server)
Data warehouse concepts and best practices
Behavioural Competencies:
Information gathering and problem analysis
Applying professional / specialist / technical expertise
Creating and innovating
Quality & Detail orientation
Planning and organizing
Presenting and Communicating information
Analysing
Leadership
The closing date for applications is 9 July 2019.
Posted on 25 Jun 13:32
",https://www.bizcommunity.com/Company/Job.aspx?cid=221357&i=369014
JOB115075221391,Data Engineer (Java/ Data/ Big Data Developer),Data Engineer (Java/ Data/ Big Data Developer),"Agile Engineering (Kanban, Lean, Hybrid agile experience is a big plus)","Engage in super interesting high profile projects,Join a fun team full of flair and personality, contribute and be recognized for your value add!,Zero Bureaucracy environment - we are about embracing creative talent,Passionate about working on complex Data problems,You will ideally have a solid demonstrated Big Data experience,Java/ Data/ Big Data Development","
Data Engineer (SJava/ Data/ Big Data Developer), Melbourne CBD, fantastic long duration contract, asap start
Melbourne
Are you a Data Engineer with Java/ Data/ Big Data Development experience seeking a new contract? If you answered yes, I have the ""perfect"" role for you!!!
Working with a reputable iconic Australian brand name in Melbourne CBD you will be a part of a leading customer analytics platform team.
The position is available due to growth and they are in need of a talented Data Engineer to work on next generation data tools and pipelines. This is where Data Engineering meets Data Science!
What is in it for you?
Engage in super interesting high profile projects
Join a fun team full of flair and personality, contribute and be recognized for your value add!
Zero Bureaucracy environment - we are about embracing creative talent
Who are you?
Passionate about working on complex Data problems
You will ideally have a solid demonstrated Big Data experience
Your ""perfect"" role:
As a talented Data engineer you will demonstrate expertise in:
Java/ Data/ Big Data Development
Agile Engineering (Kanban, Lean, Hybrid agile experience is a big plus)
Your value add to this team will be:
• Java / data work putting together a prototype for a Big Data linking engine, preference for Big Data experience
• Every day is a different idea, a different challenge, you ""will be"" up for it!
• Outgoing personality with a creative flair, not stage shy and experienced with senior stakeholders!
If this sounds like you, I would love to find out more about you! Apply by sending you CV in word format.To be considered for the role click the 'Apply' button or for more information about this and other opportunities please contact Kenny Nerlekar on 03 8680 4202. Please quote our job reference number: 200165301.
Reference Number: 200165301_2
Contact Details:
How to Apply?
Click on the link below
Click here for more information about this job
",http://www.techworld.com.au/jobs/view/20718/data-engineer-java-data-big-data-developer/
JOB115694874120,Data Engineer Asc Mgr,Data Engineer Asc Mgr,,,,https://www.avjobs.com/jobs/positions.asp?q=Data+Engineer+Asc+Mgr
JOB116543719323,Senior Data Engineer,Senior Data Engineer,"Degree educated in Data Science or similar,Strong experience with data preparation techniques including exploration and visualisation,Experience with statistical models, times series analysis and multiple machine learning techniques such as clustering, regression and classification,Strong skills using Python, SQL & Elastic and visualise the data in a surfacing tool,Experience developing machine learning systems,Experience in Amazon Quicksite will be an advantage","Provide analytical and statistical expertise to company.,Become familiar with a range of data sets, looking at raw customer data, financial data and marketing data.,Experiment with algorithms, machine learning and data exploration in order to build solutions and tools for data-driven purposes.,Perform clustering analysis on customer data, along with segmentation and clustering.,Present and tell the story of the data to clients.,Support in the creation of real time reporting using Kibana.,Own recommendation engines and machine learning systems.,Own reporting data flows include ETL processes,Perform updates to production databases","
Currently looking for a Senior Data Engineer for Australia's Leading cashback website, Data Preparation, Python, SQL, Amazon Quicksite, Chatswood
Sydney
We are currently looking to engage a Senior Data Engineer who can support an enterprise wide program of work for one of Australia's largest cashback sites.
This organisation is the 4 th fastest tech company within the Asian region and according to Deloitte is the fasting growing tech company within Australia.
Working as part of a well-established and high performing team, you will be required to innovate and develop new ways in which companies can engage with their customers on a more personal level, looking to drive satisfaction, return on investment, customer conversion rate but most importantly unlocking the value of their data in order to grow and improve clients.
Role Responsibilities:
Provide analytical and statistical expertise to company.
Become familiar with a range of data sets, looking at raw customer data, financial data and marketing data.
Experiment with algorithms, machine learning and data exploration in order to build solutions and tools for data-driven purposes.
Perform clustering analysis on customer data, along with segmentation and clustering.
Present and tell the story of the data to clients.
Support in the creation of real time reporting using Kibana.
Own recommendation engines and machine learning systems.
Own reporting data flows include ETL processes
Perform updates to production databases
Experience Requirements:
Degree educated in Data Science or similar
Strong experience with data preparation techniques including exploration and visualisation
Experience with statistical models, times series analysis and multiple machine learning techniques such as clustering, regression and classification
Strong skills using Python, SQL & Elastic and visualise the data in a surfacing tool
Experience developing machine learning systems
Experience in Amazon Quicksite will be an advantage
If you are interested in the role, please apply or send updated resume to Ra'id at rahmad@paxus.com.au
To be considered for the role click the 'Apply' button or for more information about this and other opportunities please contact Ra'id Ahmad on 02 9464 5554. Please quote our job reference number: 200167644.
Reference Number: 200167644_1
Contact Details:
How to Apply?
Click on the link below
Click here for more information about this job
",https://www.techworld.com.au/jobs/view/23527/senior-data-engineer/
JOB116772117369,Data Engineer,Data Engineer,,,"
Job title: Data Engineer Location : Zurich. Switzerland Job type : Contract Data Engineer with Hadoop/Apache Sparc Knowledge - - Build a data processing layer based on Hadoop,Spark, Neo4J - Ensure appropriate security processes are integrated with access...
Data Engineer We have had a role come available for a Data Engineer in London. The role will require you to either hold a DV Clearance. Key Experience: Data Analysis experience; Strong SQL skills; Data Processing using ETL tools; Understanding of procurement...
Data Engineer - Contract - Remote Based Data Engineer Until end November 2020 initially Remote Based (Office is based in Chester) Competitive pwd Ltd Company Tech Skills Required: ETL Design, Talend, MYSQL, Vertica We are currently looking for a Data Tester...
Data Engineer - Contract - Remote Based Data Engineer Until end November 2020 initially Remote Based (Office is based in Chester) Competitive pwd Ltd Company Tech Skills Required: ETL Design, Talend, MYSQL, Vertica We are currently looking for a Data Tester...
Site Name: UK - London - Brentford, USA - Pennsylvania - Upper Providence Posted Date: Jun 4 2020 Are you looking for a challenging opportunity to work in an area where cutting edge science meets cutting edge technology with an aim of delivering drugs...
Site Name: UK - London - Brentford, USA - North Carolina - Research Triangle Park, USA - Pennsylvania - Philadelphia Posted Date: Mar 17 2020 Data Engineer is accountable for developing and delivering cloud-based data ingestion solutions across the Pharma...
AWS Data Engineer x 2 Real Estate business Solve a key problem for the client. Work with AWS & PostgreSQL. 3 month initial contract outside of IR35. My client is looking for 2 AWS Data Engineers with solid experience working with post code / address...
Remote working. Up to 550 p/day. SQL Server, SSIS, AWS 6-month contract opportunity for a Senior Data Engineer with financial services experience. What you'll be doing Working for a large financial services client, you will work in a team of data engineers...
Azure Data Engineer Leading Insurance business Work on a large scale Azure migration project. Build dimensional models. 6 month initial contract - inside IR35 My client is looking for 2 Data Engineers with excellent Microsoft Azure experience for a large...
Senior Data Engineer - Permanent Data Idols are working with a well known Technology company who are looking for a Senior Data Engineer to join a cross-functional team. This industry disruptor has been changing the way people interact with an everyday...
Our client, a global travel company require a Digital Data Engineer with strong GCP/ Big Query skills to join their analytics engineering team. Your Role You will be responsible for developing reporting infrastructure and providing actionable reporting...
Supporting a fast growing, global organisation the Interim Data Engineer will become a business partner to a newly established international client. You will be responsible for the following: - Building reporting architectures and pipelines for streamed...
SENIOR DATA ENGINEER 550- 650 PER DAY 3 MONTH CONTRACT REMOTE/ LONDON BASED As a Senior Data Engineer you will have the chance to work for a innovative e-commerce client in productionising ML models using Python, SQL and Airflow alongside AWS services...
Data Engineer SC cleared London, Titchfield or Newport 3 months to start - but until march 2021 Outside IR35 SC cleared holder before applying - due to quick start of work Key Responsibilities Collaborating with key members of the Data Engineering team...
Digital Data Engineer 500 per day 3-months Remote/London As a Data Engineer, you will be helping with a Digital Transformation project, in setting up a Google Big Query data warehouse. THE COMPANY: This company specialise in the travel industry and are...
Digital Data Engineer | 3 Month Contract As Digital Data Engineer, you will be responsible for developing reporting infrastructure and providing actionable reporting on my client's web properties (website, app). You will be working closely with stakeholders...
An exciting opportunity has opened up in Mechelen, Belgium for a Big Data Engineer. Skills and experience required: Scala Spark Kafka HLD, DLD and e2e ownership for Big Data projects Proficient in requirement gathering This is a 9-month contract. Salt...
Data Engineer Cutting edge machine learning Mission led start-up Crucial hire An established mission-led start-up is currently looking for an experienced Data Engineer/Software Engineer to join their team on an initial 3-month contract to extend/go permanent...
Python Software Engineer / Developer (PostgreSQL) Remote Interview. Are you a bright, motivated Python Software Engineer looking to work on complex, data centric systems whilst continually learning and gaining valuable knowledge of financial trading systems?...
Big Data Engineer Must be security cleared 45,000 - 55,000 Home working initially but candidate must be able to commute to Croydon / Kent in time If you are interested in working with sophisticated data to solve real world problems within a focused and...
DATA ENGINEER 400- 500 PER DAY 3 MONTH CONTRACT FULLY REMOTE As a Data Engineer you will have the chance to work for a online retail client using SQL heavily and DBT for modelling. THE COMPANY: As a Data Engineer, you will be working for an exciting online...
DATA ENGINEER 400- 500 PER DAY 3 MONTH CONTRACT FULLY REMOTE As a Data Engineer you will have the chance to work for a media company using Big Query, Airflow and Python for ETL work. THE COMPANY: As a Data Engineer, you will be working for a well known...
Are you a seasoned professional with prior data center construction experience? Do you have a deep knowledge of electrical systems? Looking for a new opportunity? An exciting opportunity to become the subject matter expert for the electrical systems within...
",https://www.reed.co.uk/jobs/data-engineer/40304782
JOB118299798043,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-nz/details/200188037/ai-ml-search-data-engineer-siri-data
JOB118417567971,Senior Big Data Engineer,Senior Big Data Engineer,"Splunk, Hadoop and similar","Provide Big Data Engineering support to the Media Analytics and User Experience team and Media (Network and Engineering) data customers,Lead the Media Analytics program of work to integrate video streaming data into the development of apps and websites - particularly sports and entertainment.,Drive tangible business values through actionable insights that lead to measurable improvements of the received customer experience and customers engagements,Setting benchmarks and targets for continual improvements of the customers video streaming experience,Engaging and influencing Senior Managers, Product managers, Technology managers, Operations managers, Program managers to promote Media's capabilities and aligning with corporate strategic programs;,Be a key influence in the development and production of automated reporting, recommendations on data sources, data centric platforms and tools, and contribute to the implementation of data centric applications.,Recommending and supporting best of bread Media data source identification and documentation.,Data validation, data access, integration and aggregation to support work of analysts, data scientist and the deployment of data centric applications and solutions,Having the ability to query databases, make data available to experimental and/or production environments and assess data suitability for performing statistical analysis,Experience working in established diverse digital ecosystems with a variety of systems, tools, limitations and stakeholders,Understanding the technologies for the delivery of online streaming video (live and on-demand). Technologies including video compression (eg: H.264, HEVC etc), adaptive bit rate streaming (eg: Microsoft Smooth streaming (MSS), Apple HTTP Live Streaming (HLS), Adobe HTTP's Dynamic Streaming (HDS), Widevine, MPEG-DASH, etc) and Content Delivery Network (CDN).,Experience in the development of OTT Video streaming services and applications.,Understanding metrics for video quality and the measurements of received customer experience for media services,Experience with dashboard and analytical tools supporting data,A working knowledge of protocols related to Internet (TCP/IP),Knowledge of Cloud, NFV and SDN.,Knowledge of video streaming software and analytics tools e.g. Conviva (highly desirable),Practical experience with SQL and/or non SQL storage methods and APIs,Experience in Unix / Linux, administration and scripting - Mandatory,Object orientated and procedural programming languages,R, SAS,,Python","
Join a large telco organisation and lead the media analytics program of work including video stream data!
Melbourne
12 months contract
Melbourne CBD
Lead the end-to-end data integration program for video streaming including scoping/planning, development, lifecycle and support.
Key Accountabilities:
Provide Big Data Engineering support to the Media Analytics and User Experience team and Media (Network and Engineering) data customers
Lead the Media Analytics program of work to integrate video streaming data into the development of apps and websites - particularly sports and entertainment.
Drive tangible business values through actionable insights that lead to measurable improvements of the received customer experience and customers engagements
Setting benchmarks and targets for continual improvements of the customers video streaming experience
Engaging and influencing Senior Managers, Product managers, Technology managers, Operations managers, Program managers to promote Media's capabilities and aligning with corporate strategic programs;
Be a key influence in the development and production of automated reporting, recommendations on data sources, data centric platforms and tools, and contribute to the implementation of data centric applications.
Recommending and supporting best of bread Media data source identification and documentation.
You will have experience in the following:
Data validation, data access, integration and aggregation to support work of analysts, data scientist and the deployment of data centric applications and solutions
Having the ability to query databases, make data available to experimental and/or production environments and assess data suitability for performing statistical analysis
Experience working in established diverse digital ecosystems with a variety of systems, tools, limitations and stakeholders
Understanding the technologies for the delivery of online streaming video (live and on-demand). Technologies including video compression (eg: H.264, HEVC etc), adaptive bit rate streaming (eg: Microsoft Smooth streaming (MSS), Apple HTTP Live Streaming (HLS), Adobe HTTP's Dynamic Streaming (HDS), Widevine, MPEG-DASH, etc) and Content Delivery Network (CDN).
Experience in the development of OTT Video streaming services and applications.
Understanding metrics for video quality and the measurements of received customer experience for media services
Experience with dashboard and analytical tools supporting data
A working knowledge of protocols related to Internet (TCP/IP)
Knowledge of Cloud, NFV and SDN.
Knowledge of video streaming software and analytics tools e.g. Conviva (highly desirable)
Practical experience with SQL and/or non SQL storage methods and APIs
Experience in Unix / Linux, administration and scripting - Mandatory
Object orientated and procedural programming languages
R, SAS,
Python
Splunk, Hadoop and similar
To be considered for the role click the 'Apply' button or for more information about this and other opportunities please contact Jo-Ann Lim on 03 86804321. Please quote our job reference number: 200168361.
Reference Number: 200168361_5
Contact Details:
How to Apply?
Click on the link below
Click here for more information about this job
",https://www.computerworld.co.nz/jobs/view/25954/senior-big-data-engineer/
JOB118918005590,461 Associate Data Engineer Jobs,461 Associate Data Engineer Jobs,,,,https://www.ziprecruiter.com/Jobs/Associate-Data-Engineer
JOB119150846260,Automation / Mechatronics / Data Engineer,Automation / Mechatronics / Data Engineer,,, ,http://www.infomine.com/careers/jobs/automation-mechatronics-data-engineer_1664299/
JOB119562136094,HID Data Engineer,HID Data Engineer,"Expertise in Python programming (functional and object-oriented),Strong foundation in statistical analysis,Able to develop optimized pipelines for data acquisition, pruning and preprocessing; insightful data and performance visualizations and iterating over algorithm variants",,"Join the engineering team that turns sensor signals into next-generation human interfaces for AirPods, iPhone, iPad, Macs, and exciting new products. You will be part of a strong team with a wide range of backgrounds, including signal and image processing, statistics, machine learning, human factors, and firmware development. This is a role where you will design, develop and support high quality, scalable data processing platforms that enable quick algorithm development for Apple products.
Expertise in Python programming (functional and object-oriented)
Strong foundation in statistical analysis
Able to develop optimized pipelines for data acquisition, pruning and preprocessing; insightful data and performance visualizations and iterating over algorithm variants
Some exposure to developing infrastructure for large-scale data processing and annotation.
We are looking for a data engineer who can develop efficient pipelines for data processing and annotation. You will work closely with human factors and algorithm engineers to mine critical data, implement algorithm evaluation pipelines, visualize data and optimize algorithm tuning workflows. HID operates at the intersection of hardware, software, and design. That means the problems you take on will have many interesting facets, the work and challenges are dynamic, and you will get to know and collaborate with skilled, diverse people all across the company.
",https://jobs.apple.com/en-us/details/200167672/hid-data-engineer
JOB119846103566,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/ro-ro/details/200188037/ai-ml-search-data-engineer-siri-data
JOB120181074470,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/pl-pl/details/200188037/ai-ml-search-data-engineer-siri-data
JOB120630167588,"Digital Library Software Engineer – Linked Data Engineer, Stanford University Libraries","Digital Library Software Engineer – Linked Data Engineer, Stanford University Libraries","Subject to and expected to comply with all applicable University policies and procedures, including but not limited to the personnel policies and other policies found in the University’s Administrative Guide, http://adminguide.stanford.edu.","Propose, conceptualize, design, and implement solutions for difficult and complex applications independently, including both infrastructure and user-facing components.,Adapt and adopt technologies and methods from open source projects; participate in such efforts through code, process and community contributions, especially in the Cultural Heritage Linked Data environment.,Oversee testing, debugging, change control, and documentation for major projects, comprising both new development and refactoring of existing mission critical products.,Engage in strategic technical and architectural planning with a variety of stakeholders.,Define and promote complex application development administration and programming standards.,Oversee the support, maintenance, operation, and upgrades of applications.,Lead projects, as necessary, for special systems and application development in areas of complex problems.,Appropriately discuss, troubleshoot and resolve complex technical problems in a team environment.,Work with other technical professionals—both within and outside Stanford—to develop standards and implement best practices.,Promote the adoption of Linked Data technologies within the institution and broadly within the community,Previous work related to libraries, digital preservation and/or digital repositories,,Participation in large, long-running and successful open source projects,Standards, architecture and/or engineering on linked-data based systems, within or outside the library domain,Expertise in designing, developing, testing, and deploying applications, such as those based on Linked Data.,Proficiency with application design and data modeling, such as for cultural heritage domains, common library-based XML-based schema, relational database and graph-based models.,Ability to define and solve logical problems for highly technical applications.,Strong communication skills with both technical and non-technical partners.,Ability to lead activities on structured team development projects.,Ability to select, adapt, and effectively use a variety of programming methods, such as Java, Ruby / Ruby-on-Rails, Python, and X-query/XSLT.,Knowledge of library and linked data domains.,demonstrated success in engineering linked data systems at scale,demonstrated success in engineering for performance with linked data,successful leadership in open source or collaborative projects in the library or linked data domain,Ability to quickly learn and adapt to new technologies and programming tools.,Demonstrated experience in designing, developing, testing, and deploying applications, such as those based on Linked Data.,Strong understanding of data design; architecture; graph-based, XML and relational data structures; and data modeling.,Ability to define and solve logical problems for highly technical applications.,Thorough understanding of all aspects of software development life cycle and quality control practices, such as automated testing and test driven development practices.,Demonstrated experience leading technical activities on structured team development projects.,Ability to recognize and recommend needed changes in user and/or operations procesures.,Strong understanding of Ruby and Ruby on Rails.,Demonstrated experience with Linked Data patterns, data modeling and architecture,Successful participation and leadership in open source software development.,Constantly perform desk-based computer tasks.,Frequently sit, grasp lightly/fine manipulation.,Occasionally stand/walk, writing by hand.,Rarely use a telephone, lift/carry/push/pull objects that weigh up to 10 pounds.,May work extended hours, evening and weekends.,Interpersonal Skills: Demonstrates the ability to work well with Stanford colleagues and with external partner organizations.,Promote Culture of Safety: Demonstrates commitment to personal responsibility and value for safety; communicates safety concerns; uses and promotes safe behaviors based on training and lessons learned.","
Software Developer 2 / 3
Job Family: Information Technology Services
Job Series: Software Developer
Job Code: 4822 / 23
Classification Level: J / L
Exemption: Exempt
Effective/Revision Date: 04/01/2015
Job Series Matrix URL: View PDF
Formal application must happen via the Stanford HR site at https://stanford.taleo.net/careersection/mobile_stanford_external/jobdetail.ftl?job=70984&lang=en
People can contact Bess Sadler (bess@stanford.edu) for more information.
Note: Not all unique aspects of the job are covered by this job description
JOB PURPOSE:
The Digital Library Software Engineer is a member of the Digital Library Systems and Services (DLSS) team in the Stanford University Libraries. The engineer will focus on the development and maintenance of Stanford’s Digital Library, with a focus on the integration and development of systems based on Linked Open Data technologies. The role will also engage in community-based development of technologies and approaches to advance the use and integration of Linked Data into production environments. This position works in an agile development environment at Stanford, and extensively with open source and standards communities in the Web, Library and Cultural Heritage sectors, such as the LD4Star, Hydra, IIIF, and the Fedora Repository projects.
As a senior developer, the role performs difficult and complex programming and analysis work, and contributes to all phases of a project, including systems analysis, program design, development, implementation and maintenance. Stanford’s efforts on these fronts are recognized internationally, and have a major programmatic impact on the University’s operation and that of Libraries and Repositories worldwide.
CORE DUTIES*:
Propose, conceptualize, design, and implement solutions for difficult and complex applications independently, including both infrastructure and user-facing components.
Adapt and adopt technologies and methods from open source projects; participate in such efforts through code, process and community contributions, especially in the Cultural Heritage Linked Data environment.
Oversee testing, debugging, change control, and documentation for major projects, comprising both new development and refactoring of existing mission critical products.
Engage in strategic technical and architectural planning with a variety of stakeholders.
Define and promote complex application development administration and programming standards.
Oversee the support, maintenance, operation, and upgrades of applications.
Lead projects, as necessary, for special systems and application development in areas of complex problems.
Appropriately discuss, troubleshoot and resolve complex technical problems in a team environment.
Work with other technical professionals—both within and outside Stanford—to develop standards and implement best practices.
Promote the adoption of Linked Data technologies within the institution and broadly within the community
* – Other duties may also be assigned
MINIMUM REQUIREMENTS:
To qualify at Software Developer 2 level:
Education & Experience
Bachelor’s degree and five years of relevant experience, or a similar combination of education and relevant experience.
Relevant experience may include:
Previous work related to libraries, digital preservation and/or digital repositories,
Participation in large, long-running and successful open source projects
Standards, architecture and/or engineering on linked-data based systems, within or outside the library domain
Knowledge, Skills and Abilities:
Expertise in designing, developing, testing, and deploying applications, such as those based on Linked Data.
Proficiency with application design and data modeling, such as for cultural heritage domains, common library-based XML-based schema, relational database and graph-based models.
Ability to define and solve logical problems for highly technical applications.
Strong communication skills with both technical and non-technical partners.
Ability to lead activities on structured team development projects.
Ability to select, adapt, and effectively use a variety of programming methods, such as Java, Ruby / Ruby-on-Rails, Python, and X-query/XSLT.
Knowledge of library and linked data domains.
To qualify at Software Developer 3 level:
The above criteria, plus…
Education & Experience
Bachelor’s degree and eight years of relevant experience, or a similar combination of education and relevant experience.
Relevant experience may include:
demonstrated success in engineering linked data systems at scale
demonstrated success in engineering for performance with linked data
successful leadership in open source or collaborative projects in the library or linked data domain
Knowledge, Skills and Abilities:
Ability to quickly learn and adapt to new technologies and programming tools.
Demonstrated experience in designing, developing, testing, and deploying applications, such as those based on Linked Data.
Strong understanding of data design; architecture; graph-based, XML and relational data structures; and data modeling.
Ability to define and solve logical problems for highly technical applications.
Thorough understanding of all aspects of software development life cycle and quality control practices, such as automated testing and test driven development practices.
Demonstrated experience leading technical activities on structured team development projects.
Ability to recognize and recommend needed changes in user and/or operations procesures.
Relevant experience at both levels may include:
Strong understanding of Ruby and Ruby on Rails.
Demonstrated experience with Linked Data patterns, data modeling and architecture
Successful participation and leadership in open source software development.
Certifications and Licenses:
None
PHYSICAL REQUIREMENTS*:
Constantly perform desk-based computer tasks.
Frequently sit, grasp lightly/fine manipulation.
Occasionally stand/walk, writing by hand.
Rarely use a telephone, lift/carry/push/pull objects that weigh up to 10 pounds.
* – Consistent with its obligations under the law, the University will provide reasonable accommodation to any employee with a disability who requires accommodation to perform the essential functions of his or her job.
WORKING CONDITIONS:
May work extended hours, evening and weekends.
WORK STANDARDS:
Interpersonal Skills: Demonstrates the ability to work well with Stanford colleagues and with external partner organizations.
Promote Culture of Safety: Demonstrates commitment to personal responsibility and value for safety; communicates safety concerns; uses and promotes safe behaviors based on training and lessons learned.
Subject to and expected to comply with all applicable University policies and procedures, including but not limited to the personnel policies and other policies found in the University’s Administrative Guide, http://adminguide.stanford.edu.
",https://www.diglib.org/digital-library-software-engineer-linked-data-engineer-stanford-university-libraries/
JOB124248212308,"37,800 Principal Data Engineer Jobs","37,800 Principal Data Engineer Jobs",,,,https://www.ziprecruiter.com/Jobs/Principal-Data-Engineer
JOB126357848907,Data Engineer,Data Engineer,,,"
Job Description:
The Data Engineer is a technical expert and architect tasked with designing and maintaining data pipelines and systems for production level data science and analytics. This role works on the data science team to develop machine learning analytics that support decisions for the business and at the clinical point of care. Further, this position must understand existing data and infrastructure to decide whether to use existing data assets as dependencies or develop new data products to be used downstream. This role will not only develop data pipelines for managing large structured and unstructured data but also automate these workflows for continuous delivery. The data engineer will also support and contribute to rapid prototyping and deployment of analytics, model training, and model deployment. This role reports to the Director of Data Science and regularly collaborates with other departments including Business Intelligence, Actuarial, and IT.
RESPONSIBILITIES:
· Track record architecting and implementing data pipelines to support analytics delivery and persistence as data products for downstream use
· Expertise using on-demand compute tools in the cloud to efficiently analyze large and complex datasets
· Strong project management and organizational skills
· Ability to architect and implement technology projects cross-functionally with other departments including IT, BI, Finance, and Security/Privacy
· History of creating data tools for analytics and data science teams and productionalizing machine learning and analytics workloads
Must Have:
· Expertise with some or all of Spark, Python, and the PyData analytics stack (sklearn, pandas, seaborn, etc.), H2O.ai
· Experience building an optimizing “big data” data pipelines, architectures, and datasets
· Advanced SQL and database management knowledge including working with relational and non-relational databases
Requirements:
· Proficiency with Linux and bash scripting
· Proficiency with distributed systems and data processing
· Expertise with some or all of Spark, Python, and the PyData analytics stack (sklearn, pandas, seaborn, etc.), H2O.ai
· Advanced SQL and database management knowledge including working with relational and non-relational databases
· Experience building an optimizing “big data” data pipelines, architectures, and datasets
· Expertise with AWS cloud services such as EC2, EMR
· Experience with data pipeline and workflow management tools such as Airflow, Luigi, etc.
· Proficiency conducting non-trivial data transformations on real world messy datasets including building validation and alerts
· Passion for working at a healthcare organization
· Preference for experience with clinical claims and health record data
· Experience building data pipelines in the cloud under the constraints of HIPAA
",https://www.ziprecruiter.com/jobs/agile-global-solutions-af0ca96c/data-engineer-1421b5c5?mid=5902&email_send_uid=ea7da760-2327-11e9-a40d-06253eb23016&apply_method=magic5-email&source=magic5-candidate-auto-send&source_board_id=5902&auth_token=_v3_74b4ef21f529b6c0d78de5c3175cf3fbf2b58ffd936a7db96782c24726921278&contact_id=c671f373&purpose=email-click&expires=1548871795
JOB126987862987,"Big Data Engineer - Hadoop, SalesForce.com, SQL Server required","Big Data Engineer - Hadoop, SalesForce.com, SQL Server required",,," Big Data Engineer - Hadoop, SalesForce.com, SQL Server required - Berkshire - £550-£600pd
Spargonet Consulting, an IT Services Consultancy, is looking for a Big Data Engineer to help set-up a data lake for one of our customers in the Leisure Industry. This is a green field development opportunity. The ideal candidate will be able to provide thought leadership and architectural guidance. We are looking for an experienced engineer with a proven track record.
Main activities
- Help set up a data lake
- Setup Integration points from various back end systems into the data lake
- Help with the overall Big data strategy, architectural approach and Hadoop eco system tool selection
Mandatory skills :
- Big Data Engineer - Hadoop, SalesForce.com, SQL Server required
- SQL Server (2008 & 2012)
- Web/Call Analytics
- Hadoop/HDFS
- Oozie
- Sqoop
- Kafka
- Flume
- SOAP/ RESTful web services
Desired skills :
- Java
- PIG
- Spark
- Scala
- HBASE
- Cloudera
Working knowledge :
- Good to have travel industry experience
- Good working knowledge of Spark, Hive and Impala would be very beneficial
- A good knowledge of the languages Scala and Java
- Google Analytics
Spargonet Consulting Plc is a leading IT consultancy with over thirty years pedigree and experience of supplying IT services to household name blue chip clients within a range of business sectors.
By joining the personable team at Spargonet, you become a valued member of our personnel with good prospects of a rewarding and challenging opportunity.
All applications welcome for an informal and confidential discussion.
",https://www.careerjet.co.uk/clk/121359b44b6c26fa0e25d098f82fced7.html
JOB127260043818,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/no-no/details/200188037/ai-ml-search-data-engineer-siri-data
JOB128539129338,Dev/Ops/Data Engineer,Dev/Ops/Data Engineer,do NOT contact us with unsolicited services or offers,"Principals only. Recruiters, please don't contact this job poster."," This NYC-based MediaTech company is looking for a Senior DevOps engineer to join their team mobile development team. They have been at the forefront of bringing digital media to multiple technology platforms for over a decade.
This company is on the cutting edge of expanding our horizon of what we think is possible in mobile technology. Whether it's music, movies, games, live streaming video, or apps that help them keep close to the people who matter most, they thrives on giving people the fresh and entertaining experiences they deserve--whenever, wherever they want. They are looking for a DevOps engineer or any engineer who is very heavy on Data side with an ability to manipulate Spark Clusters, work with Cassandra, and has experience using a configuration management tools like Ansible/Puppet/Chef.
Required Skills & Experience
Experience in ZooKeeper;
Experience in monitoring and cluster
Good scripting abilities.
Experience in AWS
Java/Scala development
Spark Core, Spark SQL and Spark Streaming
Benefits & Perks
Collaborative team environment, growth opportunity, equity
Principals only. Recruiters, please don't contact this job poster.
do NOT contact us with unsolicited services or offers
",http://newyork.craigslist.org/mnh/eng/6065644605.html
JOB128935356967,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-my/details/200188037/ai-ml-search-data-engineer-siri-data
JOB129550290264,Lead Data Engineer,Lead Data Engineer,50+ career categories,"Find a better job, faster!,Hand-screened leads,No ads, scams, junk,Great job search support","
Lead data engineer needed for a full-time opportunity. This position will eventually involve travel. Remote during the pandemic. Will be responsible for developing modern data architecture and writing clean code. Related experience required.
Job Details
Remote - During Pandemic
Employee
Full-Time
Manager
Yes, a bit
Company name here
Other benefits listed here
Find a better job, faster!
Hand-screened leads
No ads, scams, junk
Great job search support
50+ career categories
Create an Account to Unlock
To find out more about or apply to this Lead Data Engineer job—and other great opportunities like it—become a FlexJobs member today!
With FlexJobs, you'll find the best flexible jobs and fantastic expert resources to support you in your job search. If you have any questions, please feel free to contact us.
",https://www.flexjobs.com/publicjobs/lead-data-engineer-1295971
JOB129693909966,"Data Engineer (DBMS, Oracle, SQL Server Data Analysis) AI Software","Data Engineer (DBMS, Oracle, SQL Server Data Analysis) AI Software",,,"
An innovative software company based near Sutton Coldfield are continuing their mission to grow and build an awesome team.
They love all things data and AI so they are looking for tech passionate people who want to work with the latest Machine Learning technologies and Data Platforms.
We are looking for a budding data driven technologist to step into the role of DBMS Data Engineer and begin their journey on an awesome career path with endless opportunity.
The DBMS (Oracle, MySQL, SQL Server) Data Engineer will be responsible for the migration of customer and external data as well as supporting pre-sales with data analysis. You will also be working on the enhancement and development of critical process and building tools to improve efficiency.
To be considered for the role you will need the following.
·Minimum of 2 years DBMS experience (Oracle, MySQL, SQL Server)
·Skilled programmer able to write clear and understandable PL/SQL code
·Ability to quickly learn, understand & apply new technologies
·Data Analysis experience and experience producing insights to solve business problems
·Any exposure to AWS, Docker, Postgres and Hadoop would be beneficial
There will be an opportunity for the right person to progress into Data Science role where you will be trained in using bleeding edge technology. The progression options in this role are endless so why not make the move to a company you can grow with!
The role is paying up to £40,000 with private medical, 25 days holiday, flexible working and pension.
If you would like to be considered for the DBMS (Oracle, MySQL, SQL Server) Data Engineer role then please send over your CV for immediate consideration.
",https://www.careerjet.co.uk/clk/3b5f2b2c9271ca215930da5846527cf9.html
JOB130109004665,Data Engineer,Data Engineer,,,"
Data Engineer
London
3 months
£400-£450 per day
An opportunity for a Data Engineer has arisen within a growing customer analytics agency with one of their financial services clients. As a Data Engineer you will be working as part of a fluid and dynamic organisation who are responsible for working with some of the biggest names to help further their data useage and knowledge. The ideal Data Engineer will be working to create an analytics platform in Teradata to be able to injest marketing and customer data within the financial arena.
THE ROLE
As a Data Engineer you will be working with a large financial services client to:
- Develop ETL procedures to connect internal and external data into a Teradata environment
- Creating analytical data marts for reporting and marketing teams
- Running SQL queries
- Assisting in building out the customer strategy
KEY SKILLS AND REQUIREMENTS
As a Data Engineer you will be required to be an expert in Teradata to be able to centralise their customer data. Your experience should include:
- Working within commerial Teradata Environments
- Excellent SQL exposure
- Consistent experience integrating data platforms
- Exposure to financial, banking, retail or agency environments.
HOW TO APPLY
If you are a Data Engineer looking for your next contract and are available immediately I would love to hear from you. Send your CV direct by applying to this advert.
Reference: 39652979
Bank or payment details should never be provided when applying for a job. For information on how to stay safe in your job search, visit SAFERjobs.
Report this job
",https://www.reed.co.uk/jobs/data-engineer/39652979
JOB131037092718,Data Engineer Jobs,Data Engineer Jobs,,,"
DESCRIPTION At Amazon Advertising, we are dedicated to drive measurable outcomes for brand advertisers, agencies, authors, and entrepreneurs. Our ad solutions—including sponsored, display, video, and custom ads—leverage Amazon’s innovations and insights...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
As the Data Engineer for this amazing corporate Insurance company, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL, together...
See more: Engineer jobs
As a data engineer within the exciting, new claims advanced analytics capability, you will be building big data solutions to solve some of the organization’s toughest problems and delivering significant business value. This is a really exciting time to...
See more: Engineer jobs
Data Engineer - 70,000 Job Description An AWS Partner based in Central London is looking to expand the data side of their business due to growth. They are looking for Data Engineers with significant commercial experience ingesting large quantities of data...
See more: Engineer jobs
As the Data Engineer for this amazing corporate Insurance company in the City, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
DATA ENGINEER - TEMPORARILY REMOTE 400- 450 PER DAY 3 MONTH CONTRACT EUROPE BASED As a Data Engineer you will be working heavily with Scala and Spark to improve the quality of data. THE COMPANY: You will be working for dynamic data driven company. As a...
See more: Engineer jobs
40'000- 50'000 Pension 8% Technical Progression Healthcare Holidays More Horley, Surrey Are you seeking a new challenge within a rapidly expanding Eco-Energy Tech company where you will be having huge technical autonomy in building a data preform right...
See more: Engineer jobs
Data Engineer Portsmouth and surrounding areas encouraged to apply, multiple office locations Data Engineer required for established, international business. The business is at the forefront of new technologies working with leading Government organisations...
See more: Engineer jobs
Data Engineer A brand new role has arisen for an experienced Database / BI Developer to take the next step in their career and transition into a full Data Engineer to work for one of the most recognisable NGO's in London. We are looking for someone with...
See more: Engineer jobs
Role: Data Engineer Client: Government agency (BPSS will be required) Location: Glasgow Duration: 8 Months Rate: 400 per day (outside IR35) Note: The office is based in Glasgow city centre. It is expected that the consultant would be available for physical...
See more: Engineer jobs
Data Engineer Opus are working with an excellent niche software development company in Newcastle. The company is at the forefront of their industry and due to their on-going success are now looking for a Data Engineer to take responsibility for organising...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
A leading Insurance Company are currently recruiting for a Data Engineer to join their dynamic and growing business. They are looking to hire a cross functional, highly tenacious and bright Data Engineer with a passion for functional programming. The ideal...
See more: Engineer jobs
Data Engineer- 50K Manchester Adria Solutions has an exciting opportunity for a talented Data Engineer to join our rapidly expanding client based near Manchester. The role requires you to work closely with other members of the data team and stakeholders...
See more: Engineer jobs
Data Engineer - 6 months - Ware - Hertfordshire Global FMCG is looking for an experienced Data Engineer who will play a pivotal role in operationalizing data and analytics initiatives for digital business initiatives. The bulk of the data engineer's work...
See more: Engineer jobs
We are currently recruiting a highly motivated Data Engineer, for a company who are based in London. The Data Engineer will help develop and maintain the business. The Data Engineer will be responsible for the following; Key responsibilities- - Working...
See more: Engineer jobs
Data Engineer - I am currently recruiting for a Data Engineer based in Bath. The role would be on a permanent basis and is paying 40,000 to 45,000 (There could be flex for the right candidate) PA plus a variety of excellent benefits as well as the flexibility...
See more: Engineer jobs
Data Engineer - London - 550-600 per day - 6 month contract SearchData is currently looking to recruit a Data Engineer to work on a cutting-edge DWH project in the financial services industry. As the Data Engineer your role will be to take a leadership...
See more: Engineer jobs
Data Engineer - REMOTE WORK If you are a strong Data Engineer, with experience working with Python, R and SQL then this role is ideal. I am working with a large organisation that are market leaders in their respected field. This role will report in to...
See more: Engineer jobs
Data Engineer London 55,000 - 65,000 Benefits Our client, an exciting RegTech business is looking to recruit for a Data Engineer to join their growing team. The successful candidate will be joining the artificial intelligence team, working on a brand new...
See more: Engineer jobs
An exciting opportunity for an experienced Data Engineer has arisen in Leeds. After hiring a number of new members of staff at the end of 2019, the organisation are continuing to expand due to winning more projects. Key responsibilites include: Building...
See more: Engineer jobs
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
See more: Engineer jobs
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
See more: Engineer jobs
",http://www.reed.co.uk/jobs/data-engineer/39769840
JOB131595135502,Power & Performance Data Engineer,Power & Performance Data Engineer,"Excellent programming skills in C, C++, Python or Java,Prior experience developing production software,2 years minimum experience with Linux system administration and command line tools,Strong analytical thinking,Self-motivated and able to work independently",,"Meaningful insights require a solid infrastructure that is able to scale with the large amount of data coming in. Our team is responsible for discovering such great insights from a sea of data, and our infrastructure needs innovative ideas to improve its performance and ease-of-use. Would you like to help understand the challenges of building and maintaining a large-scale analytics infrastructure? Are you excited about identifying areas for improvement and creating out-of-the-box solutions? If this describes you, we would love to hear from you!
Excellent programming skills in C, C++, Python or Java
Prior experience developing production software
2 years minimum experience with Linux system administration and command line tools
Strong analytical thinking
Self-motivated and able to work independently
Excellent spoken and written communication skills
We're looking for a motivated engineer with excellent programming, problem solving and communication skills. In this role, you will be responsible for effective provisioning, installation/configuration, operation, and maintenance of our team’s analytics infrastructure. You will enable continued innovation and progress within the infrastructure through research and development. You will help and support the execution, test and roll-out of solutions. To be successful in this role, you must have a solid software engineering background and be able to write production level code. As a member of this team, you will have the opportunity to solve challenging engineering problems across a broad range of Apple products.
",https://jobs.apple.com/en-us/details/200116510/power-performance-data-engineer
JOB132380305980,"AI/ML - Sr Data Engineer, Siri Data","AI/ML - Sr Data Engineer, Siri Data","5+ years of experience in developing ETL jobs for analyzing and processing high-volume data in Apache Hadoop ecosystem, especially with Spark,Expert knowledge of one or more object-oriented programming languages (Scala preferred),Proficient at schema design and data modeling,Experience with data tools (Jupyter Notebooks, Zeppelin...),Excellent problem-solving and analytic skills,Ability to program in several scripting languages such as Python, Perl, and Bash,Experience with workflow management tools: Oozie, Airflow, Azkaban, etc.,Experience with batch and streaming data processing,Ability to learn and research new technologies rapidly,Passion for customer privacy,Strong interpersonal skills and experience working on cross-functional projects",,"Would you like to play a critical part in the next revolution in human-computer interaction? Contribute to the advancement of a product that is redefining human-computer interaction, and work with the people who build the intelligent assistant that helps hundreds of millions of people get things done — just by asking? The vision for the Siri Data organization is to improve Siri by using data as the voice of our customers. Within this organization, the mission of the Data Platform team is to build scalable, quality, and performant data systems with the overarching goal of improving Siri quality. We’re looking for exceptional data engineers who love working with data and are passionate about customer experience. As a data engineer on the team, you will design, develop and maintain highly available and scalable data systems, while maintaining the highest degree of security and privacy. As a part of this group, you will work with one of the most exciting high-performance computing environments, with petabytes of data, billions of events a day, and have an opportunity to imagine and build products that delight our customers.
5+ years of experience in developing ETL jobs for analyzing and processing high-volume data in Apache Hadoop ecosystem, especially with Spark
Expert knowledge of one or more object-oriented programming languages (Scala preferred)
Proficient at schema design and data modeling
Experience with data tools (Jupyter Notebooks, Zeppelin...)
Excellent problem-solving and analytic skills
Ability to program in several scripting languages such as Python, Perl, and Bash
Experience with workflow management tools: Oozie, Airflow, Azkaban, etc.
Experience with batch and streaming data processing
Ability to learn and research new technologies rapidly
Passion for customer privacy
Strong interpersonal skills and experience working on cross-functional projects
Nice to have: Developed large-scale backend storage systems
You will be an integral part of the team that is in a unique position to align our quality initiatives to a singular platform. This platform allows data analysis, metric reporting, annotation, model training, and evaluation to utilize the unified data foundation to achieve consistency, quality, and efficiency. This platform also empowers our developers to perform queries into their problem space to tackle or validate the effectiveness of their code from a quality perspective. You will have experience in data analysis and data processing to design, implement, manage many large scale datasets and backend services, those data systems will be utilized by many Siri teams. Thus deep technical capabilities, strong communication skills and a knack to using hard data to triage issues is a must-have requirement. YOUR RESPONSIBILITIES INCLUDE, BUT ARE NOT LIMITED TO: - participate in instrumentation architectural reviews, collaborate with partners with specialist knowledge in data handling to review requirements & ensure instrumentation is designed correctly in a privacy-safe way - analyze and extract raw data from different sources and process (clean, transform) data - implement data storage solutions - instrument & surface data quality and pipeline metrics - work with data consumers to understand and utilize our data systems - collaborate with our quality initiative leaders to ensure the platform meets the needs, and iterate and innovate based on requirements and observations - evolve our pipelines & question the status quo
",https://jobs.apple.com/en-us/details/200124495/ai-ml-sr-data-engineer-siri-data
JOB133371609251,Senior Data Engineer,Senior Data Engineer,"Identify data sources that can add value to decision making.,Work with source system owners and analysts to understand source data, e.g. data profiling, definition and mapping.,Design and implement efficient data loads, using traditional structured data ETL techniques.,Design and implement real time and near real time data load solutions, using technologies like data streaming.,Design and implement unstructured data loads, e.g. text speech, images and video.,Design and implement load monitoring tools and procedures and perform continuous monitoring and optimising of loads.,Work with analysts and architect to design and implement effective and efficient data models using appropriate modelling techniques.,Design and implement data warehouse data models.,Design and implement data pipelines for ad hoc, unstructured and other data models.,Design and implement appropriate aggregation data structures that enhance usability of data, e.g. multi-dimensional OLAP structures, summary tables etc.,Design, implement and maintain appropriate indexing on tables to enhance speed of access.,Design and implement data models that support automated decision making and/or further analytics.,Continuously search for data elements from other sources to enhance existing data objects to supplement / enhance context.,Design and implement interfaces for data access, e.g. batch exports, real-time decision API’s etc.,Design and implement interface monitoring and management solutions to ensure availability and accuracy.,Monitor and maintain integrity of existing environment, troubleshoot technical and data issues and make appropriate changes where required.,Implement meta-data solutions that assist with understanding and managing data.,Work together with business owners, analysts and IT to maintain good data governance.,Provide technical and data related support to source system teams and external parties with whom we exchange data.,Manage data growth and usage by designing and implementing effective strategies, e.g. archiving and indexing.,Manage systems, technology and tools that enable data management and analytics.,Take ownership of own work by delivering high quality work on time.,Show initiative and be pre-active in finding opportunities to improve data and/or processes.,Take ownership of own career development by continuously improving skills, knowledge and the application thereof in designing and implementing solutions.,Positive engagement in team activities and actively contribute ideas to improve team dynamics and performance.,Stakeholder management (internal and external).,Assist in development of others, e.g. mentoring and knowledge share.,Quality control of other’s work.,Degree in information technology / mathematics / engineering / actuarial science or related discipline.,At least 5+ years in a technical data role, preferably in a formal data, data warehouse or business intelligence environment.,SQL,Data analysis,Data visualisation,Data modelling,Microsoft business intelligence data technologies (SSIS, SSAS, SQL Server),Data warehouse concepts and best practices,Financial services knowledge, specifically personal or unsecured loans,Business process monitoring and optimising,Microsoft business intelligence visualisation technologies (SSRS, Power BI),IT infrastructure, e.g. storage, networking, servers, security,Unstructured data experience,Information gathering and problem analysis,Applying professional / specialist / technical expertise,Creating and innovating,Quality & Detail orientation,Analysing",,"Senior Data Engineer
Job description
Capfin is a leading unsecured loan provider with a successful business model supported by great people with a strong culture of innovation and data driven decision making. The purpose of this role is to create business value by applying data engineering and data management disciplines to design and build data solutions that enable data driven decision support, in order to optimize business decisions and processes, as well as train and mentor more junior team members.
Requirements
Key Performance Areas:
Sourcing data
Identify data sources that can add value to decision making.
Work with source system owners and analysts to understand source data, e.g. data profiling, definition and mapping.
Loading data
Design and implement efficient data loads, using traditional structured data ETL techniques.
Design and implement real time and near real time data load solutions, using technologies like data streaming.
Design and implement unstructured data loads, e.g. text speech, images and video.
Design and implement load monitoring tools and procedures and perform continuous monitoring and optimising of loads.
Storing data
Work with analysts and architect to design and implement effective and efficient data models using appropriate modelling techniques.
Design and implement data warehouse data models.
Design and implement data pipelines for ad hoc, unstructured and other data models.
Enhancing data
Design and implement appropriate aggregation data structures that enhance usability of data, e.g. multi-dimensional OLAP structures, summary tables etc.
Design, implement and maintain appropriate indexing on tables to enhance speed of access.
Design and implement data models that support automated decision making and/or further analytics.
Continuously search for data elements from other sources to enhance existing data objects to supplement / enhance context.
Making data available
Design and implement interfaces for data access, e.g. batch exports, real-time decision API’s etc.
Design and implement interface monitoring and management solutions to ensure availability and accuracy.
Managing data
Monitor and maintain integrity of existing environment, troubleshoot technical and data issues and make appropriate changes where required.
Implement meta-data solutions that assist with understanding and managing data.
Work together with business owners, analysts and IT to maintain good data governance.
Provide technical and data related support to source system teams and external parties with whom we exchange data.
Manage data growth and usage by designing and implementing effective strategies, e.g. archiving and indexing.
Manage systems, technology and tools that enable data management and analytics.
Leadership responsibilities
Take ownership of own work by delivering high quality work on time.
Show initiative and be pre-active in finding opportunities to improve data and/or processes.
Take ownership of own career development by continuously improving skills, knowledge and the application thereof in designing and implementing solutions.
Positive engagement in team activities and actively contribute ideas to improve team dynamics and performance.
Stakeholder management (internal and external).
Assist in development of others, e.g. mentoring and knowledge share.
Quality control of other’s work.
Qualifications:
Degree in information technology / mathematics / engineering / actuarial science or related discipline.
Experience:
At least 5+ years in a technical data role, preferably in a formal data, data warehouse or business intelligence environment.
Functional Competencies:
SQL
Data analysis
Data visualisation
Data modelling
Microsoft business intelligence data technologies (SSIS, SSAS, SQL Server)
Data warehouse concepts and best practices
Financial services knowledge, specifically personal or unsecured loans
Business process monitoring and optimising
Microsoft business intelligence visualisation technologies (SSRS, Power BI)
IT infrastructure, e.g. storage, networking, servers, security
Unstructured data experience
Behavioural Competencies:
Information gathering and problem analysis
Applying professional / specialist / technical expertise
Creating and innovating
Quality & Detail orientation
Analysing
Posted on 25 Jun 13:34
",https://www.bizcommunity.com/Company/Job.aspx?cid=221357&i=369015
JOB134057756546,Senior Data Engineer,Senior Data Engineer,"Possess a bachelor's degree in Computer Science, Applied Mathematics, Engineering, or any other technology related field.","Responsible for the maintenance, improvement, cleaning, and manipulation of data in the business's operational and analytics databases.,Identification and discovery of complex data sets that align to defined use cases,Contribute to the development of data aggregation and metrics calculations,Selecting and integrating any Big Data tools and frameworks,Implementing ETL process,Monitoring performance and advising any necessary infrastructure changes,Defining data retention policies,Define and builds the data pipelines that will enable faster, better, data-informed decision-making within the business.,At least 3 years of working experience as a database engineering support personnel or a database engineering administrator within a fast-paced a complex business setting.,You will also have experience in defining and building data roadmaps, Spark, NoSQL databases, Big Data ML toolkits and good knowledge of Big Data querying tools,Demonstrate experience working with large and complex data sets as well as experience analyzing volumes of data,Experience in the creation and debugging of databases critical to the business's mission. You will have a strong working and conceptual knowledge of building and maintaining physical and logical data models and experience with Tableau, Qlik or other toolsets,Preferable experience with monitoring, disaster recovery, backup, automated testing, automated schema migration, and continuous deployment.,High level of business and commercial acumen with a demonstrated ability to interpret business requirements and deliver outputs that align with business improvement objectives.,High quality written and oral communication skills including presentation skills,Telecommunications Industry experience","
Fantastic opportunity to work close to home and work on large complex datasets. Clayton location
Melbourne
Clayton location
Contract to 15th December 2017
Your accountabilities include:
Responsible for the maintenance, improvement, cleaning, and manipulation of data in the business's operational and analytics databases.
Identification and discovery of complex data sets that align to defined use cases
Contribute to the development of data aggregation and metrics calculations
Selecting and integrating any Big Data tools and frameworks
Implementing ETL process
Monitoring performance and advising any necessary infrastructure changes
Defining data retention policies
Define and builds the data pipelines that will enable faster, better, data-informed decision-making within the business.
You will have the following skills and experience:
At least 3 years of working experience as a database engineering support personnel or a database engineering administrator within a fast-paced a complex business setting.
You will also have experience in defining and building data roadmaps, Spark, NoSQL databases, Big Data ML toolkits and good knowledge of Big Data querying tools
Demonstrate experience working with large and complex data sets as well as experience analyzing volumes of data
Experience in the creation and debugging of databases critical to the business's mission. You will have a strong working and conceptual knowledge of building and maintaining physical and logical data models and experience with Tableau, Qlik or other toolsets
Preferable experience with monitoring, disaster recovery, backup, automated testing, automated schema migration, and continuous deployment.
High level of business and commercial acumen with a demonstrated ability to interpret business requirements and deliver outputs that align with business improvement objectives.
High quality written and oral communication skills including presentation skills
Telecommunications Industry experience
Possess a bachelor's degree in Computer Science, Applied Mathematics, Engineering, or any other technology related field.
To be considered for the role click the 'Apply' button or for more information about this and other opportunities please contact Jo-Ann Lim on 03 86804321. Please quote our job reference number: 200167951.
Reference Number: 200167951_2
Contact Details:
How to Apply?
Click on the link below
Click here for more information about this job
",https://www.techworld.com.au/jobs/view/24136/senior-data-engineer/
JOB137265667054,Senior Data Engineer,Senior Data Engineer,,"Building SQL models that transform raw data into actionable insights,Managing graph-oriented workflows in Python to automate repetitive tasks,Communication with technical and non-technical audiences, and ability to translate between the domains of business problems and implementations,Team-oriented development: building modular & re-usable tools, writing maintainable code, owning technical and business documentation,Extend the Operating Model to accommodate new product offerings and support our expansion to new markets,Identify bottlenecks and improve scalability to support our growing customer base,Improve data governance and quality control to pre-empt data quality issues in critical systems.,Cultivated familiarity with Inspire’s frameworks & operating model,Delivery of high-quality pull requests, evidencing strong code standards & testing practices,High quality documentation for both technical and non-technical audiences,Comfort with self-directed project management: requiring minimal oversight to assess a problem, formulate a solution, deliver code, and document changes.,Analytical: Able to develop a keen understanding of the problem before deciding on a solution,Curious: Desire to understand the underpinnings of complex business processes in order to design the correct technical solution,Determined: Able to focus on the problem at hand and deliver a complete solution quickly.,Open minded: Incorporates new information quickly in a fast changing environment; willing to take input from others.,4+ years experience working with Python in a data intensive application,1-2 years working with Apache Spark,4+ years experience with the software development life cycle (git, Pull Requests, Code Reviews, Testing, etc),Strong SQL experience working with large complex datasets,Experience working in the energy industry,Experience working with financial data and complex financial models,Experience with Machine Learning tools and techniques, understanding how models make decisions from data,Experience with key technologies: Snowflake, dbt, Airflow,Experience at a similar scale of data processing (Multi-TB/billions of rows),Experience with containerized development using Docker, Kubernetes,Experience with technical communication to audiences of diverse backgrounds","Inspire is a clean energy technology company on a mission to transform the way consumers access clean energy and to accelerate the world’s transition to a net-zero carbon future.
We provide our customers with access to renewable energy from wind, solar, and hydro powered sources without service interruptions or costly installations at a flat, predictable monthly rate. For every year that a customer spends with Inspire Clean Energy, they have a greater impact on climate change than 10 years of strict recycling.
Our rapidly growing team of mission-driven, climate enthusiasts is passionate, innovative and committed to a better future for the planet.
POSITION SUMMARY
As a Sr. Data Engineer on our Operating Model Team, your work will help drive down costs, manage risk, accelerate growth and improve our member experience — broadening access to clean energy as we grow to new markets, and enabling new products that accelerate a net zero carbon future.
Inspire’s Operating Model is the heart and the brain of our clean energy platform — tracking and forecasting costs and revenues as the source of truth for key stakeholders across the business to make decisions about growth, optimization and strategy.
You will work closely with executive stakeholders alongside machine learning engineers and data scientists to apply sophisticated modeling techniques on a modern data stack to predict and build the future of energy usage and customer engagement.
THE SENIOR DATA ENGINEER HAS 5 MAIN RESPONSIBILITIES
Building SQL models that transform raw data into actionable insights
Managing graph-oriented workflows in Python to automate repetitive tasks
Communication with technical and non-technical audiences, and ability to translate between the domains of business problems and implementations
Team-oriented development: building modular & re-usable tools, writing maintainable code, owning technical and business documentation
Working with our Data Science and ML Engineering Team to provide high-fidelity datasets for our machine learning algorithms and assess and understand the performance of our ML Models
SOME YEAR 1 DELIVERABLES
Extend the Operating Model to accommodate new product offerings and support our expansion to new markets
Identify bottlenecks and improve scalability to support our growing customer base
Improve data governance and quality control to pre-empt data quality issues in critical systems.
Work with our Applied Modelling team to ensure quality and reliability as we introduce increasingly sophisticated machine learning algorithms into our Operating Model
SUCCESS METRICS
Cultivated familiarity with Inspire’s frameworks & operating model
Delivery of high-quality pull requests, evidencing strong code standards & testing practices
High quality documentation for both technical and non-technical audiences
Comfort with self-directed project management: requiring minimal oversight to assess a problem, formulate a solution, deliver code, and document changes.
Positive interactions with department stakeholders: guidance and input that creates business value for non-technical personnel; feedback on priorities, status, and estimates that create transparency and build trust.
DESIRED TRAITS
Analytical: Able to develop a keen understanding of the problem before deciding on a solution
Curious: Desire to understand the underpinnings of complex business processes in order to design the correct technical solution
Determined: Able to focus on the problem at hand and deliver a complete solution quickly.
Open minded: Incorporates new information quickly in a fast changing environment; willing to take input from others.
Growth Mindset: Looking for challenges and opportunities to develop new skills and acquire knowledge.
EXPERIENCE
Must Have
4+ years experience working with Python in a data intensive application
1-2 years working with Apache Spark
4+ years experience with the software development life cycle (git, Pull Requests, Code Reviews, Testing, etc)
Strong SQL experience working with large complex datasets
Proficiency working with the command line
Nice to Have
Experience working in the energy industry
Experience working with financial data and complex financial models
Experience with Machine Learning tools and techniques, understanding how models make decisions from data
Experience with key technologies: Snowflake, dbt, Airflow
Experience at a similar scale of data processing (Multi-TB/billions of rows)
Experience with containerized development using Docker, Kubernetes
Experience with technical communication to audiences of diverse backgrounds
Experience with problem solving and exploratory data analysis
Apply Now
",https://technical.ly/job/inspire-senior-data-engineer-72528/
JOB137419271692,Remote Senior Aerospace Industry Data Engineer Hot,Remote Senior Aerospace Industry Data Engineer Hot,,,"
Apply Now I'm Interested
Remote Senior Aerospace Industry Data Engineer job at VirtualVocations in Rochester MN
Description, duties, responsibilities
A security company has an open position for a Remote Senior Aerospace Industry Data Engineer.
Core Responsibilities of this position include:
Optimizing the use of Infrastructure as Code for automation of Data Ops deployments Assessing the complete landscape of Data Ops Services Developing CI/CD pipelines to manage effective changes to multiple infrastructure footprints
Qualifications Include:
May be required to travel to an office location for periodic meetings Bachelor s Degree in Engineering Computer Science or other related discipline 3+ Years of experience working with Kubernetes 2+ Years of experience working with Big Data Technologies such as Spark Kafka and Presto Experience with DevOps tools: Docker Git Continuous Integration Continuous Deployment Experience with data processing (such as Hadoop Spark Pig Hive MapReduce etc)
VirtualVocations Company Overview
The following jobs have been promoted on the Aviation Ad Network and are to be considered - current, newsworthy aviation employment information (FYI). No guarantee is made as to the accuracy, completeness or timeliness of any information, projections or opinions in announcements obtained through the promoted jobs. The information contained in this announcement is compiled for the convenience of site visitors and is accepted by the site visitor on the condition that errors or omissions are not the responsibility of Avjobs and shall not be made the basis for any claim, demand or cause of action. Please visit this companys web site for additional details and information. Please reference Avjobs when applying.
Apply Now I'm Interested
",http://www.avjobs.com/jobs/public.asp?Company=VirtualVocations&g=332E689C-99D6-410B-8CDC-B054E0FD792D&t=Remote+Senior+Aerospace+Industry+Data+Engineer&l=Rochester%2BMN
JOB138573019071,Big Data Engineer,Big Data Engineer,"NoSQL and other databases like MongoDB, Cassandra, Neo4J","design, develop or interface into new or existing data feeds, in order to manipulate and transform data into desired target architectures / applications,manage all aspects of day to day delivery in an Agile or DevOps environment,You will work with clients to identify a data transformation roadmap,Internally, you will help identify improved ways of working mentor junior and share knowledge,Strong software engineering/development background (in Java or C# or COTS Products).,Data manipulation (XML processing, customised ETL solutions) and data merging experience,Data Transformation using ETL COTS tooling.,Experience of engineering solutions to cope with Big (volume) and Fast (real/near real time) requirements,Experience developing, interfacing or designing data centric applications.,Experience of middleware integration applications, either commercial (i.e. Mulesoft) or Open Source,Experience of DevOps type operations – use of source control (GitHub, Stash), Build tools (Puppet, Jenkins, etc), continuous integration, test driven development (i.e. Cucumber, Lettuce etc),Experience of Cloud Infrastructure usage and set up,Hadoop administration, set up , security and tuning,Data ingestion,Kafka, Flume, Spark,SQL on Hadoop tools,Hawq and Greenplum,ETL tools like Pentaho, Informatica BDE, Talend,Elastic Search& SOLR"," now Location Whilst you may have any of our UK offices as a base location, you must be fully flexible in terms of assignment location, as these roles may involve periods of time away from home during the week at short notice.
Who you'll be working with The Big Data Analytics team is part of the Insights and Data Global Practice and has seen strong growth and continued success across a variety of projects and sectors. We continue to grow and need to add to our talented team with other, experienced, Big Data Analytics SME’s. We very much try to encourage a ‘leave your grade at the door’ mentality so everyone feels comfortable contributing to our innovation. We also have a great sense of community, we encourage sharing of ideas, we sponsor meet ups for your peers and have a large calendar of social events throughout the year.
If you are keen on working on some truly cutting edge programmes, learning new technologies and techniques and joining a team with like minded big data architects, engineers and analysts, then click the link below and apply now.
The focus of your role We are looking to bring in a wide range of experience and expertise across grades. If you join us, you would be involved with the full life cycle of designing and delivering modern analytical data solutions, using a wide range of Open Source and COTS products. Our projects are varied, sometimes you may be asked to help define a client’s data transformation roadmap, other times you may be rolling your sleeves up and creating some innovative solution for a complex problem.
What you'll do
You will work within or lead an engineering team to ;
design, develop or interface into new or existing data feeds, in order to manipulate and transform data into desired target architectures / applications
manage all aspects of day to day delivery in an Agile or DevOps environment
You will work with clients to identify a data transformation roadmap
Internally, you will help identify improved ways of working mentor junior and share knowledge
What you'll bring This will be dependent upon the grade, but if you can demonstrate some or all of these characteristics then we’d really like to talk to you -
Strong software engineering/development background (in Java or C# or COTS Products).
Data manipulation (XML processing, customised ETL solutions) and data merging experience
Data Transformation using ETL COTS tooling.
Experience of engineering solutions to cope with Big (volume) and Fast (real/near real time) requirements
Experience developing, interfacing or designing data centric applications.
Experience of middleware integration applications, either commercial (i.e. Mulesoft) or Open Source
Experience of DevOps type operations – use of source control (GitHub, Stash), Build tools (Puppet, Jenkins, etc), continuous integration, test driven development (i.e. Cucumber, Lettuce etc)
Experience of Cloud Infrastructure usage and set up
Any Experience of:
Hadoop ecosystem (Cloudera, Hortonworks, IBM, AWS, MicroSoft & Google)
Hadoop administration, set up , security and tuning
Data ingestion
Kafka, Flume, Spark
SQL on Hadoop tools
Hawq and Greenplum
ETL tools like Pentaho, Informatica BDE, Talend
Elastic Search& SOLR
NoSQL and other databases like MongoDB, Cassandra, Neo4J
What we'll offer you Professional development. Accelerated career progression. An environment that encourages entrepreneurial spirit. It’s all on offer at Capgemini. And although collaboration is at the core of the way we work, we also recognise individual needs with a flexible benefits package you can tailor to suit you.
Why we're different At Capgemini, we help organisations across the world become more agile, more competitive and more successful. Smart, tailored, often-groundbreaking technical solutions to complex problems are the norm. But so, too, is a culture that’s as collaborative as it is forward thinking. Working closely with each other, and with our clients, we get under the skin of businesses and to the heart of their goals. You will too.
Capgemini positively encourages applications from suitably qualified and eligible candidates regardless of sex, race, disability, age, sexual orientation, gender reassignment, religion or belief, marital status, or pregnancy and maternity. We are committed to hiring, developing and retaining the best people to deliver innovative, world-class solutions for our clients. We foster an inclusive culture that enables everyone to achieve their full potential and enjoy a fulfilling career with us. Our comprehensive flexible benefits package and lifestyle policies enable our employees to balance their individual, family and work-life needs.
",https://www.indeed.co.uk/job/Big-Data-Engineer-at-Capgemini-in-United-Kingdom-f68d7cde3c052821
JOB138997209977,Data Engineer Jobs,Data Engineer Jobs,,,"
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
Data Engineer Salary Dependent on Experience Closing Date for this application is 30/06/2020 If this position receives high volumes of applications we reserve the right to close this advert earlier than stated, so please apply early to avoid disappointment...
See more: Engineer jobs
As a data engineer within the exciting, new claims advanced analytics capability, you will be building big data solutions to solve some of the organization’s toughest problems and delivering significant business value. This is a really exciting time to...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
DATA ENGINEER - TEMPORARILY REMOTE 400- 450 PER DAY 3 MONTH CONTRACT EUROPE BASED As a Data Engineer you will be working heavily with Scala and Spark to improve the quality of data. THE COMPANY: You will be working for dynamic data driven company. As a...
See more: Engineer jobs
Data Engineer Portsmouth and surrounding areas encouraged to apply, multiple office locations Data Engineer required for established, international business. The business is at the forefront of new technologies working with leading Government organisations...
See more: Engineer jobs
Data Engineer A brand new role has arisen for an experienced Database / BI Developer to take the next step in their career and transition into a full Data Engineer to work for one of the most recognisable NGO's in London. We are looking for someone with...
See more: Engineer jobs
Data Engineer- 50K Manchester Adria Solutions has an exciting opportunity for a talented Data Engineer to join our rapidly expanding client based near Manchester. The role requires you to work closely with other members of the data team and stakeholders...
See more: Engineer jobs
We are looking for a Data Engineer to work with the Translational team, of a biopharmaceutical company, who are responsible for the development and delivery of data and analyses that turn exploratory hypotheses into actionable insights from clinical trials...
See more: Engineer jobs
40'000- 50'000 Pension 8% Technical Progression Healthcare Holidays More Horley, Surrey Are you seeking a new challenge within a rapidly expanding Eco-Energy Tech company where you will be having huge technical autonomy in building a data preform right...
See more: Engineer jobs
Vacancy: Data Engineer (INTERVIEW SLOTS 25/06/2020) Skills: Python AND Hadoop (1 Year experience minimum) AND SQL AND Leadership Education : Relevant BSc or MSc: Computer Science, Artificial Intelligence, Mathematics etc (relevant degrees accepted) Location:...
See more: Engineer jobs
Role: Data Engineer Client: Government agency (BPSS will be required) Location: Glasgow Duration: 8 Months Rate: 400 per day (outside IR35) Note: The office is based in Glasgow city centre. It is expected that the consultant would be available for physical...
See more: Engineer jobs
A leading Insurance Company are currently recruiting for a Data Engineer to join their dynamic and growing business. They are looking to hire a cross functional, highly tenacious and bright Data Engineer with a passion for functional programming. The ideal...
See more: Engineer jobs
Data Engineer - REMOTE WORK If you are a strong Data Engineer, with experience working with Python, R and SQL then this role is ideal. I am working with a large organisation that are market leaders in their respected field. This role will report in to...
See more: Engineer jobs
Data Engineer - I am currently recruiting for a Data Engineer based in Bath. The role would be on a permanent basis and is paying 40,000 to 45,000 (There could be flex for the right candidate) PA plus a variety of excellent benefits as well as the flexibility...
See more: Engineer jobs
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
See more: Engineer jobs
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
See more: Engineer jobs
Job Title: SC Data Engineer Location: Portsmouth Salary: 40k - 50k All candidates must have current SC clearance to be considered A leading Defence organisation have recently won a contract to help improve the way in which Data is rolled out to their vast...
See more: Engineer jobs
Job Description AWS DATA ENGINEER - 6 MONTHS - LONDON - OUTSIDE IR35 Key Skills Experience with functional programming and distributed systems Exposure with streaming technologies, preferably Kafka Experience with Amazon AWS platform (Athena, S3, DynamoDB...
See more: Engineer jobs
Our client in Guildford is looking for a Data Engineer to integrate data and generate models that enable their data scientists to build and assess a multitude of analytical use cases designed to optimise human decisions and manual processes across their...
See more: Engineer jobs
A large consultancy business in London is looking for a Data Engineer to integrate data and generate models that enable their data scientists to build and assess a multitude of analytical use cases designed to optimise human decisions and manual processes...
See more: Engineer jobs
Data Engineer - I am currently recruiting for a Data Engineer based in Bath. The role would be on a permanent basis and is paying 40,000 to 50,000 (There could be flex for the right candidate) PA plus a variety of excellent benefits as well as the flexibility...
See more: Engineer jobs
An exciting opportunity for an experienced Data Engineer has arisen in Leeds. After hiring a number of new members of staff at the end of 2019, the organisation are continuing to expand due to winning more projects. Key responsibilites include: Building...
See more: Engineer jobs
Data Engineer Salary Dependent on Experience Closing Date for this application is 30/06/2020 If this position receives high volumes of applications we reserve the right to close this advert earlier than stated, so please apply early to avoid disappointment...
See more: Engineer jobs
Title: Data Engineer Our client is currently looking for a Data Engineer to play a vital role in the continual development of our digital transformation strategy and earth science analytics. Candidates must have Python, R and SQL. We expect candidates...
See more: Engineer jobs
The world of Data is growing at an extremely rapid pace and the skills needed to work within this space are growing at a similar rate. Working within Data roles as a Data Engineer requires transitional skill sets, such as numerical and analytical skills...
See more: Engineer jobs
",https://www.reed.co.uk/jobs/senior-big-data-engineer/39816753?source=searchResults
JOB139572756633,BI/SQL Data Engineer,BI/SQL Data Engineer,"You are precise in thought and code.,You have serious interest in SQL and Data.,Your T-SQL Dev skills are strong – Stored Procs etc.,You do have some knowledge of SSIS – standard ETL but that’s not what drives you.,Some SSAS would be useful.",,"BI/SQL Data Engineer
Job description
Big Bank. Very cool units. They’re the people solving the complex technical issues for their quants, modellers and analytics teams.
Lots of deep SQL design and build.
Rarely using pre-packaged frameworks, often coding highly optimised SQL/T-SQL solutions.
Requirements
They’re looking for intelligent developers:
You are precise in thought and code.
You have serious interest in SQL and Data.
Your T-SQL Dev skills are strong – Stored Procs etc.
You do have some knowledge of SSIS – standard ETL but that’s not what drives you.
Some SSAS would be useful.
Any C# coding experience would be useful but not essential.
The reference number for this position is JP39451-2018 which is a permanent position based in Sandton offering a salary between 400 - 700k per annum CTC negotiable on experience.
The time for change is now! e-Merge IT recruitment are specialist niche recruiters with a wide range of positions available. We offer researched positions with top companies to strong technical candidates. Email Jason on Jason@e-merge.co.za or call him on 011 463 3633 to discuss this and other opportunities.
Check out our website www.e-merge.co.za for more positions that might be right for you!
Do you have a friend who is a technology specialist? We pay big cash to you if we place a friend that you sent us!
If you haven’t heard from e-Merge IT within two weeks of your application, please consider it unsuccessful for this position.
Posted on 11 Jan 15:46
",https://www.bizcommunity.com/Company/Job.aspx?cid=123552&i=358980
JOB139680098819,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-th/details/200188037/ai-ml-search-data-engineer-siri-data
JOB140767619618,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-be/details/200188037/ai-ml-search-data-engineer-siri-data
JOB140911713120,Data Engineer Jobs,Data Engineer Jobs,,,"
DESCRIPTION At Amazon Advertising, we are dedicated to drive measurable outcomes for brand advertisers, agencies, authors, and entrepreneurs. Our ad solutions—including sponsored, display, video, and custom ads—leverage Amazon’s innovations and insights...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
As the Data Engineer for this amazing corporate Insurance company, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL, together...
See more: Engineer jobs
As a data engineer within the exciting, new claims advanced analytics capability, you will be building big data solutions to solve some of the organization’s toughest problems and delivering significant business value. This is a really exciting time to...
See more: Engineer jobs
Data Engineer - 70,000 Job Description An AWS Partner based in Central London is looking to expand the data side of their business due to growth. They are looking for Data Engineers with significant commercial experience ingesting large quantities of data...
See more: Engineer jobs
As the Data Engineer for this amazing corporate Insurance company in the City, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
DATA ENGINEER - TEMPORARILY REMOTE 400- 450 PER DAY 3 MONTH CONTRACT EUROPE BASED As a Data Engineer you will be working heavily with Scala and Spark to improve the quality of data. THE COMPANY: You will be working for dynamic data driven company. As a...
See more: Engineer jobs
40'000- 50'000 Pension 8% Technical Progression Healthcare Holidays More Horley, Surrey Are you seeking a new challenge within a rapidly expanding Eco-Energy Tech company where you will be having huge technical autonomy in building a data preform right...
See more: Engineer jobs
Role: Data Engineer Client: Government agency (BPSS will be required) Location: Glasgow Duration: 8 Months Rate: 400 per day (outside IR35) Note: The office is based in Glasgow city centre. It is expected that the consultant would be available for physical...
See more: Engineer jobs
Data Engineer Opus are working with an excellent niche software development company in Newcastle. The company is at the forefront of their industry and due to their on-going success are now looking for a Data Engineer to take responsibility for organising...
See more: Engineer jobs
A leading Insurance Company are currently recruiting for a Data Engineer to join their dynamic and growing business. They are looking to hire a cross functional, highly tenacious and bright Data Engineer with a passion for functional programming. The ideal...
See more: Engineer jobs
Data Engineer - 6 months - Ware - Hertfordshire Global FMCG is looking for an experienced Data Engineer who will play a pivotal role in operationalizing data and analytics initiatives for digital business initiatives. The bulk of the data engineer's work...
See more: Engineer jobs
Data Engineer Portsmouth and surrounding areas encouraged to apply, multiple office locations Data Engineer required for established, international business. The business is at the forefront of new technologies working with leading Government organisations...
See more: Engineer jobs
Data Engineer A brand new role has arisen for an experienced Database / BI Developer to take the next step in their career and transition into a full Data Engineer to work for one of the most recognisable NGO's in London. We are looking for someone with...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
Data Engineer- 50K Manchester Adria Solutions has an exciting opportunity for a talented Data Engineer to join our rapidly expanding client based near Manchester. The role requires you to work closely with other members of the data team and stakeholders...
See more: Engineer jobs
We are currently recruiting a highly motivated Data Engineer, for a company who are based in London. The Data Engineer will help develop and maintain the business. The Data Engineer will be responsible for the following; Key responsibilities- - Working...
See more: Engineer jobs
Data Engineer - I am currently recruiting for a Data Engineer based in Bath. The role would be on a permanent basis and is paying 40,000 to 45,000 (There could be flex for the right candidate) PA plus a variety of excellent benefits as well as the flexibility...
See more: Engineer jobs
Data Engineer - London - 550-600 per day - 6 month contract SearchData is currently looking to recruit a Data Engineer to work on a cutting-edge DWH project in the financial services industry. As the Data Engineer your role will be to take a leadership...
See more: Engineer jobs
An exciting opportunity for an experienced Data Engineer has arisen in Leeds. After hiring a number of new members of staff at the end of 2019, the organisation are continuing to expand due to winning more projects. Key responsibilites include: Building...
See more: Engineer jobs
Data Engineer - REMOTE WORK If you are a strong Data Engineer, with experience working with Python, R and SQL then this role is ideal. I am working with a large organisation that are market leaders in their respected field. This role will report in to...
See more: Engineer jobs
Data Engineer London 55,000 - 65,000 Benefits Our client, an exciting RegTech business is looking to recruit for a Data Engineer to join their growing team. The successful candidate will be joining the artificial intelligence team, working on a brand new...
See more: Engineer jobs
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
See more: Engineer jobs
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
See more: Engineer jobs
",http://www.reed.co.uk/jobs/data-engineer/39882690
JOB141748738887,Data Engineer,Data Engineer,,,"
Data Engineer X 2 – Manchester. Our client based near Manchester are currently looking for 2 Data Engineers with Azure experience. The company is currently going through a large digital transformation, they are looking for talented Data specialist to help...
Job Title: Data Engineer Salary: 45,000 to 54,000 plus Benefits Location: Cambridge This is a very rare opportunity for an experienced Data Engineer with a strong background in building Python based data processing pipelines to join a company that are...
",https://www.reed.co.uk/jobs/data-engineer/40270394
JOB142734564196,Data Engineer Jobs,Data Engineer Jobs,,,"
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
Data Engineer Salary Dependent on Experience Closing Date for this application is 30/06/2020 If this position receives high volumes of applications we reserve the right to close this advert earlier than stated, so please apply early to avoid disappointment...
See more: Engineer jobs
As a data engineer within the exciting, new claims advanced analytics capability, you will be building big data solutions to solve some of the organization’s toughest problems and delivering significant business value. This is a really exciting time to...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
DATA ENGINEER - TEMPORARILY REMOTE 400- 450 PER DAY 3 MONTH CONTRACT EUROPE BASED As a Data Engineer you will be working heavily with Scala and Spark to improve the quality of data. THE COMPANY: You will be working for dynamic data driven company. As a...
See more: Engineer jobs
Data Engineer Portsmouth and surrounding areas encouraged to apply, multiple office locations Data Engineer required for established, international business. The business is at the forefront of new technologies working with leading Government organisations...
See more: Engineer jobs
Data Engineer A brand new role has arisen for an experienced Database / BI Developer to take the next step in their career and transition into a full Data Engineer to work for one of the most recognisable NGO's in London. We are looking for someone with...
See more: Engineer jobs
Data Engineer- 50K Manchester Adria Solutions has an exciting opportunity for a talented Data Engineer to join our rapidly expanding client based near Manchester. The role requires you to work closely with other members of the data team and stakeholders...
See more: Engineer jobs
We are looking for a Data Engineer to work with the Translational team, of a biopharmaceutical company, who are responsible for the development and delivery of data and analyses that turn exploratory hypotheses into actionable insights from clinical trials...
See more: Engineer jobs
40'000- 50'000 Pension 8% Technical Progression Healthcare Holidays More Horley, Surrey Are you seeking a new challenge within a rapidly expanding Eco-Energy Tech company where you will be having huge technical autonomy in building a data preform right...
See more: Engineer jobs
Vacancy: Data Engineer (INTERVIEW SLOTS 25/06/2020) Skills: Python AND Hadoop (1 Year experience minimum) AND SQL AND Leadership Education : Relevant BSc or MSc: Computer Science, Artificial Intelligence, Mathematics etc (relevant degrees accepted) Location:...
See more: Engineer jobs
Role: Data Engineer Client: Government agency (BPSS will be required) Location: Glasgow Duration: 8 Months Rate: 400 per day (outside IR35) Note: The office is based in Glasgow city centre. It is expected that the consultant would be available for physical...
See more: Engineer jobs
A leading Insurance Company are currently recruiting for a Data Engineer to join their dynamic and growing business. They are looking to hire a cross functional, highly tenacious and bright Data Engineer with a passion for functional programming. The ideal...
See more: Engineer jobs
Data Engineer - REMOTE WORK If you are a strong Data Engineer, with experience working with Python, R and SQL then this role is ideal. I am working with a large organisation that are market leaders in their respected field. This role will report in to...
See more: Engineer jobs
Data Engineer - I am currently recruiting for a Data Engineer based in Bath. The role would be on a permanent basis and is paying 40,000 to 45,000 (There could be flex for the right candidate) PA plus a variety of excellent benefits as well as the flexibility...
See more: Engineer jobs
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
See more: Engineer jobs
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
See more: Engineer jobs
Job Title: SC Data Engineer Location: Portsmouth Salary: 40k - 50k All candidates must have current SC clearance to be considered A leading Defence organisation have recently won a contract to help improve the way in which Data is rolled out to their vast...
See more: Engineer jobs
Job Description AWS DATA ENGINEER - 6 MONTHS - LONDON - OUTSIDE IR35 Key Skills Experience with functional programming and distributed systems Exposure with streaming technologies, preferably Kafka Experience with Amazon AWS platform (Athena, S3, DynamoDB...
See more: Engineer jobs
Our client in Guildford is looking for a Data Engineer to integrate data and generate models that enable their data scientists to build and assess a multitude of analytical use cases designed to optimise human decisions and manual processes across their...
See more: Engineer jobs
A large consultancy business in London is looking for a Data Engineer to integrate data and generate models that enable their data scientists to build and assess a multitude of analytical use cases designed to optimise human decisions and manual processes...
See more: Engineer jobs
Data Engineer - I am currently recruiting for a Data Engineer based in Bath. The role would be on a permanent basis and is paying 40,000 to 50,000 (There could be flex for the right candidate) PA plus a variety of excellent benefits as well as the flexibility...
See more: Engineer jobs
An exciting opportunity for an experienced Data Engineer has arisen in Leeds. After hiring a number of new members of staff at the end of 2019, the organisation are continuing to expand due to winning more projects. Key responsibilites include: Building...
See more: Engineer jobs
Data Engineer Salary Dependent on Experience Closing Date for this application is 30/06/2020 If this position receives high volumes of applications we reserve the right to close this advert earlier than stated, so please apply early to avoid disappointment...
See more: Engineer jobs
Title: Data Engineer Our client is currently looking for a Data Engineer to play a vital role in the continual development of our digital transformation strategy and earth science analytics. Candidates must have Python, R and SQL. We expect candidates...
See more: Engineer jobs
The world of Data is growing at an extremely rapid pace and the skills needed to work within this space are growing at a similar rate. Working within Data roles as a Data Engineer requires transitional skill sets, such as numerical and analytical skills...
See more: Engineer jobs
",https://www.reed.co.uk/jobs/senior-big-data-engineer/39816751?source=searchResults
JOB142762525528,"How Much Do Remote Data Engineer Jobs Pay per Year in Hartford, CT?","How Much Do Remote Data Engineer Jobs Pay per Year in Hartford, CT?",,,"
","https://www.ziprecruiter.com/Jobs/Remote-Data-Engineer/-in-Hartford,CT"
JOB142899714938,Data Engineer,Data Engineer,,,"
Data Engineer X 2 – Manchester. Our client based near Manchester are currently looking for 2 Data Engineers with Azure experience. The company is currently going through a large digital transformation, they are looking for talented Data specialist to help...
Job Title: Data Engineer Salary: 45,000 to 54,000 plus Benefits Location: Cambridge This is a very rare opportunity for an experienced Data Engineer with a strong background in building Python based data processing pipelines to join a company that are...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
As a data engineer within the exciting, new claims advanced analytics capability, you will be building big data solutions to solve some of the organization’s toughest problems and delivering significant business value. This is a really exciting time to...
Data Engineer - 70,000 Job Description An AWS Partner based in Central London is looking to expand the data side of their business due to growth. They are looking for Data Engineers with significant commercial experience ingesting large quantities of data...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Title: Data Engineer Our client is currently looking for a Data Engineer to play a vital role in the continual development of our digital transformation strategy and earth science analytics. Candidates must have Python, R and SQL. We expect candidates...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer - Python - Permanent Data Idols are working with a well-known client in the e-commerce space who are looking for a Data Engineer to join an existing team. THE ROLE As a Data Engineer, you will be working with the existing Data team to help...
Data Engineer - Manchester A growing business based in Manchester City Centre are currently looking for a Data Engineer to help shape their newly formed Data Engineering team and build scalable, reliable and secure cloud datawarehouse solutions and data...
An exciting start up Fintech company has a new opportunity for a Data Engineer where you will play an active part in the success of the company. This role will see you joining a small team where you'll have the opportunity to take responsibility for Data...
Data Engineer Location: Petersfield Salary: 30,000 - 40,000 P/A Hours: Flexible Dynamite Recruitment is delighted to be recruiting a Data Engineer for a global organisation in Petersfield This is an exciting opportunity for an experienced individual to...
Job title : Data Engineer Location: London Job type: Permanent Salary: Up to 70,000 per annum Reporting to: Head of Data Engineering Overview A fantastic internet company based in Central London are currently looking for a Data Engineer to come on board...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer- 50K Manchester Adria Solutions has an exciting opportunity for a talented Data Engineer to join our rapidly expanding client based near Manchester. The role requires you to work closely with other members of the data team and stakeholders...
Data Engineer / Data Scientist / Biomedical Informatics / Human Genetics / Python / SQL / R / Oxford / Cambridge / Permanent 60 - 90K (Depending on Experience) Excellent Benefits COVID Safe Interview Process 100% Remote during Covid and up to 50% Post...
Data Engineer London 80,000 - 90,000 Benefits This Data Engineering role will allow you to expand and utilise your skills in a growing team working along side one of the largest data sets in the UK. The Company As a global leader they generate tons of...
Data Engineer (12-month Fixed Term Contract) 50,000 - 55,000 We are looking for a Data Engineer to join a market leading business we're representing, based in central London. Working as part of the central Data Science & Analytics team, you will be...
",https://www.reed.co.uk/jobs/data-engineer/40286525
JOB143606180380,Apple Music - Senior Software Data Engineer,Apple Music - Senior Software Data Engineer,"Expert in designing, implementing and supporting highly scalable data systems and services in Java and/or Scala,Extensive experience with Hadoop-ecosystem technologies in particular MapReduce, Spark / Spark-SQL / Spark Streaming, Hive, YARN/MR2,Expertise building and running large-scale data pipelines, including distributed messaging such as Kafka, data ingest to/from multiple sources to feed batch and near-realtime/streaming compute components,Experience in data-modeling and data-architecture optimized for big data patterns, ie. warehousing concepts; efficient storage and query on HDFS; data security and privacy techniques),Knowledgable about distributed storage and network resources, at the level of hosts, clusters and DCs, to troubleshoot and prevent performance issues",,"This team is more than a group of engineers — it’s a group of music lovers. That passion has made Apple Music the world’s most complete music experience, with over 60 million songs, thousands of playlists, and daily selections from music experts for 115 countries. The team’s data-driven engineers focus relentlessly on the customer experience by running worldwide experiments and analyzing usage and latency, while collaborating with Apple’s product groups. As a result, someone can use the Shazam app to identify an intriguing song in a café in the morning, add it to their playlist from Apple Watch, listen to it through their AirPods on their commute, and share it with their family on HomePod at dinnertime. And there’s more where that came from, because personalization powered by machine learning and music science helps listeners discover more of what they love. Apple Music is a big part of Apple’s business because it’s a big part of people’s lives. Areas of work: macOS/iOS Engineering, Full-Stack Engineering, Front-End Engineering, Back-End Engineering, Quality Engineering, Machine Learning Engineering, Data Science, Data Engineering, Site Reliability Engineering, Commerce Engineering, and Engineering Project Management.
Expert in designing, implementing and supporting highly scalable data systems and services in Java and/or Scala
Extensive experience with Hadoop-ecosystem technologies in particular MapReduce, Spark / Spark-SQL / Spark Streaming, Hive, YARN/MR2
Expertise building and running large-scale data pipelines, including distributed messaging such as Kafka, data ingest to/from multiple sources to feed batch and near-realtime/streaming compute components
Experience in data-modeling and data-architecture optimized for big data patterns, ie. warehousing concepts; efficient storage and query on HDFS; data security and privacy techniques)
Knowledgable about distributed storage and network resources, at the level of hosts, clusters and DCs, to troubleshoot and prevent performance issues
Experience with low-latency NoSQL datastores and traditional relational databases is desired
Our Data Engineering team is seeking a hardworking, performance-savvy, experienced engineer to build out the big data platform and services, which power many of these customer features — existing and new. You will be responsible for designing and implementing features that rely on processing and serving very large datasets with an awareness of scalability. This will include crafting systems to model, ingest, process and compute large-scale, mission-critical data across Apple Music. High-throughput and reliability are essential.
Bachelors degree in Computer Science, or equivalent experience. We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.
",https://jobs.apple.com/en-us/details/200166454/apple-music-senior-software-data-engineer
JOB144500477263,Data Engineer,Data Engineer,,,"
Remote position will help drive the optimization, testing/tooling to improve data quality, write, debug/test ETL processes for data pipelines, write/maintain database design, and create new data models. Must have three years of experience.
",https://www.flexjobs.com/publicjobs/data-engineer-1185728
JOB144971039603,Data Engineer (Sports Analytics),Data Engineer (Sports Analytics),,," Job Description
Data Engineer (Sports Analytics)
If you are a Data Engineer (Sports Analytics) with experience, please read on!
What You Will Be Doing
- Help make an impact within the world of sports betting
- Architect and implement data pipelines
- Build a cloud-based workflow which makes deploying, updating, and debugging models easy
- Work closely with data scientists and develop production models
What You Need for this Position
- A love for sports
- Bachelors or Masters Degree in Computer Science, Statistics or related field
- Proficient in Python
- Significant experience in building and maintaining relational databases
- An understanding of statistics and the ability to work with statisticians
- Experience working in a cloud-based ecosystem
Nice to have:
- Sports analytics experience
What's In It for You
- Competitive comp + benefits + equity!
- Relocation!
- Flexible Schedule!
- Great team and culture!
- Surround yourself with sports!
So, if you are a Data Engineer (Sports Analytics) with experience, please apply today!
-
Applicants must be authorized to work in the U.S.
CyberCoders, Inc is proud to be an Equal Opportunity Employer
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.
Your Right to Work – In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.
","https://www.ziprecruiter.com/c/CyberCoders/Job/Data-Engineer-(Sports-Analytics)/-in-Washington,DC?jid=DQ0a7fcc07b730118b67be32d8b2512d61&job_id=6c8bd152b984c8718b5a2ab9c982c2f7"
JOB145247152641,Maps POI Senior Data Engineer,Maps POI Senior Data Engineer,"10+ years of software engineering experience,A track record of making a difference in past projects,Naturally accountable, responsible, self motivated and self sufficient,Experience designing distributed systems/services for scale,Experience working with: Cassandra, SOLR, Spark, Hadoop, Kafka and similar technologies in production contexts at scale,Preference for experience with Scala, Python,Apple’s most important resource, our soul, is our people. Apple benefits help further the well-being of our employees and their families in meaningful ways. No matter where you work at Apple, you can take advantage of our health and wellness resources and time-away programmes. We’re proud to provide stock grants to employees at all levels of the company, and we also give employees the option to buy Apple stock at a discount — both offer everyone at Apple the chance to share in the company’s success. You’ll discover many more benefits of working at Apple, such as programmes that match your charitable contributions, reimburse you for continuing your education and give you special employee pricing on Apple products.,Apple benefits programmes vary by country and are subject to eligibility requirements.",,"The Apple Maps Places of Interest (POI) team is looking for a great hands-on Senior Engineering Manager. You will be joining the team builds the platform to process, curate, and manage the POI data that is used in Maps. POI is a key pillar of the overall Maps experience so you will directly impact the success and future of the Maps product and beyond.
10+ years of software engineering experience
A track record of making a difference in past projects
Naturally accountable, responsible, self motivated and self sufficient
Experience designing distributed systems/services for scale
Experience working with: Cassandra, SOLR, Spark, Hadoop, Kafka and similar technologies in production contexts at scale
Preference for experience with Scala, Python
Experience with designing, implementing, and operating large scale data processing pipelines
The POI platform is used by a wide variety of different teams within Apple beyond just the Maps team. Good accuracy, coverage, and richness of the POI data is what ensures a good user experience for Maps. This is a challenging problem as POI data is constantly evolving. In addition to the volatility of the data, the mapping space is growing with new and exciting features being planned continuously. The Maps team is looking for software engineers that can thrive in this type of fast-paced environment where both individual drive and team collaboration are keys to success. You will be expected to thoroughly understand the systems and their interdependencies, in order to effectively evaluate asks and push back and/or suggest alternatives. In addition to solid technical skills, candidates must also have: - Strong interpersonal and communication skills - Be self-starters with a strong sense of personal responsibility and ownership - Comfortable with unknowns and have a “learner’s” mindset Finally, you will be helping to care for a system that serves the passions and needs of millions of customers, so we're looking for somebody who can be equally hardworking!
Apple’s most important resource, our soul, is our people. Apple benefits help further the well-being of our employees and their families in meaningful ways. No matter where you work at Apple, you can take advantage of our health and wellness resources and time-away programmes. We’re proud to provide stock grants to employees at all levels of the company, and we also give employees the option to buy Apple stock at a discount — both offer everyone at Apple the chance to share in the company’s success. You’ll discover many more benefits of working at Apple, such as programmes that match your charitable contributions, reimburse you for continuing your education and give you special employee pricing on Apple products.
Apple benefits programmes vary by country and are subject to eligibility requirements.
Apple is an equal opportunity employer that is committed to inclusion and diversity. We take affirmative action to ensure equal opportunity for all applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, Veteran status, or other legally protected characteristics. Apple is committed to working with and providing reasonable accommodation to applicants with physical and mental disabilities. Apple is a drug-free workplace
",https://jobs.apple.com/en-us/details/200169164/maps-poi-senior-data-engineer
JOB145415793207,Data Engineer/ Software Engineer - Zurich Vision Lab,Data Engineer/ Software Engineer - Zurich Vision Lab,"High-level understanding as well as hands-on experience in implementing data pipelines,Proficient in scripting and/or functional programming languages such as Python, Scala, Bash, Groovy, Ruby,Experience with database, message queueing, and data streaming solutions (for instance: PostgreSQL, AWS RDS, Apache Kafka, AWS Kinesis, RabbitMQ, Redis, Apache Spark, or similar tools),Experience in (regression) testing data pipelines,Experience with DevOps and application monitoring tools is a plus (for instance: Docker, Kubernetes, Terraform, CloudFormation, Ansible, Chef, Puppet, Salt, Splunk, Elastic/ELK Stack, Sentry, Datadog, or similar tools),Knowledge of Machine Learning and Computer Vision is a plus",,"Data Engineer/ Software Engineer - Zurich Vision Lab
Our team is focused on real-time computer vision and image processing, combining modern machine learning approaches with geometric knowledge from Computer Vision. In the context of machine learning we need to collect large amounts of data, push it reliably through data processing pipelines, let large clouds crunch on it, continuously verify and report the accuracy of the resulting algorithms, and finally transfer trained models to products. We are working on the groundbreaking of academic research while creating shipping features, such as portrait mode, ARKit and Animoji. We are looking for a talented person who feels eager to act both, as a Software Engineer as well as Data Engineer, to shape the future of our data pipelines. You will be working in a diverse, fast moving team based in Zürich and will interact regularly with teams based in Cupertino, USA.
High-level understanding as well as hands-on experience in implementing data pipelines
Proficient in scripting and/or functional programming languages such as Python, Scala, Bash, Groovy, Ruby
Experience with database, message queueing, and data streaming solutions (for instance: PostgreSQL, AWS RDS, Apache Kafka, AWS Kinesis, RabbitMQ, Redis, Apache Spark, or similar tools)
Experience in (regression) testing data pipelines
Experience with DevOps and application monitoring tools is a plus (for instance: Docker, Kubernetes, Terraform, CloudFormation, Ansible, Chef, Puppet, Salt, Splunk, Elastic/ELK Stack, Sentry, Datadog, or similar tools)
Knowledge of Machine Learning and Computer Vision is a plus
Knowledge of Mac and Linux environments is a plus
You will be working on data pipelines to support the development of the next generation video and image analysis projects in our computer vision research. Our work is focused on real time performance and finds its way into the whole range of future apple products. Your contribution will ensure that Apple delivers these products with the highest quality.
",https://jobs.apple.com/en-us/details/200158822/data-engineer-software-engineer-zurich-vision-lab
JOB145568537552,Data Engineer,Data Engineer,"Bachelor’s degree or higher in a quantitative/technical field (Computer Science, Statistics, Engineering),Minimum two years work experience in related field required,Working knowledge of data design, architecture and warehousing,Understanding of data management fundamentals and data storage principles,Knowledge of distributed systems as it pertains to data storage and cloud computing,Understanding and administration of AWS, Docker and Linux-based systems,Experience in custom ETL design, implementation and maintenance,Experience in large scale data processing using traditional and distributed systems like Hadoop, Spark, Dataflow, and Airflow.,Knowledge and practical experience in machine learning and AI fundamentals,Experience implementing machine learning solutions at scale,Experience working with both Batch and Real Time data processing systems,Ability to work and communicate effectively with stakeholders.,Opportunity to work with one of the fastest-growing financial startups in the country,Competitive Salary + Equity,401k with Company Match,Gym + Public Transportation Subsidy,Student Loan Assistance,Relocation Assistance,Unlimited PTO","Analyze and resolve complex challenges around data and tools. Optimize analytical workflows by identifying opportunities and automating them,Implement solutions to bring together application data generated by distributed systems, third-party data, and real-time user data needed to make key business decisions,Work within the Data Science team to serve machine learning solutions at scale,Work on projects of growing responsibility, both individually and as part of a team, to build experience and skills at a pace matched to your shown ability","Nearly half of U.S. households struggle to handle an unexpected expense of $400 or more. When it comes to managing household expenses, things like a broken appliance or a growing family can be financially burdensome. Ranked 5th on Inc. Magazine’s 2019 list of fastest-growing private companies in the United States, our team is on a mission to make life’s purchases more accessible and affordable.
Located in the heart of vibrant Philadelphia, we’re building a FinTech-enabled e-commerce marketplace that combines quality brands with sensible financing to improve the lives of our neighbors and communities.
We are searching for a Data Engineer who is a quantitative, critical thinker with a passion for data and the capacity to work in a fast-paced, entrepreneurial environment. We are looking for an individual who desires experience in serving data-driven solutions at scale, crossing multiple functional areas and driving organizational efficiency. Applicants should be highly motivated and comfortable with taking on and adapting to a diverse array of subject matter. This opportunity is both unique and pivotal, as it provides the chance to contribute greatly to a rapidly-growing team.
Initial Responsibilities:
Analyze and resolve complex challenges around data and tools. Optimize analytical workflows by identifying opportunities and automating them
Implement solutions to bring together application data generated by distributed systems, third-party data, and real-time user data needed to make key business decisions
Work within the Data Science team to serve machine learning solutions at scale
Work on projects of growing responsibility, both individually and as part of a team, to build experience and skills at a pace matched to your shown ability
Learn more about the industry and Perpay, establishing a solid foundation to be better positioned for long-term career success
Basic Qualifications:
Bachelor’s degree or higher in a quantitative/technical field (Computer Science, Statistics, Engineering)
Minimum two years work experience in related field required
Working knowledge of data design, architecture and warehousing
Understanding of data management fundamentals and data storage principles
Knowledge of distributed systems as it pertains to data storage and cloud computing
Understanding and administration of AWS, Docker and Linux-based systems
Experience in custom ETL design, implementation and maintenance
Experience in large scale data processing using traditional and distributed systems like Hadoop, Spark, Dataflow, and Airflow.
Strong working knowledge of SQL/NoSQL, relational databases and Python is required (2+ years experience)
Preferred Qualifications:
Knowledge and practical experience in machine learning and AI fundamentals
Experience implementing machine learning solutions at scale
Experience working with both Batch and Real Time data processing systems
Ability to work and communicate effectively with stakeholders.
Effective project management, problem solving, analytical and troubleshooting skills.
What We Offer:
Opportunity to work with one of the fastest-growing financial startups in the country
Competitive Salary + Equity
401k with Company Match
Health / Dental / Vision Insurance
Additional Perks:
Gym + Public Transportation Subsidy
Student Loan Assistance
Relocation Assistance
Unlimited PTO
We’re excited to move into our brand new home at 2400 Market St. in early 2021. Currently under construction, our new office will incorporate all the best aspects of our first home (espresso bar, full kitchen, work/lounge space) in a riverfront setting with iconic Philadelphia Art Museum views. We can’t wait to make our new space in Center City’s vibrant Fitler Square neighborhood our own and we’re looking for passionate & motivated folks to help us grow into it together.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.
We don’t work with recruiters – please contact us or apply directly.
Apply Now
",https://technical.ly/?p=43555
JOB146160261969,Data Engineer Jobs,Data Engineer Jobs,,,"
DESCRIPTION At Amazon Advertising, we are dedicated to drive measurable outcomes for brand advertisers, agencies, authors, and entrepreneurs. Our ad solutions—including sponsored, display, video, and custom ads—leverage Amazon’s innovations and insights...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
As the Data Engineer for this amazing corporate Insurance company, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL, together...
See more: Engineer jobs
As a data engineer within the exciting, new claims advanced analytics capability, you will be building big data solutions to solve some of the organization’s toughest problems and delivering significant business value. This is a really exciting time to...
See more: Engineer jobs
Data Engineer - 70,000 Job Description An AWS Partner based in Central London is looking to expand the data side of their business due to growth. They are looking for Data Engineers with significant commercial experience ingesting large quantities of data...
See more: Engineer jobs
As the Data Engineer for this amazing corporate Insurance company in the City, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
DATA ENGINEER - TEMPORARILY REMOTE 400- 450 PER DAY 3 MONTH CONTRACT EUROPE BASED As a Data Engineer you will be working heavily with Scala and Spark to improve the quality of data. THE COMPANY: You will be working for dynamic data driven company. As a...
See more: Engineer jobs
We are looking for a Data Engineer to work with the Translational team, of a biopharmaceutical company, who are responsible for the development and delivery of data and analyses that turn exploratory hypotheses into actionable insights from clinical trials...
See more: Engineer jobs
40'000- 50'000 Pension 8% Technical Progression Healthcare Holidays More Horley, Surrey Are you seeking a new challenge within a rapidly expanding Eco-Energy Tech company where you will be having huge technical autonomy in building a data preform right...
See more: Engineer jobs
Role: Data Engineer Client: Government agency (BPSS will be required) Location: Glasgow Duration: 8 Months Rate: 400 per day (outside IR35) Note: The office is based in Glasgow city centre. It is expected that the consultant would be available for physical...
See more: Engineer jobs
A leading Insurance Company are currently recruiting for a Data Engineer to join their dynamic and growing business. They are looking to hire a cross functional, highly tenacious and bright Data Engineer with a passion for functional programming. The ideal...
See more: Engineer jobs
Data Engineer - 6 months - Ware - Hertfordshire Global FMCG is looking for an experienced Data Engineer who will play a pivotal role in operationalizing data and analytics initiatives for digital business initiatives. The bulk of the data engineer's work...
See more: Engineer jobs
Data Engineer - I am currently recruiting for a Data Engineer based in Bath. The role would be on a permanent basis and is paying 40,000 to 45,000 (There could be flex for the right candidate) PA plus a variety of excellent benefits as well as the flexibility...
See more: Engineer jobs
Data Engineer Portsmouth and surrounding areas encouraged to apply, multiple office locations Data Engineer required for established, international business. The business is at the forefront of new technologies working with leading Government organisations...
See more: Engineer jobs
Data Engineer A brand new role has arisen for an experienced Database / BI Developer to take the next step in their career and transition into a full Data Engineer to work for one of the most recognisable NGO's in London. We are looking for someone with...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
Data Engineer- 50K Manchester Adria Solutions has an exciting opportunity for a talented Data Engineer to join our rapidly expanding client based near Manchester. The role requires you to work closely with other members of the data team and stakeholders...
See more: Engineer jobs
An exciting opportunity for an experienced Data Engineer has arisen in Leeds. After hiring a number of new members of staff at the end of 2019, the organisation are continuing to expand due to winning more projects. Key responsibilites include: Building...
See more: Engineer jobs
Vacancy: Data Engineer (INTERVIEW SLOTS 25/06/2020) Skills: Python AND Hadoop (1 Year experience minimum) AND SQL AND Leadership Education : Relevant BSc or MSc: Computer Science, Artificial Intelligence, Mathematics etc (relevant degrees accepted) Location:...
See more: Engineer jobs
Data Engineer - REMOTE WORK If you are a strong Data Engineer, with experience working with Python, R and SQL then this role is ideal. I am working with a large organisation that are market leaders in their respected field. This role will report in to...
See more: Engineer jobs
Data Engineer London 55,000 - 65,000 Benefits Our client, an exciting RegTech business is looking to recruit for a Data Engineer to join their growing team. The successful candidate will be joining the artificial intelligence team, working on a brand new...
See more: Engineer jobs
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
See more: Engineer jobs
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
See more: Engineer jobs
Job Description AWS DATA ENGINEER - 6 MONTHS - LONDON - OUTSIDE IR35 Key Skills Experience with functional programming and distributed systems Exposure with streaming technologies, preferably Kafka Experience with Amazon AWS platform (Athena, S3, DynamoDB...
See more: Engineer jobs
Our client in Guildford is looking for a Data Engineer to integrate data and generate models that enable their data scientists to build and assess a multitude of analytical use cases designed to optimise human decisions and manual processes across their...
See more: Engineer jobs
A large consultancy business in London is looking for a Data Engineer to integrate data and generate models that enable their data scientists to build and assess a multitude of analytical use cases designed to optimise human decisions and manual processes...
See more: Engineer jobs
",http://www.reed.co.uk/jobs/aws-devops-data-engineer/39915797
JOB146432547347,Data Engineer - 70988BR,Data Engineer - 70988BR,,,"
This job has expired
Job Description
Participates in the design, build and management of large scale data structures and pipelines and efficient Extract/Load/Transform (ETL) workflows.
Fundamental Components
Assists in the development of large scale data structures and pipelines to organize, collect and standardize data that helps generate insights and addresses reporting needs. Applies understanding of key business drivers to accomplish own work. Uses expertise, judgment and precedents to contribute to the resolution of moderately complex problems. Leads portions of initiatives of limited scope, with guidance and direction. Writes ETL (Extract / Transform / Load) processes, designs database systems and develops tools for real-time and offline analytic processing. Collaborates with client team to transform data and integrate algorithms and models into automated processes. Uses knowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries to build data pipelines. Uses programming skills in Python, Java or any of the major languages to build robust data pipelines and dynamic systems. Builds data marts and data models to support clients and other internal customers. Integrates data from a variety of sources, assuring that they adhere to data quality and accessibility standards.
Background Experience
Strong problem solving skills and critical thinking ability.Strong collaboration and communication skills within and across teams.3 or more years of progressively complex related experience.Ability to leverage multiple tools and programming languages to analyze and manipulate data sets from disparate data sources.Ability to understand complex systems and solve challenging analytical problems.Experience with bash shell scripts, UNIX utilities & UNIX Commands.Knowledge in Java, Python, Hive, Cassandra, Pig, MySQL or NoSQL or similar.Knowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries against data in the HDFS environment.Experience building data transformation and processing solutions.Has strong knowledge of large scale search applications and building high volume data pipelines. Master's degree or PhD preferred.Bachelor's degree or equivalent work experience in Computer Science, Engineering, Machine Learning, or related discipline.
Education
Master's degree
Percent of Travel Required
0 - 10%
Business Overview
Aetna, a CVS Health company, we are joined in a common purpose: helping people on their path to better health. We are working to transform health care through innovations that make quality care more accessible, easier to use, less expensive and patient-focused. Working together and organizing around the individual, we are pioneering a new approach to total health that puts people at the heart.
We are committed to maintaining a diverse and inclusive workplace. CVS Health is an equal opportunity and affirmative action employer. We do not discriminate in recruiting, hiring or promotion based on race, ethnicity, gender, gender identity, age, disability or protected veteran status. We proudly support and encourage people with military experience (active, veterans, reservists and National Guard) as well as military spouses to apply for CVS Health job opportunities.
",https://www.gettinghired.com/job-details/1645720/data-engineer-70988br/
JOB146534312455,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-sa/details/200188037/ai-ml-search-data-engineer-siri-data
JOB146585099106,Data Engineer Jobs,Data Engineer Jobs,,,"
DESCRIPTION At Amazon Advertising, we are dedicated to drive measurable outcomes for brand advertisers, agencies, authors, and entrepreneurs. Our ad solutions—including sponsored, display, video, and custom ads—leverage Amazon’s innovations and insights...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
As the Data Engineer for this amazing corporate Insurance company, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL, together...
See more: Engineer jobs
As the Data Engineer for this amazing corporate Insurance company in the City, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL...
See more: Engineer jobs
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
See more: Engineer jobs
As a data engineer within the exciting, new claims advanced analytics capability, you will be building big data solutions to solve some of the organization’s toughest problems and delivering significant business value. This is a really exciting time to...
See more: Engineer jobs
Data Engineer - 70,000 Job Description An AWS Partner based in Central London is looking to expand the data side of their business due to growth. They are looking for Data Engineers with significant commercial experience ingesting large quantities of data...
See more: Engineer jobs
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
See more: Engineer jobs
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
See more: Engineer jobs
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
Data Engineer - Python - Permanent Data Idols are working with a well-known client in the e-commerce space who are looking for a Data Engineer to join an existing team. THE ROLE As a Data Engineer, you will be working with the existing Data team to help...
See more: Engineer jobs
Job title : Data Engineer Location: London Job type: Permanent Salary: Up to 70,000 per annum Reporting to: Head of Data Engineering Overview A fantastic internet company based in Central London are currently looking for a Data Engineer to come on board...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
Data Engineer- 50K Manchester Adria Solutions has an exciting opportunity for a talented Data Engineer to join our rapidly expanding client based near Manchester. The role requires you to work closely with other members of the data team and stakeholders...
See more: Engineer jobs
Data Engineer- 50K Manchester Adria Solutions has an exciting opportunity for a talented Data Engineer to join our rapidly expanding client based near Manchester. The role requires you to work closely with other members of the data team and stakeholders...
See more: Engineer jobs
DATA ENGINEER - TEMPORARILY REMOTE 400- 450 PER DAY 3 MONTH CONTRACT EUROPE BASED As a Data Engineer you will be working heavily with Scala and Spark to improve the quality of data. THE COMPANY: You will be working for dynamic data driven company. As a...
See more: Engineer jobs
Data Engineer - London - 550-600 per day - 6 month contract SearchData is currently looking to recruit a Data Engineer to work on a cutting-edge DWH project in the financial services industry. As the Data Engineer your role will be to take a leadership...
See more: Engineer jobs
Job title: Data Engineer Location : Zurich. Switzerland Job type : Contract Data Engineer with Hadoop/Apache Sparc Knowledge - - Build a data processing layer based on Hadoop,Spark, Neo4J - Ensure appropriate security processes are integrated with access...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
Data Engineer Location: Petersfield Salary: 30,000 - 40,000 P/A Hours: Flexible Dynamite Recruitment is delighted to be recruiting a Data Engineer for a global organisation in Petersfield This is an exciting opportunity for an experienced individual to...
See more: Engineer jobs
Data Engineer - REMOTE WORK If you are a strong Data Engineer, with experience working with Python, R and SQL then this role is ideal. I am working with a large organisation that are market leaders in their respected field. This role will report in to...
See more: Engineer jobs
",http://www.reed.co.uk/jobs/data-engineer/40061308
JOB146777119560,Big Data Engineer Internet of Things,Big Data Engineer Internet of Things,,"Scala OR Python | Spark, Cassandra, Kafka, AWS,Data Engineering - the development of a petabyte scale Big Data platform and data pipelines/ETL, primarily using Spark, Cassandra and Kafka, programming in either Scala or Python,Back-end Software Development - building the back end of the Data Science product,Excellent programming skills with either Scala or Python (functional programming being a big plus) and associated libraries, e.g. Cats, Shapeless, Pandas, Numpy,A background developing large scale, production level Big Data platforms, including e.g. Hadoop, Spark, Cassandra,Knowledge of how to build highly scalable, highly tolerable software,An awesome opportunity to join one of the best teams in the industry and build highly complex software, unrivalled by any other competitor,The chance to innovate and gain exposure to a massive scale Big Data platform & production level Machine Learning","
Big Data Engineer | London | Internet of Things
Scala OR Python | Spark, Cassandra, Kafka, AWS
£40,000 to £80,000 plus bonus & a strong benefits package
WHO'S HIRING
The biggest disruptor to the energy/utilities industry in years, who are building a first-of-its-kind Data Science product, applying Machine Learning to smart meter & IoT devices in order to generate complex insight into consumers and market trends.
You'll join a cross-functional Big Data & Data Science team renowned for being one of the best in the industry, giving you exposure to a variety of new techniques, including functional Scala programming, Machine Learning and real-time data streaming.
Most of the industry's biggest companies are already queuing up for the product, meaning your role will be very delivery focused and you'll have the opportunity to have a massive commercial impact.
WHAT'S THE ROLE
As Big Data Engineer, you'll have a broad role & working in either Python or Scala for:
Data Engineering - the development of a petabyte scale Big Data platform and data pipelines/ETL, primarily using Spark, Cassandra and Kafka, programming in either Scala or Python
Back-end Software Development - building the back end of the Data Science product
Data Science support - the productionisation of Machine Learning algorithms, refactoring of code etc.
WHAT ARE THEY LOOKING FOR
Excellent programming skills with either Scala or Python (functional programming being a big plus) and associated libraries, e.g. Cats, Shapeless, Pandas, Numpy
A background developing large scale, production level Big Data platforms, including e.g. Hadoop, Spark, Cassandra
Knowledge of how to build highly scalable, highly tolerable software
A willingness to take on a range of ad-hoc projects and work with new tech
WHY SHOULD I APPLY
An awesome opportunity to join one of the best teams in the industry and build highly complex software, unrivalled by any other competitor
The chance to innovate and gain exposure to a massive scale Big Data platform & production level Machine Learning
£40,000 to £80,000 plus bonus & an excellent benefits package
HOW TO APPLY
If you feel that this is the one for you, click the apply link on this page - if not, but you're interested in other Big Data positions, please get in touch with Jethro Willett at Harnham, as the Big Data market has never been busier!
KEYWORDS
Big Data Engineer, Big Data Developer, Hadoop Engineer, Scala Developer, Scala Engineer, Python Developer, Python Engineer, Spark, Hadoop, Kafka, Cassandra, London
Reference: 32839168
Bank or payment details should not be provided when applying for a job. reed.co.uk is not responsible for any external website content. All applications should be made via the 'Apply now' button.
Report this job
",https://www.careerjet.co.uk/clk/0aca4e8179926cd2c7bb301e29fd1b2e.html
JOB149464013794,Data Engineer,Data Engineer,"Bachelor’s degree or higher in a quantitative/technical field (Computer Science, Statistics, Engineering),Working knowledge of data design, architecture and warehousing,Understanding of data management fundamentals and data storage principles,Knowledge of distributed systems as it pertains to data storage and cloud computing,Understanding and administration of AWS, Docker and Linux-based systems,Experience in custom ETL design, implementation and maintenance,Experience in large scale data processing using traditional and distributed systems like Hadoop, Spark, Dataflow, and Airflow.,Knowledge and practical experience in machine learning and AI fundamentals,Experience implementing machine learning solutions at scale,Experience working with both Batch and Real Time data processing systems,Ability to work and communicate effectively with stakeholders.,Opportunity to work with one of the fastest growing financial startups,Competitive salary + equity,Health/dental/vision insurance + 401K,Gym + public transportation subsidy,Relocation assistance","Analyze and resolve complex challenges around data and tools. Optimize analytical workflows by identifying opportunities and automating them,Implement solutions to bring together application data generated by distributed systems, third-party data, and real-time user data needed to make key business decisions,Work within the Data Science team to serve machine learning solutions at scale,Work on projects of growing responsibility, both individually and as part of a team, to build experience and skills at a pace matched to your shown ability","Nearly half of U.S. households struggle to handle an unexpected expense of $400 or more. When it comes to managing household expenses, things like a broken appliance or a growing family can be financially burdensome. Ranked 5th on Inc. Magazine’s annual list of fastest-growing private companies in the United States, our team is on a mission to make life’s purchases more accessible and affordable.
Located in the heart of vibrant Philadelphia, we’re building a FinTech-enabled e-commerce marketplace that combines quality brands with sensible financing to improve the lives of our neighbors and communities.
Position Overview
We are searching for a Data Engineer who is a quantitative, critical thinker with a passion for data and the capacity to work in a fast-paced, entrepreneurial environment. We are looking for an individual who desires experience in serving data-driven solutions at scale, crossing multiple functional areas and driving organizational efficiency. Applicants should be highly motivated and comfortable with taking on and adapting to a diverse array of subject matter. This opportunity is both unique and pivotal, as it provides the chance to contribute greatly to a rapidly-growing team.
Initial Responsibilities
Analyze and resolve complex challenges around data and tools. Optimize analytical workflows by identifying opportunities and automating them
Implement solutions to bring together application data generated by distributed systems, third-party data, and real-time user data needed to make key business decisions
Work within the Data Science team to serve machine learning solutions at scale
Work on projects of growing responsibility, both individually and as part of a team, to build experience and skills at a pace matched to your shown ability
Learn more about the industry and Perpay, establishing a solid foundation to be better positioned for long-term career success
Basic Qualifications
Bachelor’s degree or higher in a quantitative/technical field (Computer Science, Statistics, Engineering)
Working knowledge of data design, architecture and warehousing
Understanding of data management fundamentals and data storage principles
Knowledge of distributed systems as it pertains to data storage and cloud computing
Understanding and administration of AWS, Docker and Linux-based systems
Experience in custom ETL design, implementation and maintenance
Experience in large scale data processing using traditional and distributed systems like Hadoop, Spark, Dataflow, and Airflow.
Strong working knowledge of SQL/NoSQL, relational databases and Python is required (2+ years experience)
Preferred Qualifications
Knowledge and practical experience in machine learning and AI fundamentals
Experience implementing machine learning solutions at scale
Experience working with both Batch and Real Time data processing systems
Ability to work and communicate effectively with stakeholders.
Effective project management, problem solving, analytical and troubleshooting skills.
Benefits:
Opportunity to work with one of the fastest growing financial startups
Competitive salary + equity
Health/dental/vision insurance + 401K
Gym + public transportation subsidy
Relocation assistance
Centrally located in downtown Philadelphia
We don’t work with external recruiting agencies, please contact us or apply directly!
Apply Now
",https://technical.ly/job/perpay-data-engineer-43555/
JOB150733072916,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-no/details/200188037/ai-ml-search-data-engineer-siri-data
JOB150766639936,Senior Data Engineer - Oxford,Senior Data Engineer - Oxford,,,"
Reqiva are working with an excellent biotechnology company that have created a revolutionary piece of technology to ensure efficiency to healthcare services.
This is a fantastic opportunity for an enthusiastic Senior Data Engineer to join an innovative company using their strong analytical skills for the benefit to society.
Types of Roles and Responsibilities as a Senior Data Engineer:
* Working with other software developers and data scientists to design, plan and implement new software
* Ability to analyse large amounts of data
* Share and input new ideas
Skills and Requirements for a Senior Data Engineer:
* Language Agnostic - confident in using multiple programming languages and technology stacks including C/C++, C#, Java and Python
* Extensive experience working on Linux
* Some experience working with DevOps
* Excellent communication
* Passion for coding and software development
* Strong evidence of good coding and development practices
* Experience / interest in working in the Medical Sector
If you would like to work for a cutting-edge technology company - Apply Now!
India Parsons - Software Engineering Consultant - Reqiva ltd -
Reference: 39770820
Bank or payment details should never be provided when applying for a job. For information on how to stay safe in your job search, visit SAFERjobs.
Report this job
",https://www.reed.co.uk/jobs/senior-data-engineer-oxford/39770820
JOB153181231970,"Senior Data Engineer - Java, Kafka streams","Senior Data Engineer - Java, Kafka streams",,,"
SENIOR DATA ENGINEER LONDON, CURRENTLY FLEXIBLE / REMOTE / HOME WORKING UP TO 80,000 BENEFITS BONUS Harnham are partnered with a leading e-commerce company in Central London - this company are building a next-gen data platform from the ground up using...
Senior Data & BI Developer / Engineer - BI platforms, database and data warehouse infrastructure - Microsoft, SQL, Azure - Poole - a design, develop build role to help transform data infrastructure and BI platforms In this business critical role you...
Office 365 Senior Systems Engineer / Cloud Technical Consultant, with proven Office 365 and Azure implementation and support experience, is required for a leading technology organisation based in High Wycombe (with flexible & home working), paying...
DevOps Engineer (Senior) - AWS (Lambda) & Python - FinTech Big Player Our client is looking for a DevOps Engineer to Join their existing exclusive team of DevOps engineers in a continuously growing and adapting environment supporting the fintech industry...
Senior DevOps Engineer Job Opportunity in Wrexham I am working with a leading business that are on a huge expansion drive now, of whom are seeking to add a Senior DevOps Engineer to their team. You will be working collaboratively with Data Engineers, Data...
Senior Java Developer / Backend Software Engineer Remote Interview WFH. Would you like to make an impact and advance your career, working on complex systems that provide daily challenges and enjoy a range of perks from open plan offices with all the latest...
Network Security Engineer (Firewall Engineer) International Banking Group - Perm up to 70,000 Benefits Good Bonus Scheme Central London (Initially Home Working) As a preferred and trusted recruitment partner to this international banking group for over...
C# Developer / Software Engineer (C# .Net SQL Big Data) Remote Interview WFH. Global FinTech is seeking a senior C# Developer with a data centric mindset. As a C# Developer you will design and develop components of a complex data analytics platform that...
Senior Python Developer / Engineer Remote Interview. Are you an inquisitive, data centric Python Developer looking to progress your career working on complex and challenging systems, collaborating with peers to solve problems and contributing to architectural...
Data Architect A brand new role has arisen for a Data Architect to join a well-known charity as they look for someone to make sense of their complicated data sets and build data models. You will be brought on board to map out the structure of their data...
SENIOR BACKEND ENGINEER 50,000 - 60,000 Dependent on Experience Top Engineer Wanted To Join Creative Development Team Mediafly is seeking a back-end engineer to join us in building the technology platform, which powers our suite of web, mobile, and tablet...
Software Developer / Architect (.Net Core microservices Data) Remote Interview WFH. Would you like to take ownership, make the technical decisions and remain hands-on with code? You could be joining a specialist Hedge Fund to deliver a long term strategic...
Software Developer / Engineer (C# .Net Core SQL Big Data) Remote Interview WFH. Global FinTech is seeking a senior Software Developer with a data centric mindset. As a Software Developer you will design and develop components of a complex data analytics...
Senior Java Developer / Software Engineer (microservices Kotlin CI/CD SpringBoot). Trailblazing technology company is seeking an accomplished Senior Java Developer to take ownership of critical technical projects, influence strategic decisions and guide...
Java Developer / Engineer Remote Interview WFH. Would you like to make an impact and advance your career, working on complex systems that provide daily challenges and enjoy a range of perks from open plan offices with all the latest kit; a well stocked...
Lead Software Engineer (Java microservices Kotlin CI/CD SpringBoot) Remote Process Are you an ambitious Lead Software Engineer looking for your next challenge? Would you like an opportunity to accelerate your career in a trailblazing technology company...
A global Software brand with offices in Staines are searching for a Senior Finance Analyst to join its team. Working with the Consulting division (with scope widening as the role progresses), you will be tasked with helping the business operationally and...
Senior Software Engineer (Symfony), Oxford or remote Avanti Recruitment is currently working with an award winning SAAS provider based in the Oxford area. This role can be based from the offices, you can work from home or a mix of onsite and remote. It's...
Lead Python Developer / Engineer Remote Interview. Are you an inquisitive, data centric Python Developer looking to progress your career working on complex and challenging systems, collaborating with peers to solve problems and contributing to architectural...
Job Title : Software Developer Location: Primarily home based but will need to commute occasionally to London & Southend Salary: 45,000 - 55,000 per annum, depending on experience Job Type: Permanent, Full time The Company: Hood Group is a privately-owned...
3 Certifications in your first 6 months Technology Agnostic. You will work with the latest technology from AWS to Kubernetes. Enterprise projects working with the likes of MOD, MOJ and the Home Office If the above sounds interesting to you, keep reading...
Senior Information Security Analyst Global Audit, Tax and Advisory Consultancy 50,000 - 60,000 Basic Salary Corporate Benefits Central London (Home working until 2021) Would you like to work for the one of the worlds largest Audit, Tax and Financial Advisory...
3 Certifications in your first 6 months Technology Agnostic. You will work with the latest technology from AWS to Kubernetes. Enterprise projects working with the likes of MOD, MOJ and the Home Office If the above sounds interesting to you, keep reading...
In this role you will be a Java Architect ( can come from Architect or Snr SWE background ) working on cutting edge Systems Managers area where you define architectural decisions and the frameworks in like with overall product goals / company strategy...
A fantastic opportunity has arisen to join a local organisation in assisting a strategic plan to improve traffic / transport projects. Ongoing contract, initially until Jan 2021 but likely to be extended - Home working initially but some office based requirements...
",https://www.reed.co.uk/jobs/senior-data-engineer-working-from-home/40329096
JOB153832823641,Data Engineer Jobs,Data Engineer Jobs,,,"
From: Up to £10,000
To: Up to £10,000
",http://www.reed.co.uk/jobs/data-analysis-and-support-engineer/39958999
JOB153944398351,Federal - Data Engineer,Federal - Data Engineer,"Experience with SQL databases, Graph Databases- largest growth - No /SQL- Neo4J currently,Data transformation experience with scripting (Python, Java, Perl, PL/SQL) or platforms such as Spark, or Knime,,Exposure to AWS Data Services,Experience with Architect, design, and implement updates and enhancements to data repositories and indices to support data ingest, enrichment, analysis, visualization, and dissemination",,"
This job has expired
Job Description
Organization: Accenture Federal Services
Location: Washington, D.C.
We are:
AccentureFederal Servicesbring together commercial innovation with the latest technology to unleash the potential for our federal clients. Operating in the nation's Capital, we stay ahead of what is coming next. Drawing from the power of Accenture, we deliver integrated, mobile and interactive experiences that exceed our people's expectations. Join us where ideas are freely exchanged, and concepts evolve into practical solutions.
You are:
A Data Engineer ready to design and implement distributed, cloud-native data pipelines, storage systems, and query support. You will help support next generation defense and intelligence operations with a focus on enabling machine learning and automation. Your team is eager to work in an Agile development environment and expected to identify and mitigate risks and bottlenecks associated with big data environments.
The work:
• Architect, design, and implement updates and enhancements to data repositories and indices to support data ingest, enrichment, analysis, visualization, and dissemination
• Perform database engineering and management activities associated with designing, developing, maintaining, and enhancing Big Data analytic systems using an Agile DevSecOps model
• Integrate data from multiple sources in batches and real time
• Review, design, and develop data quality management processes and automated procedures intended to produce high levels of data integrity
• Research and recommend solutions to complex problems
• Oversee code reviews and delivering feedback regarding designs/code
• Perform research and development and provide technical support to identify and integrate new and emerging technologies into the data environment
• Design and implement storage and indexing strategies to provide efficient storage and retrieval to support visualizations such as graph-based and geospatial indices
• Support design and development of data access APIs that allow enterprise access (as appropriate) to data
• Develop or provide input to engineering artifacts associated with the data repositories
Qualifications
Here's what you need:
Experience with SQL databases, Graph Databases- largest growth - No /SQL- Neo4J currently
Data transformation experience with scripting (Python, Java, Perl, PL/SQL) or platforms such as Spark, or Knime,
Exposure to AWS Data Services
Experience with Architect, design, and implement updates and enhancements to data repositories and indices to support data ingest, enrichment, analysis, visualization, and dissemination
U.S. Citizenship; no Dual Citizens
Bonus Points:
• Familiarity with no-SQL databases like Neo4j, ElasticSearch, or Cassandra
• Familiarity with SQL query engines, preferably PrestoDB or SparkSQL
• Familiarity with distributed platforms (i.e. HBase, Kafka, Spark, NiFi) and the cloud (i.e. AWS, GCP, Azure), preferably Amazon Web Services
• Experience integrating open API based data access and processing
• DOD8570 IAT Level 1 or 2 certified (A+, Security+, etc. certification)
Important information
This role requires US Citizenship with no dual Citizenship accepted.
Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture Federal Services.
Accenture Federal Services is an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.
Equal Employment Opportunity: All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.
Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.
Accenture Federal Services is committed to providing veteran employment opportunities to our service men and women.
Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.
An active security clearance or the ability to obtain one may be required for this role.
Locations
DC,DC - Washington
APPLY NOW
Register for Job Alerts
To apply from a mobile device, your CV must be in the cloud. Not Ready? Send this job to an email address To apply from a tablet device, your CV must be in the cloud. Not Ready? Send this job to an email address
[{ ""@context"": ""https://schema.org"", ""@type"": ""JobPosting"", ""title"": ""Federal - Data Engineer"", ""jobLocation"": { ""@type"": ""Place"", ""address"": { ""addressLocality"": ""DC,DC - Washington"", ""addressRegion"": ""South"", ""addressCountry"": ""USA"", ""postalCode"": ""unavailable"", ""streetAddress"": ""unavailable"" } }, ""baseSalary"": { ""@type"": ""MonetaryAmount"", ""value"": ""unavailable"", ""currency"": ""unavailable"" }, ""qualifications"": ""Here's what you need:Experience with SQL databases, Graph Databases- largest growth - No /SQL- Neo4J currentlyData transformation experience with scripting (Python, Java, Perl, PL/SQL) or platforms such as Spark, or Knime, Exposure to AWS Data ServicesExperience with Architect, design, and implement updates and enhancements to data repositories and indices to support data ingest, enrichment, analysis, visualization, and disseminationU.S. Citizenship; no Dual Citizens Bonus Points: • Familiarity with no-SQL databases like Neo4j, ElasticSearch, or Cassandra•\tFamiliarity with SQL query engines, preferably PrestoDB or SparkSQL•\tFamiliarity with distributed platforms (i.e. HBase, Kafka, Spark, NiFi) and the cloud (i.e. AWS, GCP, Azure), preferably Amazon Web Services•\tExperience integrating open API based data access and processing•\tDOD8570 IAT Level 1 or 2 certified (A+, Security+, etc. certification)Important information This role requires US Citizenship with no dual Citizenship accepted. Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture Federal Services. Accenture Federal Services is an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities. Equal Employment Opportunity: All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law. Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process. Accenture Federal Services is committed to providing veteran employment opportunities to our service men and women. Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration. An active security clearance or the ability to obtain one may be required for this role."", ""description"": ""Organization: Accenture Federal ServicesLocation: Washington, D.C. We are:AccentureFederal Servicesbring together commercial innovation with the latest technology to unleash the potential for our federal clients. Operating in the nation's Capital, we stay ahead of what is coming next. Drawing from the power of Accenture, we deliver integrated, mobile and interactive experiences that exceed our people's expectations. Join us where ideas are freely exchanged, and concepts evolve into practical solutions.You are: A Data Engineer ready to design and implement distributed, cloud-native data pipelines, storage systems, and query support. You will help support next generation defense and intelligence operations with a focus on enabling machine learning and automation. Your team is eager to work in an Agile development environment and expected to identify and mitigate risks and bottlenecks associated with big data environments. The work: •\tArchitect, design, and implement updates and enhancements to data repositories and indices to support data ingest, enrichment, analysis, visualization, and dissemination•\tPerform database engineering and management activities associated with designing, developing, maintaining, and enhancing Big Data analytic systems using an Agile DevSecOps model•\tIntegrate data from multiple sources in batches and real time•\tReview, design, and develop data quality management processes and automated procedures intended to produce high levels of data integrity•\tResearch and recommend solutions to complex problems•\tOversee code reviews and delivering feedback regarding designs/code•\tPerform research and development and provide technical support to identify and integrate new and emerging technologies into the data environment•\tDesign and implement storage and indexing strategies to provide efficient storage and retrieval to support visualizations such as graph-based and geospatial indices•\tSupport design and development of data access APIs that allow enterprise access (as appropriate) to data• Develop or provide input to engineering artifacts associated with the data repositories"", ""responsibilities"": ""unavailable"", ""datePosted"": ""9/18/2020 6:09:29 AM"", ""validThrough"": ""10/20/2021 6:02:41 PM"", ""hiringOrganization"": ""Accenture"", ""employmentType"": ""Full-time"", ""skills"": ""Analytics and Insights"", ""Industry"": ""unavailable"" }]
Related Jobs
USA MD - Gaithersburg
Federal - Junior Enterprise Data Warehouse Engineer
Analytics and Insights
Posted 5 days ago
Multiple Locations
Federal - Data Integration Engineer
Analytics and Insights
Posted 5 days ago
Multiple Locations
Federal - Data Scientist
Analytics and Insights
Posted 7 days ago
View More Jobs
Life at Accenture
Work where you're inspired to explore your passions and where your talents are nurtured and cultivated. Innovate with leading-edge technologies on some of the coolest projects you can imagine.
Training and Development
Take time away to learn and learn all the time in our regional learning hubs, connected classrooms, online courses and learning boards.
LEARN MORE
Work Environment
Be your best every day in a work environment that helps drive innovation in everything you do.
LEARN MORE
Rewards & Benefits
With Accenture's Total Rewards, you are empowered to be your best-for the business, for your family, and for yourself.
LEARN MORE
View All
View Less
Learn more about Accenture
With more than 500,000 employees in more than 120 countries, Accenture solves our clients' toughest challenges by providing a broad range of services and solutions in strategy, consulting, digital, technology and operations.
Our Expertise
New isn't on its way. We're applying it now. See how we bring the new to life with our clients in every industry, in every country, every day.
FIND OUT MORE
Meet Our People
Get to know some of our 500,000+ colleagues from around the globe who are changing the way the world works and lives.
FIND OUT MORE
View All
View Less
Stay connected
Join Our Team
Search open positions that match your skills and interest. We look for passionate, curious, creative and solution-driven team players.
SEARCH ACCENTURE JOBS
Keep Up to Date
Stay ahead with careers tips, insider perspectives, and industry-leading insights you can put to use today-all from the people who work here.
READ CAREERS BLOG
Stay Connected
Receive job alerts, latest news and insider tips tailored to your preferences. See what exciting and rewarding opportunities await.
JOIN TALENT COMMUNITY
View All
View Less
",https://www.gettinghired.com/job-details/1634298/federal-data-engineer/
JOB154991258124,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-pl/details/200188037/ai-ml-search-data-engineer-siri-data
JOB156222230607,Data Engineer,Data Engineer,"Relevant degree or equivalent.,Applied knowledge of database architecture concepts, within traditional RDBMS environments and also in-memory, noSQL, virtualised or federated approaches, columnar and streaming databases.,Strong knowledge of concepts such as OLTP, OLAP, star and snowflake schemas, dimensional modelling and normalisation.,Extensive track record of performing in the data engineering domain, including:,Extracting data from enterprise systems such as SAP,Security management,Data modelling,ETL development using tools such as Data Integrator/Services,Experience of experience of scrum/agile project management.,Annual Bonus Plan,Discretionary Cash Award,Group Personal Pension Plan with enhanced company contribution,Medical, Travel, Health & Life Insurances,Holiday, 25 days annual leave with option to buy an additional 5 days per year,Sabbatical, 20 paid days every four-year of service,Volunteering, One (1) paid working day each year (TeamARM),Varies by location: cycle to work, free car parking, gym on site, team and social events",,"
We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
Job Description
Part of our IT strategy is to increase our agility, speed and innovation. Connecting information with our users is a key aspect of achieving this. This job is within the Analytics platform team at ARM, which is responsible for architecting, delivering and operating a best in class analytics platform.
We are looking for a Data Engineer to join the team who has good delivery experience and a willingness to learn and grow their skills.
Job Requirements
Qualifications and education:
Relevant degree or equivalent.
Knowledge of the field and current developments in this area.
Essential Skills & Experience:
Applied knowledge of database architecture concepts, within traditional RDBMS environments and also in-memory, noSQL, virtualised or federated approaches, columnar and streaming databases.
Strong knowledge of concepts such as OLTP, OLAP, star and snowflake schemas, dimensional modelling and normalisation.
Extensive track record of performing in the data engineering domain, including:
Extracting data from enterprise systems such as SAP
Security management
Data modelling
ETL development using tools such as Data Integrator/Services
Creating reports using reporting tools such as SAP Business objects, Tableau and Power BI
Solid experience with Oracle or MySQL or SQL Server.
Desirable Skills & Experience:
Experience of experience of scrum/agile project management.
Knowledge of APIs and microservices.
About ARM
ARM® is at the heart of the world's most advanced digital products. Our technology enables the creation of new markets and transformation of industries and society. We design scalable, energy efficient-processors and related technologies to deliver the intelligence in applications ranging from sensors to servers, including smartphones, tablets, enterprise infrastructure and the Internet of Things.
Our innovative technology is licensed by ARM Partners who have shipped more than 50 billion Systems on Chip (SoCs) containing our intellectual property since the company began in 1990. Together with our Connected Community, we are breaking down barriers to innovation for developers, designers and engineers, ensuring a fast, reliable route to market for leading electronics companies.
With offices around the world, ARM is a diverse community of dedicated, innovative and highly talented professionals. By enabling an inclusive, meritocratic and open workplace where all our people can grow and succeed, we encourage our people to share their unique contributions to ARM's success in the global marketplace.
Your particular benefits package will depend on position and type of employment and may be subject to change. Your package will be confirmed on offer of employment. ARM’s benefits program provides permanent employees with the opportunity to stay innovative and healthy, ensure the wellness of their families, and create a positive working environment.
Annual Bonus Plan
Discretionary Cash Award
Group Personal Pension Plan with enhanced company contribution
Medical, Travel, Health & Life Insurances
Holiday, 25 days annual leave with option to buy an additional 5 days per year
Sabbatical, 20 paid days every four-year of service
Volunteering, One (1) paid working day each year (TeamARM)
Varies by location: cycle to work, free car parking, gym on site, team and social events
About ARM
ARM® technology is at the heart of a computing and connectivity revolution that is transforming the way people live and businesses operate. From the unmissable to the invisible; our advanced, energy-efficient processor designs are enabling the intelligence in 86 billion silicon chips and securely powering products from the sensor to the smartphone to the supercomputer. With more than 1,000 technology partners including the world’s most famous business and consumer brands, we are driving ARM innovation into all areas compute is happening inside the chip, the network and the cloud.
With offices around the world, ARM is a diverse community of dedicated, innovative and highly talented professionals. By enabling an inclusive, meritocratic and open workplace where all our people can grow and succeed, we encourage our people to share their unique contributions to ARM's success in the global marketplace.
About the office
At our global HQ in Cambridge, England we house the majority of our engineering and our corporate groups that deliver our extraordinary success. As a world-renowned university town, Cambridge boasts both a beautiful countryside and a historical town center. Local activities include punting on the River Cam and the many museums that reside within Cambridge University.
",https://careers.peopleclick.com/careerscp/client_arm/external/jobDetails.do?functionName=getJobDetail&jobPostId=31441&localeCode=en-us
JOB158179371533,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-cl/details/200188037/ai-ml-search-data-engineer-siri-data
JOB159901391721,Python Developer / Data Engineer,Python Developer / Data Engineer,,,"
Python Developer / Software Engineer Remote Process WFH (Linux SQL C ). Hugely profitable eTrading company is seeking a technologist Python Developer with back office trading experience. As a Python Developer you'll focus on post trade systems (commission...
Junior Software Engineer / Data Developer (Python Data SQL) Remote Interview. Would you like to work on complex, data centric systems whilst continually learning and gaining valuable knowledge of financial trading systems? You could be joining a global...
Python Developer Python Developer needed for a data analytics project, working on a remote basis. The role would involve working with the current development team to help move their service based offering into a product based offering (SAAS platform)....
Python Developer / Software Engineer (Python SQL Linux R&D) Remote Interview WFH. Would you like to utilise your Python Developer skills to earn significant bonuses at a massively profitable algorithmic trading house? You'll be based in fantastic riverside...
A Global leading company is currently recruiting for a Python Developer that has experience with Python, SQL, Spark and Tableau. Based in Preston, Lancashire. Experience and skills required: Python (2-8 years) SQL Spark Tableau Demonstrated experience...
Python Developer / Software Engineer (Python SQL Linux R&D) Remote Interview WFH. Would you like to utilise your Python Developer skills to earn significant bonuses at a massively profitable algorithmic trading house? You'll be based in fantastic riverside...
Backend Software Engineer / Developer (Python Linux SQL R&D) Remote Interview WFH. Algorithmic trading firm is seeking a skilled Backend Software Engineer with strong Python skills. As a Backend Software Engineer you'll focus on designing and building...
Software Engineer / Python Developer (Linux R&D Python SQL) Remote Interview WFH. Opportunity to earn significant bonuses at a massively profitable algorithmic trading house. You'll be based in fantastic riverside offices in Central London with superb...
Lead Python Developer / Engineer Remote Interview. Are you an inquisitive, data centric Python Developer looking to progress your career working on complex and challenging systems, collaborating with peers to solve problems and contributing to architectural...
Python Software Engineer / Developer (PostgreSQL) Remote Interview. Are you a bright, motivated Python Software Engineer looking to work on complex, data centric systems whilst continually learning and gaining valuable knowledge of financial trading systems?...
Data Engineer / Python Developer – Remote working A Data Engineer / Python Developer is required to join an exciting software house based in central Oxford. The role is offered with as much working from home as you want, all the way up to fully remote ...
Python Developer position based in London This is not inside IR35. Mandatory skills: Python SQL Job description: 2 - 8 years of experience in Python Demonstrated experience in Analytics/Big Data. Knowledge of end Data Science Life Cycle. Extract data from...
Software Engineer / Developer Remote Process WFH (Linux SQL C ). Skilled Software Engineer with back office trading systems experience sought by hugely profitable algorithmic trading company. As a Software Engineer you'll focus on post trade systems (commission...
Senior Python Data Developer is currently required for a 6 month project with an Analytics Consultancy in central London who have secured a fantastic long term engagement with their client. The client have experienced an extremely positive increase in...
Software Engineer / Python Developer (Trading Linux SQL R&D) Remote Process WFH Are you a process-driven Software Engineer looking for a unique challenge? Would you like the opportunity to earn significant bonuses in a highly profitable, industry-leading...
Backend Software Engineer / Developer Remote Process WFH (Linux SQL C ). Are you a technologist with back office trading systems experience seeking complex and interesting systems to apply your skills? You could be join a hugely profitable eTrading company...
We have a contract Python Developer position open in Preston It is a 6-month contract where the candidate will be working remotely for the first 3 months and at the office thereafter. Skills and experience required: Python (2-8 years) SQL Demonstrated...
Senior Python Data Developer is currently required for a 6 month project with an Analytics Consultancy in central London who have secured a fantastic long term engagement with their client. The client have experienced an extremely positive increase in...
Overall Purpose of Job This is an exceptional opportunity for a talented quantitative developer to join the Analytics team, responsible for building cutting-edge technology, optimizing and delivering statistical and financial models. The candidate will...
Our client is looking for a Finnish speaking BI Developer in Helsinki, Finland. This is a 6 months contract role in BFSI domain. The required skills are following. Strong experience in data models, BI tools and SQL Practical experience in working with...
Software Developer in Test / QA Test Automation Engineer Remote Interview WFH. Massively profitable algorithmic trading firm is seeking a Software Developer in Test with strong Python coding skills. Joining a highly driven, Agile development team that...
Lead Frontend Developer (REMOTE) London With the conversation around money significantly changing, people are now looking for better ways to be able to make their money work for them. We are, however, mostly still none the wiser on how to do this. Our...
QA Engineer / Software Developer in Test (Python Automation Testing). Massively profitable algorithmic trading firm is seeking a highly technical QA Engineer. Joining a highly driven, Agile development team that cares about code quality, you'll be responsible...
Informatica Developer - Egham The Role At its core this is an Informatica Developer / Consultant role. A hands-on, technical role requiring an in-depth knowledge of the Informatica products, strong SQL skills and a knowledge of Cloud data platforms. It's...
",https://www.reed.co.uk/jobs/data-developer-python-sql/40308497
JOB160110347241,Senior Data Engineer - BODS | BO | Sybase IQ,Senior Data Engineer - BODS | BO | Sybase IQ,,,"
Would you like to join a great technical team and have the opportunity to develop within Data Services?
I am looking for a Data Engineering professional with significant experience in ETL processes and integration.
In terms of technology, the desirable skill set will be:
4 to 5 years SAP Data Services/ BODS - Mandatory
Business Objects - highly desirable
Sybase IQ - Desirable
SQL expertise - essential
CMC - desirable
If you also have some experience mentoring colleagues and minimal exposure to Qlikview/Tableau/Power BI, this is the ideal role for you.
Get in touch for further details - Apply ASAP
",https://www.careerjet.co.uk/clk/913192c9b0ead5920624e32f7ed10b6e.html
JOB160597384002,Data Engineer,Data Engineer,,,"
Data Engineer X 2 – Manchester. Our client based near Manchester are currently looking for 2 Data Engineers with Azure experience. The company is currently going through a large digital transformation, they are looking for talented Data specialist to help...
Job Title: Data Engineer Salary: 45,000 to 54,000 plus Benefits Location: Cambridge This is a very rare opportunity for an experienced Data Engineer with a strong background in building Python based data processing pipelines to join a company that are...
",https://www.reed.co.uk/jobs/data-engineer/40343647
JOB161700326194,EY looking for Data Engineer with 2-4 year experience,EY looking for Data Engineer with 2-4 year experience,"Experience in areas such as data-driven statistical modeling, discriminative methods, feature extraction and analysis, supervised learning.","Conduct advanced statistical analysis to provide actionable insights, identify trends, and measure performance,Use data-mining techniques to collect and compile data from a wide variety of data repositories.,Build learning systems that monitor data flows and react to changes in customer preferences and business objectives,Build high-performance predictive and prescriptive algorithms using cutting-edge statistical techniques (e.g. neural networks).,Research new machine learning solutions to complex business problems,Collaborate with engineers to implement and deploy scalable solutions,Provide thought leadership by researching best practices, conducting experiments, and collaborating with industry leader,Use data visualization tools to develop visuals that can be used to effectively communicate technical findings to a non-technical audience,Teach data science concepts to more junior members of the team,PhD with 1-2 years of experience or Masters with 3-4 years of experience in Data Science, Computer Science, Engineering, Statistics, or related field.,Strong background in machine learning and statistics (Deep Learning and Bayesian statistics is a plus),Prototyping Expertise: quick to build proofs-of-concept involving data munging, scripting and analysis.,Solid foundation in data structures and algorithms,Hands on experience building models with deep learning frameworks like MXNet, Tensorflow, Caffe, Torch, Theano or similar.,Experience processing massive amounts of structured and unstructured data using Spark/SQL/Hive/Impala/HBase.,Proficiency in Python for numerical/statistical programming (including Numpy, Pandas, and Scikit-learn),Experience with natural language processing,Experience using Cloud computing (AWS/Azure/GCP),Experience with Java, Scala, Python etc.,Experience working with large data sets and distributed computing tools a plus (Map/Reduce, Hadoop, Hive, Spark)","
EY looking for Data Engineer with 2-4 year experience
Application Period: May 17, 2018 - June 29, 2018
Contact: To apply, visit link below.
EY's people in more than 150 countries are committed to operating with integrity, quality and professionalism in the provision of audit, tax, transaction and advisory services. We strive to help all of our people achieve their professional and personal goals through an inclusive environment that values everyone's contributions, appreciates diversity of thought, fosters growth, and provides continuous opportunities for development. Recognized as one of Canada's top employers, EY continually strives to be a great place to work.
Our IT Advisory Analytics practice works collaboratively with our clients to enhance their ability to use and interpret data, and develop their own enhanced information management capabilities to support better decision making, along with regulatory compliance within their business. Our clients need the vision to articulate the big picture and the precision to see the smallest of details.
Information and intelligence are the assets which enable this, and our Analytics practice provides innovative approaches to unlocking this information, solving many of our clients’ biggest challenges. We are working to integrate this capability into all Advisory service offerings and assists clients to leverage data as an asset throughout its business processes.
We are looking for someone to:
Conduct advanced statistical analysis to provide actionable insights, identify trends, and measure performance
Use data-mining techniques to collect and compile data from a wide variety of data repositories.
Build learning systems that monitor data flows and react to changes in customer preferences and business objectives
Build high-performance predictive and prescriptive algorithms using cutting-edge statistical techniques (e.g. neural networks).
Research new machine learning solutions to complex business problems
Collaborate with engineers to implement and deploy scalable solutions
Provide thought leadership by researching best practices, conducting experiments, and collaborating with industry leader
Use data visualization tools to develop visuals that can be used to effectively communicate technical findings to a non-technical audience
Teach data science concepts to more junior members of the team
We are looking for someone with:
PhD with 1-2 years of experience or Masters with 3-4 years of experience in Data Science, Computer Science, Engineering, Statistics, or related field.
Strong background in machine learning and statistics (Deep Learning and Bayesian statistics is a plus)
Prototyping Expertise: quick to build proofs-of-concept involving data munging, scripting and analysis.
Solid foundation in data structures and algorithms
Hands on experience building models with deep learning frameworks like MXNet, Tensorflow, Caffe, Torch, Theano or similar.
Experience processing massive amounts of structured and unstructured data using Spark/SQL/Hive/Impala/HBase.
Proficiency in Python for numerical/statistical programming (including Numpy, Pandas, and Scikit-learn)
Experience with natural language processing
Experience using Cloud computing (AWS/Azure/GCP)
Experience with Java, Scala, Python etc.
Experience working with large data sets and distributed computing tools a plus (Map/Reduce, Hadoop, Hive, Spark)
Experience in areas such as data-driven statistical modeling, discriminative methods, feature extraction and analysis, supervised learning.
If you think you can meet the challenges of a focused consulting organisation, understand how to grow and lead in a large practice and work in the most complex of sectors our Analytics team is looking forward to hearing from you.
To apply, click https://eygbl.referrals.selectminds.com/experienced-opportunities/jobs/senior-consultant-–-data-analytics-25321
EY is committed to inclusiveness, equity and accessibility. We encourage all qualified candidates to apply.
",https://www.cs.mcgill.ca/postings/184/
JOB162286082941,Part-Time Data Engineer Jobs,Part-Time Data Engineer Jobs,,,"
From:
To:
",https://www.reed.co.uk/jobs/data-engineer-jobs?parttime=True
JOB162512366126,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-cn/details/200188037/ai-ml-search-data-engineer-siri-data
JOB163223569216,"58,789 Data Engineer Manager Jobs","58,789 Data Engineer Manager Jobs",,,"
Quick Apply
Data Engineer- Mid Level (World's Largest Social Media Company!)
Design, construct, install, test and maintain highly scalable data management systems. * Ensure ... Skills: * 3-10 years experience working within Data Engineering, preferably Hadoop and Big Data ...
",https://www.ziprecruiter.com/Jobs/Data-Engineer-Manager
JOB164138339703,Lead Data Engineer,Lead Data Engineer,50+ career categories,"Find a better job, faster!,Hand-screened leads,No ads, scams, junk,Great job search support","
Lead Data Engineer
Full-time job, remote option.Needs six years' data management experience and experience with AWS technologies. build a state of the art data and analytics stack, be a thought leader for how data is consumed and contribute changes to the data pipeline.
Job Details
Option for Remote
Employee
Full-Time
Experienced
No
Training and Growth Benefits, Vision Insurance, Mental Health Coverage, Pet Insurance,Quarterly Tech Events, Fully Stocked Kitchens
Health Insurance, Paid Vacation, Maternity Leave, Dental Insurance, Stock Options
Company name here
Other benefits listed here
Find a better job, faster!
Hand-screened leads
No ads, scams, junk
Great job search support
50+ career categories
Create an Account to Unlock
To find out more about or apply to this Lead Data Engineer job—and other great opportunities like it—become a FlexJobs member today!
With FlexJobs, you'll find the best flexible jobs and fantastic expert resources to support you in your job search. If you have any questions, please feel free to contact us.
",https://www.flexjobs.com/publicjobs/lead-data-engineer-1310209
JOB164344912736,Data Engineer Jobs,Data Engineer Jobs,,,"
DESCRIPTION At Amazon Advertising, we are dedicated to drive measurable outcomes for brand advertisers, agencies, authors, and entrepreneurs. Our ad solutions—including sponsored, display, video, and custom ads—leverage Amazon’s innovations and insights...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
As the Data Engineer for this amazing corporate Insurance company, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL, together...
See more: Engineer jobs
As a data engineer within the exciting, new claims advanced analytics capability, you will be building big data solutions to solve some of the organization’s toughest problems and delivering significant business value. This is a really exciting time to...
See more: Engineer jobs
Data Engineer - 70,000 Job Description An AWS Partner based in Central London is looking to expand the data side of their business due to growth. They are looking for Data Engineers with significant commercial experience ingesting large quantities of data...
See more: Engineer jobs
As the Data Engineer for this amazing corporate Insurance company in the City, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
DATA ENGINEER - TEMPORARILY REMOTE 400- 450 PER DAY 3 MONTH CONTRACT EUROPE BASED As a Data Engineer you will be working heavily with Scala and Spark to improve the quality of data. THE COMPANY: You will be working for dynamic data driven company. As a...
See more: Engineer jobs
40'000- 50'000 Pension 8% Technical Progression Healthcare Holidays More Horley, Surrey Are you seeking a new challenge within a rapidly expanding Eco-Energy Tech company where you will be having huge technical autonomy in building a data preform right...
See more: Engineer jobs
Role: Data Engineer Client: Government agency (BPSS will be required) Location: Glasgow Duration: 8 Months Rate: 400 per day (outside IR35) Note: The office is based in Glasgow city centre. It is expected that the consultant would be available for physical...
See more: Engineer jobs
Data Engineer Opus are working with an excellent niche software development company in Newcastle. The company is at the forefront of their industry and due to their on-going success are now looking for a Data Engineer to take responsibility for organising...
See more: Engineer jobs
A leading Insurance Company are currently recruiting for a Data Engineer to join their dynamic and growing business. They are looking to hire a cross functional, highly tenacious and bright Data Engineer with a passion for functional programming. The ideal...
See more: Engineer jobs
Data Engineer - 6 months - Ware - Hertfordshire Global FMCG is looking for an experienced Data Engineer who will play a pivotal role in operationalizing data and analytics initiatives for digital business initiatives. The bulk of the data engineer's work...
See more: Engineer jobs
Data Engineer Portsmouth and surrounding areas encouraged to apply, multiple office locations Data Engineer required for established, international business. The business is at the forefront of new technologies working with leading Government organisations...
See more: Engineer jobs
Data Engineer A brand new role has arisen for an experienced Database / BI Developer to take the next step in their career and transition into a full Data Engineer to work for one of the most recognisable NGO's in London. We are looking for someone with...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
Data Engineer- 50K Manchester Adria Solutions has an exciting opportunity for a talented Data Engineer to join our rapidly expanding client based near Manchester. The role requires you to work closely with other members of the data team and stakeholders...
See more: Engineer jobs
We are currently recruiting a highly motivated Data Engineer, for a company who are based in London. The Data Engineer will help develop and maintain the business. The Data Engineer will be responsible for the following; Key responsibilities- - Working...
See more: Engineer jobs
Data Engineer - I am currently recruiting for a Data Engineer based in Bath. The role would be on a permanent basis and is paying 40,000 to 45,000 (There could be flex for the right candidate) PA plus a variety of excellent benefits as well as the flexibility...
See more: Engineer jobs
Data Engineer - London - 550-600 per day - 6 month contract SearchData is currently looking to recruit a Data Engineer to work on a cutting-edge DWH project in the financial services industry. As the Data Engineer your role will be to take a leadership...
See more: Engineer jobs
An exciting opportunity for an experienced Data Engineer has arisen in Leeds. After hiring a number of new members of staff at the end of 2019, the organisation are continuing to expand due to winning more projects. Key responsibilites include: Building...
See more: Engineer jobs
Data Engineer - REMOTE WORK If you are a strong Data Engineer, with experience working with Python, R and SQL then this role is ideal. I am working with a large organisation that are market leaders in their respected field. This role will report in to...
See more: Engineer jobs
Data Engineer London 55,000 - 65,000 Benefits Our client, an exciting RegTech business is looking to recruit for a Data Engineer to join their growing team. The successful candidate will be joining the artificial intelligence team, working on a brand new...
See more: Engineer jobs
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
See more: Engineer jobs
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
See more: Engineer jobs
",http://www.reed.co.uk/jobs/data-engineer/39769859
JOB165514144282,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-ae/details/200188037/ai-ml-search-data-engineer-siri-data
JOB166965254994,Data Engineer,Data Engineer,,,"
Data Engineer X 2 – Manchester. Our client based near Manchester are currently looking for 2 Data Engineers with Azure experience. The company is currently going through a large digital transformation, they are looking for talented Data specialist to help...
Job Title: Data Engineer Salary: 45,000 to 54,000 plus Benefits Location: Cambridge This is a very rare opportunity for an experienced Data Engineer with a strong background in building Python based data processing pipelines to join a company that are...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Data Engineer - 70,000 Job Description An AWS Partner based in Central London is looking to expand the data side of their business due to growth. They are looking for Data Engineers with significant commercial experience ingesting large quantities of data...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer - Python - Permanent Data Idols are working with a well-known client in the e-commerce space who are looking for a Data Engineer to join an existing team. THE ROLE As a Data Engineer, you will be working with the existing Data team to help...
Data Engineer - Manchester A growing business based in Manchester City Centre are currently looking for a Data Engineer to help shape their newly formed Data Engineering team and build scalable, reliable and secure cloud datawarehouse solutions and data...
An exciting start up Fintech company has a new opportunity for a Data Engineer where you will play an active part in the success of the company. This role will see you joining a small team where you'll have the opportunity to take responsibility for Data...
Job title : Data Engineer Location: London Job type: Permanent Salary: Up to 70,000 per annum Reporting to: Head of Data Engineering Overview A fantastic internet company based in Central London are currently looking for a Data Engineer to come on board...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer- 50K Manchester Adria Solutions has an exciting opportunity for a talented Data Engineer to join our rapidly expanding client based near Manchester. The role requires you to work closely with other members of the data team and stakeholders...
Data Engineer / Data Scientist / Biomedical Informatics / Human Genetics / Python / SQL / R / Oxford / Cambridge / Permanent 60 - 90K (Depending on Experience) Excellent Benefits COVID Safe Interview Process 100% Remote during Covid and up to 50% Post...
Data Engineer London 80,000 - 90,000 Benefits This Data Engineering role will allow you to expand and utilise your skills in a growing team working along side one of the largest data sets in the UK. The Company As a global leader they generate tons of...
Data Engineer (12-month Fixed Term Contract) 50,000 - 55,000 We are looking for a Data Engineer to join a market leading business we're representing, based in central London. Working as part of the central Data Science & Analytics team, you will be...
Data Engineer London 55,000 - 65,000 Benefits Our client, an exciting RegTech business is looking to recruit for a Data Engineer to join their growing team. The successful candidate will be joining the artificial intelligence team, working on a brand new...
Recruiting for multiple Data Engineer roles with a global organisation based in Swindon to develop their cloud based platforms and infrastructure. These are permanent opportunities to join a newly created Agile team, offering competitive salaries/benefits...
Data Engineer- Stockport, Cheshire ""Our Client will be interviewing and onboarding remotely during COVID-19"" Adria Solutions has an exciting opportunity for a talented Data Engineer to join our reputable client based near Stockport. As a Data Engineer...
Data Engineer, Central London - Up to 60k DOE plus benefits This Data Engineer will need social media data experience - please clearly detail this in your application This tech business are experts at understanding the impact of political narratives on...
Data Engineer - Permanent Data Idols are working with a well-known client in the e-commerce space who are looking for a Data Engineer to join an existing team on a permanent basis. THE ROLE As a Data Engineer, you will be working with the existing Data...
",https://www.reed.co.uk/jobs/data-engineer/40306486
JOB167713741660,Data Engineer Jobs in Swansea,Data Engineer Jobs in Swansea,,,"
From:
To:
",https://www.reed.co.uk/jobs/data-engineer-jobs-in-swansea
JOB168080098125,Staff Big Data Engineer,Staff Big Data Engineer,"Experience building data pipelines and analytics systems on distributed data systems on AWS, using spark.,Experience Scala and Python,Experience building batch pipelines with data from event data streams, NoSQL and APIs.,Competitive health and insurance benefits,Competitive salary,Annual target bonus or commission,Paid vacation and sick time,Vacation rental on a yearly basis (taxable benefit),Employee Stock Purchase Program,Free snacks and beverages,Frequent company update talks with our leadership team,Free listing on HomeAway. com,Electronic, adjustable stand-up desk,Discounted Metro & Rail pass","Drive technical design and development around real-time data analytics.,Lead data analytics initiative in a multi-functional matrixed environment.,Design cloud data analytics platform & enable self-service tools to democratize data.,Audience focused (C-team, Engineers, Leaders etc.) communications with influence and clarity.","
Position at HomeAway
HomeAway, a world leader in the vacation rental industry, is the place to book beach houses, cabins, and condos with more than two million places to stay in 190 countries. The site makes it easy to find and book the perfect vacation rental for any getaway, often for less than the cost of traditional hotel accommodations. HomeAway is part of the Expedia Group family of brands.
The Opportunity:
Are you passionate about turning click stream data into actionable insights for the company? Can you design and develop next generation real-time data pipelines and self-service analytics around event streams? Do you love to solve challenging problems at speed and scale? You want to work for a company that is product centric and data driven? You want to be a part of culture that fosters test & learn and OneTeam approach across the company? If so, this opportunity is a great fit for you.
What You ll Do:
Drive technical design and development around real-time data analytics.
Lead data analytics initiative in a multi-functional matrixed environment.
Design cloud data analytics platform & enable self-service tools to democratize data.
Audience focused (C-team, Engineers, Leaders etc.) communications with influence and clarity.
Mentor and develop data Engineering teams on newer technologies.
Qualifications:
Experience building data pipelines and analytics systems on distributed data systems on AWS, using spark.
Experience Scala and Python
Experience building batch pipelines with data from event data streams, NoSQL and APIs.
Solid experience in Clickstream domain (tracking libraries, server side logging, canonical event model, data & self-service analytics etc.) a huge plus
Benefits & Perks:
Competitive health and insurance benefits
Competitive salary
Annual target bonus or commission
Paid vacation and sick time
Vacation rental on a yearly basis (taxable benefit)
Employee Stock Purchase Program
Free snacks and beverages
Frequent company update talks with our leadership team
Free listing on HomeAway. com
Electronic, adjustable stand-up desk
Discounted Metro & Rail pass
Casual dress
","https://www.ziprecruiter.com/c/HomeAway/Job/Staff-Big-Data-Engineer/-in-Chicago,IL?ojob=37496dc140e838d8bddec24b71baaa18"
JOB168110067034,Data Engineer,Data Engineer,,,"
The remote data engineer will create data solutions; work on BI, ETL, and database development; and conduct code reviews. Must have at least five years' cloud-based data analysis and integration experience with three years' NoSQL experience.
",https://www.flexjobs.com/publicjobs/data-engineer-1314105
JOB168166654127,Senior Data Engineer,Senior Data Engineer,"Identify data sources that can add value to decision making.,Work with source system owners and analysts to understand source data, e.g. data profiling, definition and mapping.,Design and implement efficient data loads, using traditional structured data ETL techniques.,Design and implement real time and near real time data load solutions, using technologies like data streaming.,Design and implement unstructured data loads, e.g. text speech, images and video.,Design and implement load monitoring tools and procedures and perform continuous monitoring and optimising of loads.,Work with analysts and architect to design and implement effective and efficient data models using appropriate modelling techniques.,Design and implement data warehouse data models.,Design and implement data pipelines for ad hoc, unstructured and other data models.,Design and implement appropriate aggregation data structures that enhance usability of data, e.g. multi-dimensional OLAP structures, summary tables etc.,Design, implement and maintain appropriate indexing on tables to enhance speed of access.,Design and implement data models that support automated decision making and/or further analytics.,Continuously search for data elements from other sources to enhance existing data objects to supplement / enhance context.,Design and implement interfaces for data access, e.g. batch exports, real-time decision API’s etc.,Design and implement interface monitoring and management solutions to ensure availability and accuracy.,Monitor and maintain integrity of existing environment, troubleshoot technical and data issues and make appropriate changes where required.,Implement meta-data solutions that assist with understanding and managing data.,Work together with business owners, analysts and IT to maintain good data governance.,Provide technical and data related support to source system teams and external parties with whom we exchange data.,Manage data growth and usage by designing and implementing effective strategies, e.g. archiving and indexing.,Manage systems, technology and tools that enable data management and analytics.,Take ownership of own work by delivering high quality work on time.,Show initiative and be pre-active in finding opportunities to improve data and/or processes.,Take ownership of own career development by continuously improving skills, knowledge and the application thereof in designing and implementing solutions.,Positive engagement in team activities and actively contribute ideas to improve team dynamics and performance.,Stakeholder management (internal and external).,Assist in development of others, e.g. mentoring and knowledge share.,Quality control of other’s work.,Degree in information technology / mathematics / engineering / actuarial science or related discipline.,At least 5+ years in a technical data role, preferably in a formal data, data warehouse or business intelligence environment.,SQL,Data analysis,Data visualisation,Data modelling,Microsoft business intelligence data technologies (SSIS, SSAS, SQL Server),Data warehouse concepts and best practices,Financial services knowledge, specifically personal or unsecured loans,Business process monitoring and optimising,Microsoft business intelligence visualisation technologies (SSRS, Power BI),IT infrastructure, e.g. storage, networking, servers, security,Unstructured data experience,Information gathering and problem analysis,Applying professional / specialist / technical expertise,Creating and innovating,Quality & Detail orientation,Analysing",,"Job description
Capfin is a leading unsecured loan provider with a successful business model supported by great people with a strong culture of innovation and data driven decision making. The purpose of this role is to create business value by applying data engineering and data management disciplines to design and build data solutions that enable data driven decision support, in order to optimize business decisions and processes, as well as train and mentor more junior team members.
Requirements
Key Performance Areas:
Sourcing data
Identify data sources that can add value to decision making.
Work with source system owners and analysts to understand source data, e.g. data profiling, definition and mapping.
Loading data
Design and implement efficient data loads, using traditional structured data ETL techniques.
Design and implement real time and near real time data load solutions, using technologies like data streaming.
Design and implement unstructured data loads, e.g. text speech, images and video.
Design and implement load monitoring tools and procedures and perform continuous monitoring and optimising of loads.
Storing data
Work with analysts and architect to design and implement effective and efficient data models using appropriate modelling techniques.
Design and implement data warehouse data models.
Design and implement data pipelines for ad hoc, unstructured and other data models.
Enhancing data
Design and implement appropriate aggregation data structures that enhance usability of data, e.g. multi-dimensional OLAP structures, summary tables etc.
Design, implement and maintain appropriate indexing on tables to enhance speed of access.
Design and implement data models that support automated decision making and/or further analytics.
Continuously search for data elements from other sources to enhance existing data objects to supplement / enhance context.
Making data available
Design and implement interfaces for data access, e.g. batch exports, real-time decision API’s etc.
Design and implement interface monitoring and management solutions to ensure availability and accuracy.
Managing data
Monitor and maintain integrity of existing environment, troubleshoot technical and data issues and make appropriate changes where required.
Implement meta-data solutions that assist with understanding and managing data.
Work together with business owners, analysts and IT to maintain good data governance.
Provide technical and data related support to source system teams and external parties with whom we exchange data.
Manage data growth and usage by designing and implementing effective strategies, e.g. archiving and indexing.
Manage systems, technology and tools that enable data management and analytics.
Leadership responsibilities
Take ownership of own work by delivering high quality work on time.
Show initiative and be pre-active in finding opportunities to improve data and/or processes.
Take ownership of own career development by continuously improving skills, knowledge and the application thereof in designing and implementing solutions.
Positive engagement in team activities and actively contribute ideas to improve team dynamics and performance.
Stakeholder management (internal and external).
Assist in development of others, e.g. mentoring and knowledge share.
Quality control of other’s work.
Qualifications:
Degree in information technology / mathematics / engineering / actuarial science or related discipline.
Experience:
At least 5+ years in a technical data role, preferably in a formal data, data warehouse or business intelligence environment.
Functional Competencies:
SQL
Data analysis
Data visualisation
Data modelling
Microsoft business intelligence data technologies (SSIS, SSAS, SQL Server)
Data warehouse concepts and best practices
Financial services knowledge, specifically personal or unsecured loans
Business process monitoring and optimising
Microsoft business intelligence visualisation technologies (SSRS, Power BI)
IT infrastructure, e.g. storage, networking, servers, security
Unstructured data experience
Behavioural Competencies:
Information gathering and problem analysis
Applying professional / specialist / technical expertise
Creating and innovating
Quality & Detail orientation
Analysing
Posted on 06 Sep 12:34
",https://www.bizcommunity.com/Job/196/594/373060.html
JOB168686879611,"Architect, Principal Data Engineer - Pipelines","Architect, Principal Data Engineer - Pipelines","BS, MS or equivalent in Computer Science or related technical field,10+ years of software engineering with OOP languages,7+ years of architectural experience developing scalable data pipelines and data processing frameworks in a cloud-native or distributed computing environment.,3+ years serving as a lead data or pipeline architect in a large-scale, cloud-based, high-volume data processing organization or business division.,Demonstrated experience writing architectural requirements and systems design documents.,Experience designing and governing scalable cloud-native backend compute capabilities (REST APIs, microservices, distributed computing frameworks, geospatial processing and indexing, messaging frameworks and paradigms, data quality management).,Excellent written and verbal communication including the presentation of complex engineering designs, concepts, and solutions in a clear and concise manner to technical and non-technical audiences alike.,Expertise in processing and aggregating high-volume, geospatially-oriented IoT data.,Expertise in imagery processing and feature extraction from satellite and aerial sources.,Depth of knowledge in the Data Operations and Data Quality management space.,Experience with layered geospatial data structures and data representations.,Expertise designing and implementing highly scalable data-intensive distributed computing solutions using modern cloud-native processing frameworks.,Experience with Amazon Web Services (EC2, S3, RDS, SQS, etc.) is strongly preferred,Experience with a compiled JVM language, including Scala, is a plus,Superb medical, dental, vision, life, disability benefits, and a 401k matching program,A stocked kitchen with a large assortment of snacks & drinks to get you through the day,Encouragement to get out of the office and into the field with agents and farmers to see first-hand how our products are being used,Inspire one another,Innovate in all we do,Leave a mark on the world,Find the possible in the impossible","Lead technical direction and architectural evolution of our data pipelines and related digital farming platform capabilities.,Partner with other architects and technical leads to collaborate, design and validate appropriate solutions and institute appropriate data governance mechanisms.,Partner with Digital Farming Platform leads to establish and steward a multi-year Data Pipelines technical capabilities roadmap.,Develop cloud-based pipeline architectures that enable massively scalable data processing, while maintaining less than linear operating cost profiles.,Continuously assess next-generation geospatial data and imagery processing techniques to support use cases unique to the agriculture industry.,Work with key leaders and subject matter experts in our Data Science and Product organizations to integrate and enable the latest agronomic data innovations and data quality algorithms.","
As a senior technical leader in the Data Pipelines engineering organization, you will technically guide a team chartered with ingesting and transforming agronomic data into canonical and post-canonical datasets. You will be accountable for the design and technical stewardship of existing and next-generation large scale data pipelines processing geospatial data acquired from a global farming user base. You will drive pipeline and capability architectures that facilitate the rapid integration of data science based agronomic, data quality, and imagery processing models directly into our data pipelines.
What You Will Do:
Lead technical direction and architectural evolution of our data pipelines and related digital farming platform capabilities.
Partner with other architects and technical leads to collaborate, design and validate appropriate solutions and institute appropriate data governance mechanisms.
Partner with Digital Farming Platform leads to establish and steward a multi-year Data Pipelines technical capabilities roadmap.
Develop cloud-based pipeline architectures that enable massively scalable data processing, while maintaining less than linear operating cost profiles.
Continuously assess next-generation geospatial data and imagery processing techniques to support use cases unique to the agriculture industry.
Work with key leaders and subject matter experts in our Data Science and Product organizations to integrate and enable the latest agronomic data innovations and data quality algorithms.
Evangelize and mentor others on topics such as data governance, data quality, and data management best practices and techniques.
Basic Qualifications:
BS, MS or equivalent in Computer Science or related technical field
10+ years of software engineering with OOP languages
7+ years of architectural experience developing scalable data pipelines and data processing frameworks in a cloud-native or distributed computing environment.
3+ years serving as a lead data or pipeline architect in a large-scale, cloud-based, high-volume data processing organization or business division.
Demonstrated experience writing architectural requirements and systems design documents.
Experience designing and governing scalable cloud-native backend compute capabilities (REST APIs, microservices, distributed computing frameworks, geospatial processing and indexing, messaging frameworks and paradigms, data quality management).
Expertise designing and deploying solutions on at least one cloud-based provider such as Amazon Web Services, Google Cloud Platform or Microsoft Azure.
Preferred Qualifications:
Excellent written and verbal communication including the presentation of complex engineering designs, concepts, and solutions in a clear and concise manner to technical and non-technical audiences alike.
Expertise in processing and aggregating high-volume, geospatially-oriented IoT data.
Expertise in imagery processing and feature extraction from satellite and aerial sources.
Depth of knowledge in the Data Operations and Data Quality management space.
Experience with layered geospatial data structures and data representations.
Expertise designing and implementing highly scalable data-intensive distributed computing solutions using modern cloud-native processing frameworks.
Experience with Amazon Web Services (EC2, S3, RDS, SQS, etc.) is strongly preferred
Experience with a compiled JVM language, including Scala, is a plus
Working knowledge of open-source and commercial data pipeline tooling (Apache NiFi, Cloudera, Informatica, etc) strongly preferred.
What We Offer:
Our teams are composed of industry experts, top scientists, and talented engineers. The environment is extremely engaging and fast-paced, with dozens of specialties coming together to provide the best possible products and experiences for our customers.
We provide competitive salaries and some of the best perks in the industry, including:
Superb medical, dental, vision, life, disability benefits, and a 401k matching program
A stocked kitchen with a large assortment of snacks & drinks to get you through the day
Encouragement to get out of the office and into the field with agents and farmers to see first-hand how our products are being used
We take part and offer various workshops, conferences, meet-up groups, tech-talks, and hackathons to encourage participation and growth in both community involvement and career development
We also hinge our cultural DNA on these five values:
Inspire one another
Innovate in all we do
Leave a mark on the world
Find the possible in the impossible
Be direct and transparent
Learn more about our team and our mission:
The Climate Corporation - The Technology Behind Making A Difference
https://youtu.be/c5TgbpE9UBI or visit https://climate.com/careers
Climate aims to create a welcoming and collaborative environment for our employees in which a diverse set of perspectives and voices are represented and celebrated.
As part of our dedication to the diversity of our workforce, The Climate Corporation is committed to Equal Employment Opportunity and does not discriminate based on race, religion, color, national origin, ethnicity, gender, sex (including pregnancy), protected veteran status, age, disability, sexual orientation, gender identity, gender expression, or any unlawful criterion existing under applicable federal, state, or local laws. If you need assistance or an accommodation due to a disability, you may contact us at accommodations@climate.com
\#LI-BW1
","https://www.ziprecruiter.com/c/Bayer/Job/Architect,-Principal-Data-Engineer-Pipelines/-in-Clarksville,TN?ojob=3e0ff024b6c7c20e911cebe588c1444a"
JOB169225981250,Data Engineer,Data Engineer,,,"
Remote in pandemic. Maintain data pipelines, provide mentoring of teams, oversee cloud-based platforms, create data test tools, and work with teams to analyze insights. Requires 3+ years' software experience and knowledge of 2+ programming languages.
",https://www.flexjobs.com/publicjobs/data-engineer-1307013
JOB172788027537,Cloud-udvikler/Data Engineer,Cloud-udvikler/Data Engineer,,,,"https://www.computerworld.dk/modules/job/morerandomjobs.php?op=list&start=6&limit=3&jobidsused=672492,673696,670013,674209,671112,665801&layout=cwglassbox"
JOB172792132046,"Newton, Data Engineer (Front Office)","Newton, Data Engineer (Front Office)","Extensive experience in relational database development, particularly Oracle and MS SQL server,Experience of writing and optimising stored procedures and views to transform and deliver data,Experience using performance, monitoring and alerting tools,Experience in scripting/automation language (Shell, Python),Familiar with ETL processes,Interest in NoSQL database and BigData concepts and systems,Knowledge of SCRUM or other Agile methodologies,Any experience of Data Architecture and Dimensional Modelling would be a plus,Any experience with Markit EDM would be a plus,Knowledge of investment management, including investment risk, would be a definite plus,Good communicator and collaborator keen to work closely across teams and the business,Take ownership and show a willingness to tackle difficult issues,Embrace, and effectively manage, change,Get hands-on, providing technical direction and/or problem solving to support the team,Ensure all third-party development conforms to organisation best-practice and quality standards,Demonstrate exceptional problem solving skills and intellectual curiosity,Show a passion for innovation and continuous improvement and initiate efforts to implement alternative solutions",,"
Job Purpose
This database engineering role is an opportunity to significantly contribute to the design and delivery of Newton's data pipelines across multiple database platforms.
This hand on technical role will require the candidate to understand Newton's database estate and how it is consumed by different groups across the business. This will involve working with business teams to understand their data needs, in addition to working with various development teams to deliver the data.
This is a great role for an experienced database developer/engineer who enjoys a level of business user interaction and enjoys being a data subject matter expert.
Company Overview:
Newton Investment Management Limited is an active investment management firm, using thematic ideas about the long-term investment landscape to create and manage strategies that help secure clients' futures. Newton thinks on a global basis, with its single London-based investment team working collaboratively across asset classes and regions. The firm builds bold solutions, designed to meet the real-world challenges clients face, and the team manage them responsibly in the broadest sense - through embedding environmental, social and governance considerations, and engaging on issues that affect their clients. Those clients are based around the world, and include pension funds, corporations and charities and, via Newton's parent company BNY Mellon, individuals.
With offices in London and New York, Newton has £49.8bn assets under management (as at 31 March 2018), including assets managed by Newton Investment Management Limited as dual officers of Newton Investment Management (North America) Limited and The Bank of New York Mellon. News and other information about Newton is available at www.newtonim.com and via Twitter: @NewtonIM.
Key Responsibilities
• Hands on responsibility for data engineering of relational databases (Oracle and Microsoft SQL server)
• Ensure the smooth running of all processes that use or derive data from data feeds
• Development and maintenance of existing and future data pipelines
• Analysis and solution construction for ad hoc business data enquiries
• Provide impact analysis of data change across multiple systems
• Contributing to the development of analytics capabilities across the company
• Making improvements to the build and deployment mechanisms for database changes
Qualifications
Job Specific Competencies
Technical Skills/Systems Knowledge (and associated skill level)
Extensive experience in relational database development, particularly Oracle and MS SQL server
Experience of writing and optimising stored procedures and views to transform and deliver data
Experience using performance, monitoring and alerting tools
Experience in scripting/automation language (Shell, Python)
Familiar with ETL processes
Interest in NoSQL database and BigData concepts and systems
Knowledge of SCRUM or other Agile methodologies
Any experience of Data Architecture and Dimensional Modelling would be a plus
Any experience with Markit EDM would be a plus
Knowledge of investment management, including investment risk, would be a definite plus
Good communicator and collaborator keen to work closely across teams and the business
Take ownership and show a willingness to tackle difficult issues
Embrace, and effectively manage, change
Get hands-on, providing technical direction and/or problem solving to support the team
Ensure all third-party development conforms to organisation best-practice and quality standards
Demonstrate exceptional problem solving skills and intellectual curiosity
Show a passion for innovation and continuous improvement and initiate efforts to implement alternative solutions
Preferred but non-essential Technical Skills/Systems Knowledge
Academic/Professional Qualifications (or equivalent qualifiers)
• Formal education in Computer Science, Engineering or related discipline preferred
People (team-working/collaboration skills)
Self (integrity and the ability to reflect confidence)
Results (the ability to be proactive and take action)
Thought ( problem solving, innovation and continuous improvement )
BNY Mellon is an Equal Employment Opportunity Employer.
Primary Location: United Kingdom-Greater London-London
Job: Asset Management
Internal Jobcode: 51575
Organization: Newton-HR06148
Requisition Number: 1816556
",https://www.efinancialcareers.com/jobs-UK-London-Newton_Data_Engineer_Front_Office.id05208633
JOB173073165995,Data Engineer II,Data Engineer II,,,"
Description:
Description:
For more information and/or to apply, please visit our career site at:
my100bank.com
GENERAL DESCRIPTION OF POSITION
Data Engineer II designs, builds, and maintains databases for data storage, processing, and analytics. This role develops, supports, and implements strategies for warehouse implementation, data acquisition and access, data archiving and recovery, and data reporting and visualization. Extensive Star Schema Fact Table Dimensional modeling with Slowly Changing Dimensions (SCD) and Extract Transform Load (ETL) processes architecting will be owned by this role. This role develops and maintains Extract Transform Load (ETL) processes and monitors and maintains our database and cloud infrastructure. This position will work closely with our Business Intelligence group to produce data analysis and reports. In addition, this role builds data models and defines the structure, attributes and nomenclature of data elements along with evaluating new data sources for adherence to the organization's quality standards and ease of integration.
ESSENTIAL DUTIES AND RESPONSIBILITIES
1. Design, implementation, and administration of database systems in a team environment. This duty is performed daily, about 50% of the time.
2. Maintain awareness and knowledge of industry/vendor technology and trends in order to ensure optimal use and value of the LAN/WAN resources. This duty is performed weekly, about 10% of the time.
3. Oversee projects from the planning stage to completion to meet the organization's requirements. This duty is performed daily, about 10% of the time.
4. Oversee regular maintenance of our database systems. This duty is performed daily, about 10% of the time.
5. Assist in maintaining and troubleshooting existing and new software applications. This duty is performed daily, about 15% of the time.
6. Provide guidance to level one engineers and technicians in issue troubleshooting and resolution. This duty is performed daily, about 5% of the time.
7. Conduct research and consult with VP Network Administration concerning new storage, applications, and systems related purchases. This duty is performed monthly, about 5% of the time.
8. The ability to work in a constant state of alertness and in a safe manner. This duty is performed daily, about 100% of the time.
9. Completes required BSA/AML training and other compliance training as assigned. This duty is performed as needed.
10. Develops and maintains Extract Transform Load (ETL) processes.
11. Monitors and mantains database and cloud infrastructure.
12. Perform any other related duties as required or assigned.
QUALIFICATIONS
To perform this job successfully, an individual must be able to perform each essential duty mentioned satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required.
EDUCATION AND EXPERIENCE
Broad knowledge of such fields as accounting, marketing, business administration, finance, etc. Equivalent to a four year college degree, plus 4 years related experience and/or training, or equivalent combination of education and experience.
COMMUNICATION SKILLS
Ability to read a limited number of words and recognize similarities and differences between words and between series of numbers; Ability to write and speak simple sentences as a means for basic communication. Ability to read and understand simple instructions, short correspondence, notes, letters and memos; Ability to write simple correspondence. Ability to read and understand documents such as policy manuals, safety rules, operating and maintenance instructions, and procedure manuals; Ability to write routine reports and correspondence. Ability to effectively communicate information and respond to questions in person-to-person and small group situations with customers, clients, general public and other employees of the organization. Ability to read, analyze, and understand general business/company related articles and professional journals; Ability to speak effectively before groups of customers or employees. Ability to write reports, business correspondence, and policy/procedure manuals; Ability to effectively present information and respond to questions from groups of managers, clients, customers, and the general public. Ability to read, analyze, and understand common scientific and technical journals, financial reports, and legal documents; Ability to respond to complex or difficult inquiries or complaints from customers, regulatory agencies, or members of the business community.
MATHEMATICAL SKILLS
Ability to calculate figures and amounts such as discounts, interest, commissions, proportions, percentages, area, circumference, and volume. Ability to apply concepts such as fractions, ratios, and proportions to practical situations.
CRITICAL THINKING SKILLS
Ability to define problems, collect data, establish facts, and draw valid conclusions. Ability to interpret an extensive variety of technical instructions in mathematical or diagram form and deal with several abstract and concrete variables.
REQUIRED CERTIFICATES, LICENSES, REGISTRATIONS
Not indicated.
PREFERRED CERTIFICATES, LICENSES, REGISTRATIONS
Azure Certification
Microsoft Certification
SOFTWARE SKILLS REQUIRED
Advanced: Database
Intermediate: Programming Languages, Spreadsheet
Basic: 10-Key, Accounting, Alphanumeric Data Entry, Presentation/PowerPoint, Word Processing/Typing
WORKING CONDITIONS
Periodically exposed to such elements as noise, intermittent standing, walking, occasionally pushing, carrying, or lifting; but none are present to the extent of being disagreeable.
ENVIRONMENTAL CONDITIONS
The following work environment characteristics described here are representative of those an employee encounters while performing essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
While performing the functions of this job, the employee is occasionally exposed to risk of electrical shock.The noise level in the work environment is usually moderate.
PHYSICAL ACTIVITIES
The following physical activities described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions and expectations.
Semi-repetitive, low physical. Semi-repetitive type work which requires periods of concentration for varied time cycles as prescribed by the tasks.
While performing the functions of this job, the employee is continuously required to sit; regularly required to stand, walk, reach with hands and arms, climb or balance, stoop, kneel, crouch, or crawl, talk or hear. The employee must occasionally lift and/or move up to 50 pounds. Specific vision abilities required by this job include close vision.
ADDITIONAL INFORMATION
Required Education and Experience:
- 5 + years of experience installing, maintaining and troubleshooting Microsoft SQL Server
- 3 + years of experience installing, maintaining and troubleshooting Microsoft Server Products
Required Proficiency:
- Must be well organized with excellent technical documentation skills
- Strong interpersonal, written, and oral communication skills
- Ability to conduct research into networking issues and products as required
- Must be self-motivated and work with minimal supervision
- Basic understanding of scripting and PowerShell
- Mature logic critical thinking skills
Preferred:
3 years experience with Azure SQL Data Warehouse, Azure Analysis Services, Azure Data Factory, and SQL 2017
This position may require the use of a vehicle to install, troubleshoot, and/or remove IT-related equipment, network, etc. Therefore, this position is classified as a safety sensitive position.
WE OFFER:
Competitive Salaries
Paid holidays and vacation
401K Plan
Health Insurance
• Home BancShares, Inc. is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, race, color, sex, religion, national origin, disability, veteran status, family or marital status, gender identity or expression, or any other characteristic protected by law.
• EEO/AA/Veteran/Disabled/F/M
",https://www.arkansasbusiness.com/jobs/detail/10946/data-engineer-ii
JOB173191581839,Data Engineer,Data Engineer,,,,"https://www.computerworld.dk/modules/job/morerandomjobs.php?op=list&start=3&limit=3&jobidsused=785865,791851,786634&layout=cwglassbox"
JOB174388701712,Data Engineer - Retail Business Intelligence,Data Engineer - Retail Business Intelligence,"7+ years of data extraction and front end report building (PHP or similar),Proficient with data access/preparation methods using Teradata SQL and relational databases,Proficient with scripting/glue languages like PHP or Python and web-technologies like HTML, CSS, and Javascript,Strong interpersonal skills, both verbal and written,Ability to work on multiple assignments with excellent attention to detail,Flexibility to handle directional changes and ability to support multiple deadline-specific projects while maintaining day-to-day business support,Driven, Self-motivated individual who is experienced working in a global, matrixed, fast-paced environment,Ability to comprehensively understand data elements, sources and relationships,Ability to establish and manage relationships in a cross-functional team environment,Apple is an Equal Opportunity Employer that is committed to inclusion and diversity. We also take affirmative action to offer employment and advancement opportunities to all applicants, including minorities, women, protected veterans, and individuals with disabilities. Apple will not discriminate or retaliate against applicants who inquire about, disclose, or discuss their compensation or that of other applicants.",,"At Apple, extraordinary ideas have a way of becoming phenomenal products, services, and customer experiences very quickly. Bring passion and dedication to your job and there's no telling what you could accomplish. Would you like to work in a dynamic environment where your technical abilities will be challenged on a day-to-day basis? If so, Apple's Retail Business Intelligence team is seeking an expert Data Engineer to support marketing campaign automation and data analysis for Retail. In this role you will interface with both business and IT partners, using their passion to expose the operational value of data to drive value in both domains. This role requires you to architect easy-to-use data objects, create email campaigns, and build reporting assets that end users can utilize for data driven decisions. Are you ready to tackle on an exciting new challenge?
7+ years of data extraction and front end report building (PHP or similar)
Proficient with data access/preparation methods using Teradata SQL and relational databases
Proficient with scripting/glue languages like PHP or Python and web-technologies like HTML, CSS, and Javascript
Strong interpersonal skills, both verbal and written
Ability to work on multiple assignments with excellent attention to detail
Flexibility to handle directional changes and ability to support multiple deadline-specific projects while maintaining day-to-day business support
Driven, Self-motivated individual who is experienced working in a global, matrixed, fast-paced environment
Ability to comprehensively understand data elements, sources and relationships
Ability to establish and manage relationships in a cross-functional team environment
Unix programming/scripting experience a plus
Define how data is structured, organized and interpreted for consistent executive reporting. Define and automate campaigns using tools like UNICA Develop and implement reporting for data quality, data capture rates and monitor data quality Partner with database developers to have designs for database objects implemented and validated Perform ad-hoc analytics to support incoming requests from business partners Engage with IT and project teams to ensure reporting requirements are covered Define, build and deploy impactful metrics Develop and implement web reports and analytical tools based on business requirements Provide consultation and training to users of analytical tools Additional responsibilities will include extracting, cleaning and manipulating data from multiple systems fo research & advanced analytics.
Apple is an Equal Opportunity Employer that is committed to inclusion and diversity. We also take affirmative action to offer employment and advancement opportunities to all applicants, including minorities, women, protected veterans, and individuals with disabilities. Apple will not discriminate or retaliate against applicants who inquire about, disclose, or discuss their compensation or that of other applicants.
",https://jobs.apple.com/en-us/details/200102503/data-engineer-retail-business-intelligence
JOB174910794290,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/fi-fi/details/200188037/ai-ml-search-data-engineer-siri-data
JOB175057754999,Data Engineer Jobs,Data Engineer Jobs,,,"
DESCRIPTION At Amazon Advertising, we are dedicated to drive measurable outcomes for brand advertisers, agencies, authors, and entrepreneurs. Our ad solutions—including sponsored, display, video, and custom ads—leverage Amazon’s innovations and insights...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
As the Data Engineer for this amazing corporate Insurance company, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL, together...
See more: Engineer jobs
As a data engineer within the exciting, new claims advanced analytics capability, you will be building big data solutions to solve some of the organization’s toughest problems and delivering significant business value. This is a really exciting time to...
See more: Engineer jobs
Data Engineer - 70,000 Job Description An AWS Partner based in Central London is looking to expand the data side of their business due to growth. They are looking for Data Engineers with significant commercial experience ingesting large quantities of data...
See more: Engineer jobs
As the Data Engineer for this amazing corporate Insurance company in the City, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
DATA ENGINEER - TEMPORARILY REMOTE 400- 450 PER DAY 3 MONTH CONTRACT EUROPE BASED As a Data Engineer you will be working heavily with Scala and Spark to improve the quality of data. THE COMPANY: You will be working for dynamic data driven company. As a...
See more: Engineer jobs
40'000- 50'000 Pension 8% Technical Progression Healthcare Holidays More Horley, Surrey Are you seeking a new challenge within a rapidly expanding Eco-Energy Tech company where you will be having huge technical autonomy in building a data preform right...
See more: Engineer jobs
Data Engineer Portsmouth and surrounding areas encouraged to apply, multiple office locations Data Engineer required for established, international business. The business is at the forefront of new technologies working with leading Government organisations...
See more: Engineer jobs
Data Engineer A brand new role has arisen for an experienced Database / BI Developer to take the next step in their career and transition into a full Data Engineer to work for one of the most recognisable NGO's in London. We are looking for someone with...
See more: Engineer jobs
Role: Data Engineer Client: Government agency (BPSS will be required) Location: Glasgow Duration: 8 Months Rate: 400 per day (outside IR35) Note: The office is based in Glasgow city centre. It is expected that the consultant would be available for physical...
See more: Engineer jobs
Data Engineer Opus are working with an excellent niche software development company in Newcastle. The company is at the forefront of their industry and due to their on-going success are now looking for a Data Engineer to take responsibility for organising...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
A leading Insurance Company are currently recruiting for a Data Engineer to join their dynamic and growing business. They are looking to hire a cross functional, highly tenacious and bright Data Engineer with a passion for functional programming. The ideal...
See more: Engineer jobs
Data Engineer- 50K Manchester Adria Solutions has an exciting opportunity for a talented Data Engineer to join our rapidly expanding client based near Manchester. The role requires you to work closely with other members of the data team and stakeholders...
See more: Engineer jobs
Data Engineer - 6 months - Ware - Hertfordshire Global FMCG is looking for an experienced Data Engineer who will play a pivotal role in operationalizing data and analytics initiatives for digital business initiatives. The bulk of the data engineer's work...
See more: Engineer jobs
We are currently recruiting a highly motivated Data Engineer, for a company who are based in London. The Data Engineer will help develop and maintain the business. The Data Engineer will be responsible for the following; Key responsibilities- - Working...
See more: Engineer jobs
Data Engineer - I am currently recruiting for a Data Engineer based in Bath. The role would be on a permanent basis and is paying 40,000 to 45,000 (There could be flex for the right candidate) PA plus a variety of excellent benefits as well as the flexibility...
See more: Engineer jobs
Data Engineer - London - 550-600 per day - 6 month contract SearchData is currently looking to recruit a Data Engineer to work on a cutting-edge DWH project in the financial services industry. As the Data Engineer your role will be to take a leadership...
See more: Engineer jobs
Data Engineer - REMOTE WORK If you are a strong Data Engineer, with experience working with Python, R and SQL then this role is ideal. I am working with a large organisation that are market leaders in their respected field. This role will report in to...
See more: Engineer jobs
Data Engineer London 55,000 - 65,000 Benefits Our client, an exciting RegTech business is looking to recruit for a Data Engineer to join their growing team. The successful candidate will be joining the artificial intelligence team, working on a brand new...
See more: Engineer jobs
An exciting opportunity for an experienced Data Engineer has arisen in Leeds. After hiring a number of new members of staff at the end of 2019, the organisation are continuing to expand due to winning more projects. Key responsibilites include: Building...
See more: Engineer jobs
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
See more: Engineer jobs
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
See more: Engineer jobs
",http://www.reed.co.uk/jobs/data-engineer/39801564
JOB175357782591,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-lu/details/200188037/ai-ml-search-data-engineer-siri-data
JOB175827639258,Senior Data Engineer,Senior Data Engineer,"Minimum of five years data analytics, programming, database administration, or data management experience.",,"Core Responsibilities
1. Writes ETL (Extract / Transform / Load) processes, designs database systems, and develops tools for real-time and offline analytic processing.
2. Troubleshoots software and processes for data consistency and integrity. Integrates large scale data from a variety of sources for business partners to generate insight and make decisions.
3. Translates business specifications into design specifications and code. Responsible for writing complex programs, ad hoc queries, and reports. Ensures that all code is well structured, includes sufficient documentation, and is easy to maintain and reuse.
4. Partners with internal clients to gain an enhanced understanding of business functions and informational needs. Gains expertise in tools, technologies, and applications/databases in specific business areas and company-wide systems.
5. Leads all phases of solution development. Explains technical considerations at related meetings, including those with internal clients and less experienced team members.
6. Tests code thoroughly for accuracy of intended purpose. Reviews end product with the client to ensure adequate understanding. Provides data analysis guidance as required.
7. Designs and conducts training sessions on tools and data sources used by the team and self provisioners. Provides job aids to team members and business users.
8. Tests and implements new software releases through regression testing. Identifies issues and engages with vendors to resolve and elevate software into production.
9. Participates in special projects and performs other duties as assigned.
Qualifications
Minimum of five years data analytics, programming, database administration, or data management experience.
Undergraduate degree or equivalent combination of training and experience.
Vanguard is not offering visa sponsorship for this position.
About Vanguard
We are Vanguard. Together, we’re changing the way the world invests.
For us, investing doesn’t just end in value. It starts with values. Because when you invest with courage, when you invest with clarity, and when you invest with care, you can get so much more in return. We invest with purpose – and that’s how we’ve become a global market leader. Here, we grow by doing the right thing for the people we serve. And so can you.
We want to make success accessible to everyone. This is our opportunity. Let’s make it count.
Inclusion Statement
Vanguard’s continued commitment to diversity and inclusion is firmly rooted in our culture. Every decision we make to best serve our clients, crew (internally employees are referred to as crew), and communities is guided by one simple statement: “Do the right thing.”
We believe that a critical aspect of doing the right thing requires building diverse, inclusive, and highly effective teams of individuals who are as unique as the clients they serve. We empower our crew to contribute their distinct strengths to achieving Vanguard’s core purpose through our values.
When all crew members feel valued and included, our ability to collaborate and innovate is amplified, and we are united in delivering on Vanguard’s core purpose.
Our core purpose: To take a stand for all investors, to treat them fairly, and to give them the best chance for investment success.
Apply Now
",https://technical.ly/job/vanguard-senior-data-engineer-59699/
JOB177040694090,Data Engineer,Data Engineer,,,"
Job title: Data Engineer Location : Zurich. Switzerland Job type : Contract Data Engineer with Hadoop/Apache Sparc Knowledge - - Build a data processing layer based on Hadoop,Spark, Neo4J - Ensure appropriate security processes are integrated with access...
Data Engineer We have had a role come available for a Data Engineer in London. The role will require you to either hold a DV Clearance. Key Experience: Data Analysis experience; Strong SQL skills; Data Processing using ETL tools; Understanding of procurement...
Data Engineer / Data Scientist / Biomedical Informatics / Human Genetics / Python / SQL / R / Oxford / Cambridge / Permanent 60 - 90K (Depending on Experience) Excellent Benefits COVID Safe Interview Process 100% Remote during Covid and up to 50% Post...
Data Engineer - Contract - Remote Based Data Engineer Until end November 2020 initially Remote Based (Office is based in Chester) Competitive pwd Ltd Company Tech Skills Required: ETL Design, Talend, MYSQL, Vertica We are currently looking for a Data Tester...
Data Engineer - Contract - Remote Based Data Engineer Until end November 2020 initially Remote Based (Office is based in Chester) Competitive pwd Ltd Company Tech Skills Required: ETL Design, Talend, MYSQL, Vertica We are currently looking for a Data Tester...
Site Name: UK - London - Brentford, USA - Pennsylvania - Upper Providence Posted Date: Jun 4 2020 Are you looking for a challenging opportunity to work in an area where cutting edge science meets cutting edge technology with an aim of delivering drugs...
Site Name: UK - London - Brentford, USA - North Carolina - Research Triangle Park, USA - Pennsylvania - Philadelphia Posted Date: Mar 17 2020 Data Engineer is accountable for developing and delivering cloud-based data ingestion solutions across the Pharma...
Urgent Requirement for Azure Data Engineer Someone with 2-3 yrs experience within the data field and proven record of accomplishment of developing and designing technical solutions using cloud platforms such as Microsoft Azure to deliver analytics-driven...
Remote working. Up to 550 p/day. SQL Server, SSIS, AWS 6-month contract opportunity for a Senior Data Engineer with financial services experience. What you'll be doing Working for a large financial services client, you will work in a team of data engineers...
LEAD DATA ENGINEER LONDON, CURRENTLY FLEXIBLE / REMOTE / HOME WORKING UP TO 100,000 BENEFITS BONUS Harnham are partnered with an exciting tech scale up based in Central London. They are looking for an experienced data engineer to lead the build of a greenfield...
Senior Data Engineer - Permanent Data Idols are working with a well known Technology company who are looking for a Senior Data Engineer to join a cross-functional team. This industry disruptor has been changing the way people interact with an everyday...
THE COMPANY Leading telecommunication company who are looking to improve their Data Engineering function. My client is looking for a data engineer to join their team of world class engineers and Data Scientists to build end-to-end applications that make...
Our client, a global travel company require a Digital Data Engineer with strong GCP/ Big Query skills to join their analytics engineering team. Your Role You will be responsible for developing reporting infrastructure and providing actionable reporting...
Supporting a fast growing, global organisation the Interim Data Engineer will become a business partner to a newly established international client. You will be responsible for the following: - Building reporting architectures and pipelines for streamed...
Data Engineer Quantitative Trading - London One of the world's leading online CFD and financial spread betting providers is looking for a talented Data Engineer to join their business in London and support Data Science team. ROLE AND RESPONSIBILITIES -...
A Global leading company is currently recruiting for a Big Data Engineer that has experience with Python, SQL, Spark and Tableau. Based in Preston. Experience and skills required: Python (2-8 years) SQL Spark Tableau Demonstrated experience in Analytics/Big...
Digital Data Engineer 500 per day 3-months Remote/London As a Data Engineer, you will be helping with a Digital Transformation project, in setting up a Google Big Query data warehouse. THE COMPANY: This company specialise in the travel industry and are...
An exciting opportunity has opened up in Mechelen, Belgium for a Big Data Engineer. Skills and experience required: Scala Spark Kafka HLD, DLD and e2e ownership for Big Data projects Proficient in requirement gathering This is a 9-month contract. Salt...
Data Engineer Cutting edge machine learning Mission led start-up Crucial hire An established mission-led start-up is currently looking for an experienced Data Engineer/Software Engineer to join their team on an initial 3-month contract to extend/go permanent...
Python Software Engineer / Developer (PostgreSQL) Remote Interview. Are you a bright, motivated Python Software Engineer looking to work on complex, data centric systems whilst continually learning and gaining valuable knowledge of financial trading systems?...
Big Data Engineer Must be security cleared 45,000 - 55,000 Home working initially but candidate must be able to commute to Croydon / Kent in time If you are interested in working with sophisticated data to solve real world problems within a focused and...
DATA ENGINEER 400- 500 PER DAY 3 MONTH CONTRACT FULLY REMOTE As a Data Engineer you will have the chance to work for a online retail client using SQL heavily and DBT for modelling. THE COMPANY: As a Data Engineer, you will be working for an exciting online...
An award-winning sports marketing agency are recruiting a Lead Azure Data Engineer in their Central London office, to lead on the design and delivery of cutting-edge solutions. They currently employ around 200 professionals across Europe and North America...
DATA ENGINEER 400- 500 PER DAY 3 MONTH CONTRACT FULLY REMOTE As a Data Engineer you will have the chance to work for a media company using Big Query, Airflow and Python for ETL work. THE COMPANY: As a Data Engineer, you will be working for a well known...
Are you a seasoned professional with prior data center construction experience? Do you have a deep knowledge of electrical systems? Looking for a new opportunity? An exciting opportunity to become the subject matter expert for the electrical systems within...
",https://www.reed.co.uk/jobs/data-engineer/40281571
JOB177143017696,Senior Data Engineer,Senior Data Engineer,"Degree educated in Data Science or similar,Strong experience with data preparation techniques including exploration and visualisation,Experience with statistical models, times series analysis and multiple machine learning techniques such as clustering, regression and classification,Strong skills using Python, SQL & Elastic and visualise the data in a surfacing tool,Experience developing machine learning systems,Experience in Amazon Quicksite will be an advantage","Provide analytical and statistical expertise to company.,Become familiar with a range of data sets, looking at raw customer data, financial data and marketing data.,Experiment with algorithms, machine learning and data exploration in order to build solutions and tools for data-driven purposes.,Perform clustering analysis on customer data, along with segmentation and clustering.,Present and tell the story of the data to clients.,Support in the creation of real time reporting using Kibana.,Own recommendation engines and machine learning systems.,Own reporting data flows include ETL processes,Perform updates to production databases","
Currently looking for a Senior Data Engineer for Australia's Leading cashback website, Data Preparation, Python, SQL, Amazon Quicksite, Chatswood
Sydney
We are currently looking to engage a Senior Data Engineer who can support an enterprise wide program of work for one of Australia's largest cashback sites.
This organisation is the 4 th fastest tech company within the Asian region and according to Deloitte is the fasting growing tech company within Australia.
Working as part of a well-established and high performing team, you will be required to innovate and develop new ways in which companies can engage with their customers on a more personal level, looking to drive satisfaction, return on investment, customer conversion rate but most importantly unlocking the value of their data in order to grow and improve clients.
Role Responsibilities:
Provide analytical and statistical expertise to company.
Become familiar with a range of data sets, looking at raw customer data, financial data and marketing data.
Experiment with algorithms, machine learning and data exploration in order to build solutions and tools for data-driven purposes.
Perform clustering analysis on customer data, along with segmentation and clustering.
Present and tell the story of the data to clients.
Support in the creation of real time reporting using Kibana.
Own recommendation engines and machine learning systems.
Own reporting data flows include ETL processes
Perform updates to production databases
Experience Requirements:
Degree educated in Data Science or similar
Strong experience with data preparation techniques including exploration and visualisation
Experience with statistical models, times series analysis and multiple machine learning techniques such as clustering, regression and classification
Strong skills using Python, SQL & Elastic and visualise the data in a surfacing tool
Experience developing machine learning systems
Experience in Amazon Quicksite will be an advantage
If you are interested in the role, please apply or send updated resume to Ra'id at rahmad@paxus.com.au
To be considered for the role click the 'Apply' button or for more information about this and other opportunities please contact Ra'id Ahmad on 02 9464 5554. Please quote our job reference number: 200167644.
Reference Number: 200167644_1
Contact Details:
How to Apply?
Click on the link below
Click here for more information about this job
",https://www.computerworld.co.nz/jobs/view/23527/senior-data-engineer/
JOB177197889460,Senior Data Engineer,Senior Data Engineer,"The stated experience level is a guide and does not preclude applications from candidates with more or less experience, provided the requisite skills can be demonstrated.",," Funding Circle brings together small businesses and investors in a way that is truly revolutionary. Our mission is to foster an environment where small business can thrive. Our online platform provides a marketplace where investors receive better returns and small businesses find lower rates. The driving force behind our product is our engineering team; we are building elegant, sustainable, and scalable infrastructure on a global scale, and we want you to be a part of it! Our mission: to build a better financial world.
Prospectus :
Would you describe yourself as a data fanatic? Do you have a passion for integrating and analysing data sources to help your company make better decisions faster? If you answer yes to these questions then we're looking for you to join our team! Funding Circle’s Data Team are looking for a Senior Data Engineer to help build and transform FC UK’s data warehouse.
The right person will be:
An enthusiast - you understand what a good data warehouse can bring to a business and what it takes to build one.
A communicator - you can communicate effectively to engineers as well as business users.
A builder - you are experienced in all stages of warehouse development, from data modelling to building out comprehensive ETL.
A pathfinder - you are interested in solving problems today while helping shape strategic direction for the months and years ahead.
A thinker - you have an inquisitive mindset and the desire and ability to turn business requirements into working software.
An owner - you’ll take pride and ownership in the quality of the work you and the team produce.
The UK data team are part of a global team tasked with building and maintaining the data platform that supports analytics and reporting for FC. Our stakeholders are from every area of the business - from teams tracking performance, through BI specialists to data scientists. We have identified data as one of our key strategic assets and so this role is one in which you can make a visible impact on the business.
The ideal candidate will have:
7+ years in a development and data engineering role preferably in tech, consulting, or finance.*
Extensive hands-on experience with SQL (we use Postgres).
Strong programming skills (Python, Java, Ruby, Scala, Clojure; we love them all).
Familiarity with AWS stack including EMR, Lambda & EC2.
Proficiency using large data sets and relational and dimensional modeling.
Expertise in a Unix environment.
Experience with messaging and streaming platforms (Kafka/RabbitMQ/JMS/etc.).
Exposure to big data/NoSQL systems and the issues that arise from working with large data sets.
A self-starter attitude with an enthusiasm to work in a fast-paced, team-oriented, start-up environment.
Bonus points for:
Engineering/CS or Finance degree.
Experience in virtualized environments (Mesos, Marathon, Chronos, Docker, etc.).
Skills working with structured and unstructured data sets.
Microservice architecture development experience.
The stated experience level is a guide and does not preclude applications from candidates with more or less experience, provided the requisite skills can be demonstrated.
Other jobs you may like
",https://www.indeed.co.uk/job/Senior-Data-Engineer-at-Funding-Circle-UK-in-London-2388f2a96fd2a817
JOB179074604012,Senior Data Engineer,Senior Data Engineer,,"Building SQL models that transform raw data into actionable insights,Managing graph-oriented workflows in Python to automate repetitive tasks,Communication with technical and non-technical audiences, and ability to translate between the domains of business problems and implementations,Team-oriented development: building modular & re-usable tools, writing maintainable code, owning technical and business documentation,Extend the Operating Model to accommodate new product offerings and support our expansion to new markets,Identify bottlenecks and improve scalability to support our growing customer base,Improve data governance and quality control to pre-empt data quality issues in critical systems.,Cultivated familiarity with Inspire’s frameworks & operating model,Delivery of high-quality pull requests, evidencing strong code standards & testing practices,High quality documentation for both technical and non-technical audiences,Comfort with self-directed project management: requiring minimal oversight to assess a problem, formulate a solution, deliver code, and document changes.,Analytical: Able to develop a keen understanding of the problem before deciding on a solution,Curious: Desire to understand the underpinnings of complex business processes in order to design the correct technical solution,Determined: Able to focus on the problem at hand and deliver a complete solution quickly.,Open minded: Incorporates new information quickly in a fast changing environment; willing to take input from others.,4+ years experience working with Python in a data intensive application,1-2 years working with Apache Spark,4+ years experience with the software development life cycle (git, Pull Requests, Code Reviews, Testing, etc),Strong SQL experience working with large complex datasets,Experience working in the energy industry,Experience working with financial data and complex financial models,Experience with Machine Learning tools and techniques, understanding how models make decisions from data,Experience with key technologies: Snowflake, dbt, Airflow,Experience at a similar scale of data processing (Multi-TB/billions of rows),Experience with containerized development using Docker, Kubernetes,Experience with technical communication to audiences of diverse backgrounds","Inspire is a clean energy technology company on a mission to transform the way consumers access clean energy and to accelerate the world’s transition to a net-zero carbon future.
We provide our customers with access to renewable energy from wind, solar, and hydro powered sources without service interruptions or costly installations at a flat, predictable monthly rate. For every year that a customer spends with Inspire Clean Energy, they have a greater impact on climate change than 10 years of strict recycling.
Our rapidly growing team of mission-driven, climate enthusiasts is passionate, innovative and committed to a better future for the planet.
SENIOR DATA ENGINEER SUMMARY
As a Sr. Data Engineer on our Operating Model Team, your work will help drive down costs, manage risk, accelerate growth and improve our member experience — broadening access to clean energy as we grow to new markets, and enabling new products that accelerate a net zero carbon future.
Inspire’s Operating Model is the heart and the brain of our clean energy platform — tracking and forecasting costs and revenues as the source of truth for key stakeholders across the business to make decisions about growth, optimization and strategy.
You will work closely with executive stakeholders alongside machine learning engineers and data scientists to apply sophisticated modeling techniques on a modern data stack to predict and build the future of energy usage and customer engagement.
THE SENIOR DATA ENGINEER HAS 5 MAIN RESPONSIBILITIES
Building SQL models that transform raw data into actionable insights
Managing graph-oriented workflows in Python to automate repetitive tasks
Communication with technical and non-technical audiences, and ability to translate between the domains of business problems and implementations
Team-oriented development: building modular & re-usable tools, writing maintainable code, owning technical and business documentation
Working with our Data Science and ML Engineering Team to provide high-fidelity datasets for our machine learning algorithms and assess and understand the performance of our ML Models
SOME YEAR 1 DELIVERABLES
Extend the Operating Model to accommodate new product offerings and support our expansion to new markets
Identify bottlenecks and improve scalability to support our growing customer base
Improve data governance and quality control to pre-empt data quality issues in critical systems.
Work with our Applied Modelling team to ensure quality and reliability as we introduce increasingly sophisticated machine learning algorithms into our Operating Model
SUCCESS METRICS
Cultivated familiarity with Inspire’s frameworks & operating model
Delivery of high-quality pull requests, evidencing strong code standards & testing practices
High quality documentation for both technical and non-technical audiences
Comfort with self-directed project management: requiring minimal oversight to assess a problem, formulate a solution, deliver code, and document changes.
Positive interactions with department stakeholders: guidance and input that creates business value for non-technical personnel; feedback on priorities, status, and estimates that create transparency and build trust.
DESIRED TRAITS
Analytical: Able to develop a keen understanding of the problem before deciding on a solution
Curious: Desire to understand the underpinnings of complex business processes in order to design the correct technical solution
Determined: Able to focus on the problem at hand and deliver a complete solution quickly.
Open minded: Incorporates new information quickly in a fast changing environment; willing to take input from others.
Growth Mindset: Looking for challenges and opportunities to develop new skills and acquire knowledge.
EXPERIENCE
Must Have
4+ years experience working with Python in a data intensive application
1-2 years working with Apache Spark
4+ years experience with the software development life cycle (git, Pull Requests, Code Reviews, Testing, etc)
Strong SQL experience working with large complex datasets
Proficiency working with the command line
Nice to Have
Experience working in the energy industry
Experience working with financial data and complex financial models
Experience with Machine Learning tools and techniques, understanding how models make decisions from data
Experience with key technologies: Snowflake, dbt, Airflow
Experience at a similar scale of data processing (Multi-TB/billions of rows)
Experience with containerized development using Docker, Kubernetes
Experience with technical communication to audiences of diverse backgrounds
Experience with problem solving and exploratory data analysis
Apply Now
",https://technical.ly/job/inspire-senior-data-engineer-72506/
JOB179316533771,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/pt-pt/details/200188037/ai-ml-search-data-engineer-siri-data
JOB179652995646,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-gb/details/200188037/ai-ml-search-data-engineer-siri-data
JOB180157406060,Security Cleared Big Data Engineer,Security Cleared Big Data Engineer,,," Security Cleared Big Data Engineer Salary: Competitive DOE Benefits Location: Croydon / Kent and WFH VR/02776R For this role we are looking for a Big Data Engineer who is SC Cleared. We would also consider candidates who should be eligible for SC Clearing...
",https://www.reed.co.uk/jobs/data-engineer-security-cleared/40402062
JOB181209009535,"Data Engineer - Senior Consultant - Manager, Strategy and Transactions","Data Engineer - Senior Consultant - Manager, Strategy and Transactions",,,"
Data Engineer - Senior Consultant - Manager, Strategy and Transactions
Remote, full-time. Evaluate and select data tools for warehouse administration, design and test features, coordinate with teams on data harvesting projects, and develop best practices for department. Requires 2 years work with data mapping and Azure.
Job Details
Option for Remote
Employee
Flexible Schedule, Full-Time
Experienced
No specification
Health Insurance, Paid Vacation, Maternity Leave
Company name here
Other benefits listed here
Create an Account to Unlock
To find out more about or apply to this Data Engineer - Senior Consultant - Manager, Strategy and Transactions job—and other great opportunities like it—become a FlexJobs member today!
With FlexJobs, you'll find the best flexible jobs and fantastic expert resources to support you in your job search. If you have any questions, please feel free to contact us.
Get new job postings, the latest job search tips, trends, news, and exclusive promotions!
",https://www.flexjobs.com/publicjobs/data-engineer-senior-consultant-manager-strategy-and-transactions-1293730
JOB181367063390,Senior Data Engineer (Remote),Senior Data Engineer (Remote),,,"
Calance US
Calance is a recognized leader in providing top-tier Information Technology professionals across North America. With over 25 years of experience recruiting professionals ranging from Programmers to CIOs, Calance provide valuable staffing solutions for short and long term projects, as well as your permanent hiring needs. Our professionals are experts at helping organizations realize their information technology goals by selecting the best talent for each project or position. Calance helps clients respond quickly to economic, strategic or technological changes by utilizing a flexible workforce. We offer highly-skilled professional IT consultants on a temporary or project basis. Consultants are employees of Calance while on assignment for the client, allowing for cost savings, risk management and operational benefits. Calance's Contract-to-Hire option allows an IT organization to evaluate an individual before making a decision to bring them on as a full-time employee. Depending on the length of the temporary assignment, placement fees are waived or reduced. Calance realizes that IT organizations often have needs for talented people to fill specific roles and that filling those needs can be challenging. Our highly experienced Account Managers and recruiting staff work closely with our clients to determine the desired skills, background and traits required for the position. We apply our unique recruiting methodology to locate and recruit the most highly qualified candidates to match the requirements of your full-time employee position. Calance can assist in every step of the hiring process, from determining the exact job requirements to final negotiations, to help bring on-board the candidates you need.
","https://www.ziprecruiter.com/c/Calance-US/Job/Senior-Data-Engineer-(Remote)/-in-East-Township,NY?jid=Q328a992b-9f202f28"
JOB183518784031,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-jp/details/200188037/ai-ml-search-data-engineer-siri-data
JOB184542485367,Spark Data Engineer (with Databricks experience) Required - 3-6 months+ - Leeds,Spark Data Engineer (with Databricks experience) Required - 3-6 months+ - Leeds,,"Apache Spark,Databricks,Data,Spark","
Our consultancy client is urgently seeking a Spark Data Engineer, with experience of Databricks, to assist with their new project. The role is develop the datapath pipeline for the data access environment.
Skills/Experience Required:
Apache Spark
Databricks
Python (desirable)
Duration - 3-6 months initially
Location - Leeds
Start - ASAP
If you would be interested in applying for this role, please apply asap!
Reference: 39764632
Bank or payment details should never be provided when applying for a job. For information on how to stay safe in your job search, visit SAFERjobs.
Report this job
",https://www.reed.co.uk/jobs/spark-data-engineer-with-databricks-experience-required-3-6-months-leeds/39764632
JOB185557068299,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-tr/details/200188037/ai-ml-search-data-engineer-siri-data
JOB185693297645,Data Engineer,Data Engineer,,"Develop, test and maintain data architecture.,Design and implement secure data pipelines to prepare, process, ingest and organize data into data data lake / data warehouse from disparate on-premise and cloud data sources.,QA and troubleshoot performance of data pipelines and queries accessing data warehouse,Clean, transform and model data to power our analytics and user facing products,Ensure proper data governance and privacy practices,Partner with Analytics team on buildout of advanced data products,Capable coder with Python, Scala, and R,Familiar with modern, cloud-native, scalable ETL solutions/tools, ex: Informatica, Stitch/Talend, Mulesoft/Salesforce, etc…,Experience with workflow orchestration principles & platforms (DAGs, Airflow, DBT, Luigi, Dagster, Prefect, etc…),Prefer experience with Google Cloud Platform(Bigquery, Dataproc, Dataflow, Pub/Sub, etc…). Experience with AWS (DynamoDb, Kinesis Stream, etc…) is a plus,Building an analytic engine, segmentation and grouping data,Experience writing scripts to automate the provisioning and maintenance of systems in a distributed, virtualized infrastructure,Familiarity with managed cloud-based options for building machine learning models,RDBMS database development using SQL queries and stored procedures","Job Summary
The Data Engineer will focus on modernizing, building out and maintaining our data technology infrastructure and processes. Processes include ETL tasks, data modeling and manipulation, and building out data pipelines to power our applications and products. The role is a unique opportunity to create and shape the technology, methods and data related processes.
What You’ll Do
Develop, test and maintain data architecture.
Design and implement secure data pipelines to prepare, process, ingest and organize data into data data lake / data warehouse from disparate on-premise and cloud data sources.
QA and troubleshoot performance of data pipelines and queries accessing data warehouse
Clean, transform and model data to power our analytics and user facing products
Ensure proper data governance and privacy practices
Partner with Analytics team on buildout of advanced data products
Assist with automation and orchestration
Who We’re Looking For
Capable coder with Python, Scala, and R
Familiar with modern, cloud-native, scalable ETL solutions/tools, ex: Informatica, Stitch/Talend, Mulesoft/Salesforce, etc…
Experience with workflow orchestration principles & platforms (DAGs, Airflow, DBT, Luigi, Dagster, Prefect, etc…)
Prefer experience with Google Cloud Platform(Bigquery, Dataproc, Dataflow, Pub/Sub, etc…). Experience with AWS (DynamoDb, Kinesis Stream, etc…) is a plus
Building an analytic engine, segmentation and grouping data
Experience writing scripts to automate the provisioning and maintenance of systems in a distributed, virtualized infrastructure
Familiarity with managed cloud-based options for building machine learning models
RDBMS database development using SQL queries and stored procedures
Nice to have experience with ElasticSearch, DataDog, Serverless microservices
Apply Now
",https://technical.ly/job/the-philadelphia-inquirer-data-engineer-66640/
JOB185811724845,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-ro/details/200188037/ai-ml-search-data-engineer-siri-data
JOB186462264179,Data Engineer,Data Engineer,,"Experience working on cloud-based platforms such as AWS,Expertise with Python,Have worked with streaming technologies such as Spark and Kafka,Exposure to liaising with senior stakeholders","
Data Engineer
Central London
6-month Contract
£550 per day
As a Big Data Engineer, you are required to implement technologies to ingest real-time data and build Data Science models. You will be working for the global leading advertising technology company.
THE COMPANY:
This company are tremendously data-driven and base their success around the technologies that they use to market their product. They use data taken from their customers' locations to tailor their advertising so that their clients can see who to advertise to. They use some of the most advanced technology in the market to keep track of this data.
THE ROLE:
As a Data Engineer, you will be joining their Data team to support the Data Scientists, build their models to predict the necessary products to advertise based on their customers' locations. You are required to implement the real-time technologies such as PySpark and Kafka to cope with the vast volume of data that is ingested each second. You will be working on an AWS platform, so it is ideal that you are familiar with this cloud-based technology and the ability to model data warehouses using DBT and Databricks.
YOUR SKILLS AND EXPERIENCE:
The ideal Data Engineer will have:
Experience working on cloud-based platforms such as AWS
Expertise with Python
Have worked with streaming technologies such as Spark and Kafka
Exposure to liaising with senior stakeholders
Data modeling skills using DBT
HOW TO APPLY:
Please register your interest by sending your CV via the Apply link on this page.
Reference: 39711960
Bank or payment details should never be provided when applying for a job. For information on how to stay safe in your job search, visit SAFERjobs.
Report this job
",https://www.reed.co.uk/jobs/data-engineer/39711960
JOB186603674474,Data Engineer,Data Engineer,,,"
Data Engineer X 2 – Manchester. Our client based near Manchester are currently looking for 2 Data Engineers with Azure experience. The company is currently going through a large digital transformation, they are looking for talented Data specialist to help...
Job Title: Data Engineer Salary: 45,000 to 54,000 plus Benefits Location: Cambridge This is a very rare opportunity for an experienced Data Engineer with a strong background in building Python based data processing pipelines to join a company that are...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
As a data engineer within the exciting, new claims advanced analytics capability, you will be building big data solutions to solve some of the organization’s toughest problems and delivering significant business value. This is a really exciting time to...
Data Engineer - 70,000 Job Description An AWS Partner based in Central London is looking to expand the data side of their business due to growth. They are looking for Data Engineers with significant commercial experience ingesting large quantities of data...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Title: Data Engineer Our client is currently looking for a Data Engineer to play a vital role in the continual development of our digital transformation strategy and earth science analytics. Candidates must have Python, R and SQL. We expect candidates...
Job title: Data Engineer Location : Zurich. Switzerland Job type : Contract Data Engineer with Hadoop/Apache Sparc Knowledge - - Build a data processing layer based on Hadoop,Spark, Neo4J - Ensure appropriate security processes are integrated with access...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer - Manchester A growing business based in Manchester City Centre are currently looking for a Data Engineer to help shape their newly formed Data Engineering team and build scalable, reliable and secure cloud datawarehouse solutions and data...
Data Engineer - Python - Permanent Data Idols are working with a well-known client in the e-commerce space who are looking for a Data Engineer to join an existing team. THE ROLE As a Data Engineer, you will be working with the existing Data team to help...
An exciting start up Fintech company has a new opportunity for a Data Engineer where you will play an active part in the success of the company. This role will see you joining a small team where you'll have the opportunity to take responsibility for Data...
Data Engineer Location: Petersfield Salary: 30,000 - 40,000 P/A Hours: Flexible Dynamite Recruitment is delighted to be recruiting a Data Engineer for a global organisation in Petersfield This is an exciting opportunity for an experienced individual to...
Job title : Data Engineer Location: London Job type: Permanent Salary: Up to 70,000 per annum Reporting to: Head of Data Engineering Overview A fantastic internet company based in Central London are currently looking for a Data Engineer to come on board...
Data Engineer We have had a role come available for a Data Engineer in London. The role will require you to either hold a DV Clearance. Key Experience: Data Analysis experience; Strong SQL skills; Data Processing using ETL tools; Understanding of procurement...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer- 50K Manchester Adria Solutions has an exciting opportunity for a talented Data Engineer to join our rapidly expanding client based near Manchester. The role requires you to work closely with other members of the data team and stakeholders...
Data Engineer / Data Scientist / Biomedical Informatics / Human Genetics / Python / SQL / R / Oxford / Cambridge / Permanent 60 - 90K (Depending on Experience) Excellent Benefits COVID Safe Interview Process 100% Remote during Covid and up to 50% Post...
",https://www.reed.co.uk/jobs/data-engineer/40314087
JOB187341249510,Data Engineer,Data Engineer,"3+ years professional experience as a Data Engineer,Experience in software engineering or operations in a full-stack development environment,Proficiency in Python, SQL,Experience with Airflow or similar tools,Experience with DBT or similar tools,Experience with API integration to automate business processes, and enhance the sharing and embedding of data between various applications and systems,Experience with cloud platforms, preferably AWS (eg. Redshift, Lambda, Glue, Kinesis, DynamoDB, S3, etc.),Experience provisioning services using Docker, Kubernetes with Terraform, Cloudwatch, GitHub, etc.,Ability to convert complex problems into concrete requirements and build innovative solutions,Ability to communicate clearly, efficiently, and empathetically with technical and non-technical stakeholders","Developing and testing ELT pipelines for our various batch data processes across multiple data sources.,Building a data platform upon which other tools and internal services can sit upon,Bolstering our data governance systems and ensuring customer data is secured,Conceive, plan, and prioritize data projects with the team lead and Director of Data,Work closely and collaboratively with Product, Data Science, Business Intelligence, and many other teams to provide internal data services,Build, improve, and maintain ELT pipelines and help scale our data warehouse,Improve the foundations of our streaming data capabilities","Overview
Penn Interactive (PI) is a real-money interactive gaming company headquartered in Philadelphia with offices in Cherry Hill, NJ and Las Vegas, NV. As the digital arm of Penn National Gaming (NASDAQ: PENN), the largest regional casino operator in the U.S., we are poised for fast-paced growth in the sports betting and online casino space.
We are looking for a Data Engineer to join the Data team. The Data Engineering team here at Penn is responsible for building the data platform to power the Barstool sportsbook product from top to bottom. We are looking for someone who is capable of contributing to the design, scaling, development of ELT pipelines, stream processing solutions, and data APIs to create a world class data-centric product experience. We want to build tools and utilities to make the Barstool Sportsbook more fun and engaging for our users while at the same time creating industry leading tooling around responsible gaming to keep our users safe!
What you’ll be working on
Developing and testing ELT pipelines for our various batch data processes across multiple data sources.
Building a data platform upon which other tools and internal services can sit upon
Bolstering our data governance systems and ensuring customer data is secured
Laying the groundwork more more real-time streaming data solutions
Your daily responsibilities include
Conceive, plan, and prioritize data projects with the team lead and Director of Data
Work closely and collaboratively with Product, Data Science, Business Intelligence, and many other teams to provide internal data services
Build, improve, and maintain ELT pipelines and help scale our data warehouse
Improve the foundations of our streaming data capabilities
Write and maintain Terraform to safely deploy tools and services
Qualifications
3+ years professional experience as a Data Engineer
Experience in software engineering or operations in a full-stack development environment
Proficiency in Python, SQL
Experience with Airflow or similar tools
Experience with DBT or similar tools
Experience with API integration to automate business processes, and enhance the sharing and embedding of data between various applications and systems
Experience with cloud platforms, preferably AWS (eg. Redshift, Lambda, Glue, Kinesis, DynamoDB, S3, etc.)
Experience provisioning services using Docker, Kubernetes with Terraform, Cloudwatch, GitHub, etc.
Ability to convert complex problems into concrete requirements and build innovative solutions
Ability to communicate clearly, efficiently, and empathetically with technical and non-technical stakeholders
Bonus: Experience in any of Tableau, Mode, Datadog, Looker, ThoughtSpot, etc
Something to leave you with
Penn Interactive is committed to helping our team members live their best, healthy life. We offer unique and competitive benefits that help our employees, through a private exchange which allows our team members the ability to choose from several coverage levels and insurance carriers (both local and national carriers). Along with medical, prescription, dental, and vision coverage, there are also voluntary plans available to employees. PI also offers our employees office perks such as free catered lunches, snacks, and beverages in the office.
Apply Now
",https://technical.ly/job/penn-interactive-data-engineer-75152/
JOB189135209343,Senior Data Engineer,Senior Data Engineer,"Bachelors degree in Computer Science, Computer Engineering, Applied Math, Statistics or related field,Certified Data Management Professional (CDMP) a plus,8+ years experience designing, building, and maintaining data management systems,Broad experience in planning, architecting, and delivering mission-critical enterprise-grade systems and solutions,Experience with cloud architecture and data repositories,Data design experience,Experience in data cleansing and optimization for data consumption,Experience with source control tools such as Git and TFS a plus,Experience in .Net framework and Web Services (SOAP, REST, XML) a plus,Experience with Azure Service Fabric and microservices a plus,Working familiarity of front-end web framework using C#, JavaScript and/or Angular a plus,Experience using CSV/JSON/XML data formats,Experience in developing LOB (Line of Business) Applications, as well as Consumer Websites,Experience in consumer-facing, ecommerce and mobile systems a plus,FREE 7-day resort stays and cruises on your anniversary,Medical Health Insurance,Onsite Wellness Clinic,Long Term Disability,Life Insurance,Dental & Vision Coverage,401K Plan,Pet Care Insurance,Legal Insurance,Flexible Spending Accounts (FSA),Employee Assistance Program,Discounted Employee Services (dry-cleaning, nail services, massage, personal training, etc.),Dedicated Employee Enrichment & Recognition Programs","Design, construct, install, test and maintain highly scalable data management systems,Ensure systems meet business requirements and industry best practices,Create and maintain data management documentation,Design and build scalable data repositories enabling high-performance of consumer/member transaction volume within the ICE products,Build APIs for data consumption and integration of external datasets as necessary,Build high-performance algorithms, prototypes, predictive models and proof of concepts,Problem-solve issues around data integration, unusable data elements, unstructured data sets, and other data management incidents,Research opportunities for data acquisition and new uses for existing data,Develop data set processes for data modeling, mining and production,Integrate new data management technologies and software engineering tools into existing structures,Create custom software components (e.g. specialized UDFs) and analytics applications,Employ a variety of languages and tools (e.g. scripting languages) to marry systems together,Install, implement and update disaster recovery procedures,Recommend ways to ensure continuous improvement around data reliability, efficiency and quality,Collaborate with data architects, modelers and IT team members on project requirements and goals,Collaborate with QA Engineers and Automation to build test plans, scripts and automation to verify and validate data management systems and production implementation,Able to identify and implement a data solution strategy,Skilled in working directly with senior business management to determine requirements and present options,Statistical analysis and modeling,Database architectures,SQL-based and NoSQL-based technologies,Data modeling tools (e.g. UML, ERWin, Enterprise Architect and Visio),Data warehousing solutions,Data mining,Demonstrates initiative with or without direct authority. Able to influence and advocate for approaches to problem solving,Demonstrates intellectual curiosity in exploring new territories and finding creative ways to solve data management problems,Supports and maintains positive attitude and vision with peers, associates, and management,Demonstrates effective teamwork and collaboration,Ability to prioritize competing or conflicting requests and execute tasks in a high-pressure environment,Utilizes good judgment,Must demonstrate ability to handle diversity amongst people and environments,Must be detail oriented and able to follow-up and follow-through on project actions and tasks,Ability to maintain confidentiality of sensitive information"," Job Description
About This Job:
You will develop, construct, test and maintain architectures such as databases and large-scale data processing systems for software solutions in an innovative and dynamic technology environment. Working together with our Business Development, Product Solutions, and Software Development teams, the goal is to develop world class products designed to achieve overall business success. You will work closely with the Enterprise Architects designing the development projects following the ICE Development Lifecycle and Platform. Technology is ICEs product, so our development team is mission critical to the company and enables us to achieve our goals and objectives.
Please note, we are currently unable to provide Sponsorship to work in the US and local candidates are preferred.
Responsibilities:
Design, construct, install, test and maintain highly scalable data management systems
Ensure systems meet business requirements and industry best practices
Create and maintain data management documentation
Design and build scalable data repositories enabling high-performance of consumer/member transaction volume within the ICE products
Build APIs for data consumption and integration of external datasets as necessary
Build high-performance algorithms, prototypes, predictive models and proof of concepts
Problem-solve issues around data integration, unusable data elements, unstructured data sets, and other data management incidents
Research opportunities for data acquisition and new uses for existing data
Develop data set processes for data modeling, mining and production
Integrate new data management technologies and software engineering tools into existing structures
Create custom software components (e.g. specialized UDFs) and analytics applications
Employ a variety of languages and tools (e.g. scripting languages) to marry systems together
Install, implement and update disaster recovery procedures
Recommend ways to ensure continuous improvement around data reliability, efficiency and quality
Collaborate with data architects, modelers and IT team members on project requirements and goals
Collaborate with QA Engineers and Automation to build test plans, scripts and automation to verify and validate data management systems and production implementation
Other duties/tasks as assigned
Skills:
Able to identify and implement a data solution strategy
Skilled in working directly with senior business management to determine requirements and present options
Statistical analysis and modeling
Database architectures
SQL-based and NoSQL-based technologies
Data modeling tools (e.g. UML, ERWin, Enterprise Architect and Visio)
Data warehousing solutions
Data mining
Demonstrates initiative with or without direct authority. Able to influence and advocate for approaches to problem solving
Demonstrates intellectual curiosity in exploring new territories and finding creative ways to solve data management problems
Supports and maintains positive attitude and vision with peers, associates, and management
Demonstrates effective teamwork and collaboration
Ability to prioritize competing or conflicting requests and execute tasks in a high-pressure environment
Utilizes good judgment
Must demonstrate ability to handle diversity amongst people and environments
Must be detail oriented and able to follow-up and follow-through on project actions and tasks
Ability to maintain confidentiality of sensitive information
Extensive written and oral communication skills
Qualifications:
Bachelors degree in Computer Science, Computer Engineering, Applied Math, Statistics or related field
Certified Data Management Professional (CDMP) a plus
8+ years experience designing, building, and maintaining data management systems
Broad experience in planning, architecting, and delivering mission-critical enterprise-grade systems and solutions
Experience with cloud architecture and data repositories
Data design experience
Experience in data cleansing and optimization for data consumption
Experience with source control tools such as Git and TFS a plus
Experience in .Net framework and Web Services (SOAP, REST, XML) a plus
Experience with Azure Service Fabric and microservices a plus
Working familiarity of front-end web framework using C#, JavaScript and/or Angular a plus
Experience using CSV/JSON/XML data formats
Experience in developing LOB (Line of Business) Applications, as well as Consumer Websites
Experience in consumer-facing, ecommerce and mobile systems a plus
Experience with agile methodologies
Please note, we are currently unable to provide Sponsorship to work in the US and local candidates are preferred.
Who We Are:
Headquartered in Scottsdale, Arizona, International Cruise & Excursions, Inc. (ICE for short) is dedicated to providing branded travel, leisure, and lifestyle products to consumers (over 55 million each year). The ICE slogan reads ""Powered by Innovation,"" and we mean it.
Were proud to be consistently recognized as a CareerBuilder Top Company to Work for in Arizona, Phoenix Business Journals Best Places to Work winner, and one of Arizonas Most Admired Companies. Our ongoing entrepreneurial spirit and overwhelmingly talented employees encourage a friendly, successful work environment and thats what sets us apart. With over 2,200 employees worldwide, were always looking to expand our ICE team with career-focused leaders who are committed to exceeding expectations.
Explore our incredible company culture on our website!
Our Core Values:
Respect. Passion. Integrity. Innovation. Social Responsibility. Teamwork. Accountability.
Additional Benefits:
FREE 7-day resort stays and cruises on your anniversary
Medical Health Insurance
Onsite Wellness Clinic
Long Term Disability
Life Insurance
Dental & Vision Coverage
401K Plan
Pet Care Insurance
Legal Insurance
Flexible Spending Accounts (FSA)
Employee Assistance Program
Discounted Employee Services (dry-cleaning, nail services, massage, personal training, etc.)
Dedicated Employee Enrichment & Recognition Programs
Exclusive Employee Travel Rates on Cruise, Resorts, Hotels, Tours, Car Rentals, Dining and Merchandise offerings
#ZR
Company Description
We are on a mission to change the way that people think about going to work. At ICE, we laugh. We help each other. We support everyone’s visions. We grow together. We have a passion for creating opportunities and have helped thousands of employees over the past 22 years develop their careers and accomplishments.
It all starts with our people, which is why we are dedicated to employee wellness, financial stability, family resources and encouraging work/life balance through our exclusive VIP travel rates.
We are passionate, solution-minded, innovators creating fun and engaging vacation experiences for thousands of members. We come from different backgrounds, countries, and experiences. Some of us rock a suit and tie while others wear Hawaiian polos to get into the vacation mood but each of us are determined to inspire and recognize every employee in our ICE Nation family.
","https://www.ziprecruiter.com/c/International-Cruise-&-Excursions,-Inc.-(ICE)/Job/Senior-Data-Engineer/-in-Scottsdale,AZ?jid=8f32408a10621742"
JOB190391602522,Lead Data Engineer,Lead Data Engineer,50+ career categories,"Find a better job, faster!,Hand-screened leads,No ads, scams, junk,Great job search support","
Lead Data Engineer
Full-time job, remote option. Needs five years' work related experience and is a good team player. B in charge of the data department, build data funnels and contribute in the aggregation of raw data, evolve data stack and build data warehouse models.
Job Details
Option for Remote
Employee
Full-Time
Experienced
No
MacBook Pro, Free Lunch Delivered Daily, Quarterly Retreats in Paris
Company name here
Other benefits listed here
Find a better job, faster!
Hand-screened leads
No ads, scams, junk
Great job search support
50+ career categories
Create an Account to Unlock
To find out more about or apply to this Lead Data Engineer job—and other great opportunities like it—become a FlexJobs member today!
With FlexJobs, you'll find the best flexible jobs and fantastic expert resources to support you in your job search. If you have any questions, please feel free to contact us.
",https://www.flexjobs.com/publicjobs/lead-data-engineer-1262330
JOB190583065976,Data Engineer,Data Engineer,50+ career categories,"Find a better job, faster!,Hand-screened leads,No ads, scams, junk,Great job search support","
Support a platform that enables patients to get full access and control of their health data. Must have a bachelor's degree, 5+ years of NLP experience, and 6+ years of general software engineering. Full-time, remote position for $140-$150K.
Job Details
10/15/20
100% Remote
Employee
Full-Time
Experienced
Bachelor's Degree
No specification
140.00 USD / Annually
Company name here
Other benefits listed here
Find a better job, faster!
Hand-screened leads
No ads, scams, junk
Great job search support
50+ career categories
Create an Account to Unlock
To find out more about or apply to this Data Engineer job—and other great opportunities like it—become a FlexJobs member today!
With FlexJobs, you'll find the best flexible jobs and fantastic expert resources to support you in your job search. If you have any questions, please feel free to contact us.
",https://www.flexjobs.com/publicjobs/data-engineer-1309833
JOB192095644215,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-mx/details/200188037/ai-ml-search-data-engineer-siri-data
JOB192376888167,Data Engineer Jobs,Data Engineer Jobs,,,"
DESCRIPTION At Amazon Advertising, we are dedicated to drive measurable outcomes for brand advertisers, agencies, authors, and entrepreneurs. Our ad solutions—including sponsored, display, video, and custom ads—leverage Amazon’s innovations and insights...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
As the Data Engineer for this amazing corporate Insurance company, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL, together...
See more: Engineer jobs
As a data engineer within the exciting, new claims advanced analytics capability, you will be building big data solutions to solve some of the organization’s toughest problems and delivering significant business value. This is a really exciting time to...
See more: Engineer jobs
Data Engineer - 70,000 Job Description An AWS Partner based in Central London is looking to expand the data side of their business due to growth. They are looking for Data Engineers with significant commercial experience ingesting large quantities of data...
See more: Engineer jobs
As the Data Engineer for this amazing corporate Insurance company in the City, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
DATA ENGINEER - TEMPORARILY REMOTE 400- 450 PER DAY 3 MONTH CONTRACT EUROPE BASED As a Data Engineer you will be working heavily with Scala and Spark to improve the quality of data. THE COMPANY: You will be working for dynamic data driven company. As a...
See more: Engineer jobs
40'000- 50'000 Pension 8% Technical Progression Healthcare Holidays More Horley, Surrey Are you seeking a new challenge within a rapidly expanding Eco-Energy Tech company where you will be having huge technical autonomy in building a data preform right...
See more: Engineer jobs
Role: Data Engineer Client: Government agency (BPSS will be required) Location: Glasgow Duration: 8 Months Rate: 400 per day (outside IR35) Note: The office is based in Glasgow city centre. It is expected that the consultant would be available for physical...
See more: Engineer jobs
Data Engineer Opus are working with an excellent niche software development company in Newcastle. The company is at the forefront of their industry and due to their on-going success are now looking for a Data Engineer to take responsibility for organising...
See more: Engineer jobs
A leading Insurance Company are currently recruiting for a Data Engineer to join their dynamic and growing business. They are looking to hire a cross functional, highly tenacious and bright Data Engineer with a passion for functional programming. The ideal...
See more: Engineer jobs
Data Engineer - 6 months - Ware - Hertfordshire Global FMCG is looking for an experienced Data Engineer who will play a pivotal role in operationalizing data and analytics initiatives for digital business initiatives. The bulk of the data engineer's work...
See more: Engineer jobs
Data Engineer Portsmouth and surrounding areas encouraged to apply, multiple office locations Data Engineer required for established, international business. The business is at the forefront of new technologies working with leading Government organisations...
See more: Engineer jobs
Data Engineer A brand new role has arisen for an experienced Database / BI Developer to take the next step in their career and transition into a full Data Engineer to work for one of the most recognisable NGO's in London. We are looking for someone with...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
Data Engineer- 50K Manchester Adria Solutions has an exciting opportunity for a talented Data Engineer to join our rapidly expanding client based near Manchester. The role requires you to work closely with other members of the data team and stakeholders...
See more: Engineer jobs
We are currently recruiting a highly motivated Data Engineer, for a company who are based in London. The Data Engineer will help develop and maintain the business. The Data Engineer will be responsible for the following; Key responsibilities- - Working...
See more: Engineer jobs
Data Engineer - I am currently recruiting for a Data Engineer based in Bath. The role would be on a permanent basis and is paying 40,000 to 45,000 (There could be flex for the right candidate) PA plus a variety of excellent benefits as well as the flexibility...
See more: Engineer jobs
Data Engineer - London - 550-600 per day - 6 month contract SearchData is currently looking to recruit a Data Engineer to work on a cutting-edge DWH project in the financial services industry. As the Data Engineer your role will be to take a leadership...
See more: Engineer jobs
An exciting opportunity for an experienced Data Engineer has arisen in Leeds. After hiring a number of new members of staff at the end of 2019, the organisation are continuing to expand due to winning more projects. Key responsibilites include: Building...
See more: Engineer jobs
Data Engineer - REMOTE WORK If you are a strong Data Engineer, with experience working with Python, R and SQL then this role is ideal. I am working with a large organisation that are market leaders in their respected field. This role will report in to...
See more: Engineer jobs
Data Engineer London 55,000 - 65,000 Benefits Our client, an exciting RegTech business is looking to recruit for a Data Engineer to join their growing team. The successful candidate will be joining the artificial intelligence team, working on a brand new...
See more: Engineer jobs
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
See more: Engineer jobs
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
See more: Engineer jobs
",http://www.reed.co.uk/jobs/data-engineer/39810983
JOB192986741891,Staff Data Engineer,Staff Data Engineer,,,"VISA Commercial Payments is seeking talented Big Data Engineer. Commercial Payments team develops Data pipeline which supports Cross Border payments rail for VISA globally through advanced algorithms running on big data technologies. The ideal candidate thrives in a fast-paced environment and relishes working with petabytes of extremely complex and dynamic data. In this role you will be part of a team of high caliber data engineers to build data pipelines using big data technologies such as Apache Spark, Hive/Hadoop, and distributed query engines. You should be passionate about working with big data and have the aptitude to incorporate new technologies and evaluate them critically. You should have excellent business and communication skills and be able to work with business owners to develop and define key business questions and build solutions. You are a self-starter, comfortable with ambiguity, and working in a fast-paced and ever-changing environment. Ideally, you are also experienced with at least one of the programming languages such as Java, C++, Scala, etc.
Major Responsibilities:
• Interface with PMs, business customers, and software developers to understand requirements and implement solutions
• Design, develop, and operate highly-scalable, high-performance, low-cost, and accurate data pipelines in distributed data processing platforms
• Recognize and adopt best practices in data processing, reporting, and analysis: data integrity, test design, analysis, validation, and documentation
• Keep up to date with big data technologies, evaluate and make decisions around the use of new or existing software products to design the data architecture
Qualifications
Basic Qualifications
• Bachelor’s degree in Computer Science, Electrical Engineering, Information Systems, Mathematics, or a related field
• Ability to work and communicate effectively with developers and Business users
• Strong organizational and multitasking skills with ability to balance competing priorities
• Experience building large-scale applications and services with big data technologies
• 2+ years of experience in designing and developing analytical systems
• 1+ years of experience in designing and developing data processing pipelines using distributed computing technologies such as Spark, and Pig, Kafka streaming
• Expertise in Data storing mechanisms and No-SQL interface
• Experience with scripting languages such as Python, Perl, etc.
• Proficiency with Linux/Unix systems
Preferred Qualifications
• Experience with full software development life cycle, including coding standards, code reviews, source control management, CI/CD , Automation testing
• Experience with big data technologies such as Hadoop, Hive, Hbase, Pig, Spark, etc.
• Experience with programming languages such as Java, C++, Scala, etc.
• Experience with open source big data processing systems and infrastructure such as Spark, Hive, Kafka, H-Base, etc.
Additional Information
Candidate will be working in VISA Global Commercial Payments area, team will be building a new payment rail leveraging Blockchain technology and distributed ledger, project details can be found here --
https://usa.visa.com/visa-everywhere/innovation/visa-b2b-connect.html
https://www.wsj.com/articles/visa-taps-blockchain-for-cross-border-payment-plan-1477050830
",https://www.smartrecruiters.com/Visa/743999676618105-staff-data-engineer
JOB194396678696,"AI/ML - Sr Data Engineer, Siri Data","AI/ML - Sr Data Engineer, Siri Data","You have excellent written and verbal communication skills.,You are tenacious, relentless, & determined,You are curious: always learning new technologies, rapidly synthesizing new information, and understanding “the why” before “the what.”,You are self-directed and capable of operating amid ambiguity.,You are poised and display excellent judgment in prioritizing across difficult tradeoffs.,You are pragmatic: not letting “the perfect” be the enemy of “the good.”",,"AI/ML - Sr Data Engineer, Siri Data
Summary
Would you like to play a critical part in the next revolution of human-computer interaction? Would you like to contribute to the advancement of a product that is globally redefining how humans use voice to relate to technology? The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within Siri Data, the mission of Siri data engineering is to build the scalable & high quality data sets that curate the data required to give our customers their voice. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream analytical & product consumers.
You have excellent written and verbal communication skills.
You are tenacious, relentless, & determined
You are curious: always learning new technologies, rapidly synthesizing new information, and understanding “the why” before “the what.”
You are self-directed and capable of operating amid ambiguity.
You are poised and display excellent judgment in prioritizing across difficult tradeoffs.
You are pragmatic: not letting “the perfect” be the enemy of “the good.”
You are humble, continually growing in self-awareness and possessing a growth mindset
WHAT WILL FILL YOUR DAYS: Moving between understanding the open & unanswered questions about Siri; to defining new metrics and filters; to specifying new logging necessary with the high-level goal of using data to improve Siri. Designing, creating, and maintaining data pipelines that populate a petabyte scale data warehouse. Working with data infrastructure teams providing input to improve our platform. Working with data producing teams to specify requirements and to transparently provide rapid feedback. Partnering with your teammates across Siri data to answer questions, to provide support, and to innovate in taking our data warehouse to the next level.
Surprise us! Many will have an MS or BS in CS, Engineering, Math, Statistics, or a related field OR equivalent practical experience in data engineering. 4+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, Flink, Kafka, etc.) for building efficient & large-scale data pipelines. Software Engineering proficiency in at least one high-level programming language (Java, Scala, Python or equivalent). Experience required in building batch data processing pipelines curating data for data science consumers. Experience strongly preferred building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others.
",https://jobs.apple.com/en-us/details/200124499/ai-ml-sr-data-engineer-siri-data
JOB197570144784,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-sg/details/200188037/ai-ml-search-data-engineer-siri-data
JOB197788011982,AVAILABLE POSITIONS Principal Data Engineer,AVAILABLE POSITIONS Principal Data Engineer,Work with cool people and impact millions of daily players!,"Build and own multi PB-scale data platform.,Design, code, and develop new features/fix bugs/enhancements to systems and data pipelines (ETLs) while adhering to the SLA.,Follow engineering best methodologies towards ensuring performance, reliability, scalability, and measurability.,Collaborate with other Software Engineers, ML Engineers, Data Scientists, and other stakeholders, taking on learning and leadership opportunities that will arise every single day.,Mentor junior engineers in the team to level them up.,Raise the bar on sustainable engineering by improving best practices, producing best in class of code, documentation, testing and monitoring.,Bachelor’s degree in Computer Science, or a related technical discipline (or equivalent).,7+ years of strong data engineering design/development experience in building massively large scale distributed data platforms/products.,Advanced coding expertise in SQL & Python/JVM-based language.,Expert in heterogeneous data storage systems (relational, NoSQL, in-memory etc).,Deep knowledge of data modeling, lineage, access and its governance.,Excellent skills in AWS services like Redshift, Kinesis, Lambda, EMR, EKS/ECS etc.,Wide exposure to open source software, frameworks and broader cutting edge technologies (Airflow, Spark, Druid etc).,Familiar with infrastructure provisioning tools (e.g Terraform, Chef),Consistent proven ability to deliver work on time with attention to quality.,Excellent written and spoken communication skills and ability to work effectively with others in a team environment.,Work in a studio that has complete P&L ownership of games,Competitive salary, discretionary annual bonus scheme and Zynga RSUs,Full medical, accident as well as life insurance benefits,Catered breakfast, lunch and evening snacks,Child care facilities for women employees and discounted facilities for male employees,Well stocked pantry,Generous Paid Maternity/Paternity leave,Employee Assistance Programs,Active Employee Resource Groups – Women at Zynga,Frequent employee events,Additional leave options for most employees,Flexible working hours on many teams,Casual dress every single day","
We are seeking top engineering talent to join our creative, dynamic, and highly driven team. Zynga’s mission is to “Connect the World through Games” by building a truly social experience that makes the world a better place. The ideal candidate will have a devotion to software craftsmanship, an unwavering commitment to quality, and the desire to have their work seen by tens of millions of people worldwide.
The Analytics Engineering team is responsible for all things data at Zynga. We own the full game and player data pipeline – from ingestion to storage to driving insights and analytics. As a Principal Data Engineer, you will be responsible for the software design and development of quality services and products to support the Analytics needs of our games. In this role, you will be part of our Central Technology group focusing on advanced technology developments for building scalable data infrastructure and end-to-end services which can be leveraged by the various games. We are a 120+ organization servicing 1500 others across 13 global locations.
Your responsibilities will include
Build and own multi PB-scale data platform.
Design, code, and develop new features/fix bugs/enhancements to systems and data pipelines (ETLs) while adhering to the SLA.
Follow engineering best methodologies towards ensuring performance, reliability, scalability, and measurability.
Collaborate with other Software Engineers, ML Engineers, Data Scientists, and other stakeholders, taking on learning and leadership opportunities that will arise every single day.
Mentor junior engineers in the team to level them up.
Raise the bar on sustainable engineering by improving best practices, producing best in class of code, documentation, testing and monitoring.
Bachelor’s degree in Computer Science, or a related technical discipline (or equivalent).
7+ years of strong data engineering design/development experience in building massively large scale distributed data platforms/products.
Advanced coding expertise in SQL & Python/JVM-based language.
Expert in heterogeneous data storage systems (relational, NoSQL, in-memory etc).
Deep knowledge of data modeling, lineage, access and its governance.
Excellent skills in AWS services like Redshift, Kinesis, Lambda, EMR, EKS/ECS etc.
Wide exposure to open source software, frameworks and broader cutting edge technologies (Airflow, Spark, Druid etc).
Familiar with infrastructure provisioning tools (e.g Terraform, Chef)
Consistent proven ability to deliver work on time with attention to quality.
Excellent written and spoken communication skills and ability to work effectively with others in a team environment.
What we offer you:
Work in a studio that has complete P&L ownership of games
Competitive salary, discretionary annual bonus scheme and Zynga RSUs
Full medical, accident as well as life insurance benefits
Catered breakfast, lunch and evening snacks
Child care facilities for women employees and discounted facilities for male employees
Well stocked pantry
Generous Paid Maternity/Paternity leave
Employee Assistance Programs
Active Employee Resource Groups – Women at Zynga
Frequent employee events
Additional leave options for most employees
Flexible working hours on many teams
Casual dress every single day
Work with cool people and impact millions of daily players!
#LI-HK1
Careers region: India
Careers location: Bengaluru, India
Careers Type: Full-Time
",https://www.zynga.com/job-listing/principal-software-engineer-1/
JOB197996323124,Data Engineer,Data Engineer,,,"
Rio Tinto
",http://www.infomine.com/careers/jobs/data-engineer_1684765/
JOB198486802907,Data Engineer at NORMENT,Data Engineer at NORMENT,,,"
About the University of Oslo
The University of Oslo is Norway’s oldest and highest ranked educational and research institution, with 28 000 students and 7000 employees. With its broad range of academic disciplines and internationally recognised research communities, UiO is an important contributor to society.
The Institute of Clinical Medicine (Klinmed) is one of three institutes under the Faculty. Klinmed is responsible for the Faculty's educational and research activities at Oslo University Hospital and Akershus University Hospital. With about 800 employees spread over approximately 425 man-labour years, Klinmed is the university's largest institute. Our activities follow the clinical activity at the hospitals and are spread across a number of geographical areas.
",https://www.jobbnorge.no/ledige-stillinger/stilling/186922/data-engineer-at-norment
JOB199051680585,Data Engineer Jobs,Data Engineer Jobs,,,"
DESCRIPTION At Amazon Advertising, we are dedicated to drive measurable outcomes for brand advertisers, agencies, authors, and entrepreneurs. Our ad solutions—including sponsored, display, video, and custom ads—leverage Amazon’s innovations and insights...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
As the Data Engineer for this amazing corporate Insurance company, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL, together...
See more: Engineer jobs
As a data engineer within the exciting, new claims advanced analytics capability, you will be building big data solutions to solve some of the organization’s toughest problems and delivering significant business value. This is a really exciting time to...
See more: Engineer jobs
Data Engineer - 70,000 Job Description An AWS Partner based in Central London is looking to expand the data side of their business due to growth. They are looking for Data Engineers with significant commercial experience ingesting large quantities of data...
See more: Engineer jobs
As the Data Engineer for this amazing corporate Insurance company in the City, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
DATA ENGINEER - TEMPORARILY REMOTE 400- 450 PER DAY 3 MONTH CONTRACT EUROPE BASED As a Data Engineer you will be working heavily with Scala and Spark to improve the quality of data. THE COMPANY: You will be working for dynamic data driven company. As a...
See more: Engineer jobs
40'000- 50'000 Pension 8% Technical Progression Healthcare Holidays More Horley, Surrey Are you seeking a new challenge within a rapidly expanding Eco-Energy Tech company where you will be having huge technical autonomy in building a data preform right...
See more: Engineer jobs
Data Engineer Portsmouth and surrounding areas encouraged to apply, multiple office locations Data Engineer required for established, international business. The business is at the forefront of new technologies working with leading Government organisations...
See more: Engineer jobs
Data Engineer A brand new role has arisen for an experienced Database / BI Developer to take the next step in their career and transition into a full Data Engineer to work for one of the most recognisable NGO's in London. We are looking for someone with...
See more: Engineer jobs
Role: Data Engineer Client: Government agency (BPSS will be required) Location: Glasgow Duration: 8 Months Rate: 400 per day (outside IR35) Note: The office is based in Glasgow city centre. It is expected that the consultant would be available for physical...
See more: Engineer jobs
Data Engineer Opus are working with an excellent niche software development company in Newcastle. The company is at the forefront of their industry and due to their on-going success are now looking for a Data Engineer to take responsibility for organising...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
A leading Insurance Company are currently recruiting for a Data Engineer to join their dynamic and growing business. They are looking to hire a cross functional, highly tenacious and bright Data Engineer with a passion for functional programming. The ideal...
See more: Engineer jobs
Data Engineer- 50K Manchester Adria Solutions has an exciting opportunity for a talented Data Engineer to join our rapidly expanding client based near Manchester. The role requires you to work closely with other members of the data team and stakeholders...
See more: Engineer jobs
Data Engineer - 6 months - Ware - Hertfordshire Global FMCG is looking for an experienced Data Engineer who will play a pivotal role in operationalizing data and analytics initiatives for digital business initiatives. The bulk of the data engineer's work...
See more: Engineer jobs
We are currently recruiting a highly motivated Data Engineer, for a company who are based in London. The Data Engineer will help develop and maintain the business. The Data Engineer will be responsible for the following; Key responsibilities- - Working...
See more: Engineer jobs
Data Engineer - I am currently recruiting for a Data Engineer based in Bath. The role would be on a permanent basis and is paying 40,000 to 45,000 (There could be flex for the right candidate) PA plus a variety of excellent benefits as well as the flexibility...
See more: Engineer jobs
Data Engineer - London - 550-600 per day - 6 month contract SearchData is currently looking to recruit a Data Engineer to work on a cutting-edge DWH project in the financial services industry. As the Data Engineer your role will be to take a leadership...
See more: Engineer jobs
Data Engineer - REMOTE WORK If you are a strong Data Engineer, with experience working with Python, R and SQL then this role is ideal. I am working with a large organisation that are market leaders in their respected field. This role will report in to...
See more: Engineer jobs
Data Engineer London 55,000 - 65,000 Benefits Our client, an exciting RegTech business is looking to recruit for a Data Engineer to join their growing team. The successful candidate will be joining the artificial intelligence team, working on a brand new...
See more: Engineer jobs
An exciting opportunity for an experienced Data Engineer has arisen in Leeds. After hiring a number of new members of staff at the end of 2019, the organisation are continuing to expand due to winning more projects. Key responsibilites include: Building...
See more: Engineer jobs
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
See more: Engineer jobs
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
See more: Engineer jobs
",http://www.reed.co.uk/jobs/data-engineer/39915297
JOB202509773372,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-kr/details/200188037/ai-ml-search-data-engineer-siri-data
JOB202664995377,"Data Engineer, Apple Media Products","Data Engineer, Apple Media Products","Experience in high level programming languages such as Java, Scala, or Python.,Proficiency with databases and SQL is required.,Proficiency in data processing using technologies like Spark Streaming, Spark SQL, or Map/Reduce.,Expertise in Hadoop related technologies such as HDFS, Azkaban, Oozie, Impala, Hive, and Pig.,Expertise in developing big data pipelines using technologies like Kafka, Flume, or Storm.,Experience with large scale data warehousing, mining or analytic systems.,Ability to work with analysts to gather requirements and translate them into data engineering tasks",,"Apple is seeking a highly skilled data engineer to join the Data Engineering team within Apple Media Products. AMP (home to Apple Music, App Store, iTunes and more) has some of the most compelling data in the world. We are looking for a talented engineer who is motivated by challenging problems and well versed with big data technologies. This is a unique opportunity to join a focused team and work collaboratively with other groups to make a significant impact.
Experience in high level programming languages such as Java, Scala, or Python.
Proficiency with databases and SQL is required.
Proficiency in data processing using technologies like Spark Streaming, Spark SQL, or Map/Reduce.
Expertise in Hadoop related technologies such as HDFS, Azkaban, Oozie, Impala, Hive, and Pig.
Expertise in developing big data pipelines using technologies like Kafka, Flume, or Storm.
Experience with large scale data warehousing, mining or analytic systems.
Ability to work with analysts to gather requirements and translate them into data engineering tasks
Aptitude to independently learn new technologies.
As a member of the Data Engineering team, you will have significant responsibility and influence in shaping its future direction. This role is inherently cross-functional and the ideal candidate will work across disciplines. We are looking for someone with a love for data and ability to iterate quickly on all stages of data pipeline. This position involves working on a small team to develop large scale data pipelines and analytical solutions using Big Data technologies. Successful candidates will have strong engineering skills and communication, as well as, a belief that data driven processes lead to great products. You will need to have a passion for quality and an ability to understand complex systems.
",https://jobs.apple.com/en-ca/details/200166507/data-engineer-apple-media-products
JOB203234028048,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-ch/details/200188037/ai-ml-search-data-engineer-siri-data
JOB204341930513,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-ph/details/200188037/ai-ml-search-data-engineer-siri-data
JOB204478356031,"Data Engineer, Analytics (Instagram Ecosystems)","Data Engineer, Analytics (Instagram Ecosystems)","4+ years' experience in the data warehouse space,4+ years' experience working with either a MapReduce or an MPP system,7+ years' experience in writing complex SQL and ETL processes,4+ years' experience with object-oriented programming languages,BS/BA in Technical Field, Computer Science or Mathematics,Knowledge in Python or Java,Experience analyzing data to identify deliverables, gaps, and inconsistencies,Actively mentored team members in their careers,Experience effectively collaborating and communicating complex technical concepts to a broad variety of audiences","Craft and own the optimal data processing architecture and systems for new data and ETL pipelines,Build canonical datasets as well as scalable and fault-tolerant pipelines,Build data anomaly detection, data quality checks, and optimize pipelines for ideal compute and storage,Define and own the data engineering roadmap for Ecosystems,Collaborate with Software Engineers and Data Scientists to design technical specification for logging and add logging to production code to generate metrics both online as well as offline,Work with different cross functional partners - Data Scientists, Infra Engineering, Logging Framework Infra Teams, Product Managers,Build visualizations to provide insights into the data & metrics generated,Work with data infrastructure teams to suggest improvements and influence their roadmap,Immerse yourself in all aspects of the product, understand the problems, and tie them back to data engineering solutions,Recommend improvements and modifications to existing data and ETL pipelines,Communicate and influence strategies and processes around data modeling and architecture to multi-functional groups and leadership,Drive internal process improvements and automating manual processes for data quality and SLA management","
Facebook's mission is to give people the power to build community and bring the world closer together. Through our family of apps and services, we're building a different kind of company that connects billions of people around the world, gives them ways to share what matters most to them, and helps bring people closer together. Whether we're creating new products or helping a small business expand its reach, people at Facebook are builders at heart. Our global teams are constantly iterating, solving problems, and working together to empower people around the world to build community and connect in meaningful ways. Together, we can help people build stronger communities - we're just getting started.
Summary
Our more experienced data engineers are clearly characterized by in-depth technical experience and proven progression in leadership responsibility. If you have an interest in being responsible for the dynamics of a fast-paced environment, this is the right role for you. You will be working on many projects at a time, but also focused on the details while finding creative ways to pursue big picture challenges. You will leverage not just technical skills, but strong emphasis on program management, technical leadership, and communication. In this role, you will work closely with your direct data science counterparts, and other analytic teams around Instagram to support delivering comprehensive, accurate, and holistic data artifacts. The mission of the Instagram Ecosystems team is to make sure that Instagram thinks holistically about the user experience and that the company optimizes for the long-term success of the app. Instagram is organized into 3 main product groups: Community, Sharing Experiences, and Interests. And underneath all of them, the fabric that keeps them running is the Infra org.As a result of the company organization, Analytic teams across Instagram are focused on making sure that the products they support are successful. However, there are important questions that fall out of the scope of a single product group or that simply fall through the cracks. These are the questions that the Ecosystems team is tasked with answering. Some examples of projects are: common engagement metrics, session level metrics like time spent watching video, understanding relation between production and consumption, understanding how metric trade-off between each other and bringing conformance and standards to the way product teams measure their goals.
Required Skills
Craft and own the optimal data processing architecture and systems for new data and ETL pipelines
Build canonical datasets as well as scalable and fault-tolerant pipelines
Build data anomaly detection, data quality checks, and optimize pipelines for ideal compute and storage
Define and own the data engineering roadmap for Ecosystems
Collaborate with Software Engineers and Data Scientists to design technical specification for logging and add logging to production code to generate metrics both online as well as offline
Work with different cross functional partners - Data Scientists, Infra Engineering, Logging Framework Infra Teams, Product Managers
Build visualizations to provide insights into the data & metrics generated
Work with data infrastructure teams to suggest improvements and influence their roadmap
Immerse yourself in all aspects of the product, understand the problems, and tie them back to data engineering solutions
Recommend improvements and modifications to existing data and ETL pipelines
Communicate and influence strategies and processes around data modeling and architecture to multi-functional groups and leadership
Drive internal process improvements and automating manual processes for data quality and SLA management
Provide ongoing proactive communication and collaboration throughout the organization
Minimum Qualification
4+ years' experience in the data warehouse space
4+ years' experience working with either a MapReduce or an MPP system
7+ years' experience in writing complex SQL and ETL processes
4+ years' experience with object-oriented programming languages
7+ years' experience with schema design and dimensional data modeling
Preferred Qualification
BS/BA in Technical Field, Computer Science or Mathematics
Knowledge in Python or Java
Experience analyzing data to identify deliverables, gaps, and inconsistencies
Actively mentored team members in their careers
Experience effectively collaborating and communicating complex technical concepts to a broad variety of audiences
Consulting or Strategy experience in technical implementations or management consulting
EOE
Facebook is proud to be an Equal Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Facebook is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.
",https://www.gettinghired.com/job-details/263296/data-engineer-analytics-instagram-ecosystems-/
JOB205257317208,Data Engineer Jobs,Data Engineer Jobs,,,"
DESCRIPTION At Amazon Advertising, we are dedicated to drive measurable outcomes for brand advertisers, agencies, authors, and entrepreneurs. Our ad solutions—including sponsored, display, video, and custom ads—leverage Amazon’s innovations and insights...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
As the Data Engineer for this amazing corporate Insurance company, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL, together...
See more: Engineer jobs
As a data engineer within the exciting, new claims advanced analytics capability, you will be building big data solutions to solve some of the organization’s toughest problems and delivering significant business value. This is a really exciting time to...
See more: Engineer jobs
Data Engineer - 70,000 Job Description An AWS Partner based in Central London is looking to expand the data side of their business due to growth. They are looking for Data Engineers with significant commercial experience ingesting large quantities of data...
See more: Engineer jobs
As the Data Engineer for this amazing corporate Insurance company in the City, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
DATA ENGINEER - TEMPORARILY REMOTE 400- 450 PER DAY 3 MONTH CONTRACT EUROPE BASED As a Data Engineer you will be working heavily with Scala and Spark to improve the quality of data. THE COMPANY: You will be working for dynamic data driven company. As a...
See more: Engineer jobs
40'000- 50'000 Pension 8% Technical Progression Healthcare Holidays More Horley, Surrey Are you seeking a new challenge within a rapidly expanding Eco-Energy Tech company where you will be having huge technical autonomy in building a data preform right...
See more: Engineer jobs
Data Engineer Portsmouth and surrounding areas encouraged to apply, multiple office locations Data Engineer required for established, international business. The business is at the forefront of new technologies working with leading Government organisations...
See more: Engineer jobs
Data Engineer A brand new role has arisen for an experienced Database / BI Developer to take the next step in their career and transition into a full Data Engineer to work for one of the most recognisable NGO's in London. We are looking for someone with...
See more: Engineer jobs
Role: Data Engineer Client: Government agency (BPSS will be required) Location: Glasgow Duration: 8 Months Rate: 400 per day (outside IR35) Note: The office is based in Glasgow city centre. It is expected that the consultant would be available for physical...
See more: Engineer jobs
Data Engineer Opus are working with an excellent niche software development company in Newcastle. The company is at the forefront of their industry and due to their on-going success are now looking for a Data Engineer to take responsibility for organising...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
A leading Insurance Company are currently recruiting for a Data Engineer to join their dynamic and growing business. They are looking to hire a cross functional, highly tenacious and bright Data Engineer with a passion for functional programming. The ideal...
See more: Engineer jobs
Data Engineer- 50K Manchester Adria Solutions has an exciting opportunity for a talented Data Engineer to join our rapidly expanding client based near Manchester. The role requires you to work closely with other members of the data team and stakeholders...
See more: Engineer jobs
Data Engineer - 6 months - Ware - Hertfordshire Global FMCG is looking for an experienced Data Engineer who will play a pivotal role in operationalizing data and analytics initiatives for digital business initiatives. The bulk of the data engineer's work...
See more: Engineer jobs
We are currently recruiting a highly motivated Data Engineer, for a company who are based in London. The Data Engineer will help develop and maintain the business. The Data Engineer will be responsible for the following; Key responsibilities- - Working...
See more: Engineer jobs
Data Engineer - I am currently recruiting for a Data Engineer based in Bath. The role would be on a permanent basis and is paying 40,000 to 45,000 (There could be flex for the right candidate) PA plus a variety of excellent benefits as well as the flexibility...
See more: Engineer jobs
Data Engineer - London - 550-600 per day - 6 month contract SearchData is currently looking to recruit a Data Engineer to work on a cutting-edge DWH project in the financial services industry. As the Data Engineer your role will be to take a leadership...
See more: Engineer jobs
Data Engineer - REMOTE WORK If you are a strong Data Engineer, with experience working with Python, R and SQL then this role is ideal. I am working with a large organisation that are market leaders in their respected field. This role will report in to...
See more: Engineer jobs
Data Engineer London 55,000 - 65,000 Benefits Our client, an exciting RegTech business is looking to recruit for a Data Engineer to join their growing team. The successful candidate will be joining the artificial intelligence team, working on a brand new...
See more: Engineer jobs
An exciting opportunity for an experienced Data Engineer has arisen in Leeds. After hiring a number of new members of staff at the end of 2019, the organisation are continuing to expand due to winning more projects. Key responsibilites include: Building...
See more: Engineer jobs
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
See more: Engineer jobs
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
See more: Engineer jobs
",http://www.reed.co.uk/jobs/data-engineer/39925744
JOB206531215515,Data Engineer,Data Engineer,"Four+ years' development experience working with Python,Data skills (SQL, document stores),Large scale ETL (Apache beam or Apache spark),High scale Restful Services,Cloud experience (Google Cloud Platform, Azure, or AWS),BSc or B-Tech in Computer Science or IT preferred",,"Data Engineer
Job description
Our Client is looking for a Data Engineer who will be working in an agile environment, alongside a young, dynamic, multi-skilled team of Developers, Data Scientists and Product Managers to deliver scalable data solutions.
Requirements
Four+ years' development experience working with Python
Data skills (SQL, document stores)
Large scale ETL (Apache beam or Apache spark)
High scale Restful Services
Cloud experience (Google Cloud Platform, Azure, or AWS)
Git
Qualifications:
BSc or B-Tech in Computer Science or IT preferred
The reference number for this position is LV43318. It’s a permanent position based in Cape Town, the salary is negotiable based on experience. Contact Liza on lizavdb@e-merge.co.za or call her on 011 463 3633 to discuss this and other opportunities.
Are you ready for a change of scenery? The e-Merge IT recruitment is a specialist niche recruitment agency. We offer our candidates options so that we can successfully place the right developers with the right companies in the right roles. Check out the e-Merge website for more great positions.
Do you have a friend who is a developer or technology specialist? We pay cash for successful *referrals!
https://www.e-merge.co.za/careers/referralprogramme/
Posted on 05 Mar 09:32
",https://www.bizcommunity.com/Company/Job.aspx?cid=123552&i=363063
JOB206865407760,Data Engineer,Data Engineer,"Experience in Azure Data Factory, Data Bricks, Data Lake","Support the technical data foundation of Henkel’s digital transformation,Support and Implement Henkel wide data integration strategy for the central data foundation covering all internal & external, structured & unstructured data requirements,Support and Implement Henkel BI data model with focus on integrating data from operational systems and other data sources up to reporting and analytical applications for the region,Support and Implement an enterprise wide valid business logic and a data quality concept,Work in a global and regional, multinational BI and analytics teams in a dynamic and challenging environment,Four year degree in Computer Sciences/Information Systems or related,At least 2-3 years of experience in the area of Data Warehousing and Business Intelligence,Knowledge of modern data warehousing concepts, data modelling and data management.,Experience in relational data bases (MS SQL, Teradata, Oracle, DB2) and good knowledge of SQL,Experience in Azure Cloud technology and ETL solution,Knowledge of BI tools e.g. Analysis Server, Cognos, Oracle BI, SAP BW beneficial,Agile and DevOps Experience a plus","
United States, Rocky Hill, CT, , Stamford, CT, Integrated Business Solutions
HENKEL IS FOR THOSE WHO STEP UP. DO YOU?
At Henkel, you can make a difference and craft your career. That’s why you own your projects and take full responsibility from an early stage. Our unique brands in markets around the world open up countless opportunities to follow your convictions and explore new paths. If you have an entrepreneurial mindset that allows you to always think out of the box - take the chance and shape the digital future together with us.
YOUR ROLE
Support the technical data foundation of Henkel’s digital transformation
Support and Implement Henkel wide data integration strategy for the central data foundation covering all internal & external, structured & unstructured data requirements
Support and Implement Henkel BI data model with focus on integrating data from operational systems and other data sources up to reporting and analytical applications for the region
Support and Implement an enterprise wide valid business logic and a data quality concept
Work in a global and regional, multinational BI and analytics teams in a dynamic and challenging environment
YOUR SKILLS
Four year degree in Computer Sciences/Information Systems or related
At least 2-3 years of experience in the area of Data Warehousing and Business Intelligence
Knowledge of modern data warehousing concepts, data modelling and data management.
Experience in relational data bases (MS SQL, Teradata, Oracle, DB2) and good knowledge of SQL
Experience in Azure Cloud technology and ETL solution
Knowledge of BI tools e.g. Analysis Server, Cognos, Oracle BI, SAP BW beneficial
Agile and DevOps Experience a plus
Experience in Azure Data Factory, Data Bricks, Data Lake
Henkel is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, sex, national origin, disability, veteran status, and other legally protected characteristics.
Henkel does not accept unsolicited resumes from search firms or employment agencies. Unsolicited referrals and resumes are considered Henkel property and therefore, Henkel will not pay a fee for any placement resulting from the receipt of an unsolicited referral. At Henkel’s request only, preferred vendors may be invited to refer talent for specific open positions. In these cases, a fully-executed agreement with Henkel must be in place and current.
",https://www.henkel.com/careers/jobs-and-application/972244-972244
JOB207072143873,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-cz/details/200188037/ai-ml-search-data-engineer-siri-data
JOB207336581691,Siri - Data Engineer,Siri - Data Engineer,"2-5+ years of experience in data engineering.,Expertise with various ETL technologies and familiar with ETL tools.,You have engineered metrics and statistical information out of massive and complex datasets (e.g. Hive, Spark MLlib, Druid, Solr, Kafka).,You are proficient in at least one programming language (e.g. Python, Scala) and are comfortable developing code within a team environment (e.g. git, testing, code reviews).,You have built robust data and analytic pipelines and have a keen eye for where to automate (e.g. Oozie, Airflow).,Have solid understanding of both relational and NoSQL database technologies.,Experience with visualization, data mining, or statistical tools",,"2-5+ years of experience in data engineering.
Expertise with various ETL technologies and familiar with ETL tools.
You have engineered metrics and statistical information out of massive and complex datasets (e.g. Hive, Spark MLlib, Druid, Solr, Kafka).
You are proficient in at least one programming language (e.g. Python, Scala) and are comfortable developing code within a team environment (e.g. git, testing, code reviews).
You have built robust data and analytic pipelines and have a keen eye for where to automate (e.g. Oozie, Airflow).
Have solid understanding of both relational and NoSQL database technologies.
Experience with visualization, data mining, or statistical tools
Data architecture skills
The ideal candidate will have outstanding communication skills, proven data infrastructure design and implementation capabilities, strong business acumen, and an innate drive to deliver results. He/she will be a self-starter, comfortable with ambiguity and will enjoy working in a fast-paced dynamic environment. Responsibilities will include • Building a high-quality BI and Data Warehousing framework, implementing and operating data pipelines with high reliability and availablility. • Build relationships with Data Scientists, Product Managers and Software Engineers to understand data needs • Harden and launch new data models and data pipelines in production • Lead development of data tools to support analysis and data resources to support new product launches • Be part of a team to introduce new data engineering technologies and practices including real time streaming, bot detection and ML algorithms for data augmentation. • Coordinate the delivery of insightful dashboards and data visualizations • Establish SLA’s for all data sets and processes running in production • Excellent writing and interpersonal skills • Thorough knowledge of macOS and iOS is helpful • Ability to stay focused and prioritize a heavy workload while achieving exceptional quality • You are upbeat, adaptable, and results-oriented with a positive attitude
B.S., M.S., or PhD in Computer Science, Computer Engineering, or equivalent practical experience Apple is an equal opportunity employer that is committed to inclusion and diversity. We take affirmative action to ensure equal opportunity for all applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, Veteran status, or other legally protected characteristics.
",https://jobs.apple.com/en-us/details/200130314/siri-data-engineer
JOB210192325475,Data Engineer,Data Engineer,,"Shape the portfolio of business problems to solve by building detailed knowledge of data sources (internal and external),Model data landscape, obtain data extracts and define secure data exchange approaches,Acquire, ingest, and process data from multiple sources and systems into Cloud Data Lake,Operate in fast-paced, iterative environment while remaining compliant with Information Sec policies/standards,Collaborate with data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models,Help architect the strategic advanced analytics technology landscape,Become expert in claims data sources,Framework set up across the company to define best practice in data engineering space,Robust data sources in the data lake with increasing proportion of data held in the lake,No unexpected issues arise,Meaningful experience (2+ years) with at least two of the following technologies: Python, Scala, SQL, Java,Experience and interest in Cloud platforms such as:, Azure, AWS or Databricks,The ability to work across structured, semi-structured, and unstructured data, extracting information and identifying linkages across disparate data sets,Understanding of Information Security principles to ensure compliant handling and management of data","
As a data engineer within the exciting, new claims advanced analytics capability, you will be building big data solutions to solve some of the organization’s toughest problems and delivering significant business value. This is a really exciting time to join as you will be helping to shape the big data analytics architecture and technology stack within a new cloud based data lake
Responsibilities:
Shape the portfolio of business problems to solve by building detailed knowledge of data sources (internal and external)
Model data landscape, obtain data extracts and define secure data exchange approaches
Acquire, ingest, and process data from multiple sources and systems into Cloud Data Lake
Operate in fast-paced, iterative environment while remaining compliant with Information Sec policies/standards
Collaborate with data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models
Help architect the strategic advanced analytics technology landscape
Build re-usable code and data assets
Codify best practices, methodology and share knowledge with other data engineers/scientists in the organisation
Measures:
Become expert in claims data sources
Framework set up across the company to define best practice in data engineering space
Robust data sources in the data lake with increasing proportion of data held in the lake
No unexpected issues arise
Successful delivery of cloud projects
""Single version of the truth"" tables and views in the cloud that are used by a wide variety of end users providing accurate re-producible
Skills & Experience:
Meaningful experience (2+ years) with at least two of the following technologies: Python, Scala, SQL, Java
Experience and interest in Cloud platforms such as:, Azure, AWS or Databricks
The ability to work across structured, semi-structured, and unstructured data, extracting information and identifying linkages across disparate data sets
Meaningful experience in at least one database technology such as:
-Distributed Processing (Spark, Hadoop, EMR)
-Traditional RDBMS (MS SQL Server, Oracle, MySQL, PostgreSQL)
-MPP (AWSRedshift, Teradata)
-NoSQL (MongoDB, DynamoDB, Cassandra, Neo4J, Titan)
Understanding of Information Security principles to ensure compliant handling and management of data
Experience in traditional data warehousing / ETL tools (Informatica, Talend, Pentaho, DataStage)
Ability to clearly communicate complex solutions
",https://www.reed.co.uk/jobs/data-engineer/38410718
JOB211241360242,Data Engineer,Data Engineer,,,"
Data Engineer X 2 – Manchester. Our client based near Manchester are currently looking for 2 Data Engineers with Azure experience. The company is currently going through a large digital transformation, they are looking for talented Data specialist to help...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Data Engineer - 70,000 Job Description An AWS Partner based in Central London is looking to expand the data side of their business due to growth. They are looking for Data Engineers with significant commercial experience ingesting large quantities of data...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Data Engineer - Python - Permanent Data Idols are working with a well-known client in the e-commerce space who are looking for a Data Engineer to join an existing team. THE ROLE As a Data Engineer, you will be working with the existing Data team to help...
Data Engineer - Manchester A growing business based in Manchester City Centre are currently looking for a Data Engineer to help shape their newly formed Data Engineering team and build scalable, reliable and secure cloud datawarehouse solutions and data...
Job title : Data Engineer Location: London Job type: Permanent Salary: Up to 70,000 per annum Reporting to: Head of Data Engineering Overview A fantastic internet company based in Central London are currently looking for a Data Engineer to come on board...
Data Engineer / Data Scientist / Biomedical Informatics / Human Genetics / Python / SQL / R / Oxford / Cambridge / Permanent 60 - 90K (Depending on Experience) Excellent Benefits COVID Safe Interview Process 100% Remote during Covid and up to 50% Post...
Data Engineer London 80,000 - 90,000 Benefits This Data Engineering role will allow you to expand and utilise your skills in a growing team working along side one of the largest data sets in the UK. The Company As a global leader they generate tons of...
Data Engineer London 55,000 - 65,000 Benefits Our client, an exciting RegTech business is looking to recruit for a Data Engineer to join their growing team. The successful candidate will be joining the artificial intelligence team, working on a brand new...
Recruiting for multiple Data Engineer roles with a global organisation based in Swindon to develop their cloud based platforms and infrastructure. These are permanent opportunities to join a newly created Agile team, offering competitive salaries/benefits...
Data Engineer - Permanent Data Idols are working with a well-known client in the e-commerce space who are looking for a Data Engineer to join an existing team on a permanent basis. THE ROLE As a Data Engineer, you will be working with the existing Data...
Senior Data Enigneer - Permanent Data Idols are working with a well known Technology company who are looking for a Senior Data Engineer to join a cross-functional team. This industry disruptor has been changing the way people interact with an everyday...
DATA ENGINEER - CURRENTLY REMOTE WORKING LONDON, CURRENTLY FLEXIBLE / REMOTE / HOME WORKING BETWEEN 65,000 - 90,000 BENEFITS BONUS Harnham are exclusively partnered with a tech brand looking to hire a Python focused Data Engineer. The client operates within...
DATA ENGINEER - CURRENTLY REMOTE WORKING LONDON, CURRENTLY FLEXIBLE / REMOTE / HOME WORKING BETWEEN 65,000 - 90,000 BENEFITS BONUS Harnham are exclusively partnered with a tech brand looking to hire a Python focused Data Engineer. The client operates within...
DATA ENGINEER ENERGY LONDON BETWEEN 60,000 - 80,000 This vacancy is an excellent opportunity to join an energy trading firm who have recently launched a new data initiative. The role will involve developing a data platform utilising Python, Spark &...
A leading Insurance Company are currently recruiting for a Data Engineer to join their dynamic and growing business. They are looking to hire a cross functional, highly tenacious and bright Data Engineer with a passion for functional programming. The ideal...
Calling all Data Engineers, Wi-Fi Install engineers, Fibre Engineers and Electrical Engineers.? Acorn?is?working in a recruitment partnership with a UK based?IT & Networks solution?provider?to?join?a project in Chartres,?France.?We are?recruiting a...
Site Name: UK - London - Brentford, USA - Pennsylvania - Upper Providence Posted Date: Jun 4 2020 Are you looking for a challenging opportunity to work in an area where cutting edge science meets cutting edge technology with an aim of delivering drugs...
Calling all Data Engineers, Wi-Fi Install engineers, Fibre Engineers and Electrical Engineers. Acorn is working in a recruitment partnership with a UK based IT & Networks solution provider to join a project in Chartres, France. We are recruiting a...
Calling all Data Engineers, Wi-Fi Install engineers, Fibre Engineers and Electrical Engineers.? Acorn?is?working in a recruitment partnership with a UK based?IT and Networks solution?provider?to?join?a project in Chartres,?France.?We are?recruiting a team...
",https://www.reed.co.uk/jobs/data-engineer/40248292
JOB212106396644,BIG DATA ENGINEER: Developer / Hadoop / Scala / AWS - Music Industry,BIG DATA ENGINEER: Developer / Hadoop / Scala / AWS - Music Industry,,,"
Big Data Engineer/Developer: Hadoop/AWS/Scala/Java/JVM/Bash/Python/SQL/Apache Spark
My superb client in the heart of London are looking to add multiple Big Data Engineers/Developers/Consultants to their team. They are a leading technology-powered music company who expecting further rapid growth through 2017, that's where you come in. If you have experience in the following then please get in touch: Hadoop, AWS, Scala and a hands-on Java/Scala/Python/.Net development background.
Key Skills: Hadoop Ecosystem / AWS / Amazon Web Services / Scala / Java / Python / SQL
You will be responsible for exploiting the data contained within the business and will work on the delivery of proof of concept and prototype systems. In addition, you'll be supporting the whole development lifecycle and working extensively within AWS.
Please apply or send your CV to *************************************** for immediate consideration. Thanks!
Big Data Engineer/Developer: Hadoop/AWS/Scala/Java/JVM/Bash/Python/SQL/Apache Spark
",https://www.careerjet.co.uk/clk/c463fc90106fea551c930f39377c77b5.html
JOB212143053822,Data Engineer,Data Engineer,"You have 4 years of experience with a deep understanding of data engineering concepts and database designs.,Advanced SQL knowledge for working with relational data (Postgres) and programming experience (Java/Python) in working with unstructured data and/or APIs.,Experience with ETL and/or other integration tooling (DMS/Stitch).,Experience with data analysis and visualization tools (Mode).,Working knowledge of message queuing (SNS/SQS/RabbitMQ) and stream processing (Kinesis).,Strong communication skills, a positive attitude, and empathy.,Self-awareness and a desire to continually improve.,Desire to write and maintain a clean and well-tested code base, avoiding tech debt.,Experience with business operations tools such as Salesforce, Zuora, Hubspot, etc.,Experience with Apache Spark.,General understanding of the data science and machine learning technology landscape.,Experience with AWS services including Lambda, DynamoDB, etc.,Competitive salary,Employee Stock Option Plan,Generous health and commuter benefits,Dog Friendly Office","Translate business requirements into technical requirements, and develop data pipelines from many industry and proprietary systems into a unified data warehouse.,Collaborate with business operations, software engineers, data analysts, and data scientists.,Build scalable, maintainable data pipelines that extract, transform, and load (ETL – DMS/Stitch) high-performance data warehouses (Redshift/Snowflake).","Guru is looking for a Data Engineer to advance our data pipeline enabling our business analytics, customer-facing analytics, and machine learning product features. The Data Engineer will be a member of the Data Science team and work to integrate numerous data systems into a unified data warehouse capable of serving business intelligence and machine learning algorithms. You will demonstrate your foundational business domain and data architecture knowledge to become quickly comfortable with our data, be fully committed to data quality, develop scalable data pipelines, and design a data warehouse with efficient data models for querying that data. The Data Engineer will collaborate with our business operations team, data scientists, and software engineers in building and optimizing an innovative product that our customers love to use every day.
This job is not only about how well you develop; it’s about how you lend your positivity and presence, combined with your skill set to an energized environment and highly collaborative team. Strong sense of humor required, sarcasm detection skills a plus.
Key Responsibilities
Translate business requirements into technical requirements, and develop data pipelines from many industry and proprietary systems into a unified data warehouse.
Collaborate with business operations, software engineers, data analysts, and data scientists.
Build scalable, maintainable data pipelines that extract, transform, and load (ETL – DMS/Stitch) high-performance data warehouses (Redshift/Snowflake).
Implement the monitoring, auditing, and alerting capabilities (CloudWatch) that ensure the ongoing maintenance and quality of a data product.
Requirements
You have 4 years of experience with a deep understanding of data engineering concepts and database designs.
Advanced SQL knowledge for working with relational data (Postgres) and programming experience (Java/Python) in working with unstructured data and/or APIs.
Experience with ETL and/or other integration tooling (DMS/Stitch).
Experience with data analysis and visualization tools (Mode).
Working knowledge of message queuing (SNS/SQS/RabbitMQ) and stream processing (Kinesis).
Strong communication skills, a positive attitude, and empathy.
Self-awareness and a desire to continually improve.
Desire to write and maintain a clean and well-tested code base, avoiding tech debt.
Bachelor’s degree in Computer Science, Engineering or a related field, or equivalent training, fellowship, or relevant work experience.
Preferred but not required
Experience with business operations tools such as Salesforce, Zuora, Hubspot, etc.
Experience with Apache Spark.
General understanding of the data science and machine learning technology landscape.
Experience with AWS services including Lambda, DynamoDB, etc.
Experience with DevOps principles such as CI/CD and IaC (Terraform).
Benefits to you:
Competitive salary
Employee Stock Option Plan
Generous health and commuter benefits
Dog Friendly Office
The chance to contribute to an upbeat, fully engaged culture
About Guru:
Guru is a dynamic, fast growing start-up in Philadelphia and San Francisco. Our mission is to reinvent the way people connect with meaningful information at work. Guru’s knowledge management solution provides customer-facing teams access to expert-verified information where they work and when they need it most. We believe in cultivating a welcoming, inclusive culture that encourages personal growth through working hard and having fun.
Launched in September 2015, our vision is backed by an amazing group of investors, including FirstMark Capital, Salesforce, Michael Dell, the Slack Fund, and Emergence Capital. As we enter the next exciting stage of expansion, we’re searching for passionate individuals to join our rapidly growing team.
This is a full-time position located in our San Francisco or Philadelphia office. Re-location and/or Visa Sponsorship is not included in our hiring package. Applicants will need to be authorized to work in the US.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.
Apply Now
",https://technical.ly/job/guru-technologies-data-engineer-56917/
JOB213078186879,"Data Engineer AWS, Python, R South London","Data Engineer AWS, Python, R South London",,"Excellent understanding of Data Architecture, including both on-premise and via the AWS Cloud.,Strong experience with Data Modelling and Data Analysis, including the ability to query, prepare and analyse Data sets.,Proven commercial experience with both SQL and NoSQL databases.,Skilled in software engineering, with experience in some (not necessarily all) of the following programming languages: Python, R, Java, Scala.,Familiarity with Linux/UNIX and tools including Git and SVN.,Good understanding of Data Science models and Data Modelling in general (e.g. Star Schema, Kimball).,Mobile:,Office Line:,Email:,LinkedIn: 'Liam Haghighat',SQL,Data Science,NoSQL,Architect,Data Modelling","
I am engaged with a leading organisation in the Insurance space who are looking to recruit experienced Data Engineers into their growing 'Cloud & Data' function, based out of their HQ in South East London.
The organisation are going through a huge recruitment drive in 2020, focusing on improving the way they utilise data and you'll be pleased to know that unlike a lot of non-tech companies, they view technology as an enabler rather than a blocker.
The roles in question are focused primarily on the design and development of a strategic analytical platform (AWS) to enable integration, analysis and insight of a variety of data sets, as well as the development of data and analytics solutions for machine learning and data visualisation. Moreover, you will be expected to develop and manage relationships across data, technology and business functions (think stakeholder management), challenging existing paradigms in a constructive manner that demonstrate and promote the value of a mature data analytics capability.
Fundamentally, you will be given the opportunity to drive a data-first mentality within the organisation, a unique and rewarding challenge that is usually quite rare to find in established organisation such as this one.
In terms of their expectations… if you can demonstrate some of the below skills then you stand a good chance of being shortlisted to the interview stage:
Excellent understanding of Data Architecture, including both on-premise and via the AWS Cloud.
Strong experience with Data Modelling and Data Analysis, including the ability to query, prepare and analyse Data sets.
Proven commercial experience with both SQL and NoSQL databases.
Skilled in software engineering, with experience in some (not necessarily all) of the following programming languages: Python, R, Java, Scala.
Familiarity with Linux/UNIX and tools including Git and SVN.
Good understanding of Data Science models and Data Modelling in general (e.g. Star Schema, Kimball).
Some commercial experience with technologies in the Big Data space (e.g. Cassandra, Spark, Kafka, Hadoop, Kibana etc.).
In return, you will get the opportunity to work on cutting-edge projects in an Agile environment.
Moreover, I have personally worked with these guys for years and they have an excellent company culture, focusing on tailored personal development, genuine career progression and flexibility, whether it be home working opportunities or simply flexible working hours. They also offer a generous bonus/benefits package as well as the chance to get huge discounts on car, travel and home insurance.
So if you like the sound of the role and would like to find out more then please contact me via the following:
Mobile:
Office Line:
Email:
LinkedIn: 'Liam Haghighat'
Anything discussed will remain completely confidential and fully compliant with GDPR.
Bank or payment details should never be provided when applying for a job. For information on how to stay safe in your job search, visit SAFERjobs.
Report this job
",http://www.reed.co.uk/jobs/data-engineer-aws-python-r-south-london/40152614
JOB213831392200,Data Engineer,Data Engineer,,"Experience with data lakes and data pipelines,understanding of data and data integration concepts (SQL, data governance, enterprise patterns),problem-solving skills and the ability to independently propose new solutions,strong understanding of development best practices (SDLC, TDD/BDD, CI/CD)","Are you passionate about developing new software solutions and working on cloud native applications? Bring that passion to Macquarie’s Asset Management Technology team and showcase your skills as a Junior Data Engineer based in our Philadelphia office as you develop and maintain our new global data analytics platform.
In this role, you will work collaboratively in a global team and participate in all aspects of the development life cycle. You will manage data pipelines by understanding requirements, discuss solutions and manage scope, as well as design, build and run a global data platform using Python, Java, Javascript, and AWS.
If continuous learning and development important to you, this opportunity will be your chance to learn and apply the latest technologies, including AWS, to deliver and maintain highly scalable and robust services. You will have the opportunity to build and grow greenfield systems used across the Macquarie Asset Management business globally, evangelize new, and extend your technical abilities through collaboration with a high-performing and aspirational team.
You will be a valued member of our diverse team if you are a self-motivated team player and have excellent communication skills, enabling you to engage with all levels of stakeholders.
Ideally, you will also bring to the role:
Experience with data lakes and data pipelines
understanding of data and data integration concepts (SQL, data governance, enterprise patterns)
problem-solving skills and the ability to independently propose new solutions
strong understanding of development best practices (SDLC, TDD/BDD, CI/CD)
understanding of analytics architecture and machine learning
This role offers you a fantastic opportunity to make your mark. If you have a resilient character, a learning mindset, and relish opportunities to stretch yourself, take the next step in your career and apply via the link.
About the Corporate Operations Group
The Corporate Operations Group brings together specialist support services in Digital Transformation & Data, Technology, Operations, Human Resources, Business Services, Business Improvement & Strategy, and the Macquarie Group Foundation. We deliver service excellence to ensure Macquarie is open for business, deliver on transformational change, invest in our people and have deep relationships with our customers.
Our COVID-19 policy
The health and wellbeing of our employees is a priority. We continue to focus on providing a safe workplace for our people, our stakeholders and those who visit us, and are committed to contributing to the safety of the communities where we live and work.
In line with evolving health regulations and many of our industry peers, we require all Macquarie employees in the United States to be fully vaccinated against COVID-19 and provide proof of full vaccination in order to attend the office and to participate in external meetings and business travel, unless a reasonable accommodation is approved or as otherwise required by law.
Our commitment to Diversity and Inclusion
The diversity of our people is one of our greatest strengths, and an inclusive workplace enables us to embrace that diversity to deliver more innovative and sustainable solutions for our people, clients, shareholders and communities. At Macquarie, you’ll be encouraged to be yourself and supported to perform at your best. If you’re inspired to deliver on our purpose of ‘empowering people to innovate and invest for a better future’, we want you on our team. If you need adjustments made to the recruitment process, please reach out to your recruiter.
All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, color, religion, sex, sexual orientation, national origin, age, disability, protected veteran status, genetic information, marital status, gender identity or any other impermissible criterion or circumstance. Macquarie also takes affirmative action in support of its policy to hire and advance in employment of individuals who are minorities, women, protected veterans, and individuals with disabilities.
We equip our people with the support to work in a range of flexible ways. Talk to us about what working arrangements would help you thrive.
Apply Now
",https://technical.ly/job/macquarie-data-engineer-74098/
JOB214742641179,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/ru-ru/details/200188037/ai-ml-search-data-engineer-siri-data
JOB215175903126,Senior Data Engineer (London),Senior Data Engineer (London),"Commercial client-facing project experience, including working in close-knit teams,A proven ability in clearly communicating complex solutions,Data security & governance expertise,Strong experience in traditional data warehousing / ETL tools (Informatica, Talend, Pentaho, DataStage),Experience and interest in Big Data technologies (Hadoop / Spark / NoSQL DBs) and Cloud (AWS and Azure),Strong SQL experience, and optional Python / Scala / Java / R,Exceptional attention to detail","Work with our clients to model their data landscape, obtain data extracts and define secure data exchange approaches,Plan and execute secure, good practice data integration strategies and approaches,Acquire, ingest, and process data from multiple sources and systems into Big Data platforms,Create and manage data environments in the Cloud,Collaborate with our data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models,Have a strong understanding of Information Security principles to ensure compliant handling and management of client data,This is a fantastic opportunity to be involved in end-to-end data management for cutting edge Advanced Analytics and Data Science,Use new and innovative techniques to deliver impact for our clients as well as internal R&D projects,A proven ability to lead a project from an engineering perspective, owning the workflow and setting expectations,Mentoring junior engineers allowing them to develop and be challenged"," QuantumBlack helps companies use data to drive decisions. We combine business experience, expertise in large-scale data analysis and visualization, and advanced software engineering know-how to deliver results. From aerospace to finance to Formula One, we help companies prototype, develop, and deploy bespoke data science and data visualisation solutions to make better decisions.
You’re passionate about data and the opportunity it provides to organisations. You ‘get’ Big Data and Cloud computing for more advanced data processing and Analytics, and are excited about these technologies. You are equally comfortable talking to senior client stakeholders to understand their data as well as designing the ingestion process to store the data locally and preparing it for Data Analytics. You have experience in handling vast amounts of data – working on database design and development, data integration and ingestion, designing ETL architectures using a variety of ETL tools and techniques. You are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled Data Science team.
What you'll do
Work with our clients to model their data landscape, obtain data extracts and define secure data exchange approaches
Plan and execute secure, good practice data integration strategies and approaches
Acquire, ingest, and process data from multiple sources and systems into Big Data platforms
Create and manage data environments in the Cloud
Collaborate with our data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models
Have a strong understanding of Information Security principles to ensure compliant handling and management of client data
This is a fantastic opportunity to be involved in end-to-end data management for cutting edge Advanced Analytics and Data Science
Use new and innovative techniques to deliver impact for our clients as well as internal R&D projects
A proven ability to lead a project from an engineering perspective, owning the workflow and setting expectations
Mentoring junior engineers allowing them to develop and be challenged
Requirements:
Commercial client-facing project experience, including working in close-knit teams
A proven ability in clearly communicating complex solutions
Data security & governance expertise
Strong experience in traditional data warehousing / ETL tools (Informatica, Talend, Pentaho, DataStage)
Experience and interest in Big Data technologies (Hadoop / Spark / NoSQL DBs) and Cloud (AWS and Azure)
Strong SQL experience, and optional Python / Scala / Java / R
Exceptional attention to detail
",http://www.indeed.co.uk/job/Senior-Data-Engineer-at-QuantumBlack-in-London-4661169739662850
JOB215394098139,Data Engineer,Data Engineer,,"Data querying and processing in SQL,Data processing and task management in Python,Communication skills, and ability to translate between the domains of business problems and technical implementations,Refactor operating model code into scalable, transparent processes leveraging Airflow and DBT as core frameworks,Expand the capabilities of Inspire’s core data platform to support incremental product lines and product features,Partner with Analytics to systematize and scale high-integrity value-oriented analysis,Partner with Sales, Operations, and other business stakeholders to design and deliver new data-driven integrations,Cultivated familiarity with Inspire’s frameworks & operating model,Delivery of high-quality pull requests in DBT and Airflow, evidencing strong code standards & testing practices,Comfort with self-directed project management: requires minimal oversight to assess a problem, formulate a solution, deliver code, and document changes.,Technical competency – comfort on a command line, a good grasp on the fundamentals of programming, a general understanding of Git/source control, and a willingness to read the docs, search stack overflow, and test it until it works,Problem-Solving Mentality – gets excited about digging into complexity, wants to ask questions and learn more, and isn’t put off by problems they’ve never been explicitly told how to solve. Especially troubleshooting: ability to break down a chain of steps to narrow and locate a problem.,Number Sense – Strong background in mathematics or physics, comfort with quantitative measurement and estimation. Ability to work in establishing boundaries and orders-of-magnitude to make informed judgements without fussing over exactitude.,1 or more years in a data analytics, engineering or science role,Strong SQL experience working with large datasets, ideally in cloud-based data warehouses,Software development in Python3,Experience automating data processing, cleaning and/or preparation,Experience with key frameworks: Snowflake, Apache Airflow, dbt, AWS services, Docker, Kubernetes,Experience at a similar scale of data processing (Multi-TB/billions of rows),Work with real-time event stream data,Contextual work in the energy industry,Data consultancy experience a plus,Proven ability to break down a chain of steps to narrow and locate a problem","POSITION SUMMARY
As a Data Engineer on Inspire’s Data Platforms and Services team, you will build, maintain, and improve the infrastructure and architecture that flows critical data from internal and external sources to where it creates value for the business. We take a product-driven, agile approach to our platform, driving measurable growth and meaningful outcomes every single sprint. We build efficient, scalable processes in a service-oriented ecosystem leveraging powerful code frameworks and repeatable patterns to solve real problems for stakeholders and customers.
THE DATA ENGINEER HAS FOUR MAIN RESPONSIBILITIES
Data querying and processing in SQL
Data processing and task management in Python
Communication skills, and ability to translate between the domains of business problems and technical implementations
Team-oriented development: building modular & re-usable tools, writing maintainable code, owning technical and business documentation
SOME YEAR 1 DELIVERABLES
Refactor operating model code into scalable, transparent processes leveraging Airflow and DBT as core frameworks
Expand the capabilities of Inspire’s core data platform to support incremental product lines and product features
Partner with Analytics to systematize and scale high-integrity value-oriented analysis
Partner with Sales, Operations, and other business stakeholders to design and deliver new data-driven integrations
Partner with other engineering teams to guide refactors of existing data infrastructure to improve data quality and features.
SUCCESS METRICS
Cultivated familiarity with Inspire’s frameworks & operating model
Delivery of high-quality pull requests in DBT and Airflow, evidencing strong code standards & testing practices
Comfort with self-directed project management: requires minimal oversight to assess a problem, formulate a solution, deliver code, and document changes.
Positive interactions with department stakeholders: can offer guidance and input that creates business value for non-technical personnel.
DESIRED TRAITS
Technical competency – comfort on a command line, a good grasp on the fundamentals of programming, a general understanding of Git/source control, and a willingness to read the docs, search stack overflow, and test it until it works
Problem-Solving Mentality – gets excited about digging into complexity, wants to ask questions and learn more, and isn’t put off by problems they’ve never been explicitly told how to solve. Especially troubleshooting: ability to break down a chain of steps to narrow and locate a problem.
Number Sense – Strong background in mathematics or physics, comfort with quantitative measurement and estimation. Ability to work in establishing boundaries and orders-of-magnitude to make informed judgements without fussing over exactitude.
Big-picture awareness – Understanding of the importance of context, and willingness to understand the business problem in addition to the technical one. Focus on people & impact.
EXPERIENCE
Must Have
1 or more years in a data analytics, engineering or science role
Strong SQL experience working with large datasets, ideally in cloud-based data warehouses
Software development in Python3
Experience automating data processing, cleaning and/or preparation
Software development lifecycle familiarity in GitHub (ie environment management, testing, deployment)
Nice to Have
Experience with key frameworks: Snowflake, Apache Airflow, dbt, AWS services, Docker, Kubernetes
Experience at a similar scale of data processing (Multi-TB/billions of rows)
Work with real-time event stream data
Contextual work in the energy industry
Data consultancy experience a plus
Proven ability to break down a chain of steps to narrow and locate a problem
Strategic approach to problem solving and understand the why behind a problem
Apply Now
More jobs from Inspire
",https://technical.ly/job/inspire-data-engineer-66258/
JOB215526092317,Remote Senior Aerospace Industry Data Engineer Hot,Remote Senior Aerospace Industry Data Engineer Hot,,,"
Remote Senior Aerospace Industry Data Engineer job at Lockheed Martin Corporation in Kansas City MO
Description, duties, responsibilities
A security company has an open position for a Remote Senior Aerospace Industry Data Engineer. Core Responsibilities of this position include: Optimizing the use of Infrastructure as Code for automation of Data Ops deployments Assessing the complete landscape of Data Ops Services Developing CI/CD pipelines to manage effective changes to multiple infrastructure footprints
Qualifications Include: May be required to travel to an office location for periodic meetings Bachelors Degree in Engineering Computer Science or other related discipline 3+ Years of experience working with Kubernetes 2+ Years of experience working with Big Data Technologies such as Spark Kafka and Presto Experience with DevOps tools: Docker Git Continuous Integration Continuous Deployment Experience with data processing (such as Hadoop Spark Pig Hive MapReduce etc)
Lockheed Martin Corporation Company Overview
The following jobs have been promoted on the Aviation Ad Network and are to be considered - current, newsworthy aviation employment information (FYI). No guarantee is made as to the accuracy, completeness or timeliness of any information, projections or opinions in announcements obtained through the promoted jobs. The information contained in this announcement is compiled for the convenience of site visitors and is accepted by the site visitor on the condition that errors or omissions are not the responsibility of Avjobs and shall not be made the basis for any claim, demand or cause of action. Please visit this companys web site for additional details and information. Please reference Avjobs when applying.
",http://www.avjobs.com/jobs/public.asp?Company=Lockheed+Martin+Corporation&g=C6192ACC-BE87-41B7-9628-5DA43B00BE21&t=Remote+Senior+Aerospace+Industry+Data+Engineer&l=Kansas+City%2BMO
JOB217754692140,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-ca/details/200188037/ai-ml-search-data-engineer-siri-data
JOB219620459383,Data Engineer,Data Engineer,"Assist in gathering new data sources at scale (including API calls and web scraping),Process unstructured and structured data into a use for analysis,Proficient in one or more common scripting languages (Python preferred),Experience designing data architecture from ground-up,Experience processing large amounts of structured and unstructured data,Extensive AWS Experience",,"
“Awesome CEO, great culture, and lost of room for growth!”
Who we are
LeadCrunch is a fast-growing, venture-backed startup based in San Diego that uses data science and artificial intelligence to drive marketing pipeline and funnel performance. At a time when sales and marketing are going through the largest shift in history, LeadCrunch is positioned to dominate the MarTech and lead gen space.
We have significant traction. Here’s recent press on our company:
Forbes: “Top 11 Sales Tools Every Business Owner Needs”, more than 2,100 social media shares
Entrepreneur: “10 Sales Platforms to Help You Boost Revenue in 2017”
The Next Web: “How AI Is Going To Change Lead Generation Forever”
We are a seasoned team with a strong culture. We have started or been a part of starting more than 20 companies, including 4 exits. Our investors have realized more than $20 billion in exits from 45 companies including more than a dozen IPOs. Our culture fosters commitment, diversity, passion, curiosity, learning, fun, trust, empowerment, first principles thinking, and a bias for action.
What we need this person to do:
We are looking for a Data Engineer to join the LeadCrunch team. Our mission is to develop a deeper understanding of the millions of companies that make our economy function and use this understanding to change the way B2B sales and marketing work.
Responsibilities & Qualifications
Key Responsibilities:
Assist in gathering new data sources at scale (including API calls and web scraping)
Process unstructured and structured data into a use for analysis
Work closely with Engineering and Data Science team to integrate rapid data access to LeadCrunch products and Data Science platform
Qualifications:
Proficient in one or more common scripting languages (Python preferred)
Experience designing data architecture from ground-up
Experience processing large amounts of structured and unstructured data
Extensive AWS Experience
Experience setting up a Data Science Platform, a plus
LeadCrunch[ai] solves the problem of finding optimal B2B targets. We analyze your best customers to identify “Smart Personas"". We then engage look-alike personas with relevant content to generate permission-based leads.
Unlike other technologies, LeadCrunch[ai] combines data, outreach, and artificial intelligence to deliver the right person at the right company with the right message at the right time. We increase sales conversion rates by as much as 300%. The system continuously learns and improves based on the deals you qualify or close.
Posted date: 6 months ago
",https://www.ziprecruiter.com/jobs/leadcrunch-1ee54517/data-engineer-a1a5d38c?mid=3429&source=cpc-Glassdoor-priority
JOB219723462918,Data Engineer,Data Engineer,,,"
First People Solutions are working on behalf of a leading building support services provider who are looking for experienced Data Cabling Engineers to join their team in Halifax.
The main duties will include but is not limited to:
Data Cabling - Installation of Cat5E, Cat6, Cat6a. Testing cabling using Fluke DTX & DSX.
Fibre Cabling - Installation of fibre cabling. Ability to test fibre cabling using Fluke DTX & DSZ using multimode/single mode tester.
Voice Cabling - Ability to terminate/jumpering voice cabling within 237A Krone strips. Ability to test fibre cabling using Fluke DTX & DSZ data tester
Cabinet & Containment - Ability to install data cabinets & carry out containment.
General - Knowledge of Krone, Systimax, Brand-Rex etc
You must have the ability to work to your own initiative and be able to successfully complete tasks within given timescales. You must have a ECS Grade Card and hold a full clean driving licence.
If interested in the position please apply by attaching your CV or contact Rebecca on 0141 270 5130.
",https://www.totaljobs.com/job/data-engineer/first-people-solutions-job75164816
JOB222094515062,SAP Sybase IQ Data Engineer,SAP Sybase IQ Data Engineer,,"Several years' experience working in SAP Data Services/Sybase IQ with at least two BI projects.,Experience designing ETL solutions,The ability to liaise with the business to gather requirements and create technical documentation.,Experience in data warehouse design and build.,Data,IQ,SAP,SQL","
SAP Data Services * ETL * Data Engineer * SQL * Sybase IQ * Data Warehousing * Business Objects * Data Warehousing * Data Management
SAP Sybase IQ Data Engineer
Leeds
£48,000 - £52,000
This is an excellent role for an experienced SAP Sybase IQ Data Engineer developer to join an excellent Business Intelligence and Data Engineering team who are undertaking a Greenfield Data Warehousing project using agile methodology.
You will work on a range of end to end projects across ETL design, data warehousing, SAP IQ and Datawarehousing
This an excellent role for someone looking for career progression and to develop new techniques and skills. There will be two interviews, the first a telephone screen and the second will be in the head office.
As the Data Engineer you should have:
Several years' experience working in SAP Data Services/Sybase IQ with at least two BI projects.
Experience designing ETL solutions
The ability to liaise with the business to gather requirements and create technical documentation.
Experience in data warehouse design and build.
Excellent communication skills and the capability to interact with business stakeholders at a variety of levels.
Reference: 32944654
Bank or payment details should not be provided when applying for a job. reed.co.uk is not responsible for any external website content. All applications should be made via the 'Apply now' button.
Report this job
",https://www.careerjet.co.uk/clk/e49bc201506e50a648284ffc223404f9.html
JOB222362442608,Data Engineer,Data Engineer,,,"
Data Engineer X 2 – Manchester. Our client based near Manchester are currently looking for 2 Data Engineers with Azure experience. The company is currently going through a large digital transformation, they are looking for talented Data specialist to help...
Job Title: Data Engineer Salary: 45,000 to 54,000 plus Benefits Location: Cambridge This is a very rare opportunity for an experienced Data Engineer with a strong background in building Python based data processing pipelines to join a company that are...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Data Engineer - 70,000 Job Description An AWS Partner based in Central London is looking to expand the data side of their business due to growth. They are looking for Data Engineers with significant commercial experience ingesting large quantities of data...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer - Python - Permanent Data Idols are working with a well-known client in the e-commerce space who are looking for a Data Engineer to join an existing team. THE ROLE As a Data Engineer, you will be working with the existing Data team to help...
Data Engineer - Manchester A growing business based in Manchester City Centre are currently looking for a Data Engineer to help shape their newly formed Data Engineering team and build scalable, reliable and secure cloud datawarehouse solutions and data...
An exciting start up Fintech company has a new opportunity for a Data Engineer where you will play an active part in the success of the company. This role will see you joining a small team where you'll have the opportunity to take responsibility for Data...
Job title : Data Engineer Location: London Job type: Permanent Salary: Up to 70,000 per annum Reporting to: Head of Data Engineering Overview A fantastic internet company based in Central London are currently looking for a Data Engineer to come on board...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer- 50K Manchester Adria Solutions has an exciting opportunity for a talented Data Engineer to join our rapidly expanding client based near Manchester. The role requires you to work closely with other members of the data team and stakeholders...
Data Engineer / Data Scientist / Biomedical Informatics / Human Genetics / Python / SQL / R / Oxford / Cambridge / Permanent 60 - 90K (Depending on Experience) Excellent Benefits COVID Safe Interview Process 100% Remote during Covid and up to 50% Post...
Data Engineer London 80,000 - 90,000 Benefits This Data Engineering role will allow you to expand and utilise your skills in a growing team working along side one of the largest data sets in the UK. The Company As a global leader they generate tons of...
Data Engineer (12-month Fixed Term Contract) 50,000 - 55,000 We are looking for a Data Engineer to join a market leading business we're representing, based in central London. Working as part of the central Data Science & Analytics team, you will be...
DATA ENGINEER - CURRENTLY REMOTE WORKING LEEDS - CURRENTLY REMOTE WORKING BETWEEN 35,000 - 50,000 BENEFITS BONUS Harnham are partnered with a Financial Services Company to help hire for a Data Engineer within their Business Intelligence team. The team...
DATA ENGINEER - CURRENTLY REMOTE WORKING LEEDS - CURRENTLY REMOTE WORKING BETWEEN 35,000 - 50,000 BENEFITS BONUS Harnham are partnered with a Financial Services Company to help hire for a Data Engineer within their Business Intelligence team. The team...
Data Engineer London 55,000 - 65,000 Benefits Our client, an exciting RegTech business is looking to recruit for a Data Engineer to join their growing team. The successful candidate will be joining the artificial intelligence team, working on a brand new...
",https://www.reed.co.uk/jobs/data-engineer/40402648
JOB223190401894,Data Engineer - Information Security,Data Engineer - Information Security,"2+ years experience working with data systems,2+ years experience with data warehousing, processing, pipelines, infrastructure, and query patterns,2+ years experience with Spark or Hadoop,2+ years experience with open source ETL frameworks such as Airflow, Luigi, or similar,4+ years experience with Python and SQL,Experience with systems for data processing (Spark, Flink, Hadoop, Airflow) and storage (S3, Kafka, ElasticSearch, Dynamo, MySQL, or Postgres),Experience with ELK,Experience reading and optimizing data schema queries for content and performance","Create and promote a technical design and architectural vision for security operations data systems and tooling,Work with engineers on the team to manage infrastructure for moving and processing large-scale data,Improve log flows efficiency through data processing to reduce the cost of analysis and storage,Convert log flows from Logstash to Elastic Common Schema,Work with Analysts to determine and implement the best practices for data retention and storage,Design and promote standards for security operations data telemetry and processing,Help engineers across the team select data technologies for their development needs","
Riot's Data Engineers build tools to understand and improve the experience of our players worldwide using petabytes of data and state-of-the-art processing technology. Handling the potential these data offer is a tremendous and complex task. As we continue delivering and scaling content to passionate players, our discipline has challenges and opportunities centered on building data products that support our growth.
The Information Security group at Riot supports teams across the company to develop robust security capabilities which help protect player experiences. At the most fundamental level, our goal is to help deliver value to players and make life harder for troublemakers.
As a Data Engineer on the Security Operations team within the Information Security group, you bring a unique mix of distributed data processing, data warehousing, and software engineering skills to develop scalable data systems that inform our decisions and ensure the safety of Riot's platforms and the players using them. You can translate security requirements into sustainable data architecture and workflows. You will work with Security and Software Engineers to solve current problems and create new opportunities. You will design and promote our technical strategy for how we use data to transform security operations. You will work with engineers across Information Security group to establish and promote standards for collecting, processing, storing, and analyzing data.
Responsibilities:
Create and promote a technical design and architectural vision for security operations data systems and tooling
Work with engineers on the team to manage infrastructure for moving and processing large-scale data
Improve log flows efficiency through data processing to reduce the cost of analysis and storage
Convert log flows from Logstash to Elastic Common Schema
Work with Analysts to determine and implement the best practices for data retention and storage
Design and promote standards for security operations data telemetry and processing
Help engineers across the team select data technologies for their development needs
Be the face of data best-practices to engineers on the team around the product by advocating for data considerations early in the product life cycle and educating teammates on how to get the most out of Riot data ecosystem.
Required Qualifications:
2+ years experience working with data systems
2+ years experience with data warehousing, processing, pipelines, infrastructure, and query patterns
2+ years experience with Spark or Hadoop
2+ years experience with open source ETL frameworks such as Airflow, Luigi, or similar
4+ years experience with Python and SQL
Bachelor's degree in Computer Science or related field
Desired Qualifications:
Experience with systems for data processing (Spark, Flink, Hadoop, Airflow) and storage (S3, Kafka, ElasticSearch, Dynamo, MySQL, or Postgres)
Experience with ELK
Experience reading and optimizing data schema queries for content and performance
Experience working in agile project management methodologies (Scrum, Kanban)
For this role, you'll find success through craft expertise, a collaborative spirit, and decision-making that prioritizes the delight of players. We will be looking at your past studies, experience, and your personal relationship with games. If you embody player empathy and care about the experiences of players, this could be the role for you!
Our Perks:
We offer medical, dental, and vision plans that cover you, your spouse/domestic partner, and children. Life insurance, parental leave, plus short-term and long-term disability coverage are also available. Riot will support your retirement benefits with a company match, and double down on your donations of time and money to non-profit charitable organizations. Balance between work and personal life is encouraged with open paid time off, and a play fund so you can broaden and deepen your personal relationship with games.
===
It's our policy to provide equal employment opportunity for all applicants and members of Riot Games, Inc. Riot Games makes reasonable accommodations for handicapped and disabled Rioters and does not unlawfully discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity or expression, national origin, age, handicap, veteran status, marital status, criminal history, or any other category protected by applicable federal and state law, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance relating to an applicant's criminal history (LAMC 189.00).
Don't forget to include a resume and cover letter. We receive many applications, but we'll notice a fun, well-written intro that shows us you Dare to Dream and Execute with Excellence.
","https://www.ziprecruiter.com/c/Riot-Games/Job/Data-Engineer-Information-Security/-in-Los-Angeles,CA?ojob=52b9004fc281ef33b99facf8c35f0d9d"
JOB224219585077,"Data Engineer, Analytics (Ads Common Data Platform)","Data Engineer, Analytics (Ads Common Data Platform)","8+ years of engineering experience with 4+ years focused on architecting data platforms,Working experience on a large scale data warehouse platform,Hands-on experience working with either a MapReduce/Spark/Presto or an MPP system,Skilled in dimensional data modeling and schema design for data warehousing,Bachelor's Degree in computer science, engineering, mathematics or related fields, or equivalent experience,Expert SQL knowledge and experience optimizing for large datasets,Masters Degree in computer science, engineering, mathematics or related fields, or equivalent experience","Collaborate with Software Engineers on centralized and standardized data aggregations to pipeline metrics for UI consumption,Defining canonical data schemas and tables for ads, sales and revenue that provide a complete view of a customer,Work with data infrastructure teams to suggest improvements and influence their roadmap,Collaborate with Software Engineers to design technical specification for logging and add logging to production code to generate metrics,Recommend improvements and modifications to existing data and ETL pipelines,Communicate and influence strategies and processes around data modeling and architecture to multi-functional groups and leadership,Evangelize high quality software engineering practices in developing data infrastructure and pipelines at scale,Transform data aggregations from daily batch processing to incremental near-real time,Drive internal process improvements and automating manual processes for data quality and SLA management,Create solutions and tooling to decrease data fragmentation and promote reusability through logical data modeling and rich representations (e.g. structs) of common data objects,Data consistency and accuracy measurement and alerting,Working on better metadata management and connecting write-side/aggregations with query-side metadata,Build data anomaly detection, data quality checks, and optimize pipelines for ideal compute and storage","
Facebook's mission is to give people the power to build community and bring the world closer together. Through our family of apps and services, we're building a different kind of company that connects billions of people around the world, gives them ways to share what matters most to them, and helps bring people closer together. Whether we're creating new products or helping a small business expand its reach, people at Facebook are builders at heart. Our global teams are constantly iterating, solving problems, and working together to empower people around the world to build community and connect in meaningful ways. Together, we can help people build stronger communities - we're just getting started.
Summary
Facebook's ads and business ecosystem is highly complex and rapidly evolving. In Ads and Business Platform, Sales and Marketing Interfaces' (SMI) mission is to maximize the impact of every sales and support interaction with our advertisers and we do this by surfacing the right actionable information and directing the right human interactions to the right advertisers. Our data engineering team is responsible for data foundations and sales reporting platform for ads, customer and revenue data that underpins internal tools such as CRM and provides reporting and insights that tens of thousands of Facebook's frontline sales, support staff and leadership use every day to make decisions. In this role, you will be responsible for building data processing and reporting infrastructure that powers CRM and other UI tools. You will work closely with Sales Data Platform and Client Identity Platform software engineering teams. You will be responsible for thinking holistically about data and reporting platform, owning and implementing a roadmap defining the data architecture, pipelines, data quality and timeliness monitoring, data models and instrumentation.
Required Skills
Collaborate with Software Engineers on centralized and standardized data aggregations to pipeline metrics for UI consumption
Defining canonical data schemas and tables for ads, sales and revenue that provide a complete view of a customer
Work with data infrastructure teams to suggest improvements and influence their roadmap
Collaborate with Software Engineers to design technical specification for logging and add logging to production code to generate metrics
Recommend improvements and modifications to existing data and ETL pipelines
Communicate and influence strategies and processes around data modeling and architecture to multi-functional groups and leadership
Evangelize high quality software engineering practices in developing data infrastructure and pipelines at scale
Transform data aggregations from daily batch processing to incremental near-real time
Drive internal process improvements and automating manual processes for data quality and SLA management
Create solutions and tooling to decrease data fragmentation and promote reusability through logical data modeling and rich representations (e.g. structs) of common data objects
Data consistency and accuracy measurement and alerting
Working on better metadata management and connecting write-side/aggregations with query-side metadata
Build data anomaly detection, data quality checks, and optimize pipelines for ideal compute and storage
Craft and own the optimal data processing architecture and systems for new data and ETL pipelines
Minimum Qualification
8+ years of engineering experience with 4+ years focused on architecting data platforms
Working experience on a large scale data warehouse platform
Hands-on experience working with either a MapReduce/Spark/Presto or an MPP system
Skilled in dimensional data modeling and schema design for data warehousing
Bachelor's Degree in computer science, engineering, mathematics or related fields, or equivalent experience
Expert SQL knowledge and experience optimizing for large datasets
Experience effectively collaborating and communicating complex technical concepts to a broad variety of audiences
Preferred Qualification
Masters Degree in computer science, engineering, mathematics or related fields, or equivalent experience
EOE
Facebook is proud to be an Equal Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Facebook is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.
",https://www.gettinghired.com/job-details/2482583/data-engineer-analytics-ads-common-data-platform-/
JOB224489954134,Data Engineer,Data Engineer,,,"
Data Engineer - Central London - Consultancy
£50,000 - £90,000 (Dependent on experience)
Immediate Start Dates (January 2020)
This Client has an immediate requirement to hire x4 Data Engineers, to join their growing team based in Central London.
Due to a surge of new business, this company are seeking candidates of varying levels to work on new projects. In doing so, you will apply your knowledge within Big Data to drive business forward and continuously work towards innovation.
This company deliver exceptional results to their Client base, and are in pursuit of innovation through the use of modern, cutting-edge Big Data technologies (with a wide variety of resources at their disposal to do so!)
You will be collaborating with a variety of highly-skilled technologists across differing areas of Big Data, Analytics and DevOps.
Day to day, you will be given the autonomy to take charge of your own work, in full control of your career progression whilst having the full support and backing of your colleagues throughout.
This company offer a variety of training programmes and access to certifications, allowing you to continuously grow and keep up to date with modern technology stacks.
Skills
Experience with cloud technologies (AWS, Azure OR GCP)
Experience with different programming languages (Python, Java OR Scala)
An understanding/experience with Big Data technologies
An understanding or DevOps, CI/CD, Kubernetes, Docker
Benefits
Training and Certifications in Cloud/Data Technologies
Potential for home working
Laptop
Health Insurance
Life Insurance
Interview's are already underway, so to avoid disappointment, apply today or message:
ALEX TODD at Jefferson Frank
Email :
Number :
Linkedin : in/alex-todd-25a072105/
",https://www.reed.co.uk/jobs/data-engineer/39671652
JOB224872613811,"Senior Data Engineer jobs in Los Angeles, CA","Senior Data Engineer jobs in Los Angeles, CA",,,"
Full Time Job
The Senior Data Engineer will be a critical member of the Publisher Solutions Group responsible for working with multiple teams to create customer and business value from the Company's unique data assets. Reporting to the Head of Data Engineering for Nexstar Digital, the right candidate will work closely with other senior stakeholders including Data, Product, Revenue and Operations, Content, and Business Development. The ideal person will be a highly motivated, passionate leader from a data-driven environment that operates equally as effectively in both independent and team collaboration settings. He/she should have strong business acumen, solid technology experience, and familiarity with the broadcast and/or digital media industry in addition to possessing excellent data engineering and science skills.
The right candidate will collaborate with multiple teams and own responsibility for the technical architecture and hands-on development efforts required to create and execute on an enterprise-wide BI strategy. Working with the data and revenue team, this architecture will establish the capabilities necessary to generate meaningful, actionable insights into user and advertiser behavior across our entire network. He/She will be one of the leads responsible for building and/or integrating the solution(s) for collecting, managing, and analyzing consumer, product, social, market, competitive, and ad data to lead high-impact projects that move our business into the future. It is also a unique opportunity to build a new team and a new set of capabilities for a large broadcast company.
Responsibilities
• Architect, develop, integrate, maintain, and / or improve the systems for holistic data sets from internal and external sources
• Generate proper data visualization reports / dashboards to support executive management decision making as well as tactical next steps and KPIs
• As an SME, work with the data and revenue teams, and within the organizational structure, to drive the data architecture and research needs that will empower executive decision making and establish best practices for technologies, tools, and process
• Build on our current analytics capabilities to create a multi-platform, advanced analytics data solution
• Help establish the short- and long-term needs of the data science team, including budget, resource and system requirements, and alliance management strategies required to lead and execute on key projects to solve complex business challenges
• Provide leadership in creating, aligning and executing a data-driven, predictive strategy to optimize customer acquisition, marketing initiatives, content and social programs to help drive our long-term vision and objectives
• Identify new data sources and strategy for staying one step ahead of the competition
• Prepare research, communication materials and presentations for the senior leadership team across Nexstar Digital and the Nexstar Media Group team
Minimum Qualifications
• 7+ years in data architecture and analytics, software development, insights creation, and strategic management
• 5+ years leading a team and managing the work of others. Knowledge or prior experience in media/entertainment or with a direct to consumer streaming service a plus
• Bachelor's degree required with a major in Computer and/or Data Science, Statistics, Mathematics, or Engineering. Advanced degree preferred.
• Demonstrable thought leadership in the technologies that power Business Intelligence, Machine Learning, and Advanced Analytics solutions
• Strong cultural and team leadership skills
• Capable of having strategic conversations at the executive level and tactical, technical discussions across teams
• Creative problem-solver with ability to look beyond existing business and technology limitations to identify the ''next thing''
• In-depth understanding of all stages of customer acquisition, conversion, and lifetime value
• Proven success in the execution/project management of large-scale data mining and insights projects from inception through build and deployment
• Expertise in qualitative and quantitative research methodologies, and experience developing market-based research solutions
• System knowledge and experience
• Data Modeling and System Analysis
• EMR, Data Bricks, AWS, GCP and Other Data Platforms
• Data Integration tools such as SQL, Spark, Scala, Python, Data Bricks, Airflow and/or R, Machine Learning
• Business Intelligence reporting tools (Microstrategy, Looker, Tableau) a plus
• Digital Marketing tools for instrumentation and analysis, such as Segment, Google Analytics, Pickaxe, Google Ad Manager, STAQ, LiveRamp, BlueConic, and others
• Working knowledge of ad servers, OMS, DMP, DSP and SSP solutions including Google Ad Manager, AdX, Rubicon, WideOrbit, DV360, Amazon, and others
About Nexstar Digital
Nexstar's digital media products and services focus on providing innovative solutions to audiences, clients and any business looking to gain an edge in the shifting digital landscape. Along with Nexstar's dedication to providing local news, entertainment and sports content through its digital platforms, Nexstar Digital's companies provide digital publishing and content management platforms, a video advertising platform, digital agency services and other digital media solutions to publishers and advertisers.
If you like wild growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us!
Per your acceptance of our Terms of Use, if you aggregate, display, copy, duplicate, reproduce, or otherwise exploit for any purpose any Content (except for your own Content) in violation of these Terms without EntertainmentCareers.Net's express written permission, you agree to pay EntertainmentCareers.Net three thousand dollars ($3,000) for each day on which you engage in such conduct.#9/28/2020 2:06:02 PM
",https://www.entertainmentcareers.net/nexstar/senior-data-engineer/job/326372/
JOB225403260238,Senior Data Engineer,Senior Data Engineer,50+ career categories,"Find a better job, faster!,Hand-screened leads,No ads, scams, junk,Great job search support","
Senior Data Engineer
The sr. data engineer will be scaling event ingestion pipelines, optimizing analytical data, refining APIs, and working on backend development activities for projects. Requires at least five years' experience building web apps and APIs. Remote role.
Job Details
10/07/20
100% Remote
Employee
Full-Time
Experienced
No
Company name here
Other benefits listed here
Find a better job, faster!
Hand-screened leads
No ads, scams, junk
Great job search support
50+ career categories
Create an Account to Unlock
To find out more about or apply to this Senior Data Engineer job—and other great opportunities like it—become a FlexJobs member today!
With FlexJobs, you'll find the best flexible jobs and fantastic expert resources to support you in your job search. If you have any questions, please feel free to contact us.
",https://www.flexjobs.com/publicjobs/senior-data-engineer-1157633
JOB226339619679,"How Much Do Remote Data Engineer Jobs Pay per Year in Remote, OR?","How Much Do Remote Data Engineer Jobs Pay per Year in Remote, OR?",,,"
We design and develop data-driven tools and applications for international organisations who focus ... A day in the life of a Back End Engineer at Vizzuality We're looking for someone to work alongside ...
Quick Apply
If you have a passion for Data Cloud Engineer, looking for long term career growth & opportunity ... REMOTE working as long as you are located in the USA and have reliable internet. *** This is a W2 ...
Quick Apply
Bytecode IO is a growing data consulting company that is looking for a customer-focused Senior BI ... This is a remote full-time W2 position - US only based * You must prove you are authorized to work ...
","https://www.ziprecruiter.com/Jobs/Remote-Data-Engineer/-in-Remote,OR"
JOB226664032779,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-ie/details/200188037/ai-ml-search-data-engineer-siri-data
JOB227662490133,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/es-cl/details/200188037/ai-ml-search-data-engineer-siri-data
JOB228450134539,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-au/details/200188037/ai-ml-search-data-engineer-siri-data
JOB229113948684,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-pt/details/200188037/ai-ml-search-data-engineer-siri-data
JOB229438511627,Senior Data Engineer - 69541BR,Senior Data Engineer - 69541BR,,"Develops large scale data structures and pipelines to organize, collect and standardize data that helps generate insights and addresses reporting needs.,Writes ETL (Extract / Transform / Load) processes, designs database systems and develops tools for real-time and offline analytic processing.,Collaborates with data science team to transform data and integrate algorithms and models into automated processes.,Uses knowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries to build data pipelines. Uses strong programming skills in Python, Java or any of the major languages to build robust data pipelines and dynamic systems. Builds data marts and data models to support Data Science and other internal customers.,Integrates data from a variety of sources, assuring that they adhere to data quality and accessibility standards.,Strong problem solving skills and critical thinking ability.,Strong collaboration and communication skills within and across teams.,5 or more years of progressively complex related experience.,Ability to leverage multiple tools and programming languages to analyze and manipulate data sets from disparate data sources.,Ability to understand complex systems and solve challenging analytical problems.Experience with bash shell scripts, UNIX utilities & UNIX Commands.,Knowledge in Java, Python, Hive, Cassandra, Pig, MySQL or NoSQL or similar.,Knowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries against data in the HDFS environment.,Experience building data transformation and processing solutions.Has strong knowledge of large scale search applications and building high volume data pipelines.,Master's degree preferred.","
Description:
Leads and participates in the design, built and management of large scale data structures and pipelines and efficient Extract/Load/Transform (ETL) workflows. This is highly visible role with claims and finance internal stakeholder interface.
Fundamental Components:
Develops large scale data structures and pipelines to organize, collect and standardize data that helps generate insights and addresses reporting needs.
Writes ETL (Extract / Transform / Load) processes, designs database systems and develops tools for real-time and offline analytic processing.
Collaborates with data science team to transform data and integrate algorithms and models into automated processes.
Uses knowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries to build data pipelines. Uses strong programming skills in Python, Java or any of the major languages to build robust data pipelines and dynamic systems. Builds data marts and data models to support Data Science and other internal customers.
Integrates data from a variety of sources, assuring that they adhere to data quality and accessibility standards.
Analyzes current information technology environments to identify and assess critical capabilities and recommend solutions. Experiments with available tools and advises on new tools in order to determine optimal solution given the requirements dictated by the model/use case.
Background Experience:
Strong problem solving skills and critical thinking ability.
Strong collaboration and communication skills within and across teams.
5 or more years of progressively complex related experience.
Ability to leverage multiple tools and programming languages to analyze and manipulate data sets from disparate data sources.
Ability to understand complex systems and solve challenging analytical problems.Experience with bash shell scripts, UNIX utilities & UNIX Commands.
Knowledge in Java, Python, Hive, Cassandra, Pig, MySQL or NoSQL or similar.
Knowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries against data in the HDFS environment.
Experience building data transformation and processing solutions.Has strong knowledge of large scale search applications and building high volume data pipelines.
Master's degree preferred.
Bachelor's degree or equivalent work experience in Computer Science, Engineering, Machine Learning, or related discipline.
Potential Telework Position:
No
Percent of Travel Required:
0 - 10%
EEO Statement:
Aetna is an Equal Opportunity, Affirmative Action Employer
Benefit Eligibility:
Benefit eligibility may vary by position.
Candidate Privacy Information:
Aetna takes our candidate's data privacy seriously. At no time will any Aetna recruiter or employee request any financial or personal information (Social Security Number, Credit card information for direct deposit, etc.) from you via e-mail. Any requests for information will be discussed prior and will be conducted through a secure website provided by the recruiter. Should you be asked for such information, please notify us immediately.
#LI-DT1
",https://www.gettinghired.com/job-details/260818/senior-data-engineer-69541br/
JOB230443309916,Data Engineer,Data Engineer,,,"
Job title: Data Engineer Location : Zurich. Switzerland Job type : Contract Data Engineer with Hadoop/Apache Sparc Knowledge - - Build a data processing layer based on Hadoop,Spark, Neo4J - Ensure appropriate security processes are integrated with access...
Data Engineer We have had a role come available for a Data Engineer in London. The role will require you to either hold a DV Clearance. Key Experience: Data Analysis experience; Strong SQL skills; Data Processing using ETL tools; Understanding of procurement...
Data Engineer / Data Scientist / Biomedical Informatics / Human Genetics / Python / SQL / R / Oxford / Cambridge / Permanent 60 - 90K (Depending on Experience) Excellent Benefits COVID Safe Interview Process 100% Remote during Covid and up to 50% Post...
Data Engineer - Contract - Remote Based Data Engineer Until end November 2020 initially Remote Based (Office is based in Chester) Competitive pwd Ltd Company Tech Skills Required: ETL Design, Talend, MYSQL, Vertica We are currently looking for a Data Tester...
Data Engineer - Contract - Remote Based Data Engineer Until end November 2020 initially Remote Based (Office is based in Chester) Competitive pwd Ltd Company Tech Skills Required: ETL Design, Talend, MYSQL, Vertica We are currently looking for a Data Tester...
Data Engineer - Permanent Data Idols are working with a well-known client in the e-commerce space who are looking for a Data Engineer to join an existing team on a permanent basis. THE ROLE As a Data Engineer, you will be working with the existing Data...
Senior Data Enigneer - Permanent Data Idols are working with a well known Technology company who are looking for a Senior Data Engineer to join a cross-functional team. This industry disruptor has been changing the way people interact with an everyday...
DATA ENGINEER ENERGY LONDON BETWEEN 60,000 - 80,000 This vacancy is an excellent opportunity to join an energy trading firm who have recently launched a new data initiative. The role will involve developing a data platform utilising Python, Spark &...
Site Name: UK - London - Brentford, USA - Pennsylvania - Upper Providence Posted Date: Jun 4 2020 Are you looking for a challenging opportunity to work in an area where cutting edge science meets cutting edge technology with an aim of delivering drugs...
Site Name: UK - London - Brentford, USA - North Carolina - Research Triangle Park, USA - Pennsylvania - Philadelphia Posted Date: Mar 17 2020 Data Engineer is accountable for developing and delivering cloud-based data ingestion solutions across the Pharma...
Urgent Requirement for Azure Data Engineer Someone with 2-3 yrs experience within the data field and proven record of accomplishment of developing and designing technical solutions using cloud platforms such as Microsoft Azure to deliver analytics-driven...
Remote working. Up to 550 p/day. SQL Server, SSIS, AWS 6-month contract opportunity for a Senior Data Engineer with financial services experience. What you'll be doing Working for a large financial services client, you will work in a team of data engineers...
LEAD DATA ENGINEER LONDON, CURRENTLY FLEXIBLE / REMOTE / HOME WORKING UP TO 100,000 BENEFITS BONUS Harnham are partnered with an exciting tech scale up based in Central London. They are looking for an experienced data engineer to lead the build of a greenfield...
Azure Data Engineer Leading Insurance business Work on a large scale Azure migration project. Build dimensional models. 6 month initial contract - inside IR35 My client is looking for 2 Data Engineers with excellent Microsoft Azure experience for a large...
Senior Data Engineer - Permanent Data Idols are working with a well known Technology company who are looking for a Senior Data Engineer to join a cross-functional team. This industry disruptor has been changing the way people interact with an everyday...
THE COMPANY Leading telecommunication company who are looking to improve their Data Engineering function. My client is looking for a data engineer to join their team of world class engineers and Data Scientists to build end-to-end applications that make...
Our client, a global travel company require a Digital Data Engineer with strong GCP/ Big Query skills to join their analytics engineering team. Your Role You will be responsible for developing reporting infrastructure and providing actionable reporting...
Python Data Engineer, Oxford or remote, 65k to 75k Avanti Recruitment is working with a successful SAAS provider in the finance domain, to recruit a Python Data Engineer who will excel in a modern DevOps environment. Main areas of expertise are Python...
Supporting a fast growing, global organisation the Interim Data Engineer will become a business partner to a newly established international client. You will be responsible for the following: - Building reporting architectures and pipelines for streamed...
Data Engineer Quantitative Trading - London One of the world's leading online CFD and financial spread betting providers is looking for a talented Data Engineer to join their business in London and support Data Science team. ROLE AND RESPONSIBILITIES -...
A Global leading company is currently recruiting for a Big Data Engineer that has experience with Python, SQL, Spark and Tableau. Based in Preston. Experience and skills required: Python (2-8 years) SQL Spark Tableau Demonstrated experience in Analytics/Big...
DEVOPS ENGINEER - DATA LONDON, CURRENTLY FLEXIBLE / REMOTE / HOME WORKING UP TO 75,000 BENEFITS BONUS Harnham are partnered with one of the leaders in renewable energy initiatives and energy traders in the World. This company have been going through a...
Big Data Engineer - Permanent Data Idols are working with a well-known client in the Fintech industry. They are looking for a Big Data Engineer to join an existing data team. You will be helping build end to end applications that make use of large volumes...
SENIOR DATA ENGINEER 550- 650 PER DAY 3 MONTH CONTRACT REMOTE/ LONDON BASED As a Senior Data Engineer you will have the chance to work for a innovative e-commerce client in productionising ML models using Python, SQL and Airflow alongside AWS services...
Data Engineer SC cleared London, Titchfield or Newport 3 months to start - but until march 2021 Outside IR35 SC cleared holder before applying - due to quick start of work Key Responsibilities Collaborating with key members of the Data Engineering team...
",https://www.reed.co.uk/jobs/data-engineer/40284571
JOB231464947061,Data Engineer,Data Engineer,50+ career categories,"Find a better job, faster!,Hand-screened leads,No ads, scams, junk,Great job search support","
Full-time position with remote option. Will troubleshoot issues, resolve data, provide metrics, communicate resolutions and identify support trends. Bachelor's degree and 5+ years' related experience required.
Job Details
10/25/20
Option for Remote
Employee
Full-Time
Manager
Bachelor's Degree
No specification
Health Insurance, Retirement Planning, Paid Vacation, Life Insurance, Dental Insurance, Stock Options
Company name here
Other benefits listed here
Find a better job, faster!
Hand-screened leads
No ads, scams, junk
Great job search support
50+ career categories
Create an Account to Unlock
To find out more about or apply to this Data Engineer job—and other great opportunities like it—become a FlexJobs member today!
With FlexJobs, you'll find the best flexible jobs and fantastic expert resources to support you in your job search. If you have any questions, please feel free to contact us.
",https://www.flexjobs.com/publicjobs/data-engineer-1312559
JOB231794190907,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-ru/details/200188037/ai-ml-search-data-engineer-siri-data
JOB232114412481,Data Engineer,Data Engineer,,"Shared ownership and accountability for Platform data services (fivetran, Airflow, dbt, Snowflake) through deep knowledge and proactive maintenance of those services,Guide and execute architectural improvements to our data services,Communication skills, and ability to translate between the domains of business problems and technical solutions,Productionizing our Operating Model and Machine Learning infrastructure,Refactoring Platform services for CNNG,Platform improvements to enhance digital and direct acquisition of customers,Partner with Technology and Member Operations business stakeholders to design and deliver new data-driven integrations,Cultivated familiarity with Inspire’s frameworks & operating model,Delivery of high-quality pull requests in dbt and Airflow, evidencing strong code standards & testing practices,Comfort with self-directed project management: requires minimal oversight to assess a problem, formulate a solution, deliver code, and document changes.,Challenge the status quo – we’re looking for someone with enough experience in data engineering to have begun forming strong opinions of data best practices. Those opinions should surface in their work and at times challenge Inspire’s data practices to raise them to new standards. In the process, their opinions should stimulate growth and learning throughout the team.,3+ years of experience in a data engineering role,Strong SQL skills querying and transforming large datasets in cloud-based data warehouses (we use Snowflake),Experience creating production-grade ELT pipelines with python-based data orchestration tools at scale (we use Airflow),Experience with real-time event stream data,Experience with dbt,Spark data processing,ML Flow infrastructure","ABOUT US
Inspire is a clean energy technology company on a mission to transform the way consumers access clean energy and to accelerate the world’s transition to a net-zero carbon future.
We provide our customers with access to renewable energy from wind, solar, and hydro powered sources without service interruptions or costly installations at a flat, predictable monthly rate. For every year that a customer spends with Inspire Clean Energy, they have a greater impact on climate change than 10 years of strict recycling.
Our rapidly growing team of mission-driven, climate enthusiasts is passionate, innovative and committed to a better future for the planet.
POSITION SUMMARY
As a Data Engineer on Inspire’s Data & Analytics Engineering team, you will build, maintain, and improve the infrastructure and architecture that flows critical data from internal and external sources to where it creates value for the business. We take a product-driven, agile approach to our platform, driving measurable growth and meaningful outcomes every single sprint. We build efficient, scalable processes in a service-oriented ecosystem leveraging powerful code frameworks and repeatable patterns to solve real problems for stakeholders and customers. In this position you will collaborate with partners across the business in a shared mission to achieve a clean energy future.
THE DATA ENGINEER HAS 4 MAIN RESPONSIBILITIES
Shared ownership and accountability for Platform data services (fivetran, Airflow, dbt, Snowflake) through deep knowledge and proactive maintenance of those services
Guide and execute architectural improvements to our data services
Communication skills, and ability to translate between the domains of business problems and technical solutions
Team-oriented development: building modular & re-usable tools, writing maintainable code, team mentorship, owning technical and business documentation
SOME YEAR 1 DELIVERABLES
Expand the capabilities of Inspire’s core data platform to support incremental business lines and product features
Productionizing our Operating Model and Machine Learning infrastructure
Refactoring Platform services for CNNG
Platform improvements to enhance digital and direct acquisition of customers
Improving data quality and observability within our data infrastructure
Partner with Technology and Member Operations business stakeholders to design and deliver new data-driven integrations
Partner with other engineering teams to guide refactors of existing data infrastructure to improve data quality and features.
SUCCESS METRICS
Cultivated familiarity with Inspire’s frameworks & operating model
Delivery of high-quality pull requests in dbt and Airflow, evidencing strong code standards & testing practices
Comfort with self-directed project management: requires minimal oversight to assess a problem, formulate a solution, deliver code, and document changes.
Positive interactions with department stakeholders: can offer guidance and input that creates business value for non-technical personnel.
DESIRED TRAITS
Challenge the status quo – we’re looking for someone with enough experience in data engineering to have begun forming strong opinions of data best practices. Those opinions should surface in their work and at times challenge Inspire’s data practices to raise them to new standards. In the process, their opinions should stimulate growth and learning throughout the team.
EXPERIENCE
Must Have
3+ years of experience in a data engineering role
Strong SQL skills querying and transforming large datasets in cloud-based data warehouses (we use Snowflake)
Experience creating production-grade ELT pipelines with python-based data orchestration tools at scale (we use Airflow)
Software development lifecycle experience in GitHub (i.e. environment management, testing, deployment)
Nice to Have
Experience with real-time event stream data
Experience with dbt
Spark data processing
ML Flow infrastructure
Contextual work in the energy industry
Apply Now
",https://technical.ly/job/inspire-data-engineer-73909/
JOB232289258874,Senior Data Engineer,Senior Data Engineer,,,"
Full-time job, remote option. Needs a bachelor's degree and five years' experience writing complex queries. Communicate to non-technical audience, understand business requirements, audit data for quality improvement, translate requirements into solutions.
",https://www.flexjobs.com/publicjobs/senior-data-engineer-1311270
JOB233467301199,Senior .NET - Data Engineer,Senior .NET - Data Engineer,50+ career categories,"Hand-screened leads,No ads, scams, junk,Great job search support","
Senior .NET - Data Engineer
Discuss/implement directives for data processing and database development and maintain new/existing databases. Must have a bachelor's degree and at least 8 years' software development experience. Remote position during the pandemic.
Job Details
Remote - During Pandemic
Employee
Full-Time
Experienced
Bachelor's Degree
No specification
Company name here
Other benefits listed here
Hand-screened leads
No ads, scams, junk
Great job search support
50+ career categories
Create an Account to Unlock
To find out more about or apply to this Senior .NET - Data Engineer job—and other great opportunities like it—become a FlexJobs member today!
With FlexJobs, you'll find the best flexible jobs and fantastic expert resources to support you in your job search. If you have any questions, please feel free to contact us.
",https://www.flexjobs.com/publicjobs/senior-net-data-engineer-1300181
JOB234497157632,Data Engineer,Data Engineer,"A curious mind,An obsession for quality,Background in Data science, Data mining, Multivariate statistics, Computer vision, Machine learning,Experience working with large scale data sets,Solid programming skills including:,Python,C/C++,Experience with data visualization and presentation, familiar with data analysis tools such as Tableau",,"We are the Computer Vision Testing Group responsible for quality of many exciting projects (ARkit, Animoji, FaceID, etc.), that have been shipped on Apple products. We are now seeking a Camera Image Quality Engineer to stress test and provide responsible image quality feedback to developers. You will do hands-on image quality testing work, collaborate with developers, continuously track camera algorithm bugs and be able to represent image quality from a user's perspective.
A curious mind
An obsession for quality
Background in Data science, Data mining, Multivariate statistics, Computer vision, Machine learning
Experience working with large scale data sets
Solid programming skills including:
Python
C/C++
Experience with data visualization and presentation, familiar with data analysis tools such as Tableau
Excellent problem solving and communication skills
This Data Engineer will work closely with other members of the Video Engineering group to mine data, implement model evaluation pipeline, analyze large scale data, visualize data, and ensure the delivery is of the highest quality. This position will also require strong coding skills, presentation skills, and collaborating with multiple teams (ex: machine learning, cloud infrastructure support). The responsibilities of this position includes but not limited to the following for current and future products: - Implement algorithm evaluation methods - Analyze data and build data analysis tools - Deep-dive failure analysis - Discover new perspectives for old data - Produce / Present meaningful data visualization to higher-ups and across various involved teams
",https://jobs.apple.com/en-us/details/200142428/data-engineer
JOB234616338339,Senior Data Engineer,Senior Data Engineer,,"Proven experience and expertise building ETL solutions for data warehouses; preferably for customer insight or e-commerce projects,Experience with low latency technologies (e.g. Spark, Storm) or similar AWS managed services,Solid experience of one or more enterprise data tools (Preferably Talend, SAP Data Services; optional Informatica, DataStage etc.),Solid experience developing on SQL Server (or similar) and an excellent appreciation of data warehouse methodologies (Kimball), design and tuning techniques,Programming experience in Python, Scala, Java,AWS experience preferred though not essential as training will be provided, with particular reference to Redshift, Kinesis and EMR/Hadoop,Familiarity with web, FTP and API technologies,Documentation skills for SDLC e.g. source-target mappings and data flow diagrams","
We are currently seeking an enthusiastic and experienced Sr. Data Engineer to join the Insight team to build out and maintain our AWS cloud-based data warehouse and analytics environments which power our B2C and B2B data products for our international markets.
You will be working alongside a very experienced and high performing Development & QA team, with close collaboration with our Product, Architecture and Infrastructure disciplines, as well as business stakeholders – all co-located together at our Int’l HQ offices in Angel.
You will be immersed in our current projects designing, developing and maintaining data pipelines within SCRUM methodology, using enterprise tools (Talend, SAP Data Services) as well as low latency data technologies.
You will be key in driving our strategic work-streams by leveraging your experience and expertise in big data - to transition our architecture, delivering business value faster by driving further adoption of future state data technologies, such as Kafka, Kinesis, Storm, Spark, Hadoop, Redshift, LAMBDA, Aurora etc.
Ticketmaster is a global ticketing company and we are committed to continuing to improve our ticketing platform to retain our position as market leader. The Insight division sits at the heart of the International business providing data centric products for CRM Marketing and Reporting/Analytics to help shape the company’s strategy and support our clients’ marketing efforts.
It is an exciting time to be working with data, with the emergence and adoption of big data and cloud technologies. We have recently migrated our traditional data integration and RDBMS platforms into AWS and are fully committed to utilising more of its managed services to help us consolidate and rearchitect our environments. You’ll be heavily involved in helping us through this evolution and will gain exposure to many new state of the art tools.
WHAT YOU NEED TO KNOW
Proven experience and expertise building ETL solutions for data warehouses; preferably for customer insight or e-commerce projects
Experience with low latency technologies (e.g. Spark, Storm) or similar AWS managed services
Solid experience of one or more enterprise data tools (Preferably Talend, SAP Data Services; optional Informatica, DataStage etc.)
Solid experience developing on SQL Server (or similar) and an excellent appreciation of data warehouse methodologies (Kimball), design and tuning techniques
Programming experience in Python, Scala, Java
AWS experience preferred though not essential as training will be provided, with particular reference to Redshift, Kinesis and EMR/Hadoop
Familiarity with web, FTP and API technologies
Documentation skills for SDLC e.g. source-target mappings and data flow diagrams
SDLC and AGILE Scrum processes
Job Type: Full-time
",https://www.indeed.co.uk/cmp/Ticketmaster/jobs/Senior-Data-Engineer-0f39fcb8e53fc14e
JOB236219244028,AMFS_Data Engineer,AMFS_Data Engineer,,"Collect internal data from different departments and eventually enrich data from external sources,Consolidate various data sources, transform and clean data to build a customer level data hub,Create new variables/features to enrich customer level data,Industrialize and maintain the centralized customer hub,Be able to quickly extract, prepare and provide data according to business requirement, and eventually automate the data providing process by script/batch if needed.,Settle a data providing procedure for business to follow and recommend ongoing improvement.,Work closely with Data Scientist/Analyst to retrieve and transform high dimensional data into a proper shape for further modeling.,Process, clean and control the data used in innovation projects or for business targeting purpose.,Min S1 with background Mathematics / Statistics / Computer Science,Minimum 3 years’ experience in MIS, Data Engineering and Advanced Analytics,Excellent knowledge of Python and SQL,Good understanding of relational and non-relational database, experience with MongoDB or Elastic Search will be a plus,Experience with common data science toolkits (Jupyter notebook, Scikit-learn, Pandas, Numpy…) and linux system will be a big plus,Good understanding of big data and its infrastructure (Hadoop, Spark, HDFS, Hive…),Dynamic working environment,Learning and development,Opportunity for international working assignment,Competitive remuneration package","
Collect internal data from different departments and eventually enrich data from external sources
Consolidate various data sources, transform and clean data to build a customer level data hub
Create new variables/features to enrich customer level data
Industrialize and maintain the centralized customer hub
Be able to quickly extract, prepare and provide data according to business requirement, and eventually automate the data providing process by script/batch if needed.
Settle a data providing procedure for business to follow and recommend ongoing improvement.
Work closely with Data Scientist/Analyst to retrieve and transform high dimensional data into a proper shape for further modeling.
Process, clean and control the data used in innovation projects or for business targeting purpose.
Partner with the data steward/management in order to ensure the quality of data and data accuracy.
Min S1 with background Mathematics / Statistics / Computer Science
Minimum 3 years’ experience in MIS, Data Engineering and Advanced Analytics
Excellent knowledge of Python and SQL
Good understanding of relational and non-relational database, experience with MongoDB or Elastic Search will be a plus
Experience with common data science toolkits (Jupyter notebook, Scikit-learn, Pandas, Numpy…) and linux system will be a big plus
Good understanding of big data and its infrastructure (Hadoop, Spark, HDFS, Hive…)
Would you like to wake up every day driven and inspired by our noble mission and to work together as one global team to empower people to live a better life? Here at AXA we strive to lead the transformation of our industry. We are looking for talented individuals who come from varied backgrounds, think differently and want to be part of this exciting transformation by challenging the status quo so we can push AXA - a leading global brand and one of the most innovative companies in our industry - onto even greater things. In a fast-evolving world and with a presence in 64 countries, our 166,000 employees and exclusive distributors anticipate change to offer services and solutions tailored to the current and future needs of our 103 million customers.
PT AXA Mandiri Financial Services (AXA Mandiri) is a joint venture (JV) between PT Bank Mandiri (Persero) Tbk and the AXA Group which was founded in 2003. PT AXA Mandiri Financial Services (AXA Mandiri) is supported by more than 1,800 Financial Advisors in more than 1,800 branches of Bank Mandiri and Bank Syariah Mandiri's 170 branches throughout Indonesia. AXA Mandiri was also supported by more than 500 Telesales Officer who market insurance products through telemarketing. PT AXA Mandiri Financial Services is registered and supervised by the Financial Services Authority (FSA).
Dynamic working environment
Learning and development
Opportunity for international working assignment
Competitive remuneration package
Variant on employee enggagement program
",https://www.axa.com/en/careers/job-offers/19000BSD-AMFSData-Engineer
JOB236410568847,Senior Data Engineer,Senior Data Engineer,"Identify data sources that can add value to decision making.,Work with source system owners and analysts to understand source data, e.g. data profiling, definition and mapping.,Design and implement efficient data loads, using traditional structured data ETL techniques.,Design and implement real time and near real time data load solutions, using technologies like data streaming.,Design and implement unstructured data loads, e.g. text speech, images and video.,Design and implement load monitoring tools and procedures and perform continuous monitoring and optimising of loads.,Work with analysts and architect to design and implement effective and efficient data models using appropriate modelling techniques.,Design and implement data warehouse data models.,Design and implement data pipelines for ad hoc, unstructured and other data models.,Design and implement appropriate aggregation data structures that enhance usability of data, e.g. multi-dimensional OLAP structures, summary tables etc.,Design, implement and maintain appropriate indexing on tables to enhance speed of access.,Design and implement data models that support automated decision making and/or further analytics.,Continuously search for data elements from other sources to enhance existing data objects to supplement / enhance context.,Design and implement interfaces for data access, e.g. batch exports, real-time decision API’s etc.,Design and implement interface monitoring and management solutions to ensure availability and accuracy.,Monitor and maintain integrity of existing environment, troubleshoot technical and data issues and make appropriate changes where required.,Implement meta-data solutions that assist with understanding and managing data.,Work together with business owners, analysts and IT to maintain good data governance.,Provide technical and data related support to source system teams and external parties with whom we exchange data.,Manage data growth and usage by designing and implementing effective strategies, e.g. archiving and indexing.,Manage systems, technology and tools that enable data management and analytics.,Take ownership of own work by delivering high quality work on time.,Show initiative and be pre-active in finding opportunities to improve data and/or processes.,Take ownership of own career development by continuously improving skills, knowledge and the application thereof in designing and implementing solutions.,Positive engagement in team activities and actively contribute ideas to improve team dynamics and performance.,Stakeholder management (internal and external).,Assist in development of others, e.g. mentoring and knowledge share.,Quality control of other’s work.,Degree in information technology / mathematics / engineering / actuarial science or related discipline.,At least 5+ years in a technical data role, preferably in a formal data, data warehouse or business intelligence environment.,SQL,Data analysis,Data visualisation,Data modelling,Microsoft business intelligence data technologies (SSIS, SSAS, SQL Server),Data warehouse concepts and best practices,Financial services knowledge, specifically personal or unsecured loans,Business process monitoring and optimising,Microsoft business intelligence visualisation technologies (SSRS, Power BI),IT infrastructure, e.g. storage, networking, servers, security,Unstructured data experience,Information gathering and problem analysis,Applying professional / specialist / technical expertise,Creating and innovating,Quality & Detail orientation,Analysing",,"Senior Data Engineer
Job description
Capfin is a leading unsecured loan provider with a successful business model supported by great people with a strong culture of innovation and data driven decision making. The purpose of this role is to create business value by applying data engineering and data management disciplines to design and build data solutions that enable data driven decision support, in order to optimize business decisions and processes, as well as train and mentor more junior team members.
Requirements
Key Performance Areas:
Sourcing data
Identify data sources that can add value to decision making.
Work with source system owners and analysts to understand source data, e.g. data profiling, definition and mapping.
Loading data
Design and implement efficient data loads, using traditional structured data ETL techniques.
Design and implement real time and near real time data load solutions, using technologies like data streaming.
Design and implement unstructured data loads, e.g. text speech, images and video.
Design and implement load monitoring tools and procedures and perform continuous monitoring and optimising of loads.
Storing data
Work with analysts and architect to design and implement effective and efficient data models using appropriate modelling techniques.
Design and implement data warehouse data models.
Design and implement data pipelines for ad hoc, unstructured and other data models.
Enhancing data
Design and implement appropriate aggregation data structures that enhance usability of data, e.g. multi-dimensional OLAP structures, summary tables etc.
Design, implement and maintain appropriate indexing on tables to enhance speed of access.
Design and implement data models that support automated decision making and/or further analytics.
Continuously search for data elements from other sources to enhance existing data objects to supplement / enhance context.
Making data available
Design and implement interfaces for data access, e.g. batch exports, real-time decision API’s etc.
Design and implement interface monitoring and management solutions to ensure availability and accuracy.
Managing data
Monitor and maintain integrity of existing environment, troubleshoot technical and data issues and make appropriate changes where required.
Implement meta-data solutions that assist with understanding and managing data.
Work together with business owners, analysts and IT to maintain good data governance.
Provide technical and data related support to source system teams and external parties with whom we exchange data.
Manage data growth and usage by designing and implementing effective strategies, e.g. archiving and indexing.
Manage systems, technology and tools that enable data management and analytics.
Leadership responsibilities
Take ownership of own work by delivering high quality work on time.
Show initiative and be pre-active in finding opportunities to improve data and/or processes.
Take ownership of own career development by continuously improving skills, knowledge and the application thereof in designing and implementing solutions.
Positive engagement in team activities and actively contribute ideas to improve team dynamics and performance.
Stakeholder management (internal and external).
Assist in development of others, e.g. mentoring and knowledge share.
Quality control of other’s work.
Qualifications:
Degree in information technology / mathematics / engineering / actuarial science or related discipline.
Experience:
At least 5+ years in a technical data role, preferably in a formal data, data warehouse or business intelligence environment.
Functional Competencies:
SQL
Data analysis
Data visualisation
Data modelling
Microsoft business intelligence data technologies (SSIS, SSAS, SQL Server)
Data warehouse concepts and best practices
Financial services knowledge, specifically personal or unsecured loans
Business process monitoring and optimising
Microsoft business intelligence visualisation technologies (SSRS, Power BI)
IT infrastructure, e.g. storage, networking, servers, security
Unstructured data experience
Behavioural Competencies:
Information gathering and problem analysis
Applying professional / specialist / technical expertise
Creating and innovating
Quality & Detail orientation
Analysing
Posted on 21 Oct 19:19
",https://www.bizcommunity.com/Company/Job.aspx?cid=221357&i=375317
JOB236611312498,Senior Data Engineer,Senior Data Engineer,,,"
DESCRIPTION Senior Data Engineer Amazon Fashion is a fast moving innovative team that is revolutionizing the future of online Fashion retail to become each customer’s most loved fashion destination. We are looking for candidates that are passionate about...
Senior Data Engineer - Manchester A large organisation based in Manchester are currently looking for a Senior Data Engineer to lead and participate on a wide range of initiatives to transform the data and information landscape across the business. The...
Senior Data Engineer REF: JA26 Salary: 55,000 to 65,000 dependent on experience Location: Manchester Job Type: Permanent, Full Time Job Section: Professional Services Experience: 2 years Contact: Joel Ambrose An opportunity to work with some of the internet’s...
DESCRIPTION Amazon’s Inventory Prediction and Entitlement (IPE) team, based in Cambridge, U.K. is looking for passionate, hard-working, and talented individuals to join our fast paced, stimulating environment to help invent the future of business ownership...
DESCRIPTION Amazon’s Inventory Prediction and Entitlement (IPE) team, based in Cambridge, U.K. is looking for passionate, hard-working, and talented individuals to join our fast paced, stimulating environment to help invent the future of business ownership...
DESCRIPTION Although this job is posted in London, the real location is CAMBRIDGE, UK. Amazon’s Inventory Prediction and Entitlement (IPE) team, based in Cambridge, U.K. is looking for passionate, hard-working, and talented individuals to join our fast...
Data Engineer / Senior Data Engineer - Manchester - Multiple Roles Available - Salary DoE - 40,000 - 65,000 An exciting opportunity has arisen for a Data Engineer to join a growing consultancy firm based around the UK who focus on using the latest technologies...
Data Engineer We are currently partnering with an exciting scale up business who are looking to hire a Data Engineer. Working closely with the Data Scientist's, they need someone to help build their algorithm set and take design ideas through to production...
DESCRIPTION Love data? Love music? The Amazon Music team is looking for a brilliant, creative, and passionate professional to join our Business Intelligence team. The responsibilities include developing self-serve and automated tools that improve the efficiency...
AstraZeneca is a global biopharmaceutical business that focuses on the discovery, development and commercialisation of prescription medicines for some of the world's most serious diseases. Our growth platforms are doing deeply well, and the impact of our...
Senior Data & BI Developer / Engineer - BI platforms, database and data warehouse infrastructure - Microsoft, SQL, Azure - Poole - a design, develop build role to help transform data infrastructure and BI platforms In this business critical role you...
AstraZeneca is a global biopharmaceutical business that focuses on the discovery, development and commercialisation of prescription medicines for some of the world's most serious diseases. Our growth platforms are doing deeply well, and the impact of our...
Data Engineer - Mansfield - Growing Team & Systems - up to 65,000 An exciting opportunity has arisen for a Data Engineer to join a growing data and infrastructure team based in Mansfield who are focused on using some of the latest technologies. They're...
Senior Data Engineer - Nationwide charity: as the technical Data / BI SME on a business-critical data strategy (embracing SQL BI, Python, Cloud tech, Big Data, Data Science), you will be reporting directly to the Head of IT and working closely with key...
AstraZeneca is a global biopharmaceutical business that focuses on the discovery, development and commercialisation of prescription medicines for some of the world's most serious diseases. At AstraZeneca, we're proud to have a workplace culture that inspires...
Job Title: Technical Lead - Data Solutions Business Unit: Chief Information Office Location: Gosforth Salary Range: 42,000 - 52,500 per annum DOE Contract Type: Permanent As Virgin Money executes its Data Strategy and continues to build a strategic data...
Senior Electrical Design Engineer - Frankfurt - To €70K Accommodation, Flights and Living expenses I'm working with a large, global main contractor who specialise in the design of complex projects such as data centres, hospitals and industrial projects...
X4 Technology are currently working on a remote Senior QA Engineer position with a London based financial services organisation. Due to the growth of the company they are looking for a Senior QA Engineer to help build on existing testing services used...
Senior Data Enigneer - Permanent Data Idols are working with a well known Technology company who are looking for a Senior Data Engineer to join a cross-functional team. This industry disruptor has been changing the way people interact with an everyday...
Senior Software Engineer - Python | Linux - Data Analytics, AI Remote working This is an exciting opportunity for a big data and advanced analytics business who deliver insights through predictive analytics and machine learning approaches. The business...
A leading global bank based in the City are currently looking for an experienced Network Engineer to come in and join the vast IT team. The client is a global institution, who are a market leader with operations covering global financial markets. This...
Data Engineer - Python - Leeds We are looking for a Data Engineer with a solid fundamental basis in Python to join an up-and-coming software consultancy based in Leeds, to work on a combination of public and private sector projects. You will be working...
Senior O365 Engineer/Office 365 Specialist/Infrastructure Engineer/Infrastructure Specialist/Senior Windows Engineer/Office 365 Engineer/Unified Communications Engineer/Unified Communications Analyst/Unified Communications Specialist Type - Permanent Salary...
Would you like to work on a product that helps life-changing treatments? We are currently looking for skilled Developers to help drive our product suite forward. Senior Software Engineer The software development team are responsible for the research, development...
We have an opportunity available for a highly motivated Principal Engineer to join our Technology & Design department . You will be based in Southampton working a full time permanent basis and in return, you will receive a competitive salary of 54...
",http://www.reed.co.uk/jobs/senior-data-engineer/40287481
JOB238787576672,Senior Data Engineer - Remote consulting position (Full-time W2),Senior Data Engineer - Remote consulting position (Full-time W2),"Architect and build data pipelines,Architect and implement data warehouse structure and table schemas,Develop data models to enable end users to effectively analyze data,Optimize and tune data warehouse for query performance and analytical workloads,Identify, troubleshoot and resolve data quality issues,Write complex SQL queries for data analysis,Design and maintain robust data reporting and visualization tools based on requirements,Develop integrations from BI tools to third party productivity applications,5+ years of engineering experience,Expert in SQL, preferably across a number of dialects (we commonly write Snowflake, Redshift/PostgreSQL, MySQL, SQL Server),Experience developing software code in one or more programming languages (Python, Java, Scala, Ruby),Experience managing database or data warehouse technologies (bonus for Redshift and/or Snowflake),Experience implementing ETL tools (Bonus for Stitch, Fivetran or Matillion),Understanding of data analytics ecosystem. Experience with one or more relevant tools (Spark, Kafka, AWS Glue, Amazon Kinesis, Sqoop, Flume, Flink),Experience with implementing Business Intelligence tools (Bonus for Looker),Experience developing data pipelines from scratch",," Job Description
Are you excited to work on cutting edge technologies to solve interesting data challenges? Join the Bytecode IO team as a senior data engineering expert for an opportunity to work with a team of smart, passionate consultants helping a wide range of clients unlock the value of their data.
The ideal candidate will work independently with minimal guidance, take the lead on deciding the best course of action for specific projects and clients - while being exposed to interesting cutting edge technologies.
You can work from anywhere (within the US) and shape your work schedule to meet both your professional and personal goals.
In this position you’ll be responsible for interfacing directly with clients to understand their needs as you architect and deploy end-to-end technology stacks. The ideal team member will have extensive hands-on experience with designing, developing and operating data technologies in the Amazon Web Services or Google Cloud Platform ecosystem such as Redshift, Kinesis, Glue, EMR, Athena, BigQuery, Cloud Dataflow, or Cloud Pub/Sub.
Role Requirements
Architect and build data pipelines
Architect and implement data warehouse structure and table schemas
Develop data models to enable end users to effectively analyze data
Optimize and tune data warehouse for query performance and analytical workloads
Identify, troubleshoot and resolve data quality issues
Write complex SQL queries for data analysis
Design and maintain robust data reporting and visualization tools based on requirements
Develop integrations from BI tools to third party productivity applications
Teach technical data modeling concepts to a variety of audiences, including developers, data architects, business users, and IT professionals
Who you are and what you have done
5+ years of engineering experience
Expert in SQL, preferably across a number of dialects (we commonly write Snowflake, Redshift/PostgreSQL, MySQL, SQL Server)
Experience developing software code in one or more programming languages (Python, Java, Scala, Ruby)
Experience managing database or data warehouse technologies (bonus for Redshift and/or Snowflake)
Experience implementing ETL tools (Bonus for Stitch, Fivetran or Matillion)
Understanding of data analytics ecosystem. Experience with one or more relevant tools (Spark, Kafka, AWS Glue, Amazon Kinesis, Sqoop, Flume, Flink)
Experience with implementing Business Intelligence tools (Bonus for Looker)
Experience developing data pipelines from scratch
Experience presenting complex topics to non-technical audiences
Company Description
Bytecode IO is a 100% remote consulting company focused on helping businesses make the best use of their data. We provide our clients expertise in data and software engineering, data platform architecture and business intelligence implemented on the best cloud technologies in the market.
Our clients include a range of early stage startups to fortune 500 companies.
","https://www.ziprecruiter.com/c/Bytecode-IO/Job/Senior-Data-Engineer-Remote-consulting-position-(Full-time-W2)/-in-Remote,OR?jid=DQc84811b248ea853de16907517156a0ab&job_id=ebc9bee7d08f13c631ae97a49fba7639"
JOB240335195456,Lead Data Engineer,Lead Data Engineer,50+ career categories,"Find a better job, faster!,Hand-screened leads,No ads, scams, junk,Great job search support","
The lead data engineer will advise clients, develop data processing pipelines and data models, and provide data solutions. Requires experience developing large data pipelines and data-centric apps. This remote role will require travel in the future.
Job Details
Partial Remote
Employee
Full-Time
Experienced
No specification
Company name here
Other benefits listed here
Find a better job, faster!
Hand-screened leads
No ads, scams, junk
Great job search support
50+ career categories
Create an Account to Unlock
To find out more about or apply to this Lead Data Engineer job—and other great opportunities like it—become a FlexJobs member today!
With FlexJobs, you'll find the best flexible jobs and fantastic expert resources to support you in your job search. If you have any questions, please feel free to contact us.
",https://www.flexjobs.com/publicjobs/lead-data-engineer-1295961
JOB240645233488,Data Engineer,Data Engineer,,,"
Job title: Data Engineer Location : Zurich. Switzerland Job type : Contract Data Engineer with Hadoop/Apache Sparc Knowledge - - Build a data processing layer based on Hadoop,Spark, Neo4J - Ensure appropriate security processes are integrated with access...
Data Engineer We have had a role come available for a Data Engineer in London. The role will require you to either hold a DV Clearance. Key Experience: Data Analysis experience; Strong SQL skills; Data Processing using ETL tools; Understanding of procurement...
We're currently recruiting a Data Engineer for our insurance client in the Croydon area. This is a contract requirement to start ASAP so the role will initially be remote, but once the office reopens you will be expected to be able to travel to Croydon...
Data Engineer - Contract - Remote Based Data Engineer Until end November 2020 initially Remote Based (Office is based in Chester) Competitive pwd Ltd Company Tech Skills Required: ETL Design, Talend, MYSQL, Vertica We are currently looking for a Data Tester...
Data Engineer - Contract - Remote Based Data Engineer Until end November 2020 initially Remote Based (Office is based in Chester) Competitive pwd Ltd Company Tech Skills Required: ETL Design, Talend, MYSQL, Vertica We are currently looking for a Data Tester...
AWS Data Engineer x 2 Real Estate business Solve a key problem for the client. Work with AWS & PostgreSQL. 3 month initial contract outside of IR35. My client is looking for 2 AWS Data Engineers with solid experience working with post code / address...
Remote working. Up to 550 p/day. SQL Server, SSIS, AWS 6-month contract opportunity for a Senior Data Engineer with financial services experience. What you'll be doing Working for a large financial services client, you will work in a team of data engineers...
Azure Data Engineer Leading Insurance business Work on a large scale Azure migration project. Build dimensional models. 6 month initial contract - inside IR35 My client is looking for 2 Data Engineers with excellent Microsoft Azure experience for a large...
Our client, a global travel company require a Digital Data Engineer with strong GCP/ Big Query skills to join their analytics engineering team. Your Role You will be responsible for developing reporting infrastructure and providing actionable reporting...
SENIOR DATA ENGINEER 550- 650 PER DAY 3 MONTH CONTRACT REMOTE/ LONDON BASED As a Senior Data Engineer you will have the chance to work for a innovative e-commerce client in productionising ML models using Python, SQL and Airflow alongside AWS services...
Data Engineer SC cleared London, Titchfield or Newport 3 months to start - but until march 2021 Outside IR35 SC cleared holder before applying - due to quick start of work Key Responsibilities Collaborating with key members of the Data Engineering team...
Digital Data Engineer 500 per day 3-months Remote/London As a Data Engineer, you will be helping with a Digital Transformation project, in setting up a Google Big Query data warehouse. THE COMPANY: This company specialise in the travel industry and are...
Digital Data Engineer | 3 Month Contract As Digital Data Engineer, you will be responsible for developing reporting infrastructure and providing actionable reporting on my client's web properties (website, app). You will be working closely with stakeholders...
An exciting opportunity has opened up in Mechelen, Belgium for a Big Data Engineer. Skills and experience required: Scala Spark Kafka HLD, DLD and e2e ownership for Big Data projects Proficient in requirement gathering This is a 9-month contract. Salt...
Data Engineer Cutting edge machine learning Mission led start-up Crucial hire An established mission-led start-up is currently looking for an experienced Data Engineer/Software Engineer to join their team on an initial 3-month contract to extend/go permanent...
Big Data Engineer Must be security cleared 45,000 - 55,000 Home working initially but candidate must be able to commute to Croydon / Kent in time If you are interested in working with sophisticated data to solve real world problems within a focused and...
DATA ENGINEER 400- 500 PER DAY 3 MONTH CONTRACT FULLY REMOTE As a Data Engineer you will have the chance to work for a online retail client using SQL heavily and DBT for modelling. THE COMPANY: As a Data Engineer, you will be working for an exciting online...
DATA ENGINEER 400- 500 PER DAY 3 MONTH CONTRACT FULLY REMOTE As a Data Engineer you will have the chance to work for a media company using Big Query, Airflow and Python for ETL work. THE COMPANY: As a Data Engineer, you will be working for a well known...
Role & Responsibilities Design, Develop and maintain Bi solutions using Redshift. Ability to analysis unstructured and structured data. Ability to create patterns, and standardised Data Pipelines. Project experience using Python, Spark and Hadoop....
Data Engineer | Remote | 3-6 months I have a fantastic opportunity for a Data Engineer to join a Bristol-based business on a remote basis for 3-6 months. The Times named this company one of the most disruptive in the sector and they are now looking at...
Data Engineer Remote working 450 - 500 per day We are currently recruiting for an experienced interim Data Engineer to work remotely with occasional visits to regional sites. This is an exciting opportunity to join a forward-thinking company who operate...
Site Reliability Engineer (Cloud Data Science), 100,000 - 150,000, remote flex We are seeking a Site Reliability Engineer to join a Series D funded team at the centre of data science innovation, helping global teams to further medical discovery, improve...
Site Reliability Engineer (Cloud Data Science), 100,000 - 150,000, remote flex We are seeking a Site Reliability Engineer to join a Series D funded team at the centre of data science innovation, helping global teams to further medical discovery, improve...
Contract Senior Python Data Engineer (remote) outside IR35 // Revolutionary AI & Blockchain platform I'm hiring a talented contract Senior Python Data Engineer, in partnership with a highly innovative brand with a unique platform. About my client:...
Senior DevOps Engineer | Big Data | SC cleared Senior DevOps Engineer required by a specialist consultancy that leverages data science, machine learning and advanced mathematics to deliver cutting edge solutions to the public sector. This Senior DevOps...
",https://www.reed.co.uk/jobs/data-engineer/40252074
JOB241028848468,Data Engineer,Data Engineer,,,"
Data Engineer X 2 – Manchester. Our client based near Manchester are currently looking for 2 Data Engineers with Azure experience. The company is currently going through a large digital transformation, they are looking for talented Data specialist to help...
Job Title: Data Engineer Salary: 45,000 to 54,000 plus Benefits Location: Cambridge This is a very rare opportunity for an experienced Data Engineer with a strong background in building Python based data processing pipelines to join a company that are...
",https://www.reed.co.uk/jobs/data-engineer/40391706
JOB241124727769,Senior Data Engineer,Senior Data Engineer,,"Support planning, execution, hiring, and mentoring staff, as well as your hands-on development within the role,Develop and maintain developer tooling to support PySpark data pipelines,Implement processes and systems to ensure data is accurate and available for key stakeholders and business processes,Develop and maintain data platform components including; Kafka data producers and consumers, pipeline architecture, data lake, data warehouse, and Business Intelligence tooling,Collaborate closely with fellow data team members as well as tech and product teams and company leaders,Support continuing increases in data velocity, volume, and complexity,Write unit/integration tests and document work,Experience with or knowledge of Agile Software Development methodologies,Excellent problem solving and troubleshooting skills,Strong SQL and Python development experience,Proven experience with building systems using a microservice architecture,Proven experience with schema design and dimensional data modeling,Proven experience developing pipelines utilizing event streaming data and familiarity with the Apache Kafka framework,Practical experience with SQL and NoSQL databases,Practical experience supporting Business Intelligence tooling and third-party systems,Experience designing, building, and maintaining data processing systems,Experience working with MapReduce and Spark clusters,Experience detecting and reporting data quality issues,Familiarity with Docker, CI/CD (such as Jenkins/Circle), AWS,Competitive salary,Health insurance (100% paid for individuals, 75% for families),Primary caregiver 12-week paid leave,401K,Generous vacation policy, plus company holidays,Company equity,Commuter and cell phone benefit,A commitment to an open, inclusive, and diverse work culture,One mental health day per quarter,$100 monthly work-from-home stipend,Company-sponsored access to Ginger coaching and mental health support,OneMedical membership, including tele-health services,Increased work flexibility for parents and caretakers,Access to the Axios “Family Fund”, which was created to allow employees to request financial support when facing financial hardship or emergencies,Class pass discount","Quick take: Axios is a growth-stage startup dedicated to providing trustworthy, award-winning news content in an audience-first format. We’re hiring a Senior Data Engineer to join our growing data team!
Why it matters: As a Senior Data Engineer, this person will collaborate with engineers, analysts, and product managers to drive forward data initiatives across mission-critical Axios products. Our Data team is made of Data Engineers, Data Scientists, and Analysts who use data-driven methodologies to inform decisions and strategy, build robust scalable products and identify opportunities for innovation across the company. We round our team out with a Technical Product Manager and Data Quality Engineer to assure the team has the support it needs to succeed.
Go deeper: This Data Engineer will play a leadership role in building solutions to problems in an intelligent and nuanced way. In this role, you will make an impact on Axios through the following responsibilities:
Support planning, execution, hiring, and mentoring staff, as well as your hands-on development within the role
Develop and maintain developer tooling to support PySpark data pipelines
Implement processes and systems to ensure data is accurate and available for key stakeholders and business processes
Develop and maintain data platform components including; Kafka data producers and consumers, pipeline architecture, data lake, data warehouse, and Business Intelligence tooling
Collaborate closely with fellow data team members as well as tech and product teams and company leaders
Support continuing increases in data velocity, volume, and complexity
Write unit/integration tests and document work
Perform data analysis required to troubleshoot data-related issues and assist in the resolution of data issues
The details: Ideal candidate should have an entrepreneurial spirit, be highly collaborative, exhibit a passion for building technology products, and have the following qualifications:
Experience with or knowledge of Agile Software Development methodologies
Excellent problem solving and troubleshooting skills
Strong SQL and Python development experience
Proven experience with building systems using a microservice architecture
Proven experience with schema design and dimensional data modeling
Proven experience developing pipelines utilizing event streaming data and familiarity with the Apache Kafka framework
Practical experience with SQL and NoSQL databases
Practical experience supporting Business Intelligence tooling and third-party systems
Experience designing, building, and maintaining data processing systems
Experience working with MapReduce and Spark clusters
Experience detecting and reporting data quality issues
Familiarity with Docker, CI/CD (such as Jenkins/Circle), AWS
Experience building data visualizations and dashboards is preferred
Don’t forget:
Competitive salary
Health insurance (100% paid for individuals, 75% for families)
Primary caregiver 12-week paid leave
401K
Generous vacation policy, plus company holidays
Company equity
Commuter and cell phone benefit
A commitment to an open, inclusive, and diverse work culture
Annual learning and development stipend
Additional pandemic-related benefits:
One mental health day per quarter
$100 monthly work-from-home stipend
Company-sponsored access to Ginger coaching and mental health support
OneMedical membership, including tele-health services
Increased work flexibility for parents and caretakers
Access to the Axios “Family Fund”, which was created to allow employees to request financial support when facing financial hardship or emergencies
Class pass discount
Virtual company-sponsored social events
Equal Opportunity Employer Statement
Axios is an equal opportunity employer that is committed to diversity and inclusion in the workplace. We prohibit discrimination and harassment of any kind based on race, color, sex, religion, sexual orientation, age, gender identity, gender expression, veteran status, national origin, disability, genetic information, pregnancy, or any other protected characteristic as outlined by federal, state, or local laws.
This policy applies to all employment practices within our organization, including hiring, recruiting, promotion, termination, layoff, recall, leave of absence, compensation, benefits, training, and apprenticeship. Axios makes hiring decisions based solely on qualifications, merit, and business needs at the time.
Apply Now
",https://technical.ly/job/axios-senior-data-engineer-73623/
JOB245067586375,Data Engineer,Data Engineer,,"Use technology such as Spark, Kafka and SQS to build large scale real time and batch data pipelines.,Help implement cloud technologies such as AWS, Azure or GCP.,Program in at least one of the following languages - Java, Scala or Python.,Proven experience in data development in a big data/ Hadoop and cloud data warehouse using SQL or SQL based ETL capabilities.,Have a deep understanding of the processes, skills and technologies which are needed to deliver complex development solutions for a business.,Understand and have experience working with a variety of delivery methods, such as Agile, Waterfall and Scrum.,Experience developing in the cloud with AWS or Snowflake.,Work in one of the most data rich businesses in the UK.,Competitive bonus.,Discount across brands.","
DATA ENGINEER £40,000- 60,000 + BONUS + COMPETITIVE BONUS
CENTRAL LONDON
Are you looking to join one of the largest retailers, with one of the most visited websites in the UK as a Data Engineer where you will be working on huge data sets in a serverless environment? You will be using the latest technology solutions and have the opportunity to make a real impact within your squad due to a highly collaborative culture.
THE COMPANY:
As one of the largest retailers in the UK with multiple sub-brands you will be working in a data rich environment across a wide variety of projects. You will help deliver solutions to millions of customers across the UK and provide real value both to customers and stakeholders within the business.
THE ROLE:
You will be joining a team of highly experienced and passionate data engineers and architects to undertake data transformation and solution development. You will be working with a wide range of tools across a mix of Big Data, Cloud and open source platforms.
In specific, you can expect to be involved in the following:
Use technology such as Spark, Kafka and SQS to build large scale real time and batch data pipelines.
Help implement cloud technologies such as AWS, Azure or GCP.
Program in at least one of the following languages - Java, Scala or Python.
Work as part of an Agile squad to deliver solutions in a flexible manner.
YOUR SKILLS AND EXPERIENCE:
The successful Data Engineer will have the following skills and experience:
Proven experience in data development in a big data/ Hadoop and cloud data warehouse using SQL or SQL based ETL capabilities.
Have a deep understanding of the processes, skills and technologies which are needed to deliver complex development solutions for a business.
Understand and have experience working with a variety of delivery methods, such as Agile, Waterfall and Scrum.
Experience developing in the cloud with AWS or Snowflake.
Understand the process of developing data stores and data warehouses and have hands on experience in doing so in a previous role.
THE BENEFITS:
Work in one of the most data rich businesses in the UK.
Competitive bonus.
Discount across brands.
Competitive benefits.
HOW TO APPLY:
Please register your interest by sending your CV to Lillie via the Apply link on this page.
",https://www.reed.co.uk/jobs/data-engineer/39744112
JOB245542411084,Senior Data Engineer,Senior Data Engineer,,,"
DESCRIPTION Senior Data Engineer Amazon Fashion is a fast moving innovative team that is revolutionizing the future of online Fashion retail to become each customer’s most loved fashion destination. We are looking for candidates that are passionate about...
Senior Data Engineer - Permanent Data Idols are working with a well known Technology company who are looking for a Senior Data Engineer to join a cross-functional team. This industry disruptor has been changing the way people interact with an everyday...
Senior Data Engineer - Manchester A large organisation based in Manchester are currently looking for a Senior Data Engineer to lead and participate on a wide range of initiatives to transform the data and information landscape across the business. The...
Senior Data Engineer REF: JA26 Salary: 55,000 to 65,000 dependent on experience Location: Manchester Job Type: Permanent, Full Time Job Section: Professional Services Experience: 2 years Contact: Joel Ambrose An opportunity to work with some of the internet’s...
DESCRIPTION Amazon’s Inventory Prediction and Entitlement (IPE) team, based in Cambridge, U.K. is looking for passionate, hard-working, and talented individuals to join our fast paced, stimulating environment to help invent the future of business ownership...
DESCRIPTION Amazon’s Inventory Prediction and Entitlement (IPE) team, based in Cambridge, U.K. is looking for passionate, hard-working, and talented individuals to join our fast paced, stimulating environment to help invent the future of business ownership...
DESCRIPTION Although this job is posted in London, the real location is CAMBRIDGE, UK. Amazon’s Inventory Prediction and Entitlement (IPE) team, based in Cambridge, U.K. is looking for passionate, hard-working, and talented individuals to join our fast...
Data Engineer / Senior Data Engineer - Manchester - Multiple Roles Available - Salary DoE - 40,000 - 65,000 An exciting opportunity has arisen for a Data Engineer to join a growing consultancy firm based around the UK who focus on using the latest technologies...
Data Engineer We are currently partnering with an exciting scale up business who are looking to hire a Data Engineer. Working closely with the Data Scientist's, they need someone to help build their algorithm set and take design ideas through to production...
DESCRIPTION Love data? Love music? The Amazon Music team is looking for a brilliant, creative, and passionate professional to join our Business Intelligence team. The responsibilities include developing self-serve and automated tools that improve the efficiency...
DATA ENGINEER - CURRENTLY REMOTE WORKING LONDON, CURRENTLY FLEXIBLE / REMOTE / HOME WORKING BETWEEN 75,000 - 85,000 BENEFITS BONUS Harnham are exclusively partnered with a tech brand looking to hire a Java focused Data Engineer. The company build advanced...
AstraZeneca is a global biopharmaceutical business that focuses on the discovery, development and commercialisation of prescription medicines for some of the world's most serious diseases. Our growth platforms are doing deeply well, and the impact of our...
Senior Data & BI Developer / Engineer - BI platforms, database and data warehouse infrastructure - Microsoft, SQL, Azure - Poole - a design, develop build role to help transform data infrastructure and BI platforms In this business critical role you...
AstraZeneca is a global biopharmaceutical business that focuses on the discovery, development and commercialisation of prescription medicines for some of the world's most serious diseases. Our growth platforms are doing deeply well, and the impact of our...
SENIOR DATA ENGINEER LONDON, CURRENTLY FLEXIBLE / REMOTE / HOME WORKING UP TO 80,000 BENEFITS BONUS Harnham are partnered with a leading e-commerce company in Central London - this company are building a next-gen data platform from the ground up using...
Senior Python Engineer (Data) // 60,000 - 90,000 // Weybridge, Surrey Pre-IPO start-up, building genuinely Greenfield platforms from the ground up, MVP through to the final product - Creating own APIs to ingest and data mine throughout the Healthcare world...
Data Engineer - Mansfield - Growing Team & Systems - up to 65,000 An exciting opportunity has arisen for a Data Engineer to join a growing data and infrastructure team based in Mansfield who are focused on using some of the latest technologies. They're...
An exciting opportunity has arisen for a Senior Data Scientist/Machine Learning Engineer to work within a healthcare firm that uses some of the most progressive AI approaches to detect patterns in data to accelerate the development in medicine. The role...
Senior Data Engineer - Nationwide charity: as the technical Data / BI SME on a business-critical data strategy (embracing SQL BI, Python, Cloud tech, Big Data, Data Science), you will be reporting directly to the Head of IT and working closely with key...
Method Resourcing are really pleased to be working with one of the fastest growing tech brands who are looking for a senior data engineer. They are are championing a transformational data platform that will completely change how data is utilised at the...
Senior Data Engineer - Scala - AWS - Azure - GCP - London You must have experience of working with Scala to be considered for this role This is an opportunity to work for one of the largest, high tech bands in the world. My client are looking for a cutting...
AstraZeneca is a global biopharmaceutical business that focuses on the discovery, development and commercialisation of prescription medicines for some of the world's most serious diseases. At AstraZeneca, we're proud to have a workplace culture that inspires...
Are you looking for the next new exciting challenge in your Data Engineer and Data Science career? My client is seeking a Senior Data Engineer with knowledge in Data Science to Lead their Data Engineering and Data Science function. The company offers flexible...
Job Title: Technical Lead - Data Solutions Business Unit: Chief Information Office Location: Gosforth Salary Range: 42,000 - 52,500 per annum DOE Contract Type: Permanent As Virgin Money executes its Data Strategy and continues to build a strategic data...
Senior Data Enigneer - Permanent Data Idols are working with a well known Technology company who are looking for a Senior Data Engineer to join a cross-functional team. This industry disruptor has been changing the way people interact with an everyday...
",http://www.reed.co.uk/jobs/senior-data-engineer/40212392
JOB245998008588,Data Engineer,Data Engineer,,,"
First People Solutions are working on behalf of a leading building support services provider who are looking for experienced Data Cabling Engineers to join their team in London.
The main duties will include but is not limited to:
Data Cabling - Installation of Cat5E, Cat6, Cat6a. Testing cabling using Fluke DTX & DSX.
Fibre Cabling - Installation of fibre cabling. Ability to test fibre cabling using Fluke DTX & DSZ using multimode/single mode tester.
Voice Cabling - Ability to terminate/jumpering voice cabling within 237A Krone strips. Ability to test fibre cabling using Fluke DTX & DSZ data tester
Cabinet & Containment - Ability to install data cabinets & carry out containment.
General - Knowledge of Krone, Systimax, Brand-Rex etc
You must have the ability to work to your own initiative and be able to successfully complete tasks within given timescales. You must have a ECS Grade Card and hold a full clean driving licence.
If interested in the position please apply by attaching your CV or contact Rebecca on 0141 270 5130.
",https://www.totaljobs.com/job/data-engineer/first-people-solutions-job75164590
JOB246411805546,"3M HIS Sr. Data Engineer (Albany, NY or Meriden, CT)","3M HIS Sr. Data Engineer (Albany, NY or Meriden, CT)",,,"
Job Description:3M is seeking a Sr. Data Engineer for the Health Information Systems Division located in Albany, NY. At 3M, you can apply your talent in bold ways that matter. Here, you go.3M Health Information Systems (HIS) is the world leader for innovating the language of health and delivers comprehensive software and consulting services. Working at 3M Health Information Systems you will be helping with today s challenges, while preparing for tomorrow s. Transforming health care from a system that treats disease, to a system that improves health and wellness begins with accurate health information and payment. From improving efficiency of medical records coding, to outlining success in value-based care and health care analytics. All while working with the best and the brightest to advance more than your own career, you are working to advance the entire world. Job Summary (Sr. Data Engineer):The person hired for the position of Sr. Data Engineer will provide technical expertise and leadership to project teams regarding the analysis, design, and development of the data structures and ETL framework used in the large-scale processing and storage of healthcare data. The Sr. Data Engineer will be tasked with contributing a technical perspective that spans the disciplines of data design, software development, and project leadership and will leverage previous leadership experience to successfully interface with business owners and solution architects to convert business requirements and high-level architecture guidelines into technical requirements. In addition, the Sr. Data Engineer will need to be highly skilled and act as a technical hands-on cloud (AWS, Azure, Google cloud) SME; well experienced using cloud tools, frameworks (EMR, Hive, Spark), services, and development languages and very familiar with cloud API, as well as supporting configuration management tools.This position provides an opportunity to transition from other private, public, government or military environments to a 3M career. Primary Responsibilities (Sr. Data Engineer) include but are not limited to the following:Acts as the technical lead to one or more scrum development teamsLeads development team activities, including design solutions and development effortsImplements and designs the most optimal ETL and Data Model design that can scale and performDetermines opportunities for application and process improvementSupports leadership initiatives and the strategic technical direction of the organizationWillingness to work in a fast-paced, team-oriented environment and able to handle multiple conflicting prioritiesDesign and support of an enterprise data model.Maintain data warehouse architecture and metadata standardsWork closely with Business Analysts and Subject Matter Experts to identify key business drivers for the data warehouse using a broad base of skills including facilitation of requirements gathering and mapping data to the logical and physical data models. Actively participates in relevant corporate programs/initiatives, complies with professional and quality standards complies with corporate policies and procedures, and acts in a manner consistent with 3M s values and ethical standards.Basic Qualifications (Sr. Data Engineer): Possess a Bachelor s degree or higher (completed and verified prior to start) from an accredited institution or High School Diploma/GED or higher from an accredited institution and (10) years of equivalent experience in Data development in lieu of a Bachelor's degree education requirementMinimum of seven (7) years of combined experience with relational databases, such as Microsoft SQL Server, Oracle, MySQL including database object design (Stored Procedures, UDF, etc.) and development experience with object-oriented programming, such as Python, Java or C#Preferred Qualifications (Sr. Data Engineer):Expertise and experience large scale Healthcare DataFive (5) years of experience with database modeling tools (ER Studio, Erwin, Power Designer etc.)Expertise and experience in version control systems, such as SVN, CodeCommit or GitExpertise and experience deploying applications to Cloud (AWS, Azure, Google Cloud) platformsMinimum of one (1) year of experience with cloud (AWS, Azure, Google Cloud) services, tools, and frameworks (EMR, Hive, Spark)Expertise and experience with an agile development processKnowledge and experience with dynamic languages, such as Python or RubyFamiliarity with test-driven developmentHighly motivatedExcellent verbal and written communication skillsAbility to solve problems in a logical, methodical, and time efficient mannerAbility to direct and influence othersLocation: Albany, NY Travel Requirements: Occasional travel may be required Relocation: Maybe considered for this position Diverse & Inclusive 3M3M is a place where you can collaborate with other curious, creative people. Where your diverse talents, inclusiveness, initiative and leadership are valued. Where you ll find challenging opportunities that make your career exciting and rewarding. With a diversity of people, global locations, technologies and products, 3M is a place to grow and be rewarded for excellence.3M EthicsMost Recent great-news / Awards: 3M received recognition as being A Most Ethical Company! Promoting Ethical Business standards and practices internally, enabling managers and employees to make good choices, and shaping future industry standards by introducing tomorrow's best practices today. Honorees have historically out-performed others financially, demonstrating the connection between good ethical practices and performances that s valued. To View this recognition, please visit: Learn more about 3M s creative solutions to the world s problems at www.3M.com or on Twitter @3M.3M is an equal opportunity employer. 3M will not discriminate against any applicant for employment on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, or veteran status.Please note: your application may not be considered if you do not provide your education and work history, either by: 1) uploading a resume, or 2) entering the information into the application fields directly.3M Global Terms of Use and Privacy StatementCarefully read these Terms of Use before using this website. Your access to and use of this website and application for a job at 3M are conditioned on your acceptance and compliance with these terms.Please access the linked document by clicking here, select the country where you are applying for employment, and review. Before submitting your application you will be asked to confirm your agreement with the terms.Full time
Associated topics: data architect, data engineer, data integration, data integrity, data warehouse, database, database administrator, hbase, mongo database, sql
","https://www.ziprecruiter.com/c/3M/Job/3M-HIS-Sr.-Data-Engineer-(Albany,-NY-or-Meriden,-CT)/-in-Albany,NY?ojob=f4e4ba0ba1983a8ef94fc424b530bb91"
JOB247363420195,AWS / Big Data Engineer,AWS / Big Data Engineer,,,"
Experience : 2-3 years
Location : Remote
Skill set : Data Science, AWS, MySQL, Ubuntu, Python, H2O.ai

GeoAdvantage is looking for an AWS / Big Data Consultant to accompany us in the training and the deployment of our ML Models, from the setting up of the data migration pipeline to the automation /  ... Show more
",https://www.guru.com/jobs/aws-big-data-engineer/1740735
JOB248134179684,Data Engineer Jobs in Southampton,Data Engineer Jobs in Southampton,,,"
From:
To:
",https://www.reed.co.uk/jobs/data-engineer-jobs-in-southampton
JOB249049783242,"ELT Data Engineer (Talend, Datastage), Banking and Financial Services","ELT Data Engineer (Talend, Datastage), Banking and Financial Services",,DataStage,"
Meet our professionals
Canada-That's CGI
Position Description
We are a global IT and business consulting services leader, and after 40 years, we're still growing! Join Canada's largest IT Company in our Global Wealth and Banking Services Division in Toronto.
CGI supports our members’ career aspirations, offering learning initiatives and provides access to our global health and wellness program. We also offer competitive compensation and benefits such as our share purchase plan, a profit sharing program, flexible schedules that guarantee a good work-life balance!
Innovation, technology and service delivery are our focus. Our goal is to ensure our clients remain ahead of the competition. We provide a full spectrum of services from Business Consulting and Systems Integration to Managed Services and IP Solutions that are transforming our clients’ operations and helping them to succeed.
Your future duties and responsibilities
As a Data Engineer, you will design, develops, tests, implements, and maintains complex ELT functions, user defined functions and complex queries for custom solutions with limited direction.
Leads and coordinates code/peer review of focused development work to ensure it aligns to the business and technical requirements.
• Collaborate with Product Owners and Analysts to understand business requirements and define technical solutions.
• Design, develop, maintain and take ownership of code.
• Design reusable components, user defined functions.
Required qualifications to be successful in this role
• Minimum 5 years+ of related experience in Data Engineering.
• Education: College/Bachelor in Computer Science and or related discipline. Recent relevant technical certification an asset.
• Experience and knowledge of data architecture and concepts of relational and dimensional databases
• Experience with enterprise application architecture and enterprise integration patterns.
• Ability to implement re-usable data-integration/ETL code in an enterprise data-warehouse environment.
• Perform complex applications programming activities. Code, test, debug, document, maintain, and modify complex applications program as required.
• Examine and solve the performance bottlenecks in the ETL processes.
• Demonstrates good understanding of the Software Development Life Cycle.
• Proficiency in ETL tools - specifically Talend or DataStage.
• Strong SQL skills.
• Must have an experience working in Data Lake environment with Hive, Beeline expertise preferred.
• Previous experience of working in an Agile Development environment.
• Ability to work well in a challenging environment.
• Strong troubleshooting skills.
• Excellent writing skills, oral communication skills, strong process skills, and leadership ability.
• Ability to multi-task and prioritize under minimal supervision.
What you can expect from us
Build your career with us.
It is an extraordinary time to be in business. As digital transformation continues to accelerate, CGI is at the center of this change—supporting our clients’ digital journeys and offering our professionals exciting career opportunities.
At CGI, our success comes from the talent and commitment of our professionals. As one team, we share the challenges and rewards that come from growing our company, which reinforces our culture of ownership. All of our professionals benefit from the value we collectively create.
Be part of building one of the largest independent technology and business services firms in the world.
Learn more about CGI at www.cgi.com.
No unsolicited agency referrals please.
CGI is an equal opportunity employer. In addition, CGI is committed to providing accommodations for people with disabilities in accordance with provincial legislation. Please let us know if you require a reasonable accommodation due to a disability during any aspect of the recruitment process and we will work with you to address your needs.
",https://www.cgi.com/india/en/careers-search/J1020-2795/elt-data-engineer-talend-datastage-banking-and-financial-services
JOB249214782806,Lead Data Engineer,Lead Data Engineer,50+ career categories,"Home,Find a better job, faster!,Hand-screened leads,No ads, scams, junk,Great job search support","
Lead Data Engineer
Engage closely with stakeholders to better understand use cases, own lifecycle processes, end-to-end data management, create effective and efficient CI/CD processes and develop core architecture. Must have an expertise in SQL. Home-based position.
Job Details
100% Remote
Employee
Full-Time
Experienced
Bachelor's Degree
Yes, a bit
40
Annual home office enhancement stipend, Vision, Quarterly wellness reimbursement, Monthly internet reimbursement
Health Insurance, Retirement Planning, Paid Vacation, Maternity Leave, Education Assistance, Life Insurance, Dental Insurance, Stock Options
Company name here
Other benefits listed here
Find a better job, faster!
Hand-screened leads
No ads, scams, junk
Great job search support
50+ career categories
Create an Account to Unlock
To find out more about or apply to this Lead Data Engineer job—and other great opportunities like it—become a FlexJobs member today!
With FlexJobs, you'll find the best flexible jobs and fantastic expert resources to support you in your job search. If you have any questions, please feel free to contact us.
",https://www.flexjobs.com/publicjobs/lead-data-engineer-1308245
JOB250922090652,Senior Data Engineer,Senior Data Engineer,"Identify data sources that can add value to decision making.,Work with source system owners and analysts to understand source data, e.g. data profiling, definition and mapping.,Design and implement efficient data loads, using traditional structured data ETL techniques.,Design and implement real time and near real time data load solutions, using technologies like data streaming.,Design and implement unstructured data loads, e.g. text speech, images and video.,Design and implement load monitoring tools and procedures and perform continuous monitoring and optimising of loads.,Work with analysts and architect to design and implement effective and efficient data models using appropriate modelling techniques.,Design and implement data warehouse data models.,Design and implement data pipelines for ad hoc, unstructured and other data models.,Design and implement appropriate aggregation data structures that enhance usability of data, e.g. multi-dimensional OLAP structures, summary tables etc.,Design, implement and maintain appropriate indexing on tables to enhance speed of access.,Design and implement data models that support automated decision making and/or further analytics.,Continuously search for data elements from other sources to enhance existing data objects to supplement / enhance context.,Design and implement interfaces for data access, e.g. batch exports, real-time decision API’s etc.,Design and implement interface monitoring and management solutions to ensure availability and accuracy.,Monitor and maintain integrity of existing environment, troubleshoot technical and data issues and make appropriate changes where required.,Implement meta-data solutions that assist with understanding and managing data.,Work together with business owners, analysts and IT to maintain good data governance.,Provide technical and data related support to source system teams and external parties with whom we exchange data.,Manage data growth and usage by designing and implementing effective strategies, e.g. archiving and indexing.,Manage systems, technology and tools that enable data management and analytics.,Take ownership of own work by delivering high quality work on time.,Show initiative and be pre-active in finding opportunities to improve data and/or processes.,Take ownership of own career development by continuously improving skills, knowledge and the application thereof in designing and implementing solutions.,Positive engagement in team activities and actively contribute ideas to improve team dynamics and performance.,Stakeholder management (internal and external).,Assist in development of others, e.g. mentoring and knowledge share.,Quality control of other’s work.,Degree in information technology / mathematics / engineering / actuarial science or related discipline.,At least 5+ years in a technical data role, preferably in a formal data, data warehouse or business intelligence environment.,SQL,Data analysis,Data visualisation,Data modelling,Microsoft business intelligence data technologies (SSIS, SSAS, SQL Server),Data warehouse concepts and best practices,Financial services knowledge, specifically personal or unsecured loans,Business process monitoring and optimising,Microsoft business intelligence visualisation technologies (SSRS, Power BI),IT infrastructure, e.g. storage, networking, servers, security,Unstructured data experience,Information gathering and problem analysis,Applying professional / specialist / technical expertise,Creating and innovating,Quality & Detail orientation,Analysing",,"Job description
Capfin is a leading unsecured loan provider with a successful business model supported by great people with a strong culture of innovation and data driven decision making. The purpose of this role is to create business value by applying data engineering and data management disciplines to design and build data solutions that enable data driven decision support, in order to optimize business decisions and processes, as well as train and mentor more junior team members.
Requirements
Key Performance Areas:
Sourcing data
Identify data sources that can add value to decision making.
Work with source system owners and analysts to understand source data, e.g. data profiling, definition and mapping.
Loading data
Design and implement efficient data loads, using traditional structured data ETL techniques.
Design and implement real time and near real time data load solutions, using technologies like data streaming.
Design and implement unstructured data loads, e.g. text speech, images and video.
Design and implement load monitoring tools and procedures and perform continuous monitoring and optimising of loads.
Storing data
Work with analysts and architect to design and implement effective and efficient data models using appropriate modelling techniques.
Design and implement data warehouse data models.
Design and implement data pipelines for ad hoc, unstructured and other data models.
Enhancing data
Design and implement appropriate aggregation data structures that enhance usability of data, e.g. multi-dimensional OLAP structures, summary tables etc.
Design, implement and maintain appropriate indexing on tables to enhance speed of access.
Design and implement data models that support automated decision making and/or further analytics.
Continuously search for data elements from other sources to enhance existing data objects to supplement / enhance context.
Making data available
Design and implement interfaces for data access, e.g. batch exports, real-time decision API’s etc.
Design and implement interface monitoring and management solutions to ensure availability and accuracy.
Managing data
Monitor and maintain integrity of existing environment, troubleshoot technical and data issues and make appropriate changes where required.
Implement meta-data solutions that assist with understanding and managing data.
Work together with business owners, analysts and IT to maintain good data governance.
Provide technical and data related support to source system teams and external parties with whom we exchange data.
Manage data growth and usage by designing and implementing effective strategies, e.g. archiving and indexing.
Manage systems, technology and tools that enable data management and analytics.
Leadership responsibilities
Take ownership of own work by delivering high quality work on time.
Show initiative and be pre-active in finding opportunities to improve data and/or processes.
Take ownership of own career development by continuously improving skills, knowledge and the application thereof in designing and implementing solutions.
Positive engagement in team activities and actively contribute ideas to improve team dynamics and performance.
Stakeholder management (internal and external).
Assist in development of others, e.g. mentoring and knowledge share.
Quality control of other’s work.
Qualifications:
Degree in information technology / mathematics / engineering / actuarial science or related discipline.
Experience:
At least 5+ years in a technical data role, preferably in a formal data, data warehouse or business intelligence environment.
Functional Competencies:
SQL
Data analysis
Data visualisation
Data modelling
Microsoft business intelligence data technologies (SSIS, SSAS, SQL Server)
Data warehouse concepts and best practices
Financial services knowledge, specifically personal or unsecured loans
Business process monitoring and optimising
Microsoft business intelligence visualisation technologies (SSRS, Power BI)
IT infrastructure, e.g. storage, networking, servers, security
Unstructured data experience
Behavioural Competencies:
Information gathering and problem analysis
Applying professional / specialist / technical expertise
Creating and innovating
Quality & Detail orientation
Analysing
Posted on 25 Jun 13:34
",https://www.bizcommunity.com/Job/196/594/369015.html
JOB250994246516,Senior Data Engineer - Remote consulting position (Full-time W2),Senior Data Engineer - Remote consulting position (Full-time W2),"Architect and build data pipelines,Architect and implement data warehouse structure and table schemas,Develop data models to enable end users to effectively analyze data,Optimize and tune data warehouse for query performance and analytical workloads,Identify, troubleshoot and resolve data quality issues,Write complex SQL queries for data analysis,Design and maintain robust data reporting and visualization tools based on requirements,Develop integrations from BI tools to third party productivity applications,5+ years of engineering experience,Expert in SQL, preferably across a number of dialects (we commonly write Snowflake, Redshift/PostgreSQL, MySQL, SQL Server),Experience developing software code in one or more programming languages (Python, Java, Scala, Ruby),Experience managing database or data warehouse technologies (bonus for Redshift and/or Snowflake),Experience implementing ETL tools (Bonus for Stitch, Fivetran or Matillion),Understanding of data analytics ecosystem. Experience with one or more relevant tools (Spark, Kafka, AWS Glue, Amazon Kinesis, Sqoop, Flume, Flink),Experience with implementing Business Intelligence tools (Bonus for Looker),Experience developing data pipelines from scratch",," Job Description
Are you excited to work on cutting edge technologies to solve interesting data challenges? Join the Bytecode IO team as a senior data engineering expert for an opportunity to work with a team of smart, passionate consultants helping a wide range of clients unlock the value of their data.
The ideal candidate will work independently with minimal guidance, take the lead on deciding the best course of action for specific projects and clients - while being exposed to interesting cutting edge technologies.
You can work from anywhere (within the US) and shape your work schedule to meet both your professional and personal goals.
In this position you’ll be responsible for interfacing directly with clients to understand their needs as you architect and deploy end-to-end technology stacks. The ideal team member will have extensive hands-on experience with designing, developing and operating data technologies in the Amazon Web Services or Google Cloud Platform ecosystem such as Redshift, Kinesis, Glue, EMR, Athena, BigQuery, Cloud Dataflow, or Cloud Pub/Sub.
Role Requirements
Architect and build data pipelines
Architect and implement data warehouse structure and table schemas
Develop data models to enable end users to effectively analyze data
Optimize and tune data warehouse for query performance and analytical workloads
Identify, troubleshoot and resolve data quality issues
Write complex SQL queries for data analysis
Design and maintain robust data reporting and visualization tools based on requirements
Develop integrations from BI tools to third party productivity applications
Teach technical data modeling concepts to a variety of audiences, including developers, data architects, business users, and IT professionals
Who you are and what you have done
5+ years of engineering experience
Expert in SQL, preferably across a number of dialects (we commonly write Snowflake, Redshift/PostgreSQL, MySQL, SQL Server)
Experience developing software code in one or more programming languages (Python, Java, Scala, Ruby)
Experience managing database or data warehouse technologies (bonus for Redshift and/or Snowflake)
Experience implementing ETL tools (Bonus for Stitch, Fivetran or Matillion)
Understanding of data analytics ecosystem. Experience with one or more relevant tools (Spark, Kafka, AWS Glue, Amazon Kinesis, Sqoop, Flume, Flink)
Experience with implementing Business Intelligence tools (Bonus for Looker)
Experience developing data pipelines from scratch
Experience presenting complex topics to non-technical audiences
Company Description
Bytecode IO is a 100% remote consulting company focused on helping businesses make the best use of their data. We provide our clients expertise in data and software engineering, data platform architecture and business intelligence implemented on the best cloud technologies in the market.
Our clients include a range of early stage startups to fortune 500 companies.
","https://www.ziprecruiter.com/c/Bytecode-IO/Job/Senior-Data-Engineer-Remote-consulting-position-(Full-time-W2)/-in-Remote,OR?jid=7af319f63781ce06"
JOB253853997915,Data Engineer,Data Engineer,,,"
Data Engineer X 2 – Manchester. Our client based near Manchester are currently looking for 2 Data Engineers with Azure experience. The company is currently going through a large digital transformation, they are looking for talented Data specialist to help...
Job Title: Data Engineer Salary: 45,000 to 54,000 plus Benefits Location: Cambridge This is a very rare opportunity for an experienced Data Engineer with a strong background in building Python based data processing pipelines to join a company that are...
",https://www.reed.co.uk/jobs/data-engineer/40291175
JOB254405974902,Data Engineer,Data Engineer,,"Responsible for developing and optimising data and optimisation platforms and pipelines,Writing data pipelines as code and transforming data using appropriate and efficient methods,Working closely in a team of data scientists, machine learning engineers and operations researchers to build a fully integrated product,Data manipulation skills (SQL and NoSQL),Experience with AWS, and ideally AWS Lambda,Experience with Python","
I am currently working with a tech start up in Oxford who are looking for Data Engineers to work within their ever expanding team.
Because of their success in recent years, they are looking to expand further into the Energy sector. Thus, they are looking for a data engineer to contribute to their new product development efforts.
Responsibilities:
Responsible for developing and optimising data and optimisation platforms and pipelines
Writing data pipelines as code and transforming data using appropriate and efficient methods
Working closely in a team of data scientists, machine learning engineers and operations researchers to build a fully integrated product
Develop and maintain infrastructure to run and maintain data pipeline architecture
Profile:
Data manipulation skills (SQL and NoSQL)
Experience with AWS, and ideally AWS Lambda
Experience with Python
Eligible to work in the UK
Salary: £40,000 - £50,000
Jefferson Frank International Ltd is the global leader in AWS recruitment, advertising more AWS jobs than any other agency. We deal with both Digital Agencies & End Users globally and we have never had more live development jobs for AWS professionals. By specialising solely in placing candidates in the AWS market I have built relationships with most of the key employers.
Jefferson Frank Ltd is acting as an Employment Agency in relation to this vacancy.
To discuss this opportunity further or apply for the vacancy, please send your CV to or call Thomas Gilroy on +.
Reference: 39752712
Bank or payment details should never be provided when applying for a job. For information on how to stay safe in your job search, visit SAFERjobs.
Report this job
",https://www.reed.co.uk/jobs/data-engineer/39752712
JOB254706018875,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-es/details/200188037/ai-ml-search-data-engineer-siri-data
JOB255131619463,Senior Data Engineer,Senior Data Engineer,,,,"https://www.computerworld.dk/modules/job/morerandomjobs.php?op=list&start=3&limit=3&jobidsused=822671,824949,825453&layout=cwglassbox"
JOB255286008652,Data Engineer Jobs,Data Engineer Jobs,,,"
DESCRIPTION At Amazon Advertising, we are dedicated to drive measurable outcomes for brand advertisers, agencies, authors, and entrepreneurs. Our ad solutions—including sponsored, display, video, and custom ads—leverage Amazon’s innovations and insights...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
As the Data Engineer for this amazing corporate Insurance company, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL, together...
See more: Engineer jobs
As a data engineer within the exciting, new claims advanced analytics capability, you will be building big data solutions to solve some of the organization’s toughest problems and delivering significant business value. This is a really exciting time to...
See more: Engineer jobs
Data Engineer - 70,000 Job Description An AWS Partner based in Central London is looking to expand the data side of their business due to growth. They are looking for Data Engineers with significant commercial experience ingesting large quantities of data...
See more: Engineer jobs
As the Data Engineer for this amazing corporate Insurance company in the City, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
DATA ENGINEER - TEMPORARILY REMOTE 400- 450 PER DAY 3 MONTH CONTRACT EUROPE BASED As a Data Engineer you will be working heavily with Scala and Spark to improve the quality of data. THE COMPANY: You will be working for dynamic data driven company. As a...
See more: Engineer jobs
40'000- 50'000 Pension 8% Technical Progression Healthcare Holidays More Horley, Surrey Are you seeking a new challenge within a rapidly expanding Eco-Energy Tech company where you will be having huge technical autonomy in building a data preform right...
See more: Engineer jobs
Data Engineer Portsmouth and surrounding areas encouraged to apply, multiple office locations Data Engineer required for established, international business. The business is at the forefront of new technologies working with leading Government organisations...
See more: Engineer jobs
Data Engineer A brand new role has arisen for an experienced Database / BI Developer to take the next step in their career and transition into a full Data Engineer to work for one of the most recognisable NGO's in London. We are looking for someone with...
See more: Engineer jobs
Role: Data Engineer Client: Government agency (BPSS will be required) Location: Glasgow Duration: 8 Months Rate: 400 per day (outside IR35) Note: The office is based in Glasgow city centre. It is expected that the consultant would be available for physical...
See more: Engineer jobs
Data Engineer Opus are working with an excellent niche software development company in Newcastle. The company is at the forefront of their industry and due to their on-going success are now looking for a Data Engineer to take responsibility for organising...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
A leading Insurance Company are currently recruiting for a Data Engineer to join their dynamic and growing business. They are looking to hire a cross functional, highly tenacious and bright Data Engineer with a passion for functional programming. The ideal...
See more: Engineer jobs
Data Engineer- 50K Manchester Adria Solutions has an exciting opportunity for a talented Data Engineer to join our rapidly expanding client based near Manchester. The role requires you to work closely with other members of the data team and stakeholders...
See more: Engineer jobs
Data Engineer - 6 months - Ware - Hertfordshire Global FMCG is looking for an experienced Data Engineer who will play a pivotal role in operationalizing data and analytics initiatives for digital business initiatives. The bulk of the data engineer's work...
See more: Engineer jobs
We are currently recruiting a highly motivated Data Engineer, for a company who are based in London. The Data Engineer will help develop and maintain the business. The Data Engineer will be responsible for the following; Key responsibilities- - Working...
See more: Engineer jobs
Data Engineer - I am currently recruiting for a Data Engineer based in Bath. The role would be on a permanent basis and is paying 40,000 to 45,000 (There could be flex for the right candidate) PA plus a variety of excellent benefits as well as the flexibility...
See more: Engineer jobs
Data Engineer - London - 550-600 per day - 6 month contract SearchData is currently looking to recruit a Data Engineer to work on a cutting-edge DWH project in the financial services industry. As the Data Engineer your role will be to take a leadership...
See more: Engineer jobs
Data Engineer - REMOTE WORK If you are a strong Data Engineer, with experience working with Python, R and SQL then this role is ideal. I am working with a large organisation that are market leaders in their respected field. This role will report in to...
See more: Engineer jobs
Data Engineer London 55,000 - 65,000 Benefits Our client, an exciting RegTech business is looking to recruit for a Data Engineer to join their growing team. The successful candidate will be joining the artificial intelligence team, working on a brand new...
See more: Engineer jobs
An exciting opportunity for an experienced Data Engineer has arisen in Leeds. After hiring a number of new members of staff at the end of 2019, the organisation are continuing to expand due to winning more projects. Key responsibilites include: Building...
See more: Engineer jobs
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
See more: Engineer jobs
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
See more: Engineer jobs
",http://www.reed.co.uk/jobs/data-engineer/39966135
JOB255846564672,Lead Content / Data Engineer,Lead Content / Data Engineer,"You love to hack at things, and to come up with creative ways to approach problems.,Passionate about social, consumer applications and travel,Detail oriented, communicates clearly in writing and in conversation,2-5 years experience integrating with a variety of consumer APIs.,Comfortable working with Packer/Terraform (to update dependencies.,Experience with NLP, Named Entity Recognition & Machine Learning,PHP, Rust, React, Swift,Experience building browser plugins from scratch,Experience with Mechanical Turk and/or other similar marketplaces,Competitive Salary: 120,000 to 160,000,Equity: .25% to 1%,Healthcare,Flexible hours,Unlimited Vacation Time","Create smart solutions around complex data problems.,Work directly with our senior engineers to come up with unique solutions to import as much data as possible.,Own the importing and processing of unstructured web content,Parse content using NLP and ML to import it into our system on fly,Integrate with third party APIs,Build intelligent solutions for matching place names, addresses and geo-data","
Hey, we are Welcome.
A small passionate team creating a next generation smart city companion for around the corner or around the world.
Our platform uses friend and expert recommendations + an advanced Ai that always has an answer for the question: 'Where should I go now.'
Welcome launched four months ago, and immediately earned praise from Apple, Uncrate, Techcrunch, Product Hunt and more.
Welcome is venture backed by the best in the industry.
We are looking for a software engineer that is obsessed with API integrations, content scraping, and natural language processing.
Welcome uses a variety of data sources to make smart decisions for the user, your job is to help make Welcome smarter.
Plug into APIs, scrape web pages and documents, and translate them into smart data on the fly.
What you will do:
Create smart solutions around complex data problems.
Work directly with our senior engineers to come up with unique solutions to import as much data as possible.
Own the importing and processing of unstructured web content
Parse content using NLP and ML to import it into our system on fly
Integrate with third party APIs
Build intelligent solutions for matching place names, addresses and geo-data
Requirements
You love to hack at things, and to come up with creative ways to approach problems.
Passionate about social, consumer applications and travel
Detail oriented, communicates clearly in writing and in conversation
Skills:
2-5 years experience integrating with a variety of consumer APIs.
Comfortable working with Packer/Terraform (to update dependencies.
Experience with NLP, Named Entity Recognition & Machine Learning
Bonuses:
PHP, Rust, React, Swift
Experience building browser plugins from scratch
Experience with Mechanical Turk and/or other similar marketplaces
Benefits
Competitive Salary: 120,000 to 160,000
Equity: .25% to 1%
Healthcare
Flexible hours
Unlimited Vacation Time
","https://www.ziprecruiter.com/c/Welcome/Job/Lead-Content-Data-Engineer/-in-San-Francisco,CA?jid=DQ5c67dd67b42ab1f50bb651a0c928b40c&job_id=871ae991fb1c663c90d7bb6908fa492d"
JOB256182125417,Data Engineer/Sr Data Analyst,Data Engineer/Sr Data Analyst,,"Data/Business Analysis,SAS"," Job Description
Title: Data Analyst
Location: REMOTE- (MUST BE ON EST TIMEZONE)
Duration: 6 Month Contract-to-hire (MUST BE A US CITIZEN)
Start: ASAP Must haves:
Data/Business Analysis
SAS
SQL
Job Description
The candidate should be proficient in writing code using tools such as SAS and SQL and be able to provide management with strategic insights using data vizualization tools such as Tableau. This analyst will be required to build relationships across the organization as well as within their immediate business area to gain support and increase speed of execution of new strategies. Tasks will include, but are not limited to: reporting and analysis, performance metrics, strategy performance, development of business tools, creation of segmentation strategies, etc....
Requirements:
* 3+ years experience in strategy analysis
* 2+ years experience executing query languages such as SAS / SQL
* Solid knowledge of financial services industry and the products and services offered
* Ability to effectively analyze and interpret large amounts of raw data to accurately convey business needs.
* Demonstrated ability to identify issues of a complex nature and effectively resolve.
* Strong oral and written communication skills required to effectively and concisely present key findings to senior management is a must.
* Strong working knowledge in presenting quantitative data via PowerPoint, Excel, Word, etc.
* Ability to adjust to fluctuating work load with the pressure of aggressive deadlines
* Solid knowledge of financial services industry and the products and services offered
","https://www.ziprecruiter.com/c/Mondo/Job/Data-Engineer-Sr-Data-Analyst/-in-Wilmington,DE?jid=DQa6de76e8cddfc1d39058aac9bcd5b9c3&job_id=9ee28af4362b7a54bd71267672e97e2a"
JOB256709689824,Data Engineer at NORMENT,Data Engineer at NORMENT,,,"
About the University of Oslo
The University of Oslo is Norway’s oldest and highest ranked educational and research institution, with 28 000 students and 7000 employees. With its broad range of academic disciplines and internationally recognised research communities, UiO is an important contributor to society.
The Institute of Clinical Medicine (Klinmed) is one of three institutes under the Faculty. Klinmed is responsible for the Faculty's educational and research activities at Oslo University Hospital and Akershus University Hospital. With about 800 employees spread over approximately 425 man-labour years, Klinmed is the university's largest institute. Our activities follow the clinical activity at the hospitals and are spread across a number of geographical areas.
",https://www.jobbnorge.no/en/available-jobs/job/186922/data-engineer-at-norment
JOB256989325883,"AI/ML - Sr Search Data Engineer, Siri Data","AI/ML - Sr Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,4+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, Flink, Kafka, etc.) building efficient extraction and transformation pipelines at scale,Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth attitude,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Sr Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
4+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, Flink, Kafka, etc.) building efficient extraction and transformation pipelines at scale
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth attitude
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access to datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-us/details/200188040/ai-ml-sr-search-data-engineer-siri-data
JOB257741105708,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-dk/details/200188037/ai-ml-search-data-engineer-siri-data
JOB258139613745,Data Engineer,Data Engineer,,,"Imagine what you could do here. At Apple, new ideas have a way of becoming great products, services, and customer experiences very quickly. Bring passion and dedication to your job and there's no telling what you could accomplish. The Fraud, Engineering, Algorithms and Risk group is responsible for combating fraud and abuse for Internet Software and Services at Apple. In this role, you will be tasked with building mission-critical, robust and scalable distributed systems that can keep pace with data across a number of high-profile and large-volume Apple cloud properties. You will chip in to building the next-generation libraries, platforms, and data pipelines to empower us to rapidly build and deploy complex models to production.
We engineer high-quality, scalable and resilient distributed systems that power data exploration, model building and production models. Our core systems need to work seamlessly across different execution contexts (real-time, near real-time and batch) You will support diverse data analytics stacks such as Spark, Hadoop, Kafka, Cassandra and beyond. We work at an unusual intersection of huge data volumes and adversaries that are continuously adapting, which means we are operating at and beyond the limits of conventional alternative data systems. On our team you can be sure that every commit you make will come with the satisfaction that you are helping protect and improve the user experience of hundreds of millions of users. This role requires in-depth knowledge with cutting-edge data analytics technologies. Tuning, troubleshooting and scaling these big data technologies are a key part of our work, where having a curiosity with the internal workings of these systems is key to being successful. This is a hard-core software engineering role, where a large part of an engineer's time is spent writing code with the remainder being spent on designing and architecting systems, tuning and debugging alternative data systems, supporting production systems and supporting our data scientists.
",https://jobs.apple.com/en-us/details/200142694/data-engineer
JOB258446109225,"AI/ML - Search Data Engineer, Siri Data","AI/ML - Search Data Engineer, Siri Data","You have excellent written and verbal communication skills,You are curious and have excellent analytical and problem solving skills,You are excited about digging into massive petabyte-scale semi-structured datasets,1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.),Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent),Experience with large, complex, highly dimensional data sets; hands-on experience with SQL,You are pragmatic, not letting “the perfect” be the enemy of “the good”,You are self-directed and capable of operating amidst ambiguity,You are humble, continually growing in self-awareness and possessing a growth mindset,Extras we’d be excited about...,Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others",,"AI/ML - Search Data Engineer, Siri Data
Summary
Siri’s universal search engine powers search features across a variety of Apple products, including Siri Assistant, Spotlight, Safari, Messages, and News. The Siri Data organization seeks to improve Siri by using data as the voice of our customers. Within this organization the Search Data Engineering team builds systems that process data reliably at scale to generate scalable and high quality datasets that support confident, data-driven decision making for Siri Search. We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. As a part of this group, you will work with petabytes of data daily using diverse technologies like Spark, Flink, Kafka, Hadoop and others. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including analysts and product engineers. In this role you will build datasets to support analytics, experimentation, and machine learning. Specifically, you will build out stream processing applications powering real-time metrics and you will help to drive our self-serve strategy for reporting on-behalf of data scientists and product engineers as we collectively make Siri better.
You have excellent written and verbal communication skills
You are curious and have excellent analytical and problem solving skills
You are excited about digging into massive petabyte-scale semi-structured datasets
1+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc.)
Proficiency in at least one high-level programming language (Python, Go, Java, Scala, or equivalent)
Experience with large, complex, highly dimensional data sets; hands-on experience with SQL
You are pragmatic, not letting “the perfect” be the enemy of “the good”
You are self-directed and capable of operating amidst ambiguity
You are humble, continually growing in self-awareness and possessing a growth mindset
Extras we’d be excited about...
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others
Experience with data engineering in support of ML: Anomaly detection in time series data, engineering work to product-ionize models developed by data scientists, etc.
Developing data pipelines and/or software libraries to process, transform, and analyze data to identify signals from the billions of events we collect every day Designing and building abstractions that hide the complexity of the underlying big data stack (HDFS, Hadoop, Hive, Impala, Spark, Kafka, Parquet, etc) and that allow partners to focus on their strengths: product, data modeling, data analysis, search, information retrieval, and machine learning Defining and implementing the “source of truth” for our most fundamental data—such as search activity and content—as well as our core metrics across a variety of products Optimizing end-to-end workflows of data users (crafting libraries, providing abstractions to define jobs, scheduling data pipelines, managing access datasets, etc) Building internal services and tools to help in-house partners implement, deploy and analyze datasets with a high level of autonomy and limited friction. Surfacing datasets in near-real-time to mission critical products and business applications throughout the company, providing the signal that feeds our machine learning algorithms as well as our daily product-defining decisions Automating and handling lifecycle of datasets (schema evolution, metadata store, backfill management, deprecation, migration) Improving the quality and reliability of our pipelines (monitoring, retry, failure detection)
",https://jobs.apple.com/en-de/details/200188037/ai-ml-search-data-engineer-siri-data
JOB259878656889,Data Engineer,Data Engineer,,,"
Data Engineer X 2 – Manchester. Our client based near Manchester are currently looking for 2 Data Engineers with Azure experience. The company is currently going through a large digital transformation, they are looking for talented Data specialist to help...
Job Title: Data Engineer Salary: 45,000 to 54,000 plus Benefits Location: Cambridge This is a very rare opportunity for an experienced Data Engineer with a strong background in building Python based data processing pipelines to join a company that are...
",https://www.reed.co.uk/jobs/data-engineer/40311494
JOB259923905905,Senior Data Engineer,Senior Data Engineer,50+ career categories,"Find a better job, faster!,Hand-screened leads,No ads, scams, junk,Great job search support","
Senior Data Engineer
Monitor and maintain high-volume data. Identify issues and optimization opportunities for an application in event ticketing. Requires a bachelor's degree with 5+ yrs' experience or an equivalent combination. Work from home full-time with benefits.
Job Details
10/27/20
100% Remote
Employee
Full-Time
Manager
Bachelor's Degree
No specification
Vision & disability insurance, HSA, Pre-tax savings, Company-provided equipment, Wellness programs, Recognition programs, Flexible PTO
Health Insurance, Retirement Planning, Paid Vacation, Life Insurance, Dental Insurance
Company name here
Other benefits listed here
Find a better job, faster!
Hand-screened leads
No ads, scams, junk
Great job search support
50+ career categories
Create an Account to Unlock
To find out more about or apply to this Senior Data Engineer job—and other great opportunities like it—become a FlexJobs member today!
With FlexJobs, you'll find the best flexible jobs and fantastic expert resources to support you in your job search. If you have any questions, please feel free to contact us.
",https://www.flexjobs.com/publicjobs/senior-data-engineer-1315479
JOB261442941135,Data Engineer (Java/ Data/ Big Data Developer),Data Engineer (Java/ Data/ Big Data Developer),"Agile Engineering (Kanban, Lean, Hybrid agile experience is a big plus)","Engage in super interesting high profile projects,Join a fun team full of flair and personality, contribute and be recognized for your value add!,Zero Bureaucracy environment - we are about embracing creative talent,Passionate about working on complex Data problems,You will ideally have a solid demonstrated Big Data experience,Java/ Data/ Big Data Development","
Data Engineer (SJava/ Data/ Big Data Developer), Melbourne CBD, fantastic long duration contract, asap start
Melbourne
Are you a Data Engineer with Java/ Data/ Big Data Development experience seeking a new contract? If you answered yes, I have the ""perfect"" role for you!!!
Working with a reputable iconic Australian brand name in Melbourne CBD you will be a part of a leading customer analytics platform team.
The position is available due to growth and they are in need of a talented Data Engineer to work on next generation data tools and pipelines. This is where Data Engineering meets Data Science!
What is in it for you?
Engage in super interesting high profile projects
Join a fun team full of flair and personality, contribute and be recognized for your value add!
Zero Bureaucracy environment - we are about embracing creative talent
Who are you?
Passionate about working on complex Data problems
You will ideally have a solid demonstrated Big Data experience
Your ""perfect"" role:
As a talented Data engineer you will demonstrate expertise in:
Java/ Data/ Big Data Development
Agile Engineering (Kanban, Lean, Hybrid agile experience is a big plus)
Your value add to this team will be:
• Java / data work putting together a prototype for a Big Data linking engine, preference for Big Data experience
• Every day is a different idea, a different challenge, you ""will be"" up for it!
• Outgoing personality with a creative flair, not stage shy and experienced with senior stakeholders!
If this sounds like you, I would love to find out more about you! Apply by sending you CV in word format.To be considered for the role click the 'Apply' button or for more information about this and other opportunities please contact Kenny Nerlekar on 03 8680 4202. Please quote our job reference number: 200165301.
Reference Number: 200165301_2
Contact Details:
How to Apply?
Click on the link below
Click here for more information about this job
",http://www.computerworld.co.nz/jobs/view/20718/data-engineer-java-data-big-data-developer/
JOB262388128621,Data Engineer,Data Engineer,,,"
Job title: Data Engineer Location : Zurich. Switzerland Job type : Contract Data Engineer with Hadoop/Apache Sparc Knowledge - - Build a data processing layer based on Hadoop,Spark, Neo4J - Ensure appropriate security processes are integrated with access...
Data Engineer We have had a role come available for a Data Engineer in London. The role will require you to either hold a DV Clearance. Key Experience: Data Analysis experience; Strong SQL skills; Data Processing using ETL tools; Understanding of procurement...
Data Engineer - Contract - Remote Based Data Engineer Until end November 2020 initially Remote Based (Office is based in Chester) Competitive pwd Ltd Company Tech Skills Required: ETL Design, Talend, MYSQL, Vertica We are currently looking for a Data Tester...
Data Engineer - Contract - Remote Based Data Engineer Until end November 2020 initially Remote Based (Office is based in Chester) Competitive pwd Ltd Company Tech Skills Required: ETL Design, Talend, MYSQL, Vertica We are currently looking for a Data Tester...
Site Name: UK - London - Brentford, USA - Pennsylvania - Upper Providence Posted Date: Jun 4 2020 Are you looking for a challenging opportunity to work in an area where cutting edge science meets cutting edge technology with an aim of delivering drugs...
Site Name: UK - London - Brentford, USA - North Carolina - Research Triangle Park, USA - Pennsylvania - Philadelphia Posted Date: Mar 17 2020 Data Engineer is accountable for developing and delivering cloud-based data ingestion solutions across the Pharma...
AWS Data Engineer x 2 Real Estate business Solve a key problem for the client. Work with AWS & PostgreSQL. 3 month initial contract outside of IR35. My client is looking for 2 AWS Data Engineers with solid experience working with post code / address...
Remote working. Up to 550 p/day. SQL Server, SSIS, AWS 6-month contract opportunity for a Senior Data Engineer with financial services experience. What you'll be doing Working for a large financial services client, you will work in a team of data engineers...
Azure Data Engineer Leading Insurance business Work on a large scale Azure migration project. Build dimensional models. 6 month initial contract - inside IR35 My client is looking for 2 Data Engineers with excellent Microsoft Azure experience for a large...
Senior Data Engineer - Permanent Data Idols are working with a well known Technology company who are looking for a Senior Data Engineer to join a cross-functional team. This industry disruptor has been changing the way people interact with an everyday...
Our client, a global travel company require a Digital Data Engineer with strong GCP/ Big Query skills to join their analytics engineering team. Your Role You will be responsible for developing reporting infrastructure and providing actionable reporting...
Supporting a fast growing, global organisation the Interim Data Engineer will become a business partner to a newly established international client. You will be responsible for the following: - Building reporting architectures and pipelines for streamed...
SENIOR DATA ENGINEER 550- 650 PER DAY 3 MONTH CONTRACT REMOTE/ LONDON BASED As a Senior Data Engineer you will have the chance to work for a innovative e-commerce client in productionising ML models using Python, SQL and Airflow alongside AWS services...
Data Engineer SC cleared London, Titchfield or Newport 3 months to start - but until march 2021 Outside IR35 SC cleared holder before applying - due to quick start of work Key Responsibilities Collaborating with key members of the Data Engineering team...
Digital Data Engineer 500 per day 3-months Remote/London As a Data Engineer, you will be helping with a Digital Transformation project, in setting up a Google Big Query data warehouse. THE COMPANY: This company specialise in the travel industry and are...
Digital Data Engineer | 3 Month Contract As Digital Data Engineer, you will be responsible for developing reporting infrastructure and providing actionable reporting on my client's web properties (website, app). You will be working closely with stakeholders...
An exciting opportunity has opened up in Mechelen, Belgium for a Big Data Engineer. Skills and experience required: Scala Spark Kafka HLD, DLD and e2e ownership for Big Data projects Proficient in requirement gathering This is a 9-month contract. Salt...
Data Engineer Cutting edge machine learning Mission led start-up Crucial hire An established mission-led start-up is currently looking for an experienced Data Engineer/Software Engineer to join their team on an initial 3-month contract to extend/go permanent...
Python Software Engineer / Developer (PostgreSQL) Remote Interview. Are you a bright, motivated Python Software Engineer looking to work on complex, data centric systems whilst continually learning and gaining valuable knowledge of financial trading systems?...
Big Data Engineer Must be security cleared 45,000 - 55,000 Home working initially but candidate must be able to commute to Croydon / Kent in time If you are interested in working with sophisticated data to solve real world problems within a focused and...
DATA ENGINEER 400- 500 PER DAY 3 MONTH CONTRACT FULLY REMOTE As a Data Engineer you will have the chance to work for a online retail client using SQL heavily and DBT for modelling. THE COMPANY: As a Data Engineer, you will be working for an exciting online...
DATA ENGINEER 400- 500 PER DAY 3 MONTH CONTRACT FULLY REMOTE As a Data Engineer you will have the chance to work for a media company using Big Query, Airflow and Python for ETL work. THE COMPANY: As a Data Engineer, you will be working for a well known...
Are you a seasoned professional with prior data center construction experience? Do you have a deep knowledge of electrical systems? Looking for a new opportunity? An exciting opportunity to become the subject matter expert for the electrical systems within...
",https://www.reed.co.uk/jobs/data-engineer/40304853
JOB262647208802,Data Engineer,Data Engineer,,," Job title: Data Engineer Location : Zurich. Switzerland Job type : Contract Data Engineer with Hadoop/Apache Sparc Knowledge - - Build a data processing layer based on Hadoop,Spark, Neo4J - Ensure appropriate security processes are integrated with access...
",https://www.reed.co.uk/jobs/data-engineer/40263428
JOB263418577729,"24,644 Senior Data Engineer Jobs","24,644 Senior Data Engineer Jobs",,,"
",https://www.ziprecruiter.com/Jobs/Senior-Data-Engineer
JOB264204642879,Data Engineer,Data Engineer,"You are highly expert and battle tested, a lead or core contributor on data processing projects,Consistent record of designing and implementing scalable, performant data pipelines, data services, and data products.,This is a hands-on position, expect to write more code,Programming experience in building high quality software. Skills with Java, Python or Scala preferred,Proficiency in Hadoop, Kafka, Spark and MPP/No SQL databases like Vertica, Redshift, Snowflake in a large scale environment,Strong aptitude for learning new technologies related to Data Management and Data Science.,Demonstrated ability to work well independently and within a fast-paced, team-oriented environment,Work with noisy, dirty and unstructured data. Data cleansing, scraping unstructured data and converting into structured data,Evaluate, benchmark and improve the scalability, robustness, efficiency and performance of big data platform and applications,Experience building reports using Tableau, Microstrategy,Knowledge in engineering machine learning, feature engineering systems is a plus.",,"Imagine what you could do here. At Apple, phenomenal ideas have a way of becoming great products, services, and customer experiences very quickly. Bring passion and dedication to your job and there's no telling what you could accomplish. Imagine what you could do here. At Apple, new ideas have a way of becoming great products, services, and customer experiences very quickly. Bring passion and dedication to your job and there's no telling what you could accomplish. The Infrastructure Services Software Development team is looking for a passionate, self-motivated and hard-working engineer to be part of a diverse, fast paced and high-energy team. We are seeking an experienced Data Engineer to build high quality, scalable and resilient distributed systems that power the analytics platform and data pipelines. You will be responsible for developing some of the key components of the platform, collaborate with cross-functional teams to bring together requirements and mentor junior members in the team. You will be contributing to key and innovative technology which supports major Apple applications, with all the scalability and high-availability requirements that entails.
You are highly expert and battle tested, a lead or core contributor on data processing projects
Consistent record of designing and implementing scalable, performant data pipelines, data services, and data products.
This is a hands-on position, expect to write more code
Programming experience in building high quality software. Skills with Java, Python or Scala preferred
Proficiency in Hadoop, Kafka, Spark and MPP/No SQL databases like Vertica, Redshift, Snowflake in a large scale environment
Strong aptitude for learning new technologies related to Data Management and Data Science.
Demonstrated ability to work well independently and within a fast-paced, team-oriented environment
Work with noisy, dirty and unstructured data. Data cleansing, scraping unstructured data and converting into structured data
Evaluate, benchmark and improve the scalability, robustness, efficiency and performance of big data platform and applications
Experience building reports using Tableau, Microstrategy
Knowledge in engineering machine learning, feature engineering systems is a plus.
Excellent debugging, critical thinking and communication skills
In this role, you will be building big data platform using a combination of integration framework and Big Data processing technologies. A strong understanding of distributed systems and strong experience in using open source framework to build applications is required. As a senior member of the team, you are encouraged to take ownership of individual platform components and help set the vision and architecture for it. In the process, you will identify the requirements of new features, and propose design and drive the solution.
",https://jobs.apple.com/en-us/details/200136943/data-engineer
JOB265404695384,"12,223 Data Engineer Contract Jobs","12,223 Data Engineer Contract Jobs",,,"
Quick Apply
Senior Data Engineer
NEW!
Veteran-friendly
As a Senior Data Engineer on the Security Operations team within the Information Security group, you bring a unique mix of distributed data processing, data warehousing, and software engineering ...
Quick Apply
Data Engineer
The data engineer will provide technical expertise and leadership on architecture, design, and ... Permanent Placement, Retained, Contract, Contract-to-Hire, and Temporary Staffing. Kane Partners ...
Quick Apply
Data Engineer (Snowflake, Redshift)
Data Engineer Terms: Contract (ongoing, with possible extension or permanent conversion) Reports to: Senior Manager of Analytics Industry: AI Hardware/Software (Emerging Technology) Scope of Work
Quick Apply
Network Security Engineer - Contract to Hire
... Engineer in Playa Vista (Los Angeles). This contract will start remote and move onsite in the ... and other data. ● Working with various corporate security systems ● Work with IT End User ...
",https://www.ziprecruiter.com/Jobs/Data-Engineer-Contract
JOB265801379203,Lead Data Engineer,Lead Data Engineer,"Design, build and launch extremely efficient and reliable data pipelines to move data across a number of platforms including Data Warehouse, online caches and real-time systems.,BA/BS Degree in Computer Science, any Engineering discipline, Statistics, Information Systems or another quantitative field.,Action Oriented",,"
POSITION PURPOSE
The Lead Data Engineer within Online Analytics & BI is responsible for overseeing the data and tools to support marketing's analytics and data science needs. This person owns the marketing data pipeline which brings the data from various data sources to supports the analysis, reporting, audience creation and data science needs of the marketing organization. This person will be responsible for the continued design, development and optimization of the marketing data pipelines & data prep infrastructure in a cloud environment. This position serves as Measure & Insights primary point of contact with Marketing & IT on these systems.
MAJOR TASKS, RESPONSIBILITIES AND KEY ACCOUNTABILITIES
30% - Work with the manager, business stakeholders, analysts, team developers, IT, and other 3rd party partners to assist with determining approach and needs for analytics enablement
20% - Self-driven to communicate effectively across broad range of technical and business savvy stakeholders to assure alignment on solution and strategy/timeline to deploy
15% - Drive effective Agile project delivery protocols to assure we gather and surface reliable, actionable enterprise level analytics
20% - Ensure the team comprehends and applies the established processes and standards and mentor team on development
5% - Provide status reports to Manager and review boards on complex development projects
10% - Guide and direct project teams in the requirements gathering, design, and development of complex applications/programs
NATURE AND SCOPE
This position typically reports to the Manager
This position has 0 Direct Reports
ENVIRONMENTAL JOB REQUIREMENTS
Environment:
Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.
Travel:
Typically requires overnight travel less than 10% of the time.
Additional Environmental Job Requirements:
MINIMUM QUALIFICATIONS
Must be eighteen years of age or older.
Must be legally permitted to work in the United States.
Additional Minimum Qualifications:
Education Required:
The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.
Years of Relevant Work Experience: 5 years
Physical Requirements:
Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.
Additional:
Design, build and launch extremely efficient and reliable data pipelines to move data across a number of platforms including Data Warehouse, online caches and real-time systems.
Provide data architecture that is flexible, scalable, and consistent for cross-functional use, and aligned to stakeholder business requirements.
Manage workflow orchestration and demonstrate strength in data modeling, ETL development, and data warehousing
Build analytical tools to increase productivity of Data Analysts, Data Scientists and Marketers
Partner with BI, IT, Marketers and Data Scientists to understand data needs and assist them in accessing and leveraging key data sets
Define SLA and acceptable time lags by data source, define QA process, and socialize resolution process to ensure data is flowing accurately through data creation to our presentation layers
Help Marketing organization to become a 100% data driven organization by building a next generation data platform that brings accurate and timely data to the Marketers
Validate Data Engineering business data elements, organizational and business intelligence architecture designs for engineering functional areas from Dashboards, Data Lakes, Data Operations, ML - AI, and upstream/downstream intake and output processes
Designs and builds the data strategies and roadmaps necessary to serve marketing analytics and data science needs
Preferred Qualifications:
BA/BS Degree in Computer Science, any Engineering discipline, Statistics, Information Systems or another quantitative field.
6+ years of industry experience in data engineering, data science, or related field with a track record of manipulating, processing, and extracting value from large datasets
Experience leading a Data Engineering Team
Experience building and managing data pipelines and CI/CD to repositories in cloud environments such as Google Cloud, Microsoft Azure or AWS
Experience optimizing data pipelines/queries for performance and storage
Excellent knowledge of the industry standards and best practices
Good knowledge of coding standards and the ability to use versioning tools such as Github/subversion etc.,
Experience in Airflow is a must
Experience extracting/cleansing data and generating insights from large transactional data sets using SQL, R, Python, Spark on the cloud
Experience in Looker, Redshift, Apache Spark, Spark Structured Streaming, Spark SQL, Hive, HDFS, Kafka etc.
Experience with cloud computing with Dataproc, Databricks or similar technologies.
Strong verbal and written communications skills at all levels; ability to communicate complex customer behavior information to both functional partners and Executive Leadership
Open to idea exploration with strong problem-solving/analytical abilities
Demonstrated strength in creating partnerships and in building relationships with other functions and associates within the organization
Experience leading and presenting proof of values and business to leaders
Knowledge, Skills, Abilities and Competencies:
Action Oriented
Business Insights
Decision Quality
Manages Ambiguity
Tech Savvy
Manages Complexity
Communicates Effectively
Customer Focus
Strategic Mindset
We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class.
",https://www.careerbliss.com/jobs/detail/543760674/
JOB265826311377,Junior Data Engineer,Junior Data Engineer,,,"
Job description
Within this position you will be responsible for:
- Developing and maintaining Tableau Reports/Dashboards
- Developing and maintaining data pipelines from various sources (API,
- GoogleSheets, Databases, Email)
- Developing Data Models for our Data Warehouse
- Developing Transformation and Loading SQL scripts to keep our Data
- Warehouse up to date
- Developing scripts to leverage our Behavioural Science needs
Clients:
An exciting opportunity to work with all our clients across all internal teams. Working with external partners to develop solutions and relationships.
About you
Degree in Computer Science or similar would be ideal, but not essential.
The role requires excellent understanding of:
- Structured Query Language (SQL) and its advanced functions
- Tableau or similar Data Visualisation tools
- Object Oriented Programming and the best practices to create robust and readable code
- Experience with programming in Python is essential. Other programming languages are valuable
- Data Warehouse modelling techniques
- Talend or similar ETL tools
- AWS environment. Experience with Google BigQuery is highly valuable
Experience
Minimum of 1 year experience in a similar role.
Experience within Advertising and Media industry is a big bonus, but not essential.
Key responsibilities
- Developing and maintaining Tableau Reports/Dashboards
- Developing Transformation and Loading SQL scripts to keep our Data Warehouse up to date
- Developing and maintaining data pipelines from various sources
The Package
The Agency
Total Media is a leading independent and international media agency that connects people to brands. Our media strategies are based on people’s behaviours – understanding how audiences think, feel and act – so that we reach them contextually, during the moments that matter.
We work across the full spectrum of media planning and buying, with fantastic media teams dedicated to client servicing, broadcast, publishing, digital, data and content production.
At Total Media we are committed to diversity & inclusion and providing equal opportunities for everyone. We are dedicated to ensuring our processes are free from any form of discrimination or bias, right from the application process to life as part of the Total Media Team!
",https://ipa.co.uk/job-listing/junior-data-engineer-06-08-2020
JOB266766555993,Data Engineer Jobs,Data Engineer Jobs,,,"
DESCRIPTION At Amazon Advertising, we are dedicated to drive measurable outcomes for brand advertisers, agencies, authors, and entrepreneurs. Our ad solutions—including sponsored, display, video, and custom ads—leverage Amazon’s innovations and insights...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
As the Data Engineer for this amazing corporate Insurance company, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL, together...
See more: Engineer jobs
As a data engineer within the exciting, new claims advanced analytics capability, you will be building big data solutions to solve some of the organization’s toughest problems and delivering significant business value. This is a really exciting time to...
See more: Engineer jobs
Data Engineer - 70,000 Job Description An AWS Partner based in Central London is looking to expand the data side of their business due to growth. They are looking for Data Engineers with significant commercial experience ingesting large quantities of data...
See more: Engineer jobs
As the Data Engineer for this amazing corporate Insurance company in the City, you will focus your skills & experience on maintaining and extending their fast-growing Snowflake Cloud Data Warehousing Platform using Wherescape for automation & ETL...
See more: Engineer jobs
DESCRIPTION Come build the future of entertainment with us. Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching? Prime Video is a premium streaming service...
See more: Engine jobs
DATA ENGINEER - TEMPORARILY REMOTE 400- 450 PER DAY 3 MONTH CONTRACT EUROPE BASED As a Data Engineer you will be working heavily with Scala and Spark to improve the quality of data. THE COMPANY: You will be working for dynamic data driven company. As a...
See more: Engineer jobs
40'000- 50'000 Pension 8% Technical Progression Healthcare Holidays More Horley, Surrey Are you seeking a new challenge within a rapidly expanding Eco-Energy Tech company where you will be having huge technical autonomy in building a data preform right...
See more: Engineer jobs
Data Engineer Portsmouth and surrounding areas encouraged to apply, multiple office locations Data Engineer required for established, international business. The business is at the forefront of new technologies working with leading Government organisations...
See more: Engineer jobs
Data Engineer A brand new role has arisen for an experienced Database / BI Developer to take the next step in their career and transition into a full Data Engineer to work for one of the most recognisable NGO's in London. We are looking for someone with...
See more: Engineer jobs
Role: Data Engineer Client: Government agency (BPSS will be required) Location: Glasgow Duration: 8 Months Rate: 400 per day (outside IR35) Note: The office is based in Glasgow city centre. It is expected that the consultant would be available for physical...
See more: Engineer jobs
Data Engineer Opus are working with an excellent niche software development company in Newcastle. The company is at the forefront of their industry and due to their on-going success are now looking for a Data Engineer to take responsibility for organising...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
See more: Engineer jobs
A leading Insurance Company are currently recruiting for a Data Engineer to join their dynamic and growing business. They are looking to hire a cross functional, highly tenacious and bright Data Engineer with a passion for functional programming. The ideal...
See more: Engineer jobs
Data Engineer- 50K Manchester Adria Solutions has an exciting opportunity for a talented Data Engineer to join our rapidly expanding client based near Manchester. The role requires you to work closely with other members of the data team and stakeholders...
See more: Engineer jobs
Data Engineer - 6 months - Ware - Hertfordshire Global FMCG is looking for an experienced Data Engineer who will play a pivotal role in operationalizing data and analytics initiatives for digital business initiatives. The bulk of the data engineer's work...
See more: Engineer jobs
We are currently recruiting a highly motivated Data Engineer, for a company who are based in London. The Data Engineer will help develop and maintain the business. The Data Engineer will be responsible for the following; Key responsibilities- - Working...
See more: Engineer jobs
Data Engineer - I am currently recruiting for a Data Engineer based in Bath. The role would be on a permanent basis and is paying 40,000 to 45,000 (There could be flex for the right candidate) PA plus a variety of excellent benefits as well as the flexibility...
See more: Engineer jobs
Data Engineer - London - 550-600 per day - 6 month contract SearchData is currently looking to recruit a Data Engineer to work on a cutting-edge DWH project in the financial services industry. As the Data Engineer your role will be to take a leadership...
See more: Engineer jobs
Data Engineer - REMOTE WORK If you are a strong Data Engineer, with experience working with Python, R and SQL then this role is ideal. I am working with a large organisation that are market leaders in their respected field. This role will report in to...
See more: Engineer jobs
Data Engineer London 55,000 - 65,000 Benefits Our client, an exciting RegTech business is looking to recruit for a Data Engineer to join their growing team. The successful candidate will be joining the artificial intelligence team, working on a brand new...
See more: Engineer jobs
An exciting opportunity for an experienced Data Engineer has arisen in Leeds. After hiring a number of new members of staff at the end of 2019, the organisation are continuing to expand due to winning more projects. Key responsibilites include: Building...
See more: Engineer jobs
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
See more: Engineer jobs
DATA ENGINEER 60- 65,000 BONUS BENEFITS CENTRAL LONDON Ready to work in a fast-paced, innovative company? Eager for more responsibility in your role? Look no further An exciting opportunity to work with Python, AWS, and Airflow on a revolutionary project...
See more: Engineer jobs
",http://www.reed.co.uk/jobs/data-engineer/39966574
JOB269293172617,"Senior Big Data Engineer (Core Java, Hadoop, Spark)","Senior Big Data Engineer (Core Java, Hadoop, Spark)","Strong Java experience (mainly Core Java),Strong knowledge of OOP,SQL,Hands-on Google Cloud Platform: Dataflow, BigQuery, and Pub/Sub or Hadoop echosystem experience: Hbase, Hive, Spark.,Commercial experience with Linux.,Messagedriven architecture with experience using ActiveMQ/Kafka or similar,Track record of developing technology to enable large scale data transformation.,ETL data load process development,Experience dealing with large and/or complex data sets.,Development and Testing best practices,Maven, Git,Familiar with NoSQL technologies * Embrace agile software engineering practices and tools; TDD, Continuous Integration etc.,Understanding of software development lifecycle, Agile software design principles and build processes,Excellent organisation, communication and interpersonal skills,Ability to work both collaboratively and with limited supervision,Can deliver results within set deadlines,Bachelor's,Java: 5 years","Want to work in a business where you have a voice and can be a part of the big picture?,Excited by making and breaking things?,Love working and playing with massive amounts of data?,Excited by greenfield projects?,Handle server-side development of a distributed Google applications,Develop data loading/ETL processes for Google Big Data Platform,Write clear, efficient, tested code.,Develop code as part of a wider team, contributing to code review and solution design.,Contribute to evolution of standards and design patterns.,Deploy and maintain applications in production environment.,Solve challenging technical problems within distributed environments,Work in a team using the Scrum/Kanban methodology ensuring that your team meets your backlog commitments.","
Senior Big Data Engineer (Core Java, Hadoop, Spark)
Market leading online gambling organisation require a Senior Big Data Engineer with strong Java experience to join a World Class team.
The Role
My client, a market leading gaming / gambling developer are recruiting for a hand-on Big Data Engineer with passion for data to work alongside other developers and QAs in an agile environment. You will be work on the development of new and existing data pipelines utilising Google Cloud Platform, turning requirements into finished technical solutions and cooperating effectively with colleagues in both technical and business-facing roles. You will work with your team members delivering elegant solutions and to troubleshooting difficult problems. Working with massive large data sets to learn and apply the latest big data technologies on a fast-leading edge technology Google Big Data.
Want to work in a business where you have a voice and can be a part of the big picture?
Excited by making and breaking things?
Love working and playing with massive amounts of data?
Excited by greenfield projects?
Opportunity to train on new tech, stretching your boundaries and knowledge?
Responsibilities
Handle server-side development of a distributed Google applications
Develop data loading/ETL processes for Google Big Data Platform
Write clear, efficient, tested code.
Develop code as part of a wider team, contributing to code review and solution design.
Contribute to evolution of standards and design patterns.
Deploy and maintain applications in production environment.
Solve challenging technical problems within distributed environments
Work in a team using the Scrum/Kanban methodology ensuring that your team meets your backlog commitments.
Continuous improvement of the tools and processes used by the team.
Requirements
Experience with:
Strong Java experience (mainly Core Java)
Strong knowledge of OOP
SQL
Hands-on Google Cloud Platform: Dataflow, BigQuery, and Pub/Sub or Hadoop echosystem experience: Hbase, Hive, Spark.
Commercial experience with Linux.
Messagedriven architecture with experience using ActiveMQ/Kafka or similar
Track record of developing technology to enable large scale data transformation.
ETL data load process development
Experience dealing with large and/or complex data sets.
Development and Testing best practices
Maven, Git
Familiar with NoSQL technologies * Embrace agile software engineering practices and tools; TDD, Continuous Integration etc.
Understanding of software development lifecycle, Agile software design principles and build processes
Excellent organisation, communication and interpersonal skills
Ability to work both collaboratively and with limited supervision
Can deliver results within set deadlines
University degree in Computer Science, Computer Engineering or a related field
The company….
They want to be the World’s most entertaining online gaming company. Born in 2001 with just a handful of developers, we are now over 900 employees strong across 7 group offices worldwide with our headquarters in Central London. Over 24 million players enjoy our games, generating on average 10,000’s chat messages every hour! It started small but has grown into an award-winning team of designers, developers and operators behind several leading games and apps, an ethos of growth behind success, they are striving to grow and continue to lead market innovation.
Their commitment to using cutting edge technology, their talks at Code Mesh or simply their passion to innovate, thrill, and surprise, this business constantly pushes the boundaries to be the best in class.
Our culture is visible everywhere. Visit our reception - you’ll find sweets and our characters, in the design team a giant red lamp and the latest quad core mac pros; the breakout areas a pool table and fridges full of beer, wine and soft drinks. In the meeting rooms, you might find grass instead of carpet, in the summer you’ll meet all our families together for a celebration and in the winter you can find Mexican wrestlers or circus acts roaming around. Weekly social and sports events give you the opportunity to stretch both your mind and body whether it be getting involved in a meet up or brownbag session, playing in the poker tournament or joining one of the football teams. But our culture is not just in what you can see it's in everything we do, we're hard workers and we get stuck in. We have fun, making fun and our vision is to invent, play and discover together, to craft experiences that thrill our players and rock the world.
Job Type: Full-time
Salary: £70,000.00 to £80,000.00 /year
Required education:
Bachelor's
Required experience:
Java: 5 years
",https://www.indeed.co.uk/cmp/RG4Partners/jobs/Senior-Big-Data-Engineer-e642b8acaf3e0bb7
JOB269442325447,Data Engineer Sr,Data Engineer Sr,,"Leads in developing, supporting and implementing data solutions for multiple applications in order to meet business objectives and user requirements. Leverages technical knowledge and industry experience to design, build and maintain technology solutions.,Leads data requirement analysis and the data preparation process development for targeted data solutions.,Leads in designing and building data service infrastructure on multiple data platforms, according the workflow.,Oversees the development and implementation of data solutions for multiple applications to ensure its scalability, availability and maintainability.,CUSTOMER FOCUSED – Knowledgeable of the values and practices that align customer needs and satisfaction as primary considerations in all business decisions and able to leverage that information in creating customized customer solutions.","POSITION OVERVIEW
At PNC, our people are our greatest differentiator and competitive advantage in the markets we serve. We are all united in delivering the best experience for our customers. As a Data Architect Sr. within PNC’s Technology Asset Management organization, you will be based in Pittsburgh, PA, Cleveland, OH, and Philadelphia PA. This position will focus on PNC’s Big Data transformation within Asset Management Group. Successful candidates will have proven experience in Data Architecture, analytics, and large data technology to include Hadoop or similar tools. Candidates will be responsible for driving change with business partners and setting expectations. Azure and, amazon red shift
JOB PROFILE
Leads in developing, supporting and implementing data solutions for multiple applications in order to meet business objectives and user requirements. Leverages technical knowledge and industry experience to design, build and maintain technology solutions.
Leads data requirement analysis and the data preparation process development for targeted data solutions.
Leads in designing and building data service infrastructure on multiple data platforms, according the workflow.
Oversees the development and implementation of data solutions for multiple applications to ensure its scalability, availability and maintainability.
Consults on data migration and transformation to ensure the accuracy and security of data solutions.
PNC Employees take pride in our reputation and to continue building upon that we expect our employees to be:
CUSTOMER FOCUSED – Knowledgeable of the values and practices that align customer needs and satisfaction as primary considerations in all business decisions and able to leverage that information in creating customized customer solutions.
MANAGING RISK – Assessing and effectively managing all of the risks associated with their business objectives and activities to ensure they adhere to and support PNC’s Enterprise Risk Management Framework.
COMPETENCIES
Application Delivery Process – Knowledge of major tasks, deliverables, and formal application delivery methodologies; ability to utilize these in order to deliver new or enhanced applications.
Big Data Management and Analytics – Knowledge and ability to plan and execute, big data management and analytics.
Business Intelligence – Knowledge of and ability to utilize business processes and technologies for gathering, storing, analyzing, and providing access to data that helps the organization make better business decisions.
Consulting – Knowledge of techniques, roles, and responsibilities in providing technical or business guidance to clients, both internal and external; ability to apply this knowledge appropriately to diverse situations.
Data Analysis – Software – Knowledge of the investigation, evaluation, interpretation, and classification of data; the ability to identify, collect and analyze data to facilitate the development, implementation and application of software systems.
Data Architecture – Knowledge and ability to create models and standards to govern which data is collected, and how it is stored, arranged, integrated, and put to use in data systems and in organizations.
Database Structures – Knowledge of and the ability to utilize appropriate database structures to organize and store data in a particular manner.
Problem Solving – Knowledge of approaches, tools, techniques for recognizing, anticipating, and resolving organizational, operational or process problems; ability to apply this knowledge appropriately to diverse situations.
Software Development Life Cycle – Knowledge of and experience with using a structured methodology for delivering new or enhanced software products to the marketplace.
WORK EXPERIENCE
Roles at this level typically require a university / college degree, with 5+ years of industry-relevant experience. Specific certifications are often required. In lieu of a degree, a comparable combination of education and experience (including military service) may be considered.
EDUCATION
Bachelors
DISABILITY ACCOMMODATIONS STATEMENT
The PNC workplace is inclusive and supportive of individual needs. If you have a physical or other impairment that might require an accommodation, including technical assistance with the PNC Careers website or submission process, please call 877-968-7762 and select Option 4: Recruiting or contact us via email at pathfinder@pnc.com. The Human Resources Service Center hours of operation are Monday – Friday 9:00 AM to 5:00 PM ET.
EQUAL EMPLOYMENT OPPORTUNITY (EEO)
PNC provides equal employment opportunity to qualified persons regardless of race, color, sex, religion, national origin, age, sexual orientation, gender identity, disability, veteran status, or other categories protected by law.
Apply Now
",https://technical.ly/job/pnc-financial-services-data-engineer-sr-72920/
JOB270255322784,Data Engineering Lead/Lead Data Engineer,Data Engineering Lead/Lead Data Engineer,Travel,"Defining, building and delivering a data architecture to enable the vision of the business.,Building and implementing a data framework, that provides easy to access, clear and scalable databases/datawarehouses that will support data pipelines implemented by you in order to power machine learning capability and deliver Real Time business intelligence.,Integrating multiple, disparate data sources and unlocking data silos in the business thus i mproving the automation, frequency and quality of data collection from business assets and external sources via traditional ETL pipelines and/or APIs,Working in collaboration with the Chief Product Office r and business stakeholders to ensure timely delivery of the product roadmap, creating solutions that will perform at scale.,Providing information, feedback and mentorship to support technology-related decision making as required.,Keeping abreast of industry and technological developments in your field to ensure the architecture remains fit for purpose.,Proven experience of delivering data engineering projects, working with complex, unstructured, semi-structured and structured data. Any experience of spatial data and imagery would be a a plus but is not essential..,A track record in building and delivering data infrastructure & architecture for commercial, software solutions,A good understanding/experience of scaling eg the ability to devise, execute and maintain automated script testing, the ability to build and deploy on cloud infrastructure (or devise a scalable approach to Dev) and the ability to annotate and document to a level where others can work off your scripts, etc.,Experience of working with multiple, disparate sources of data (specific experience of working with Real Time and dynamic data from the likes of IoT sensors, vision technology and satellite data sets would be an advantage but is not essential).,The ability to implement best in class data integration routines including data validation and qualitative checks,Strong coding skills with Python, Java, Scala, C/C++, JavaScript SQL or similar.,Experience in building data driven applications for BI and intuitive consumer facing solutions/apps would be an advantage,Experience of owning the software development life cycle would be be an advantage,Competitive salary,Equity/Share options,Healthcare,Pension","Are you in a Data Engineering Lead or Lead Data Engineer role at present? Are you the type of person that is curious by nature and excited by a challenge? Does the idea of being in a role where you will be the point person on data structures, software and engineering appeal to you? If you're still reading then this could be the perfect role for you!
Agriculture is broken, my client is developing digital solutions to fight climate change, improve public health and ultimately save lives. The vision is to build a Climate Tech company that will redefine how agriculture and food supply chains are viewed globally. The company will drive and be focused on improving carbon sequestration whilst increasing product yields and nutritional quality. The next hire into the business will be the Data Engineering Lead/Lead Data Engineering and w e are looking for a highly ambitious and passionate individual with a keen interest in building solutions that can impact on global food systems, health and the environment. This is a rare and exciting opportunity where you will p lay a lead role as part of a team that is responsible for defining and delivering the software infrastructure.
As the Data Engineering Lead/Lead Data Engineer you will be responsible for creating a scalable architecture plan that will build the capability required for the coming years. Creating production ready code but also comfortable with delivering POCs as demos before entering production. You will guide and support decisions on which technologies, tools, practices and approaches will be best suited to the business working in closely with the Chief Product Officer. As the company grows you will have the opportunity to build a team around yourself and lead the data engineering and software engineering function. This is a hands-on role for somebody with proven experience developing commercially ready, scalable solutions.
What you will do;
Defining, building and delivering a data architecture to enable the vision of the business.
Building and implementing a data framework, that provides easy to access, clear and scalable databases/datawarehouses that will support data pipelines implemented by you in order to power machine learning capability and deliver Real Time business intelligence.
Integrating multiple, disparate data sources and unlocking data silos in the business thus i mproving the automation, frequency and quality of data collection from business assets and external sources via traditional ETL pipelines and/or APIs
Working in collaboration with the Chief Product Office r and business stakeholders to ensure timely delivery of the product roadmap, creating solutions that will perform at scale.
Providing information, feedback and mentorship to support technology-related decision making as required.
Keeping abreast of industry and technological developments in your field to ensure the architecture remains fit for purpose.
Skills and experience sought;
Proven experience of delivering data engineering projects, working with complex, unstructured, semi-structured and structured data. Any experience of spatial data and imagery would be a a plus but is not essential..
A track record in building and delivering data infrastructure & architecture for commercial, software solutions
A good understanding/experience of scaling eg the ability to devise, execute and maintain automated script testing, the ability to build and deploy on cloud infrastructure (or devise a scalable approach to Dev) and the ability to annotate and document to a level where others can work off your scripts, etc.
Experience of working with multiple, disparate sources of data (specific experience of working with Real Time and dynamic data from the likes of IoT sensors, vision technology and satellite data sets would be an advantage but is not essential).
The ability to implement best in class data integration routines including data validation and qualitative checks
Strong coding skills with Python, Java, Scala, C/C++, JavaScript SQL or similar.
Experience in building data driven applications for BI and intuitive consumer facing solutions/apps would be an advantage
Experience of owning the software development life cycle would be be an advantage
In Return:
Competitive salary
Equity/Share options
Healthcare
Pension
Travel
Commitment, enthusiasm and a good work ethic count for a lot with this company and it grows there will be opportunities for you to progress. I f you're excited by the chance to work towards changing the future of agricultural & climate tech then apply now with a current CV. Interviewing immediately!
","http://www.net-temps.com/gb/en/search-jobs-in-kent,-united-kingdom/data-engineering-lead-lead-data-engineer-dec585a7c235f4bcca/?utm_source=17&utm_medium=job&utm_content=1&utm_campaign=jobsearchlanding"
JOB271502607214,"29,428+ Remote Data Engineer Jobs","29,428+ Remote Data Engineer Jobs",,,"
What Does a Remote Data Engineer Do?
As a remote data engineer, you focus on collecting, storing, and organizing large amounts of information. You work from home to design, develop, and maintain systems for the mining, warehousing, and processing of data. A data engineer communicates with employers, clients, or other data professionals to assess the needs of the project and develop and implement solutions to meet those needs. Data engineers also take steps to manage current database architecture and make updates when needed. Remote engineers typically handle their responsibilities in a cloud-based environment using “big data” tools, such as Amazon Web Services (AWS) and SQL.
",https://www.ziprecruiter.com/Jobs/Remote-Data-Engineer
JOB271746161495,Data Engineer,Data Engineer,,,"
Data Engineer X 2 – Manchester. Our client based near Manchester are currently looking for 2 Data Engineers with Azure experience. The company is currently going through a large digital transformation, they are looking for talented Data specialist to help...
Job Title: Data Engineer Salary: 45,000 to 54,000 plus Benefits Location: Cambridge This is a very rare opportunity for an experienced Data Engineer with a strong background in building Python based data processing pipelines to join a company that are...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Data Engineer - 70,000 Job Description An AWS Partner based in Central London is looking to expand the data side of their business due to growth. They are looking for Data Engineers with significant commercial experience ingesting large quantities of data...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Job Title: Data Engineer Contract Length: Initial 3 Months (possible extension) Rate: Up to 250 per day Location: Chartres, France Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs...
Title: Data Engineer Our client is currently looking for a Data Engineer to play a vital role in the continual development of our digital transformation strategy and earth science analytics. Candidates must have Python, R and SQL. We expect candidates...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer - Manchester A growing business based in Manchester City Centre are currently looking for a Data Engineer to help shape their newly formed Data Engineering team and build scalable, reliable and secure cloud datawarehouse solutions and data...
Data Engineer - Python - Permanent Data Idols are working with a well-known client in the e-commerce space who are looking for a Data Engineer to join an existing team. THE ROLE As a Data Engineer, you will be working with the existing Data team to help...
An exciting start up Fintech company has a new opportunity for a Data Engineer where you will play an active part in the success of the company. This role will see you joining a small team where you'll have the opportunity to take responsibility for Data...
Job title : Data Engineer Location: London Job type: Permanent Salary: Up to 70,000 per annum Reporting to: Head of Data Engineering Overview A fantastic internet company based in Central London are currently looking for a Data Engineer to come on board...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data...
Data Engineer- 50K Manchester Adria Solutions has an exciting opportunity for a talented Data Engineer to join our rapidly expanding client based near Manchester. The role requires you to work closely with other members of the data team and stakeholders...
Data Engineer / Data Scientist / Biomedical Informatics / Human Genetics / Python / SQL / R / Oxford / Cambridge / Permanent 60 - 90K (Depending on Experience) Excellent Benefits COVID Safe Interview Process 100% Remote during Covid and up to 50% Post...
Data Engineer London 80,000 - 90,000 Benefits This Data Engineering role will allow you to expand and utilise your skills in a growing team working along side one of the largest data sets in the UK. The Company As a global leader they generate tons of...
Data Engineer (12-month Fixed Term Contract) 50,000 - 55,000 We are looking for a Data Engineer to join a market leading business we're representing, based in central London. Working as part of the central Data Science & Analytics team, you will be...
DATA ENGINEER - CURRENTLY REMOTE WORKING LEEDS - CURRENTLY REMOTE WORKING BETWEEN 35,000 - 50,000 BENEFITS BONUS Harnham are partnered with a Financial Services Company to help hire for a Data Engineer within their Business Intelligence team. The team...
DATA ENGINEER - CURRENTLY REMOTE WORKING LEEDS - CURRENTLY REMOTE WORKING BETWEEN 35,000 - 50,000 BENEFITS BONUS Harnham are partnered with a Financial Services Company to help hire for a Data Engineer within their Business Intelligence team. The team...
",https://www.reed.co.uk/jobs/data-engineer/40333281
JOB272010367140,Data Engineer,Data Engineer,,,"
","https://www.computerworld.dk/modules/job/morerandomjobs.php?op=list&start=3&limit=3&jobidsused=833670,814534,834610&layout=cwglassbox"
JOB272298737833,Lead Data Engineer,Lead Data Engineer,"Identify data sources that can add value to decision making.,Work with source system owners and analysts to understand source data, e.g. data profiling, definition and mapping.,Design and implement efficient data loads, using traditional structured data ETL techniques.,Design and implement real time and near real time data load solutions, using technologies like data streaming.,Design and implement unstructured data loads, e.g. text speech, images and video.,Design and implement load monitoring tools and procedures and perform continuous monitoring and optimising of loads.,Work with analysts and architect to design and implement effective and efficient data models using appropriate modelling techniques.,Design and implement data warehouse data models.,Design and implement data pipelines for ad hoc, unstructured and other data models.,Design and implement appropriate aggregation data structures that enhance usability of data, e.g. multi-dimensional OLAP structures, summary tables etc.,Design, implement and maintain appropriate indexing on tables to enhance speed of access.,Design and implement data models that support automated decision making and/or further analytics.,Continuously search for data elements from other sources to enhance existing data objects to supplement / enhance context.,Design and implement interfaces for data access, e.g. batch exports, real-time decision API’s etc.,Design and implement interface monitoring and management solutions to ensure availability and accuracy.,Design and implement data monitoring solutions and procedures and continuously monitor and maintain integrity of existing environment, troubleshoot technical and data issues and make appropriate changes where required.,Design and implement meta-data solutions that assist with understanding and managing data.,Work together with business owners, analysts and IT to maintain good data governance.,Work together with business owners, analysts and IT to manage changes to data in the organisation.,Provide technical and data related support to source system teams and external parties with whom we exchange data.,Manage data growth and usage by implementing effective strategies, e.g. archiving and indexing.,Manage systems, technology and tools that enable data management and analytics and liaise with IT infrastructure and IT Operations regarding system and infrastructure management.,Take ownership of own work by delivering high quality work on time.,Show initiative and be pre-active in finding opportunities to improve data and/or processes.,Take ownership of own career development by continuously improving skills, knowledge and the application thereof in designing and implementing solutions.,Positive engagement in team activities and actively contribute ideas to improve team dynamics and performance.,Complex solution and service design and implementation.,Cross functional data and team knowledge gathering and sharing.,Responsible for team activities, team dynamics and performance.,Manage project and task delivery of team.,Multiple stakeholder management (internal and external).,Assist in development of others, e.g. mentoring and knowledge share.,Quality control of other’s work.,Degree in information technology/engineering/mathematics/statistics/actuarial or related discipline,At least 8 years’ experience working in a data, business intelligence or analytics environment,SQL,Data analysis,Data visualisation,Data modelling,Microsoft business intelligence data technologies (SSIS, SSAS, SQL Server),Data warehouse concepts and best practices,Information gathering and problem analysis,Applying professional / specialist / technical expertise,Creating and innovating,Quality & Detail orientation,Planning and organizing,Presenting and Communicating information,Analysing,Leadership",,"Job description
Capfin is a leading unsecured loan provider with a successful business model supported by great people with a strong culture of innovation and data driven decision making. The purpose of this role is to create business value by leading a team that apply data engineering and data management disciplines to design and build data solutions that enable data driven decision support, in order to optimize business decisions and processes.
Requirements
Key Performance Areas:
Sourcing data
Identify data sources that can add value to decision making.
Work with source system owners and analysts to understand source data, e.g. data profiling, definition and mapping.
Loading data
Design and implement efficient data loads, using traditional structured data ETL techniques.
Design and implement real time and near real time data load solutions, using technologies like data streaming.
Design and implement unstructured data loads, e.g. text speech, images and video.
Design and implement load monitoring tools and procedures and perform continuous monitoring and optimising of loads.
Storing data
Work with analysts and architect to design and implement effective and efficient data models using appropriate modelling techniques.
Design and implement data warehouse data models.
Design and implement data pipelines for ad hoc, unstructured and other data models.
Enhancing data
Design and implement appropriate aggregation data structures that enhance usability of data, e.g. multi-dimensional OLAP structures, summary tables etc.
Design, implement and maintain appropriate indexing on tables to enhance speed of access.
Design and implement data models that support automated decision making and/or further analytics.
Continuously search for data elements from other sources to enhance existing data objects to supplement / enhance context.
Making data available
Design and implement interfaces for data access, e.g. batch exports, real-time decision API’s etc.
Design and implement interface monitoring and management solutions to ensure availability and accuracy.
Managing data
Design and implement data monitoring solutions and procedures and continuously monitor and maintain integrity of existing environment, troubleshoot technical and data issues and make appropriate changes where required.
Design and implement meta-data solutions that assist with understanding and managing data.
Work together with business owners, analysts and IT to maintain good data governance.
Work together with business owners, analysts and IT to manage changes to data in the organisation.
Provide technical and data related support to source system teams and external parties with whom we exchange data.
Manage data growth and usage by implementing effective strategies, e.g. archiving and indexing.
Manage systems, technology and tools that enable data management and analytics and liaise with IT infrastructure and IT Operations regarding system and infrastructure management.
Leadership responsibilities
Take ownership of own work by delivering high quality work on time.
Show initiative and be pre-active in finding opportunities to improve data and/or processes.
Take ownership of own career development by continuously improving skills, knowledge and the application thereof in designing and implementing solutions.
Positive engagement in team activities and actively contribute ideas to improve team dynamics and performance.
Complex solution and service design and implementation.
Cross functional data and team knowledge gathering and sharing.
Responsible for team activities, team dynamics and performance.
Manage project and task delivery of team.
Multiple stakeholder management (internal and external).
Assist in development of others, e.g. mentoring and knowledge share.
Quality control of other’s work.
Qualifications:
Degree in information technology/engineering/mathematics/statistics/actuarial or related discipline
Experience:
At least 8 years’ experience working in a data, business intelligence or analytics environment
Functional Competencies:
SQL
Data analysis
Data visualisation
Data modelling
Microsoft business intelligence data technologies (SSIS, SSAS, SQL Server)
Data warehouse concepts and best practices
Behavioural Competencies:
Information gathering and problem analysis
Applying professional / specialist / technical expertise
Creating and innovating
Quality & Detail orientation
Planning and organizing
Presenting and Communicating information
Analysing
Leadership
The closing date for applications is 9 July 2019.
Posted on 25 Jun 13:32
",https://www.bizcommunity.com/Job/196/594/369014.html
JOB273730276695,Data Engineer,Data Engineer,,,"
The data engineer will translate business needs into specifications, evaluate business systems, help oversee testing activities, & create work plans. Requires advanced SQL skills & at least five years' system analysis exp. Telecommuting considered.
",https://www.flexjobs.com/publicjobs/data-engineer-1184534
JOB274241736006,Senior Data Engineer,Senior Data Engineer,,"Hand-screened leads,No ads, scams, junk,Great job search support,50+ career categories","
Senior Data Engineer
Remote role during pandemic. Candidate will design and maintain a data warehouse that supports a rapidly evolving product and oversee reporting pipelines that organize terabytes of data. Must have 6+ years of experience in backend engineering.
Job Details
10/20/20
Remote - During Pandemic
San Francisco, CA, Oakland, CA, San Jose, CA
Employee
Full-Time
Experienced
No specification
Company name here
Other benefits listed here
Hand-screened leads
No ads, scams, junk
Great job search support
50+ career categories
Create an Account to Unlock
To find out more about or apply to this Senior Data Engineer job—and other great opportunities like it—become a FlexJobs member today!
With FlexJobs, you'll find the best flexible jobs and fantastic expert resources to support you in your job search. If you have any questions, please feel free to contact us.
Get new job postings, the latest job search tips, trends, news, and exclusive promotions!
",https://www.flexjobs.com/publicjobs/senior-data-engineer-1311319
JOB1328127880,Data Engineer - R&D,Data Engineer - R&D,"An open office environment where ideas flow among marketers and developers, product managers and support reps, who sit shoulder-to-shoulder collaborating and challenging and encouraging each other.","Work as an integral member of our Research & Development team.,Collaborate with our cross-functional team to define, architect, and implement highly scalable solutions.,Participate in an innovative Lean product development process, where you get to influence what you work on every week and flex into new skill sets.,Heavily influence technical product roadmap and implementation direction.,Build, deploy and support data-intensive applications in a multi-tier, high availability, distributed cloud-computing environment.,A minimum of 3 years relevant experience.,A proven track record of technical team leadership.,Polyglot with an attitude of flexibility and a pragmatic approach towards business solutions.,Solid experience dealing with large quantities of data across relational databases, cloud storage, and distributed compute systems.,Existing familiarity or interest in developing Machine Learning Engineering skills,A solid understanding of TDD approaches and automated testing concepts,Experience with concurrency and RESTful web services,Excitement about influencing the direction of the product,Ability to consider the big picture as just as important as your technical skills,Data stack,Postgresql,S3 + Parquet,Spark,Airflow,Redshift,Looker,Spectrum / Athena,AWS (EC2, RDS, Lambdas),Docker,Microservices,AWS ECS, Fargate, EKS,Jenkins,Programming languages,Python,Scala,Java,JavaScript / Node,Important libraries,React,PySpark,Health, dental, and vision insurance with a generous employer contribution;,An innovative and flexible paid time off policy;,A generous stock options plan and a 401(k) plan;,A kitchen stocked with breakfast and lunch food, coffee, sodas, snacks, and adult beverages;","
Description
Are you ready to join a software team whose work is revolutionizing the way consumers interact with and use energy? If you love building highly scalable, distributed systems and helping to grow a successful business, then Tendril might be the place for you.
Tendril’s Research and Development (R&D) team is rapidly bringing innovative, new products and features to market focused on energy efficiency, consumer engagement, and analytics. We have established a cross-functional product development team made up of passionate Software Engineers, Data Scientists/Engineers, Product and Creative professionals, and need to add another experienced Data Engineer to our team.
As a member of the R&D team, you will be working from our Boulder, CO office, architecting and building software on our modern, cloud-based technology stack. You’re a motivated, skilled technical leader who loves to work with big data, write high-quality testable code, and practice the craft of software development. You enjoy bringing new products to market - whether you’re building a quick prototype or architecting an elegant, scalable system.
What You’ll Do
Work as an integral member of our Research & Development team.
Collaborate with our cross-functional team to define, architect, and implement highly scalable solutions.
Participate in an innovative Lean product development process, where you get to influence what you work on every week and flex into new skill sets.
Heavily influence technical product roadmap and implementation direction.
Build, deploy and support data-intensive applications in a multi-tier, high availability, distributed cloud-computing environment.
What You Bring To Tendril
A minimum of 3 years relevant experience.
A proven track record of technical team leadership.
Polyglot with an attitude of flexibility and a pragmatic approach towards business solutions.
Solid experience dealing with large quantities of data across relational databases, cloud storage, and distributed compute systems.
Existing familiarity or interest in developing Machine Learning Engineering skills
A solid understanding of TDD approaches and automated testing concepts
Experience with concurrency and RESTful web services
Excitement about influencing the direction of the product
Ability to consider the big picture as just as important as your technical skills
Technologies We Use
Data stack
Postgresql
S3 + Parquet
Spark
Airflow
Redshift
Looker
Spectrum / Athena
Cloud Environment
AWS (EC2, RDS, Lambdas)
Docker
Microservices
AWS ECS, Fargate, EKS
Jenkins
Programming languages
Python
Scala
Java
JavaScript / Node
Important libraries
React
PySpark
If this sounds like you, let’s talk.
What Makes Working at Tendril Awesome
Tendril’s high energy, sometimes silly, fast-paced work environment will keep you engaged, motivated, and well fed. Work-life balance is a core priority at Tendril. We work hard and we play hard and often the two overlap. We love our dogs and bring them to work with us. We host family events and adult parties. We contribute to the community, we volunteer, and we mentor. Plus, we offer a ton of great benefits, including:
Health, dental, and vision insurance with a generous employer contribution;
An innovative and flexible paid time off policy;
A generous stock options plan and a 401(k) plan;
A kitchen stocked with breakfast and lunch food, coffee, sodas, snacks, and adult beverages;
An open office environment where ideas flow among marketers and developers, product managers and support reps, who sit shoulder-to-shoulder collaborating and challenging and encouraging each other.
",https://www.builtincolorado.com/job/data/data-engineer-rd/43132
JOB2865318906,Scientific Data Engineer,Scientific Data Engineer,,"Responsibility for the handling, processing and integration of data into the ChEMBL database.,Facilitating the deposition of datasets directly into ChEMBL by working closely with external collaborators.,Applying text- & data-mining techniques for the development of effective large-scale curation strategies.,Developing methods for the application and maintenance of ontologies in ChEMBL.,Working with other teams to facilitate the integration of data between different EBI resources.,A BSc (or equivalent) in a life-science subject (e.g. biological or biomedical sciences).,3+ years of postgraduate experience in scientific data integration, database development or text- & data-mining, with a demonstrable track record of achievement.,Proficient in at least one programming/scripting language (Python knowledge is highly desirable).,Good knowledge of relational databases, data modelling, SQL and PL/SQL, and RESTful web-services.,Good understanding of a range of bioinformatics tools and resources (e.g., BLAST, Pfam, PDB, UniProt).,Experience in integrating diverse data sets.,Knowledge of good practice in software engineering and good code documentation.,Good knowledge of UNIX systems.,Team player, ability to work both as part of a team and independently.,Self-motivated with a driver for quality.,Good communication (verbal and presentational).,Higher degree (e.g., MSc/PhD) or equivalent in life-sciences, computer science, or related discipline.,Formal training in programming, data/entity-relationship modeling, text- & data-mining.,Familiarity with Python, Java and Perl.,Knowledge of drug discovery and development.,Experience working with chemogenomic and pharmaceutical data.,Knowledge of cheminformatics methods (e.g., chemical structure representations, substructure & similarity searching).,Apply now"," Scientific Data Engineer
Location: EMBL-EBI, Hinxton near Cambridge, UK
Staff Category: Staff Member
Contract Duration: 3 years
Grading: 5 or 6 (monthly salary starting at £2,632 or £2,944.48 after tax).
Closing Date: 23 September 2018
Reference Number: EBI01278
The ChEMBL Team at the European Bioinformatics Institute (EMBL-EBI) is looking for a talented Scientist with a passion for data integration to manage the incorporation of drug discovery data into the ChEMBL database. ChEMBL is a world-leading chemogenomics resource, providing open bioactivity data and associated tools to the scientific community. We have a considerable number of users from academia and industry. You will work in a team-oriented environment, collaborating closely with fellow scientists and technical experts, chemo- and bio-informaticians and software engineers across EMBL-EBI and with our many external partners from the UK and internationally. You will contribute to the development of robust, production data pipelines as well as prototyping novel scientific solutions. You will have excellent communication skills, able to interact with technical experts as well as scientists seeking solutions to their ""real world"" problems.
Your role
Reporting to the ChEMBL team leader, the job responsibilities will include:
Responsibility for the handling, processing and integration of data into the ChEMBL database.
Facilitating the deposition of datasets directly into ChEMBL by working closely with external collaborators.
Applying text- & data-mining techniques for the development of effective large-scale curation strategies.
Developing methods for the application and maintenance of ontologies in ChEMBL.
Working with other teams to facilitate the integration of data between different EBI resources.
You have
A BSc (or equivalent) in a life-science subject (e.g. biological or biomedical sciences).
3+ years of postgraduate experience in scientific data integration, database development or text- & data-mining, with a demonstrable track record of achievement.
Proficient in at least one programming/scripting language (Python knowledge is highly desirable).
Good knowledge of relational databases, data modelling, SQL and PL/SQL, and RESTful web-services.
Good understanding of a range of bioinformatics tools and resources (e.g., BLAST, Pfam, PDB, UniProt).
Experience in integrating diverse data sets.
Knowledge of good practice in software engineering and good code documentation.
Good knowledge of UNIX systems.
Team player, ability to work both as part of a team and independently.
Self-motivated with a driver for quality.
Good communication (verbal and presentational).
You might also have
Higher degree (e.g., MSc/PhD) or equivalent in life-sciences, computer science, or related discipline.
Formal training in programming, data/entity-relationship modeling, text- & data-mining.
Familiarity with Python, Java and Perl.
Knowledge of drug discovery and development.
Experience working with chemogenomic and pharmaceutical data.
Knowledge of cheminformatics methods (e.g., chemical structure representations, substructure & similarity searching).
Why join us
At EMBL-EBI, we help scientists realise the potential of ‘big data’ in biology by enabling them to exploit complex information to make discoveries that benefit mankind. Working for EMBL-EBI gives you an opportunity to apply your skills and energy for the greater good. As part of the European Molecular Biology Laboratory (EMBL), we are a non-profit, intergovernmental organisation funded by 22 member states and two associate member states. We are located on the Wellcome Genome Campus near Cambridge in the UK, and our 600 staff are engineers, technicians, scientists and other professionals from all over the world.
EMBL is an inclusive, equal opportunity employer offering attractive conditions and benefits appropriate to an international research organisation. The remuneration package comprises a competitive salary, a comprehensive pension scheme and health insurance, educational and other family related benefits where applicable, as well as financial support for relocation and installation. For more information about pay and benefits click here
We have an informal culture, international working environment and excellent professional development opportunities but one of the really amazing things about us is the concentration of technical and scientific expertise – something you probably won’t find anywhere else.
If you’ve ever visited the campus you’ll have experienced first-hand our friendly, collegial and supportive atmosphere, set in the beautiful Cambridgeshire countryside. Our staff also enjoy excellent sports facilities including a gym, a free shuttle bus, an on-site nursery, cafés and restaurant and a library.
What else do I need to know
To apply please submit a covering letter and CV, with two referees, through our online system.
Applications are welcome from all nationalities - visa information will be discussed in more depth with applicants selected for interview.
EMBL-EBI is committed to achieving gender balance and strongly encourages applications from women, who are currently under-represented at all levels. Appointment will be based on merit alone.
The initial contract is for a period of three years with the possibility of a fixed-term extension.
Applications will close at 23:00 BST on the date listed above. More Software Development and Engineering jobs
Apply now
",https://jobs.newscientist.com/job/1401652831/scientific-data-engineer/
JOB8890169726,Data Engineer (Analytics),Data Engineer (Analytics),,"Analyse complex business-rules and data to maximise simplification and repeatability for end-users.,Use relevant techniques and expertise in data modelling and database design to integrate structured and unstructured data from internal and external data sources to maximise usability and discoverability for self-service analytics and data science activities.,Ensure that best practise is adopted to maximise agility and responsiveness whilst maintaining appropriate levels of governance and adherence to GDPR.,Provide guidance and consultancy to projects that use internal data, working with both specialists and senior stakeholders, as required.,Keenness to learn new things and apply them in a practical way.,An enjoyment working independently but comfortable asking for support when appropriate.,An analytical and creative approach to problem solving.,Strong data integration skills focussing on business outcomes, ideally using Alteryx.,Logical and methodical approach to solving problems.,Experience of working with complex data where stakeholders have differing requirements from the same data.,An understanding of GDPR when working with data.,Business/data analysis.,Maintenance of documentation & processes.,Data integration using Alteryx.,SQL server.,Data modelling for self-service analytics.,Data governance/data quality/master data management.,Excellent analytical skills.,Excellent attention to detail.,Proven ability to interpret and translate source data alongside business requirements to create data models that are optimised for self-service analytics.,Flexibility and a proven customer focus.,Excellent communication skills and an ability to work effectively both as part of a team and within a wider matrix structure.,Ability to manage competing priorities whilst working to deadlines.","
Are you an experienced data engineer looking to join a highly motivated and innovative team working to democratise data and to roll-out self-service analytics?
Do you have data integration and data warehouse experience?
Are you familiar with data architectures that are optimised for self-service analytics?
We're currently hiring for a Data Engineer to join our Data & Innovation team.
Additional info
To succeed in this role, you will be a technical specialist who can:
Analyse complex business-rules and data to maximise simplification and repeatability for end-users.
Use relevant techniques and expertise in data modelling and database design to integrate structured and unstructured data from internal and external data sources to maximise usability and discoverability for self-service analytics and data science activities.
Ensure that best practise is adopted to maximise agility and responsiveness whilst maintaining appropriate levels of governance and adherence to GDPR.
Provide guidance and consultancy to projects that use internal data, working with both specialists and senior stakeholders, as required.
See full job description [Link]
Experience & Skills
To succeed in this role, you'll need to have:
Keenness to learn new things and apply them in a practical way.
An enjoyment working independently but comfortable asking for support when appropriate.
An analytical and creative approach to problem solving.
Background / Experience:
Essential
Strong data integration skills focussing on business outcomes, ideally using Alteryx.
Logical and methodical approach to solving problems.
Experience of working with complex data where stakeholders have differing requirements from the same data.
An understanding of GDPR when working with data.
Business/data analysis.
Maintenance of documentation & processes.
Desirable
Data integration using Alteryx.
SQL server.
Data modelling for self-service analytics.
Data governance/data quality/master data management.
Skills:
Excellent analytical skills.
Excellent attention to detail.
Proven ability to interpret and translate source data alongside business requirements to create data models that are optimised for self-service analytics.
Flexibility and a proven customer focus.
Excellent communication skills and an ability to work effectively both as part of a team and within a wider matrix structure.
Ability to manage competing priorities whilst working to deadlines.
Education & Qualifications
Desirable: degree level or equivalent professional qualifications.
Appointment Type
Permanent
Division
",https://jobs.theguardian.com/job/6829337/data-engineer-analytics-/
JOB10986714951,Data Engineer,Data Engineer,"Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.,Several years of experience building and optimizing data pipelines, architectures and data sets.,Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.,Strong analytic skills related to working with unstructured datasets.,Build processes supporting data transformation, data structures, metadata, dependency and workload management.,Working knowledge of message queuing, stream processing, and highly scalable data stores.,Experience leading cross-functional teams in a dynamic environment.,Experience using the following software/tools:,5+ years Experience with big data tools: Hadoop, Spark, Kafka, etc.,5+ years Experience with relational SQL and NoSQL databases, including Postgres.,Experience with data pipeline and workflow management tools.,5+ years Experience with AWS cloud services: EC2, EMR, RDS, Redshift.,Experience with stream-processing systems.,A comprehensive medical/dental/vision package provided through Empire Blue Cross Blue Shield. Life and disability insurance are also included.,Enrollment in our 401K plans. Once you are enrolled in the plan, you can change your contributions rate or opt out at any time.,Stock option program.,Eight company paid holidays for the 2019 calendar year. Paid time off (PTO) is uncapped, should it be in accordance with the Company’s policy, which will be outlined during New Hire Orientation.","Lead the creation and maintenance optimal data pipeline architecture.,Assemble complex data sets that meet functional / non-functional business requirements.,Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.,Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS technologies.,Work with stakeholders including the Executive, Product, and Business Intelligence to assist with data-related technical issues and support their data infrastructure needs.","Founded in 2015, Even Financial, a NYC based FinTech company, is the leading search, comparison and recommendation engine for financial services. Leveraging Big Data and Machine Learning, Even partners with the top financial institutions and channel partners (e.g. TransUnion, The Penny Hoarder, MoneyUnder30, Empower, Tally) to surface the richest, most comprehensive list of personalized financial services for consumers (including loans, life insurance, credit cards, deposits and more), utilizing its robust yet simple API. Even is proven to lower the cost of acquisition, improve monetization, monitor compliance and deliver transparency at scale.
The Even platform serves as a trusted intermediary for financial institutions – including Prosper, LendingClub, and Marcus by Goldman Sachs – that finds consumers through its vast network of channel partners and distributes their products digitally.
We are looking for a strong senior data engineer who will play a key leadership role in expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams.
Responsibilities:
Lead the creation and maintenance optimal data pipeline architecture.
Assemble complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS technologies.
Work with stakeholders including the Executive, Product, and Business Intelligence to assist with data-related technical issues and support their data infrastructure needs.
Work with data and analytics experts to strive for greater functionality in our data systems.
Qualifications:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Several years of experience building and optimizing data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
Working knowledge of message queuing, stream processing, and highly scalable data stores.
Experience leading cross-functional teams in a dynamic environment.
Experience using the following software/tools:
5+ years Experience with big data tools: Hadoop, Spark, Kafka, etc.
5+ years Experience with relational SQL and NoSQL databases, including Postgres.
Experience with data pipeline and workflow management tools.
5+ years Experience with AWS cloud services: EC2, EMR, RDS, Redshift.
Experience with stream-processing systems.
Expertise with Scala considered a strong plus.
Full time employees are eligible for the following benefits:
A comprehensive medical/dental/vision package provided through Empire Blue Cross Blue Shield. Life and disability insurance are also included.
Enrollment in our 401K plans. Once you are enrolled in the plan, you can change your contributions rate or opt out at any time.
Stock option program.
Eight company paid holidays for the 2019 calendar year. Paid time off (PTO) is uncapped, should it be in accordance with the Company’s policy, which will be outlined during New Hire Orientation.
A subsidized gym membership with ClassPass.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.
",https://jobs.lever.co/evenfinancial/ff71997a-1584-428a-9612-1f99296c9678
JOB12630236275,Data Engineer (Big Data),Data Engineer (Big Data),,,"
Title: Data Engineer (Big Data)
Clearance: TS/SCI
Work Location: Quantico, VA
Responsibilities
• Support the Marine Corps Intelligence Activity (MCIA) Weapons and Technology Division (WTD) in Science & Technology Intelligence (S&TI) analysis of foreign basic and applied research and engineering, prototyping, technology transfer, developmental and operational testing military fielding and Integration of technologies
• Conduct S&TI research, analysis and produce finished (S&TI) assessments on information systems and emerging and disruptive technologies (E&DT) that will likely affect US Marine Corps operations.
Minimum Requirements
Required Experience
• STEM degree related to labor cat subject matter
• 3 years experience performing S&TI analysis or waivered with a demonstrated proficiency in analyzing, summarizing, and writing. MCIA will provide guidance for a writing sample related to the topic area
Desired Requirements
• Working knowledge of S&TI within the DoD including S&TI production centers and responsibilities
Mission Essential considers all applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status. Mission Essential is an EEO/AA employer and a VEVRAA Federal Contractor. Read our Privacy Policy
",https://www.clearancejobs.com/jobs/2927710/data-engineer-big-data
JOB17353039748,Senior Data Engineer,Senior Data Engineer,"Robust Perks – generous PTO, 401k contributions, tuition assistance, entertainment discounts and more!","Participate in the collaborative design and development of specialized data structures for the purpose of data consumption by a public facing website,Develop a data management framework that is effective, scalable and reliable,Be the subject matter expert for consumption layer data, providing guidance to teams on best practices, capabilities and limitations,Research and prototype new technologies,Oversee data transformation, normalization, cleansing, aggregation, workflow management and business rule application,Load, process and manage incoming data feeds,Contribute to the development of architectural roadmaps and perform periodic reviews to identify improvement opportunities.,Enable integration and deployment tools and methods for managing reliable development life cycle routines,Experience developing and deploying data applications using Open Source frameworks like Spark, Kafka, AWS S3, StreamSets and Redis,Data modeling and corporate-level data management experience,Familiarity of Relational Database Management Systems,Fluency in several programming languages such as Python, Scala or Java,SQL Programming / ETL and data architecture management experience,Define and manage critical data using Master Data Management solutions,Ability to perform Unit Tests and internal QA checks,Good collaboration and idea sharing in a team environment,A Bachelor’s Degree in Computer Science or related field preferred,Previous experience with Microsoft SQL Server is a plus,Meaningful Work – Connecting Americans with their healthcare providers,Changing the Game – evolving culture with career advancement opportunities,Community Builders – partnering with local charity and wellness initiatives","
As a Senior Data Engineer on our Provider Data as a Service team, you will develop and maintain database functionality to support corporate products and services. Primarily, your focus will be on mastering healthcare provider data for display on the Healthgrades.com website. You will collaborate with cross-functional database and product development teams using Agile / Scrum, Open Source and Microsoft technologies.
In your role, you will implement database technologies and development processes to support development of an Enterprise Data Platform that is changing the game. On this product, we are currently transitioning our Microsoft technology stacks to other Open Source technologies so experience with Scala, Spark SQL, Python, StreamSets, Reltio, AWS S3, Kafka and Redis is preferred. If you are interested in growing your expertise in these technologies, this will be an exciting opportunity for you.
What you will do:
Participate in the collaborative design and development of specialized data structures for the purpose of data consumption by a public facing website
Develop a data management framework that is effective, scalable and reliable
Be the subject matter expert for consumption layer data, providing guidance to teams on best practices, capabilities and limitations
Research and prototype new technologies
Oversee data transformation, normalization, cleansing, aggregation, workflow management and business rule application
Load, process and manage incoming data feeds
Contribute to the development of architectural roadmaps and perform periodic reviews to identify improvement opportunities.
Enable integration and deployment tools and methods for managing reliable development life cycle routines
What you will bring:
Experience developing and deploying data applications using Open Source frameworks like Spark, Kafka, AWS S3, StreamSets and Redis
Data modeling and corporate-level data management experience
Familiarity of Relational Database Management Systems
Fluency in several programming languages such as Python, Scala or Java
SQL Programming / ETL and data architecture management experience
Define and manage critical data using Master Data Management solutions
Ability to perform Unit Tests and internal QA checks
Good collaboration and idea sharing in a team environment
A Bachelor’s Degree in Computer Science or related field preferred
Previous experience with Microsoft SQL Server is a plus
Why Healthgrades?
At Healthgrades, we recognize that our people drive our greatest achievements. We are passionate about maintaining a fulfilling, rewarding and energetic work environment while setting the stage for continued success.
Meaningful Work – Connecting Americans with their healthcare providers
Changing the Game – evolving culture with career advancement opportunities
Community Builders – partnering with local charity and wellness initiatives
Robust Perks – generous PTO, 401k contributions, tuition assistance, entertainment discounts and more!
",https://www.builtincolorado.com/job/data/senior-data-engineer/39121
JOB18852879436,Specialized Software/Data Engineer,Specialized Software/Data Engineer,,,"
Specialized Software/Data Engineer
This team member shall have responsibility for customizing an Earned Value software package chosen by DCMA. He or she should have familiarity in Earned Value software packages or have experience with integrating other software packages of similar complexity or capabilities. He or she should be able to work closely with the DCMA SMEs as well as any vendor support provided.
JOB DESCRIPTION/SKILLS
NES is seeking an experienced and highly motivated Specialized Software/Data Engineer to join our Digital Services Team and work on the Earned Value Analytics System (EVAS) project. As a SS/DE, you will play a lead role in the configuration effort of the COTS software that DCMA will procure.
Primary Duties
+ Customize the COTS software
+ Build whatever ancillary tools are needed to ensure that the COTS software fulfils the needs of DCMA.
+ Interface with the rest of the team
Required Skills
+ The candidate must have a strong understanding of earned value and project schedule principles
+ Software
+ Microsoft Office and SharePoint environments (2010/2013/2016)
+ Strong familiarity with the COTS program, or other similar software packages.
Communication
+ Excellent written and oral communication skills, and ability to communicate effectively across various functions and roles within the organization (cross-functional teams)
Independent
+ A self-starter, driven, strong relationship builder, passionate about learning and making a difference
+ Strong service delivery mindset
+ Ability to work independently
+ Ability to demonstrate quality customer service, following an issue from identification to resolution
Details
+ Quick learner and good analytic thought process
Pace
+ Can achieve completion of multiple tasks in a fast-paced professional IT office environment and quickly adapt to a change in priorities (working well under pressure)
+ Ability to manage multiple deadlines
Required Experience
Successful candidate will have an understanding and knowledge base in project management, XML, SQL, and software development
+ Minimum of a Bachelor's Degree in Computer Science or a related field
+ 5+ Years of hands-on experience working with project management standards and solutions
+ Customer service experience desired
+ The selected candidate must be able to obtain a position of public trust
Tracking Code: 1045-677
",https://www.clearancejobs.com/jobs/2256615/specialized-softwaredata-engineer
JOB19756047484,Cloud Data Engineer,Cloud Data Engineer,,,"
Cloud Data Engineer
Job Duties and Responsibilities
ManTech is seeking an experienced Cloud Data Engineer to support a customer in Springfield, VA. The Cloud Data Engineer will perform one or more of the following tasks in support of computer database administration: architects, designs, oversee the development of, or administers computerized databases, installs the applicable databases onto the appropriate computer operating systems, creates databases, configure databases (for a data warehousing application), use import utilities to install databases. Includes creation of Indexes, Clusters, Snapshots, Views, and other database objects, as well as, management of Rollback Segments, Data File Size, and all the other aspects related to the performance tuning of databases. Write code for update queries, update data dictionaries as new fields are added to the database, and maintain a data correction log. Create and maintain data correction logs that identify the date the correction that was performed, tables and fields effected, submission effected, error code effected, and other pertinent metadata. Expand and update the data dictionary for the database and any related applications.
· Must possess a Bachelor’s Degree and 8 years of experience.
· Experience with the overall data requirements, data models, and the design of the databases and data integration solutions.
· Experience with designing and implementing AWS storage solutions which include S3, Glacier, Snowball, Import/Export.
· Experience in the migration of data to the cloud.
· Experience in the separation of data from logic.
Preferred:
· Experience with internal and external data sources.
· Experience with developing a plan for integrating, centralizing and maintaining all the data.
· Experience with data pipeline services.
· Experience with how the data relates to the current operations.
· Experience with the effect that proposed process changes will have on the use of data in the organization.
· Experience with how a logical design will translate into one or more physical Databases, and how the data will flow through the successive stages involved.
· Experience with database design (relational and NoSQL), data modeling, developing strategies for master data management, data integration, data organization and storage, backup, archive and recovery.
· Knowledge of Department of Defense Architecture Framework (DoDAF) or similar architecture frameworks are desirable for documentation.
Clearance:
Qualifications
A Bachelor degree or equivalent in a related field and ten to twelve years of relevant work experience are required.
Overview
ManTech International Corporation is comprised of approximately 7,300 talented employees who use advanced technology to help government and industry meet some of their greatest challenges around the world. We adhere to the simple, no-nonsense values on which ManTech was founded more than four decades ago, aligning squarely with the mission objectives of our customers. As our customer base continues to expand and diversify, we continue to diversify our workforce and solutions. Nearly half our employees have a military background, and approximately 70 percent hold a government security clearance. As a leading provider of innovative technology services and solutions for the nation's defense, security, health, space, and intelligence communities; we hold nearly 1,100 active contracts with more than 50 different government agencies.
",https://www.clearancejobs.com/jobs/2485178/cloud-data-engineer
JOB21544908611,Data Engineer,Data Engineer,,"Build and automate reliable data pipelines using batch and streaming technologies,Design and test ETL systems using the latest technologies,Collaborate with other software engineers and data scientists to develop data driven applications,Excellent communication and collaboration skills,Coding proficiency in at least one of Java, Python, C++, Go, Scala,Strong computer science skills with a focus on algorithms and data structures,Experience querying data using SQL and/or NoSQL,Familiar with MapReduce and other big data concepts,Understand trade offs among data formats such as CSV, JSON, Avro, Parquet,Experience with stream processing technologies such as Apache Beam, Spark Streaming, Flink, Kafka Streams,ETL experience on AWS using EMR, Firehose, Lambda,ETL experience on Google Cloud using Dataproc, Cloud Functions, Dataflow,Experience using a data warehouse such as Redshift or BigQuery,Familiar with messaging systems such as Kinesis, Kafka, PubSub,Competitive base salary plus meaningful equity,Comprehensive benefits (Medical, Dental, Vision, 401k),Daily catered lunches,Dog friendly office","Tradesy is a peer-to-peer marketplace for women’s designer fashion that’s pioneering a sustainable future for commerce. Backed by top tier venture capital firms, our mission is to make the resale of consumer goods as simple, safe, and stylish as retail, at scale. We have millions of passionate members, a product that people love, and an office with an ocean view in sunny Santa Monica, California.
Tradesy is seeking an exceptionally talented Data Engineer who works closely with other engineers, data scientists, architects and product owners to develop reliable, efficient, and scalable systems.
We are also migrating our systems, data warehouse and data pipelines to Google Cloud to take advantage of Google’s cutting edge technologies like BigQuery, Pub/Sub and Dataproc. We're already leveraging the power of BigQuery and Google’s Data ecosystem in very interesting ways. If this is something that sounds exciting to you then you are the right candidate for us.
You Will:
Build and automate reliable data pipelines using batch and streaming technologies
Design and test ETL systems using the latest technologies
Collaborate with other software engineers and data scientists to develop data driven applications
Become a data warehousing expert (if you aren’t already one!) and work with others to gain key insights
You Have:
Excellent communication and collaboration skills
Coding proficiency in at least one of Java, Python, C++, Go, Scala
Strong computer science skills with a focus on algorithms and data structures
Experience querying data using SQL and/or NoSQL
Familiar with MapReduce and other big data concepts
Experience with batch processing technologies (ie. Hadoop, Spark, Apache Beam, Flink)
Pluses:
Understand trade offs among data formats such as CSV, JSON, Avro, Parquet
Experience with stream processing technologies such as Apache Beam, Spark Streaming, Flink, Kafka Streams
ETL experience on AWS using EMR, Firehose, Lambda
ETL experience on Google Cloud using Dataproc, Cloud Functions, Dataflow
Experience using a data warehouse such as Redshift or BigQuery
Familiar with messaging systems such as Kinesis, Kafka, PubSub
Familiar with automation tools such as Apache Airflow, Luigi, AWS Data Pipeline
Compensation:
Competitive base salary plus meaningful equity
Comprehensive benefits (Medical, Dental, Vision, 401k)
Flexible Paid Time Off
Additional Perks:
Daily catered lunches
Dog friendly office
Collaborative, fun team
",https://jobs.lever.co/tradesy/b9beea46-3957-4cca-b85f-ec7fec024e82
JOB22179906353,Data Engineer,Data Engineer,"Vibrancy 360 Wellness Program: Yoga and fitness classes, onsite massage, volunteer opportunities, company happy hours, product demos, outings, and more.","Develop and maintain tools that bridge disparate data sources across the organization to serve data models, dashboards, decision aids, and business case analysis with up-to-date and accurate information.,Collaborate with our data scientists on engineering machine learning and predictive features from our proprietary data assets.,Prototype, implement, and optimize data new pipelines and architectures that can transform our data to impactful insights.,Create daily, weekly, or monthly automated processes built on proven and completed work.,Create innovative and efficient techniques that better solve the problems we are working on,Assess risks to proposed analytics solutions based on quality of existing data sources and actively develop QA procedures to mitigate those risks.,Tailor our syndicated data to retail and CPG business needs in a robust, repeatable, and scalable way.,Facilitate knowledge transfer across the business between Product Delivery and Commercial teams.,Recommend and implement enhancements that standardize and streamline processes, assure data quality and reliability, and reduce processing time to meet client expectations.,Have a professional quantitative background with an education that stresses analytical thinking and quantitative methods (STEM),Experience using python in a data context (iterators, pandas, scikit-learn, etc.),Are passionate about innovating new ways to answer novel problems,Are comfortable with being given the self-autonomy to work independently and experiment with new ideas and new ways to design and implement data science solutions to advance business goals,Can maintain sharp focus amidst multiple priorities and a keen aptitude to prioritize and manage time/projects,Have confidence in being the expert on SPINS data capabilities and best practices based on independent synthesis of a broad range of data,Have knowledge of working in a cloud computing environment,Familiarity with Docker or similar container framework and container orchestration tools such as Kubernetes is a plus,Experience working with retail POS or other transactional data is preferred,Vibrant – You’re passionate about doing meaningful, impactful work.,A Disruptor – You’re not afraid to do things differently,Connected – You work well as part of a team, and you build strong relationships with colleagues,Be Yourself – We are open & honest with each other; we take responsibility for our actions, and for our work,Health, dental and vision insurance,401k (Traditional and Roth) plus company match,FSA for medical and dependent care expenses,Pre-tax commuter benefit,Life insurance,Short- and long-term disability,Paid maternity and paternity leave,Bike storage,Fresh and healthy snacks","
SPINS is seeking a world class Data Engineer to join the Data Science Solutions team.
Who we are.
For 20 years, our mission has been to increase the presence and accessibility of natural and organic products to encourage healthier and more vibrant living. By leveraging SPINS’ industry-leading proprietary data and analytics, our technology enables deeper, more engaged relationships between Retailers, Brands and Consumers through our platform, web, and mobile products. At the core of our work lies a passion to create a culture of sustainable health & wellness.
What you will do.
You will create robust, scalable data pipelines that scale across the SPINS business to deliver insights to Retail and CPG companies that work with SPINS. You will be working in a “hands on” role, using python and SQL to efficiently uncover meaning and insight that leverage SPINS proprietary data. You will develop and drive the analytics efficiency of the organization by contributing to a codebase that can be leveraged in projects across the organization.
Ideally, you thrive on continuous innovation when value is determined by client results. You must have a passion for digging into data using the latest tools and methodologies.
Develop and maintain tools that bridge disparate data sources across the organization to serve data models, dashboards, decision aids, and business case analysis with up-to-date and accurate information.
Collaborate with our data scientists on engineering machine learning and predictive features from our proprietary data assets.
Prototype, implement, and optimize data new pipelines and architectures that can transform our data to impactful insights.
Create daily, weekly, or monthly automated processes built on proven and completed work.
Create innovative and efficient techniques that better solve the problems we are working on
Assess risks to proposed analytics solutions based on quality of existing data sources and actively develop QA procedures to mitigate those risks.
Tailor our syndicated data to retail and CPG business needs in a robust, repeatable, and scalable way.
Facilitate knowledge transfer across the business between Product Delivery and Commercial teams.
Recommend and implement enhancements that standardize and streamline processes, assure data quality and reliability, and reduce processing time to meet client expectations.
What you bring.
Have a professional quantitative background with an education that stresses analytical thinking and quantitative methods (STEM)
Experience using python in a data context (iterators, pandas, scikit-learn, etc.)
Are passionate about innovating new ways to answer novel problems
Are comfortable with being given the self-autonomy to work independently and experiment with new ideas and new ways to design and implement data science solutions to advance business goals
Can maintain sharp focus amidst multiple priorities and a keen aptitude to prioritize and manage time/projects
Have confidence in being the expert on SPINS data capabilities and best practices based on independent synthesis of a broad range of data
Have knowledge of working in a cloud computing environment
Familiarity with Docker or similar container framework and container orchestration tools such as Kubernetes is a plus
Experience working with retail POS or other transactional data is preferred
The SPINS Way: The right candidate for us will be…
Vibrant – You’re passionate about doing meaningful, impactful work.
A Disruptor – You’re not afraid to do things differently
Connected – You work well as part of a team, and you build strong relationships with colleagues
Be Yourself – We are open & honest with each other; we take responsibility for our actions, and for our work
Why SPINS?
Health, dental and vision insurance
401k (Traditional and Roth) plus company match
FSA for medical and dependent care expenses
Pre-tax commuter benefit
Life insurance
Short- and long-term disability
Paid maternity and paternity leave
Bike storage
Fresh and healthy snacks
Vibrancy 360 Wellness Program: Yoga and fitness classes, onsite massage, volunteer opportunities, company happy hours, product demos, outings, and more.
",https://www.builtinchicago.org/job/data/data-engineer/68244
JOB22572637289,"Data Engineer/Policy Steward, Senior","Data Engineer/Policy Steward, Senior",,,"
Data Engineer/Policy Steward, Senior
Job Number:
R0002121
Booz Allen Hamilton has been at the forefront of strategy and technology for more than 100 years Today, the firm provides management and technology consulting and engineering services to leading Fortune 500 corporations, governments, and not-for-profits across the globe. Booz Allen partners with public and private sector clients to solve their most difficult challenges through a combination of consulting, analytics, mission operations, technology, systems delivery, cybersecurity, engineering and innovation expertise.
Data Engineer/Policy Steward, Senior
Key Role:
Document data requirements from stakeholders and government leads. Maintain data and service architectures and catalogs with a focus on user needs. Collaborate on the production and maintenance of technical documentation, including data dictionaries, data flow documentation, user guides, and API documentation. Assist with policy maintenance, including MOUs or MOAs for data sharing.
Basic Qualifications:
-3+ years of experience with system analysis
-3+ years of experience with software development
-2+ years of experience with Agile software development
-2+ years of experience with DoDAF, UML, or SysML architecture documentation
-2+ years of experience with XML and JSON
-Ability to communicate effectively both orally and in writing
-TS/SCI clearance
-BA or BS degree and 6+ years of experience in a professional IT role or MA or MS degree and 4+ years of experience in a professional IT role
Clearance:
Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance is required.
Integrating a full range of consulting capabilities, Booz Allen is the one firm that helps clients solve their toughest problems. by their side to help them achieve their missions. Booz Allen is committed to delivering results that endure.
We are proud of our diverse environment, EOE, M/F/Disability/Vet.
DIG100
Date Posted: 4/3/2017
",https://www.clearancejobs.com/jobs/2452502/data-engineerpolicy-steward-senior
JOB22755817812,Data Engineer - EAward Winning Retail Start-Up,Data Engineer - EAward Winning Retail Start-Up,,,"
Over view of company
Digital Gurus are delighted to have teamed up with a multi-award winning retail start-up company, based in West London. Our exciting client have experienced rapid growth and success in the 5 years they've been founded. Their success hasn't gone un-noticed either with awards and rave reviews being received from Time Out, The Guardian, The Telegraph plus many more. With some angel investors on board they're also incredibly well backed.
What they're looking for
Our client have a solid, ambitious and passionate data team already in place. This crucial hire will see you rub shoulders with other data passionate people of all levels. You'll be working closely with product managers, data/software engineers as well as data scientists on their analytics pipeline from the design, implementation and maintenance. You'll work on various data warehousing and data modelling projects which will give you access to the latest tool and tech including Big Data technologies such as Hadoop + Spark. You'll also have the opportunity to build your own data products. Your passion and ambition to succeed will see you slot right into their team.
Requirements
BSc/MSc/PhD in a highly statistical/numerical degree
Hands on data modelling, data processing, data warehouse experience
Hands on ETL experience
Excellent knowledge of Knowledge of Python +AWS
Knowledge of Redshift + SQL
Knowledge of Big Data a plus (if not then no worries, just another area you'll get the opportunity to learn),
This is a fantastic opportunity to join an established data team in an incredibly exciting and successful start-up where there are progression/career opportunities in abundance.
If you're interested then please contact Matt on 0207 253 1054 ext. 110 / matts@digitalgurus.co.uk
",https://jobs.theguardian.com/job/6461615/data-engineer-eaward-winning-retail-start-up/
JOB25192137473,Data Engineer,Data Engineer,"3+ years of experience in a Data Engineer role.,Preferred: Bachelor or Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field - or commensurate experience,Experience using the following software/tools:,Intermediate development experience with one or more of the following: Java, Python and/or Scala,Experience with relational SQL and NoSQL databases; strong knowledge of database systems in general (Foreign keys, indexes, basic DBA tasks),Experience with big data tools: Intermediate to Advanced knowledge of Python; EMR/Spark, Lambda is a plus.,Working knowledge of a scripting language: Bash, Python, and/or PowerShell,Familiarity with a Linux/Unix environment,Experience with data pipeline and workflow management tools is a plus,Experience with stream-processing systems is a plus,​​​​​​​Willingness to roll up sleeves and do analyst work for the purposes of data exploration and assessment.,Demonstrated experience in measuring and handling large data sets and relational databases.,Communication, collaboration and project management skills with the ability to distill complex subjects to a wider audience.,Creativity, flexibility, and an entrepreneurial mindset to the solution of business issues; sound business judgment.,The ability to meet and exceed deadlines through a demonstrated sense of urgency.,Clear and concise ability to communicate complex concepts in English.,Ownership—Performance Unit Grants,Peer Recognition Awards,Employee Referral Bonus Program,401k with Company Match,Free Access to Office Health Club (Oakbrook & Chicago employees); Discounted gym memberships through BlueCross BlueShield of Illinois,Medical & Prescription Drug Insurance (monthly premiums 100% paid for employee only coverage!),Dental Insurance (monthly premiums 100% paid for employee only coverage!),Vision Insurance (monthly premiums 100% paid for employee only coverage!),Provided at No Cost to Employees: Group Term Life Insurance, Long-Term Disability, and Accidental Death & Personal Loss Insurance,Flexible Spending Accounts for Health Care, Dependent Care, and Commuter Benefits,Identity Protection Insurance,Voluntary Term Life Insurance & Group Universal Life Insurance,Accident & Critical Illness Insurance,Paid Time Off for Vacation, Illness, & Maternity/Paternity Leave,Corporate-sponsored Activities & Events Year Round","Identify, verify and score inbound consumers, on-demand, with as little as a single identifier.,Link customer data, update/add missing identifiers and enhanced attributes.,Enable improved digital marketing performance through higher match rates and complete insights.,Working with data scientist to maintain code base for analytics (Git for source control, Unit/Integration Testing, code reviews),Create and maintain optimal data pipeline architecture,,Assemble large, complex data sets that meet functional / non-functional business requirements.,Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.,Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.,Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.,Keep our data separated and secure across multiple data centers and AWS regions.,Work with data and analytics experts to strive for greater functionality in our data systems.","
Company Overview
Infutor is the expert in Consumer Identity Management. We are 100% focused on enabling brands to know everything they need to about consumers, to instantly make informed marketing and risk decisions.
Infutor’s experience linking trusted data sources result in solutions that:
Identify, verify and score inbound consumers, on-demand, with as little as a single identifier.
Link customer data, update/add missing identifiers and enhanced attributes.
Enable improved digital marketing performance through higher match rates and complete insights.
Infutor gives brands a secure, privacy compliant foundation to improve inbound engagements and outbound marketing reach, and to minimize fraud and collections risk.
Job Summary
Infutor is looking for an inquisitive, technically adept Data Engineer that loves investigating, manipulating, and finding value in our data. Looking for someone that is eager to get the job done, intellectually honest (not dogmatic), humble and enjoys brainstorming new ideas with the team. Intellectual curiosity and problem solving mentality is a must.
This position may require travel between our Oakbrook Terrace, Chicago Loop, Ft Myers and Costa Rica locations as required.
This person hired to this role may be based out of our Oakbrook Terrace, IL HQ or new Downtown Chicago Office. Note, relocation is not provided. Please apply only to your preferred location.
Sponsorship is not provided; candidate must be able to authorized to work in the US for any employer, without expectation of current or future sponsorship.
Responsibilities and Duties
As a Data Engineer you will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for our analytics team. The Data Engineer will support our developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even designing our company’s data architecture to support our next generation of data and analytics initiatives.
As a Data Engineer, your responsibilities will include, but are not limited to:
Working with data scientist to maintain code base for analytics (Git for source control, Unit/Integration Testing, code reviews)
Create and maintain optimal data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Keep our data separated and secure across multiple data centers and AWS regions.
Work with data and analytics experts to strive for greater functionality in our data systems.
Qualifications and Skills
Technical Skills
3+ years of experience in a Data Engineer role.
Preferred: Bachelor or Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field - or commensurate experience
Experience using the following software/tools:
Intermediate development experience with one or more of the following: Java, Python and/or Scala
Experience with relational SQL and NoSQL databases; strong knowledge of database systems in general (Foreign keys, indexes, basic DBA tasks)
Experience with big data tools: Intermediate to Advanced knowledge of Python; EMR/Spark, Lambda is a plus.
Working knowledge of a scripting language: Bash, Python, and/or PowerShell
Familiarity with a Linux/Unix environment
Experience with data pipeline and workflow management tools is a plus
Experience with stream-processing systems is a plus
Non-Technical Skills
​​​​​​​Willingness to roll up sleeves and do analyst work for the purposes of data exploration and assessment.
Demonstrated experience in measuring and handling large data sets and relational databases.
Communication, collaboration and project management skills with the ability to distill complex subjects to a wider audience.
Creativity, flexibility, and an entrepreneurial mindset to the solution of business issues; sound business judgment.
The ability to meet and exceed deadlines through a demonstrated sense of urgency.
Clear and concise ability to communicate complex concepts in English.
Competitive compensation package, commensurate with experience.
Benefits and Perks
Ownership—Performance Unit Grants
Peer Recognition Awards
Employee Referral Bonus Program
401k with Company Match
Free Access to Office Health Club (Oakbrook & Chicago employees); Discounted gym memberships through BlueCross BlueShield of Illinois
Medical & Prescription Drug Insurance (monthly premiums 100% paid for employee only coverage!)
Dental Insurance (monthly premiums 100% paid for employee only coverage!)
Vision Insurance (monthly premiums 100% paid for employee only coverage!)
Provided at No Cost to Employees: Group Term Life Insurance, Long-Term Disability, and Accidental Death & Personal Loss Insurance
Flexible Spending Accounts for Health Care, Dependent Care, and Commuter Benefits
Identity Protection Insurance
Voluntary Term Life Insurance & Group Universal Life Insurance
Accident & Critical Illness Insurance
Paid Time Off for Vacation, Illness, & Maternity/Paternity Leave
Corporate-sponsored Activities & Events Year Round
",https://www.builtinchicago.org/job/data/data-engineer/68163
JOB25434192217,Senior Data Engineer,Senior Data Engineer,,," • Great time to join a Leading Green Energy business.
• Data-driven strategy
• Progression opportunities to become Head of Data Engineering.
Our client is moving from a legacy to a cloud-based environment which requires changing the way they process their data. They are a data-driven organisation, it guides their strategic decision-making and service/product development. As a result, they need a Senior Data Engineer with experience in data architecture and data strategy to drive the organisation forward. The company is expanding so this type of role provides progression to become the Head of Data Engineering.
What you’ll be doing
As the Senior Data Engineer, you will be influential in supporting the migration from a legacy platform to a modern, scalable cloud-based, real-time streaming data infrastructure. This position will require working with a combination of small and Big Data Technologies.
You will support the design, roll-out and execution of the data strategy across various business units. You will collaborate with other engineering and data teams to ensure that the data is integrated and accessible.
This role requires a range of Data Engineering activities including; prototype development, ETL pipelines, architecture, process automation, data strategy and more.
What experience you’ll need to apply
• Solid ETL pipeline experience
• Python, Scala or Java development experience
• Experience of working on Big Data solutions
• Messaging broker platform such as Kafka, Kinesis, RabbitMQ or similar
• Experience of using either Spark, BigQuery, Hive, Hadoop, HDFS, Hydra
• Cloud Data Platform service migration or maintenance (GCP, AWS, Azure or Oracle)
What you’ll get in return for your experience
A competitive salary with excellent bonuses and benefits package. Grow with a leading company and have the potential to become the Head of Data Engineering.
What’s next?
Please get in touch with Scott with an up to date CV today. Don’t hesitate to call/email to discuss the job in further detail.
",https://jobs.theguardian.com/job/6843227/senior-data-engineer/
JOB31251003220,Data Engineer,Data Engineer,,,"Without data you’re just another person with an opinion. - Deming
It’s nearly impossible to find an authoritative source of truth about companies that is both always up-to-date and freely available. Our mission is to continue building the largest high-quality, live, openly editable and accessible dataset of company and people information in the world -- and to build a delightful product with slick, easy-to-use APIs around that dataset.
We love building enjoyable user experiences, complex data schemata, APIs, and scalable systems that support tens of millions of interactions per day. Our team is a group of highly skilled engineers working on formidable problems throughout the stack.
We have a flexible model for team organization at Crunchbase, centered around the principles of agile software development, allowing us to fluidly adapt to new requirements and situations as they arise. We tend towards two main types of teams:
• Feature-oriented teams:operate independently and own their projects from cradle to grave, building everything they need to execute. While they don't necessarily have to do all the work themselves, it's their responsibility to make sure the business needs are met all the way into production.
• Function-oriented teams: provide support to feature teams and have deeper expertise on particular parts of the stack. It's their responsibility to build platforms that are so good the other teams want to use them, rather than being forced into it.
We also ship code as early as we possibly can; getting betas into customer hands is a top priority. Our goal is to tune our process to customer needs as efficiently and quickly as possible. Crunchbase is built with a variety of tools - a core part of our engineering philosophy is to use the right tool for the job:
• Node.js, Angular.js, Typescript
• AWS - EC2, ELB, VPC, S3, R53, RDS, SQS, etc.
Data Engineering at Crunchbase
Our data team is responsible for building and maintaining the infrastructure for our data needs. As Crunchbase grows, so too does the amount of data we process, the number of sources it comes from, and the number of ways that people want to slice and dice it. We are currently building out a robust pipeline for our core data and we’re continually expanding use cases for it, so it must be both scalable and flexible.
At its core, Crunchbase is a data company, and data engineering is at the heart of our platform and will propel us into the future. The responsibilities of data engineers at Crunchbase include:
• Architect and build new dimensional data models and schema designs to improve accessibility, efficiency, consistency and quality of both internal and production data.
• Build, monitor, and maintain analytics and production data ETL pipelines.
• Provide the foundation for a data-driven culture by empowering other engineers and the Product team to ask questions of the dataset in an easy, reliable way.
• Enable data scientists to implement NLP and ML algorithms at scale, in fault-tolerant, highly available systems.
• Solid understanding of computer science and software engineering fundamentals.
• Motivated to participate in ongoing learning and growth through pair programming, code reviews, application of new technologies and best practices.
• Excellent verbal and written communication skills.
• Familiarity with tools we presently use is a plus, but not required -- if you know something better, we may use that instead!
What Crunchbase offers
• Competitive salary and equity
• A team of creative, transparent entrepreneurs driven to accomplish our mission
• Fitness reimbursement (to work off the catered lunches)
• Incredible medical, vision and dental benefits for employees and their families
• 401(k) and Roth plans, and free annual financial adviser check-in
• Free One Medical Group membership for employees and their families
• Commuter benefits program
• Free UberX rides anywhere in the Bay Area after late nights at the office
• Prime location in the SoMa district of SF, near CalTrain, and Muni stops
• Company and team offsites, retreats, events and happy hours
Every day our team is honored to work with entrepreneurs and innovators from every corner of the globe, and we aim to build a team that reflects the diversity of our customers. Each individual at Crunchbase brings their own perspectives, work experiences, lifestyles, and cultures with them, and we believe that a more diverse team creates more innovative products, provides a better service to its customers, and helps us all grow and learn as individuals. Crunchbase does not discriminate on the basis of race, creed, color, ethnicity, national origin, religion, sex, sexual orientation, gender expression, age, height, weight, veteran status, military obligations, or marital status.
",https://jobs.lever.co/crunchbase/28b49b30-fdb7-4203-9d79-c3a60cbcff29
JOB33908261684,Analytics Data Engineer,Analytics Data Engineer,,,"
Languages
Languages
Languages
Languages
Languages
Languages
Languages
Languages
Languages
Languages
Languages
Languages
Languages
Databases
Databases
Databases
Databases
Databases
",https://www.builtinchicago.org/job/data/analytics-data-engineer/67831
JOB34066970483,Sr. Data Engineer,Sr. Data Engineer,,"Pair up with teammates, learn about our real time streaming data pipeline and ship both a bug fix and new feature to production; demoing your work at at our end-of-sprint review session,Meet cross-functional peers on our devops, front-end, customer success, marketing and sales teams, experiencing hands-on demos of our fantastic products,The ability to work with loosely defined requirements and exercise your analytical skills to clarify questions, share your approach and build/test elegant solutions in weekly sprint/release cycles,A drive to get results and not let anything get in your way,Proficiency in Scala and/or other functional programming languages and pride in producing clean, maintainable code,A passion for developing, configuring and testing highly scalable applications/data pipelines running on Storm, Spark or similar distributed systems,Competency writing applications that interact with Kafka, Zookeeper, Elasticsearch, Redis and/or similar open source technologies,Experience working with devops teams and tools to ensure your work makes a smooth, automated, repeatable transition from your Mac to our staging and production environments,Competency locating, troubleshooting and fixing bugs and performance issues in distributed systems running on the JVM,Knowledge of best practice around continuous integration, test driven development, code review, local containerized development/testing and everything it takes to ensure your high quality code works both for you and our customers,A desire to keep abreast of the latest industry trends and technologies, a commitment to continuous learning and an open mind to others - no matter how senior or junior they are,Awesome market leading product in an expanding space,Innovative, customer centric culture & bright, passionate teammates,Competitive compensation, including equity,100% paid healthcare","Zignal Labs turns media and social intelligence into a strategic asset for the world’s largest brands and enterprises. By analyzing the full media spectrum in real-time, Zignal’s centralized platform empowers corporate communications, marketing and executive teams to understand trends, pinpoint issues and make informed decisions. Headquartered in San Francisco with offices throughout the country, Zignal serves customers around the world including Airbnb, IBM, Citrix, PepsiCo, Uber, Levis, The Sacramento Kings, Brunswick Group and FleishmanHillard. To learn more, visit: www.zignallabs.com.
To help scale the team, we’re looking for a Senior Data Engineer. The right candidate enjoys stepping up and leading technical initiatives, sharing ideas and listening to feedback from peers.
We foster an inclusive, supportive and fun team environment; fully committing to each story or initiative we’re working on. We take ideas from their initial stages right through to production collaborating closely all the way.
We’re innovative, continuous learners and value diversity of ideas and approaches.
In the first two weeks at Zignal Labs you’ll...
Pair up with teammates, learn about our real time streaming data pipeline and ship both a bug fix and new feature to production; demoing your work at at our end-of-sprint review session
Meet cross-functional peers on our devops, front-end, customer success, marketing and sales teams, experiencing hands-on demos of our fantastic products
Take advantage of the many Zignal perks including catered lunches and weekly release celebrations with themed snacks
To be successful in the role you should have...
The ability to work with loosely defined requirements and exercise your analytical skills to clarify questions, share your approach and build/test elegant solutions in weekly sprint/release cycles
A drive to get results and not let anything get in your way
Proficiency in Scala and/or other functional programming languages and pride in producing clean, maintainable code
A passion for developing, configuring and testing highly scalable applications/data pipelines running on Storm, Spark or similar distributed systems
Competency writing applications that interact with Kafka, Zookeeper, Elasticsearch, Redis and/or similar open source technologies
Experience working with devops teams and tools to ensure your work makes a smooth, automated, repeatable transition from your Mac to our staging and production environments
Competency locating, troubleshooting and fixing bugs and performance issues in distributed systems running on the JVM
Knowledge of best practice around continuous integration, test driven development, code review, local containerized development/testing and everything it takes to ensure your high quality code works both for you and our customers
A desire to keep abreast of the latest industry trends and technologies, a commitment to continuous learning and an open mind to others - no matter how senior or junior they are
A calm, assertive approach to diagnosing and fixing urgent problems in production; we have a fair on-call rotation system to ensure our system is running smoothly for our customers
Why join Zignal Labs?
Awesome market leading product in an expanding space
Innovative, customer centric culture & bright, passionate teammates
Competitive compensation, including equity
100% paid healthcare
Macbooks for everyone!
Zignal Labs is an Equal Opportunity Employer dedicated to the goal of building a culturally diverse environment, and strongly encourages applications from minorities and women. Additionally, we will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the San Francisco Fair Chance Ordinance.
",https://jobs.lever.co/zignallabs/1d37ec88-9f48-4ba0-ae64-bb3364bee4bc
JOB34694267687,Data Engineer,Data Engineer,Work with a phenomenal team of individuals that are constantly pushing the market boundaries to offer healthy food at the utmost convenience.,"Grow our existing cloud and data infrastructure, democratize access to data,,Champion the use of data and analytics at the company; be the pioneer of a data-driven culture.,Work with tech, marketing, sales, operations, finance and other business functions to scope, design and implement their data needs.,Help identify significant data sources and key variables for various business functions.,Lead the design and development of the data pipelines to productionize and ingest meaningful business data into a unified data model.,Develop machine learning and predictive analysis tools to identify new growth opportunities and personalize our services,Bachelor's degree in Computer Science/Computer Engineering or relevant industry experience,Proficiency in multiple programming languages, particularly Python, R or Javascript, with minimum two years full time professional experience,You are proficient with SQL and are rarely satisfied with the current query performance,You have developed data ingestion, data warehouse and integration pipelines,You are comfortable with both batch and stream data processing.,You know what it takes to build scalable and performant data models.,You understand the differences between relational and columnar databases and when to use them.,You are familiar with web development.,You value writing tests and people who write tests.,You have worked with one of the major public clouds (preferably AWS).,Ideally, you have experience with data visualization.,Traditional Benefits -- Health, Dental, Vision, Life, Short Term Disability, LTD,10 paid holidays,Generous PTO policy,Daily Fridge Credits,Monthly cell phone credit,Spontaneous company events and community service activities","
About the role:
We are integrating multifaceted data streams such as real-time IoT data, purchase data at the fridge, engagement data from the mobile apps, production and logistics data so that we continuously improve and optimize our business and operations workflows. We are looking for a Data Engineer to join our tech team and this could be you.
In a typical week, you will...
Grow our existing cloud and data infrastructure, democratize access to data,
Champion the use of data and analytics at the company; be the pioneer of a data-driven culture.
Work with tech, marketing, sales, operations, finance and other business functions to scope, design and implement their data needs.
Help identify significant data sources and key variables for various business functions.
Lead the design and development of the data pipelines to productionize and ingest meaningful business data into a unified data model.
Develop machine learning and predictive analysis tools to identify new growth opportunities and personalize our services
Minimum qualifications:
Bachelor's degree in Computer Science/Computer Engineering or relevant industry experience
Proficiency in multiple programming languages, particularly Python, R or Javascript, with minimum two years full time professional experience
You are proficient with SQL and are rarely satisfied with the current query performance
You have developed data ingestion, data warehouse and integration pipelines
You are comfortable with both batch and stream data processing.
You know what it takes to build scalable and performant data models.
You understand the differences between relational and columnar databases and when to use them.
You are familiar with web development.
You value writing tests and people who write tests.
You have worked with one of the major public clouds (preferably AWS).
Ideally, you have experience with data visualization.
Benefits:
Traditional Benefits -- Health, Dental, Vision, Life, Short Term Disability, LTD
10 paid holidays
Generous PTO policy
Daily Fridge Credits
Monthly cell phone credit
Spontaneous company events and community service activities
Work with a phenomenal team of individuals that are constantly pushing the market boundaries to offer healthy food at the utmost convenience.
About Farmer's Fridge:
At Farmer's Fridge, we're committed to making wholesome, delicious food simply accessible, so people can live a little happier. We aim to remove the roadblocks to eating well on the go. That means sourcing top-notch ingredients, handcrafting meals in our kitchen, packing & delivering fresh to our network of Fridges and ensuring the best possible customer experience. Unpurchased items are regularly donated to local food depositories, providing responsibly sourced nutrition to community members in need. If you're passionate about our mission to change the food system for the better, our team just may be the right fit for you.
View our disclosures related to External Agencies and Applicants below.
https://www.farmersfridge.com/careerdisclosures
",https://www.builtinchicago.org/job/data/data-engineer/65679
JOB40613200676,Data Engineer Intern - Fall 2018,Data Engineer Intern - Fall 2018,Previously healthcare experience is highly desirable,"2+ years of experience in the field,Deep experience writing in Python,Experience working with Jupyter,Experience with SQL,Experience with data acquisition (writing crawlers, interfacing with various API’s, fetching and transforming data, etc.),Experience with web services architecture,Experience implementing Spark or Hadoop,Experience with distributed computing / concurrent data pipelining,Experience with or interest in learning presentation softwares, such as D3, Tableau, Plotly, and/or MS PowerPoint","
Why we’re excited to get to work:
The mission for Payformance Solutions is simple. We aim to be a catalyst for payment transformation in the healthcare industry. Our proprietary software solutions allow payers and providers to focus on what really matters: providing patients with access to care that yields the best health outcomes, at the lowest costs.
About Us: We are Chicago based team. Our team writes beautiful & functional code that is easily reproducible and testable. We encourage open source contributions, especially with the technologies we use. We don’t release on Fridays.
In addition to the meaningful and challenging work, Payformance’s dynamic work environment emphasizes integrity, personal commitment, and teamwork. We allocate each employee innovation time each week with optional work-from-home days. Plus, outstanding benefits: 100% employer-paid health insurance options (employee, spouse, & family), dental & vision coverage, and 401k matching.
About You: We want developers that are serious about their work but don’t take themselves too seriously. You are flexible, can quickly pick up new technologies, and are a DIYer with a GSD mindset.
Minimum Experience:
2+ years of experience in the field
Deep experience writing in Python
Experience working with Jupyter
Experience with SQL
Experience with data acquisition (writing crawlers, interfacing with various API’s, fetching and transforming data, etc.)
Experience with web services architecture
Experience implementing Spark or Hadoop
Experience with distributed computing / concurrent data pipelining
Experience with or interest in learning presentation softwares, such as D3, Tableau, Plotly, and/or MS PowerPoint
Previously healthcare experience is highly desirable
Education: A minimum Bachelor’s Degree in Computer Science, Engineering or any equivalent education or experience. Master’s Degree preferred.
Not to boast, but a little bit about us:
Payformance Solutions is a health-tech company dedicated to advancing payment transformation in the healthcare industry. We are a wholly owned subsidiary of Altarum Institute, a nonprofit systems research and consulting organization that has been servicing government and private sector clients since 1946.
Altarum Institute (Altarum) is a nonprofit organization headquartered in Ann Arbor, Michigan. Altarum serves the public good by solving complex systems problems to improve human health. Altarum creates and implements solutions to advance health among vulnerable and publicly-insured populations. Public sector clients include the U.S. Department of Defense, Department of Health and Human Services, Department of Agriculture, Department of Veterans Affairs, the Occupational Safety and Health Administration, and various state agencies nationwide. Altarum also serves clients in the philanthropic and private sectors. Areas of expertise include health data and analytics; value-based care; public health systems design, development and information exchange; behavioral health and substance use disorders; childhood and adolescent health; medical education; food and nutrition; consumer engagement; elder care; health disparities and equity; and military and veterans’ health.
At Payformance, we don’t just accept difference - we celebrate, support, and thrive on it for the benefit of our employees, our clients, and our community. Payformance Solutions is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to, among other things, race, color, religion, sex, sexual orientation, gender identity, national origin, age, marital status, status as a protected veteran, or disability.
To all recruitment agencies: Payformance does not accept agency resumes, we are not responsible for any fees related to unsolicited resumes.
",https://www.builtinchicago.org/job/internship/data-engineer-intern-fall-2018/64318
JOB40798411879,Technical Support Engineer - Data Engineer,Technical Support Engineer - Data Engineer,,,"
Technical Support Engineer - Data Engineer
Description:
Leidos currently has an opening for a Technical Support Engineer - Data Engineer to work at our customer site in San Diego, Ca.
This is an exciting opportunity to use your experience helping the Distributed Common Ground/Surface System - Special Operations Forces (DCGS-SOF) Systems Integrator program. This effort provides development, integration, fielding, sustainment, and management activities in support of the DCGS-SOF Program, specifically for the development and integration of critical capabilities and functionality to meet SOF warfighter requirements. We act as the engineering and integration lead for the Program Management Office (PMO), with expertise in areas such as software and systems engineering, data engineering, Cyber Security, systems integration and interoperability support for the PMO. This effort encompasses Headquarters United States Special Operations Command (USSOCOM), United States Army Special Operations Command (USASOC), Naval Special Warfare Command (NSWC), Air Force Special Operations Command (AFSOC), Marine Corps Special Operations Command (MARSOC), and Joint Special Operations Command (JSOC).
Roles and Responsibilities:
Responsible for developing, documenting and implementing analytical methodology; identifying and documenting software functional requirements; capability testing and evaluation; identification, aggregation, and visualization of disparate data feeds. Technical support to operations and intelligence fusion through data integration and visualization of problem sets at the tactical through strategic levels. Provide technical support to multi-discipline Intelligence Analysis teams, leveraging software capabilities to assist and identify capabilities and vulnerabilities of targeted enemy organizations; identify trends, patterns and key nodes, highlighting their relationships to targeted enemy networks. Possess a thorough understanding of the intelligence process to compile, collate, analyze, produce, and evaluate all-source intelligence. Provide technical assistance with identification and dissemination of data sets to clients and partners; support technical functional requirements capture from across enterprise sites, and configure software solutions to support improved analysis across site locations. Devise strategies to extract meaning and value from structured and unstructured data. Utilize analytic models, scripting, and programming to characterize and analyze data. Analyze and configure functional capabilities to support the characterization and ingestion of new and existing data types. Identify and assist in the development and operationalization of data ingestion process flows and approval workflows. Communicate and collaborate with customer teams to understand mission needs.
Qualifications:
To be considered for this position, you must minimally meet the knowledge, skills, and abilities listed below:
Bachelor's Degree and 2 years' relevant experience or Master's Degree with 4 years' relevant experience.
Personnel are required to have DOD 8570.01-M Baseline Certification prior to being hired and become DOD 8570.01-M compliant 6 months from contract start.
Candidate must possess an active TS/SCI, or a Top Secret clearance with a current SSBI, and be eligible to obtain a TS/SCI clearance.
Candidates with these desired skills will be given preferential consideration:
Previous experience working with DoD, DCGS, or USSOCOM preferred.
Leidos Overview:
Leidos is a global science and technology solutions leader working to solve the world's toughest challenges in the defense, intelligence, homeland security, civil, and health markets. The company's 33,000 employees support vital missions for government and commercial customers. Headquartered in Reston, Virginia, Leidos reported pro forma annual revenues of approximately $10 billion for the fiscal year ended January 1, 2016 after giving effect to the recently completed combination of Leidos with Lockheed Martin's Information Systems & Global Solutions business (IS&GS). For more information, visit www.Leidos.com. The company's diverse employees support vital missions for government and commercial customers. Qualified women, minorities, individuals with disabilities and protected veterans are encouraged to apply. Leidos will consider qualified applicants with criminal histories for employment in accordance with relevant Laws. Leidos is an Equal Opportunity Employer.
",https://www.clearancejobs.com/jobs/2735350/technical-support-engineer-data-engineer
JOB42079270175,Data Engineer,Data Engineer,,,"Description
First People Solutions are working on behalf of a leading building support services provider who are looking for experienced Data Cabling Engineers to join their team in London.
The main duties will include but is not limited to:
Data Cabling - Installation of Cat5E, Cat6, Cat6a. Testing cabling using Fluke DTX & DSX.
Fibre Cabling - Installation of fibre cabling. Ability to test fibre cabling using Fluke DTX & DSZ using multimode/single mode tester.
Voice Cabling - Ability to terminate/jumpering voice cabling within 237A Krone strips. Ability to test fibre cabling using Fluke DTX & DSZ data tester
Cabinet & Containment - Ability to install data cabinets & carry out containment.
General - Knowledge of Krone, Systimax, Brand-Rex etc
You must have the ability to work to your own initiative and be able to successfully complete tasks within given timescales. You must have a ECS Grade Card and hold a full clean driving licence.
If interested in the position please apply by attaching your CV or contact Rebecca on 0141 270 5130.
Type
Contract Length
Telephone
Job Reference
Job ID
Applications
",https://www.cv-library.co.uk/job/206241487/Data-Engineer?hlkw=
JOB42124174449,Data Engineer,Data Engineer,,,"
My client are looking for an individual with a technical mind to work alongside the deployment teams as a specialist resource where you will be managing the migration and deployment of customer data. You will also be given opportunities to develop yourself, as well as increase capability within the team to senior roles.
My client are looking for an individual with a technical mind to work alongside the deployment teams as a specialist resource where you will be managing the migration and deployment of customer data. You will also be given opportunities to develop yourself, as well as increase capability within the team to senior roles.
The role:
• Helping customers understand their legacy and target data models and recommending actions to assist in effective migration
• Analysis of customer data and production of data quality reports outlining data quality issues and recommending “quick wins” for fix and highlighting issues.
• Accurate Data mapping
• Test and final load of data sets into customer environments in such a way as to give confidence in completeness and accuracy, minimising business impact
• Working with customers to support them in getting the most out of Salesforce.com and 3rd party reporting and dashboarding tools, feeding back to product teams where data model adjustments would be beneficial
• Managing your own time whilst working within the project constraints
• Taking part in project planning exercises and ensuring data concerns are given full consideration
Required:
• A minimum of 12 months experience using your choice of tooling (MS Excel, MS Access, SQL, or relevant databases) to extract, transform and load data between systems.
• Comfortable and organised whilst working across several projects simultaneously
• A proven ability to plan, organise, prioritise, manage and track numerous concurrent activities to successful outcomes
• Calm working to customer deadlines.
• A passion towards data handling
Desired:
• If you have experience working with/in the public sector this would hold in good stood as these organisations share a number of common challenges and obligations.
• A working knowledge of data modelling techniques would be a distinct advantage - For example being able to interpret and write.
• Salesforce and AWS familiarity
Start: ASAP
Location: Cambridge, Cambridgeshire
Hours: Full time
Salary: £25,000 - £30,000
If you have not received a response within 3-5 working days, unfortunately your application has been unsuccessful. aspire cambridge ltd is acting as an employment agency for this permanent vacancy.
Apply now
",https://www.cambridgenetwork.co.uk/recruitment-gateway/agency/76163/
JOB54006925173,Data Engineer,Data Engineer,,"Build statistical and machine learning algorithms that drive business decisions,Measure and predict KPIs related to user acquisition and retention,Improve upon our existing reporting strategies to communicate ongoing performance,Provide various teams with ad-hoc analysis to aide day-to-day operations,Influence product decisions through quantifiable goals,Lead projects for customer segmentation, personalization, and pricing,Identify opportunities for developing new data sources,Fluent English,Bachelor’s degree or higher in statistics, computer science, or other quantitative discipline,Understand how to use Git,Advanced SQL skills,Experience with a language suitable for data analysis such as Python, Java, or R,Fluency in data analysis and communication about data, including time series and event data analysis, and data visualization,Knowledge of recommender systems,Experience with customer retention modeling and/or survival analysis,A/B testing experience,Experience with Amazon Web Services or Google Cloud Platform,Experience processing large datasets using platforms such as Hadoop and Spark","What you’ll do:
Build statistical and machine learning algorithms that drive business decisions
Measure and predict KPIs related to user acquisition and retention
Improve upon our existing reporting strategies to communicate ongoing performance
Provide various teams with ad-hoc analysis to aide day-to-day operations
Influence product decisions through quantifiable goals
Lead projects for customer segmentation, personalization, and pricing
Identify opportunities for developing new data sources
Work closely with developers to collect metrics from their applications
What we're looking for:
Fluent English
Bachelor’s degree or higher in statistics, computer science, or other quantitative discipline
Understand how to use Git
Advanced SQL skills
Experience with a language suitable for data analysis such as Python, Java, or R
Fluency in data analysis and communication about data, including time series and event data analysis, and data visualization
Basic command-line skills and bash scripting
What will impress us:
Knowledge of recommender systems
Experience with customer retention modeling and/or survival analysis
A/B testing experience
Experience with Amazon Web Services or Google Cloud Platform
Experience processing large datasets using platforms such as Hadoop and Spark
Strong computer science fundamentals
How to apply:
Email your English CV and a brief description of your career goals to careers@iteriodata.com . Please put “Data Scientist” in the subject and feel free to send us links to your Github, portfolio, or whatever you feel is important for us to learn more about you. We look forward to hearing from you.
",https://moikrug.ru/vacancies/1000034694
JOB55567400237,"CONSULTANT, IT (Academic Data Engineer / Instructor)","CONSULTANT, IT (Academic Data Engineer / Instructor)","Distributed computing principles,Legacy and modern database architectures,Hadoop-based technologies (e.g. MapReduce, Hive and Pig),SQL-based technologies (e.g. PostgreSQL and MySQL),NoSQL technologies (e.g. Cassandra and MongoDB),Stream-processing systems (e.g. Storm or Spark-Streaming),ETL tools and APIs,Optimizing data storage and retrieval for specific use cases,Testing and validating the accuracy of data transformations,Cloud computing architectures, preferably with specific expertise in Microsoft Azure and AWS,Programming in multiple programming languages, including Python and Java,Creative problem-solving that is sensitive to available time and resource constraints,Effective listening and communication,Project managing","Working with academic faculty to monitor and optimize current forms of data collection, and develop and integrate new forms of data collection,Working with academic faculty to optimize the transformation of collected data into formats appropriate for analysis,Working with academic faculty and IT developers to apply state-of-the-art approaches in cloud service, containerization and other techniques for scaling the remote staging, storage, computation and analysis of data sets, including at scale by hundreds or thousands of students in online courses,Providing expertise in data set hygiene to the institution, facilitating the cleanup and integration of potentially multiple incomplete, irregular, and partial data sources into interesting and useful data sources for analysis,Working with various offices to ensure that information is used complies with the regulatory and security policies in place,Teaching a Database Systems core course for the MIDS program and possibly other programs,Helping develop advanced courses in Data Engineering,Developing and running workshops for the campus community in different aspects of data management and wrangling,Advising student capstone projects in the MIDS and other programs on data engineering needs,Helping evaluate capstone projects with program faculty","
CONSULTANT, IT (Academic Data Engineer / Instructor)
Job description
CONSULTANT, IT (Academic Data Engineer / Instructor)
OIT Service-Based Metrics & Reporting
Duke University seeks an outstanding Academic Data Engineer and Instructor who will (a) facilitate new research projects through the creative integration of multiple data sources, (b) inspire students with the power of data engineering and (c) function as a central member of an emerging Data Analytics Practice at Duke that stimulates new uses of data analytics in instruction and research. As an integral part of Duke's Data Science community, the staff member will be expected to work closely with faculty, students, and other departments at Duke. The staff member should be passionate about engineering ways to use new types of data to solve world problems, detail-oriented, and self-motivated to learn new skills and subjects as technology changes.
The staff member will have a central role in working with faculty to identify and leverage commonalities in support of new data-intensive degree programs (Duke's Masters in Interdisciplinary Data Science (MIDS)) and other academic programs, both in the physical classroom and as online courses. Together with personnel and support from Duke's Office of Information Technology , the staff member will be part of a growing team focused on data analytics, and will bring to that team an emphasis on academic data analytics.
The staff member's responsibilities would include:
Working with academic faculty to monitor and optimize current forms of data collection, and develop and integrate new forms of data collection
Working with academic faculty to optimize the transformation of collected data into formats appropriate for analysis
Working with academic faculty and IT developers to apply state-of-the-art approaches in cloud service, containerization and other techniques for scaling the remote staging, storage, computation and analysis of data sets, including at scale by hundreds or thousands of students in online courses
Providing expertise in data set hygiene to the institution, facilitating the cleanup and integration of potentially multiple incomplete, irregular, and partial data sources into interesting and useful data sources for analysis
Working with various offices to ensure that information is used complies with the regulatory and security policies in place
Teaching a Database Systems core course for the MIDS program and possibly other programs
Helping develop advanced courses in Data Engineering
Developing and running workshops for the campus community in different aspects of data management and wrangling
Advising student capstone projects in the MIDS and other programs on data engineering needs
Helping evaluate capstone projects with program faculty
To meet these responsibilities, the candidate should be an innovative problem solver, team-focused, highly organized, have the ability to handle-multiple and simultaneous tasks, and demonstrate an ability to stay calm and focused in emergencies. The candidate should also enjoy working in collaborative relationships, and have an approachable and relatable demeanor that inspires trust and confidence in partners.
Requirements:
Master's degree in mathematics, statistics, computer science or related field or equivalent experience. Doctorate preferred.
At least 5 years of working experience as a database engineering support personnel or a database engineering administrator within a fast-paced, complex setting.
The applicant must have expertise in the following areas:
Distributed computing principles
Legacy and modern database architectures
Hadoop-based technologies (e.g. MapReduce, Hive and Pig)
SQL-based technologies (e.g. PostgreSQL and MySQL)
NoSQL technologies (e.g. Cassandra and MongoDB)
Stream-processing systems (e.g. Storm or Spark-Streaming)
ETL tools and APIs
Optimizing data storage and retrieval for specific use cases
Testing and validating the accuracy of data transformations
Cloud computing architectures, preferably with specific expertise in Microsoft Azure and AWS
Programming in multiple programming languages, including Python and Java
Due to the applicant's role interacting with students, faculty, and staff on projects, the applicant must also be able to demonstrate skills in:
Creative problem-solving that is sensitive to available time and resource constraints
Effective listening and communication
Project managing
Duke University and Durham are located in the Research Triangle, a region that encompasses one of the nation's premier concentrations of academic, corporate, and public research. The Triangle region is rated among the most desirable areas in North America to live and work and has been identified by Money magazine as one of the ""Best Places to Live"" in the U.S.
Trustworthiness, respect, diversity, learning and teamwork are the hallmarks of Duke's guiding principles. Our accomplishments are dependent on the dedication and expertise of all who work to support Duke's mission.
Requisition Number
401380222
Location
Durham
Duke Entity
CENTRAL ADMIN MANAGEMENT CTR
Job Code
2427 CONSULTANT, IT
Job Family Level
E
Exempt/Non-Exempt
Exempt
Full Time / Part Time
FULL TIME
Regular / Temporary
Regular
Shift
First/Day
Minimum Qualifications
Duke University is an Affirmative Action/Equal Opportunity Employercommitted to providing employment opportunity without regard to anindividual's age, color, disability, gender, gender expression, genderidentity, genetic information, national origin, race, religion, sex,sexual orientation, or veteran status.
Duke aspires to create a community built on collaboration, innovation,creativity, and belonging. Our collective success depends on the robustexchange of ideas—an exchange that is best when the rich diversity ofour perspectives, backgrounds, and experiences flourishes. To achievethis exchange, it is essential that all members of the community feelsecure and welcome, that the contributions of all individuals arerespected, and that all voices are heard. All members of our communityhave a responsibility to uphold these values.
Essential Physical Job Functions:Certain jobs at Duke University and Duke University Health System mayinclude essential job functions that require specific physical and/ormental abilities. Additional information and provision for requests forreasonable accommodation will be provided by each hiring department.
Education
Refer to Job Description
Auto req ID
97455BR
Duke University is an Affirmative Action/Equal Opportunity Employer committed to providing employment opportunity without regard to an individual's age, color, disability, genetic information, gender, gender expression, gender identity, national origin, race, religion, sexual orientation, or veteran status.
Essential Physical Job Functions: Certain jobs at Duke University and Duke University Health System may include essential job functions that require specific physical and/or mental abilities. Additional information and provision for requests for reasonable accommodation will be provided by each hiring department.
PI104783817
Share this job with your network:
AAUP COMPENSATION SURVEY DATA
View more
",https://careers.insidehighered.com/job/1618045/consultant-it-academic-data-engineer-instructor-/
JOB56492589859,DATA ENGINEER,DATA ENGINEER,,,"
ABOUT THE PRODUCT AND ENGINEERING TEAM
At Centro, we’ve always been about making people’s lives better—from our employees to our clients. Today, we’re building a unified platform to execute every digital media advertising transaction, thus providing a new level of automation and intelligence in ad tech. This is an enormous task that will disrupt an industry and improve the lives of those who work within it.
To do this, we’re aggressively growing our team of engineers, product developers and designers. We are imaginative, passionate, determined and relentless in our efforts. Of course, we are fascinated by the complexity of engineering problems at this scale—it’s what brings bright minds together. But what keeps us coming back (and why we love coming to work everyday) is the chance to improve how work gets done: freeing up people’s time so that they can dream bigger and make life better.
Come build something amazing with us.
ABOUT THE ROLE
We are seeking forward-thinking Data Engineer to join Data team. You will be involved in the design and implementation of the Data Platform. We're looking for a Data Engineer who has passion for data processing and the challenges presented by different types of data at high velocity.
CORE RESPONSIBILITIES
• Implement scalable, fault tolerant and accurate ETL pipelines.
• Gather and process raw data at scale from diversified sources.
• Build enterprise business analytics and reporting applications.
• Develop platform services to operate the data applications at scale.
QUALIFICATIONS
• Proficiency with relational databases and SQL queries (Postgres, MySQL, Oracle or similar).
• Knowledge of Hadoop ecosystem components (Spark, Hive, Impala, Kafka, Oozie) is a plus.
• Understanding of factors affecting performance of ETL processes and SQL queries, ability to work on performance tuning.
• Experience in data modeling for OLTP and OLAP applications
• Experience implementing data pipelines.
• Experience coding in Python or Scala.
• Experience with tools such as Git, Jenkins, Jira, IntelliJ.
• Experience with Pentaho is a plus.
• Experience with other big data technologies such as Cassandra, MongoDB, Elastic Search is a plus.
• Ability to work independently as well as part of a team.
• Strong aptitude toward problem solving and working with different data sets.
• Having a passion and knowledge of AdTech industry is a plus.
• Have a Bachelor’s degree in computer science or software engineering.
",https://www.builtinchicago.org/job/data/data-engineer/65625
JOB60844344098,Data Engineer,Data Engineer,"SQL Server, T-SQL, SSIS, stored procedures, user-defined functions and table functions,Managing design risk,Software development lifecycles, Unit test techniques, debugging/analytical techniques,Help career growth by joining industry leader and continuing to advance Echo web based technologies,Working with an organization with defined market goals, products, customers, revenue, and development teams,Experienced mentors to learn and adopt new practices,Ability to introduce your own views and takes on our product offerings,Work in wide variety of data management,Ability to constantly enhance and improve applications,Have a clearly defined career growth track with enough flexibility to pave your own way","See technology as a passion, not something you just do between 9-5,Possess the ability to create new solutions; we operate on a web based platform and constantly facing unchartered waters,Possess strong fundamentals within coding technologies and a willingness to wear several hats when called upon,Do not wait for something to break; find a problem before it becomes one and constantly aiming to improve,Having a willingness to vocalize these ideas and pick yourself up if you get knocked down,Value passionate technologists, go-getters, and people who never stop seeking ways to improve existing technology,Have a high focus on career development and the runway to get you there,Work hard, period,Offer competitive compensation, benefits, 401k, challenging projects, company wide events, coworkers and leaders who will push you to get better, a sense of community not found anywhere else,Serve as a member of a data team that solves complex challenges and builds working database solutions using SQL Server, T-SQL, SSIS, stored procedures, views, user-defined functions, and table functions,Develop solutions and contributing to development, leveraging Object-Oriented programming techniques (.Net), Software Development Lifecycles, Unit Test Techniques, and Debugging/Analytical Techniques.,Collaborate with the team to develop database structures that fit into the overall architecture of the systems under development.,Code, install, optimize, and debug database queries and stored procedures using appropriate tools and editors.,Perform code reviews and provide feedback in a timely manner.,Promote collective code ownership for everyone to have visibility into the feature codebase.,Present technical ideas and concepts in business-friendly language.,Provide recommendations, analysis, and evaluation of systems improvements, optimization, development, and maintenance efforts, including capacity planning.,Identify and correct performance bottlenecks related to SQL code.,Support timely production releases and adherence to release activities.,Contribute to data retention strategy.","
Position Purpose
As a Data Engineer on the Echo Global Logistics team, you will contribute to database management of large scale web-based applications through the use of SQL, C#, and .NET tools. These technologies enable Echo’s business while supporting architectural vision of quality, scalability, performance and function. Our proprietary software is created with the goal to simplify transportation for our customers and carriers, and is one of our largest competitive advantages in an ever growing market.
Echo Global Logistics has recently been ranked the third largest digital company by employee size in Chicago and we are continuing to see increased growth in virtually all of our technical teams. Additionally, we have been ranked as the #1 Inbound Logistics 3PL for 2017 and look forward to speaking with you further about our team!
Essential Position Functions
You...
See technology as a passion, not something you just do between 9-5
Possess the ability to create new solutions; we operate on a web based platform and constantly facing unchartered waters
Possess strong fundamentals within coding technologies and a willingness to wear several hats when called upon
Do not wait for something to break; find a problem before it becomes one and constantly aiming to improve
Having a willingness to vocalize these ideas and pick yourself up if you get knocked down
We…
Value passionate technologists, go-getters, and people who never stop seeking ways to improve existing technology
Have a high focus on career development and the runway to get you there
Work hard, period
Offer competitive compensation, benefits, 401k, challenging projects, company wide events, coworkers and leaders who will push you to get better, a sense of community not found anywhere else
Responsibilities:
Data Engineer’s work in conjunction with Software Engineers, DBA’s, Business Analysts, Quality Assurance and business owners
Serve as a member of a data team that solves complex challenges and builds working database solutions using SQL Server, T-SQL, SSIS, stored procedures, views, user-defined functions, and table functions
Develop solutions and contributing to development, leveraging Object-Oriented programming techniques (.Net), Software Development Lifecycles, Unit Test Techniques, and Debugging/Analytical Techniques.
Collaborate with the team to develop database structures that fit into the overall architecture of the systems under development.
Code, install, optimize, and debug database queries and stored procedures using appropriate tools and editors.
Perform code reviews and provide feedback in a timely manner.
Promote collective code ownership for everyone to have visibility into the feature codebase.
Present technical ideas and concepts in business-friendly language.
Provide recommendations, analysis, and evaluation of systems improvements, optimization, development, and maintenance efforts, including capacity planning.
Identify and correct performance bottlenecks related to SQL code.
Support timely production releases and adherence to release activities.
Contribute to data retention strategy.
Position Requirements
1-3 years in commercial-grade business applications environment leveraging the following:
SQL Server, T-SQL, SSIS, stored procedures, user-defined functions and table functions
Managing design risk
1-3 years leveraging OO programming techniques
Software development lifecycles, Unit test techniques, debugging/analytical techniques
What's in it for you?
Help career growth by joining industry leader and continuing to advance Echo web based technologies
Working with an organization with defined market goals, products, customers, revenue, and development teams
Experienced mentors to learn and adopt new practices
Ability to introduce your own views and takes on our product offerings
Work in wide variety of data management
Ability to constantly enhance and improve applications
Have a clearly defined career growth track with enough flexibility to pave your own way
All qualified applicants will receive consideration for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, status as a qualified individual with a disability, or Vietnam era or other protected veteran.
",https://www.builtinchicago.org/job/data/data-engineer/70062
JOB62144512776,Senior Data Engineer,Senior Data Engineer,The opportunity to work with smart people on challenging problems!,"Design and build infrastructure to host machine learning models as microservices using modern conventions and coding practices,Help design and implement data models and database layers that support our machine learning and business intelligence activities,Use creativity and independent thinking to solve technical problems,Mentor more junior team members,Communicate clearly and effectively with technical and non-technical colleagues about our data engineering projects,Work closely with data scientists to understand their needs and processes,Work closely with our whole technology team to successfully maintain our data platform alongside the broader technology stack,Implement strong and consistent internal API conventions and documentation,Implement with an emphasis on tests, maintainability, and clean coding practices to produce simple solutions and reduce technical debt,3+ years building and maintaining back-end services in production, preferably using container-based architectures,Experience using AWS tools and services,Experience with relational databases and data pipelines,Proficient in SQL, *nix CLI tools (grep/sed/awk/BASH, etc), and Python,Experience deploying and maintaining code using git-based tools and operating in a continuous deployment/integration environment,Experience writing thorough tests and documentation for maintainable code-bases,Ability to develop creative technical solutions given a set of business requirements and a strong understanding of modern data architectures,Ability to work productively on small teams and lead workstreams independently if needed,Experience mentoring less experienced colleagues,Ability to communicate technical ideas to non-technical colleagues Preferred Skills and Experience,3+ years building and maintaining data science pipelines that incorporate machine learning models in a production environment behind an API,Experience working with data scientists in production roles,Experience with container management solutions like Kubernetes, Marathon, etc.,Experience storing and using large amounts of text data and text transformations,Competitive compensation,Medical, dental, vision, mental health insurance – with premiums fully paid by Ascent,401K offered,Unlimited PTO and Bank Holidays,Flexible work schedule,As much RAM as you can fit in a Macbook Pro,Professional development stipend,Top floor office in Prudential Plaza with an amazing view of the park/lake and Pedway access","
Who We Are
At Ascent we are building an intelligent compliance platform that enables compliance professionals to easily track and understand their compliance obligations and related regulation.
We use a hybrid approach of machine learning and legal expertise to provide our customers with the regulatory knowledge they need. To support our platform we are also building a suite of internal data, devops, and machine learning tools; this infrastructure houses and coordinates all of our data pipelines and machine learning models. We are looking for experienced, passionate engineers to help us build and maintain this infrastructure.
Who You Are
As a Senior Data Engineer at Ascent, you will be working closely with other Engineers and Data Scientists to design and build infrastructure that a) ingests and handles data (e.g. regulations, customer data, machine learning features, etc); b) deploys and coordinates data microservices such as machine learning models or other transformations; c) facilitates workflows across these microservices and data layers; and d) tests, monitors, and reports on itself. Given the increased responsibility at the Senior level, you will play a strong role in designing this infrastructure, thinking about the long-term implications of design decisions, as well as hiring and mentoring more junior engineers. We use both hosted solutions and open source tools. We have a strong bias towards containerization and internal transparency. We also place a high premium on our culture and values, both within the tech team and the company as a whole. We believe a diversity of opinions and perspectives creates a stronger team and product, and we are committed to an equal opportunity hiring process.
Responsibilities
Design and build infrastructure to host machine learning models as microservices using modern conventions and coding practices
Help design and implement data models and database layers that support our machine learning and business intelligence activities
Use creativity and independent thinking to solve technical problems
Mentor more junior team members
Communicate clearly and effectively with technical and non-technical colleagues about our data engineering projects
Work closely with data scientists to understand their needs and processes
Work closely with our whole technology team to successfully maintain our data platform alongside the broader technology stack
Implement strong and consistent internal API conventions and documentation
Implement with an emphasis on tests, maintainability, and clean coding practices to produce simple solutions and reduce technical debt
3+ years building and maintaining back-end services in production, preferably using container-based architectures
Experience using AWS tools and services
Experience with relational databases and data pipelines
Proficient in SQL, *nix CLI tools (grep/sed/awk/BASH, etc), and Python
Experience deploying and maintaining code using git-based tools and operating in a continuous deployment/integration environment
Experience writing thorough tests and documentation for maintainable code-bases
Ability to develop creative technical solutions given a set of business requirements and a strong understanding of modern data architectures
Ability to work productively on small teams and lead workstreams independently if needed
Experience mentoring less experienced colleagues
Ability to communicate technical ideas to non-technical colleagues Preferred Skills and Experience
3+ years building and maintaining data science pipelines that incorporate machine learning models in a production environment behind an API
Experience working with data scientists in production roles
Experience with container management solutions like Kubernetes, Marathon, etc.
Experience storing and using large amounts of text data and text transformations
Benefits
Ascent employees enjoy many benefits and perks, including:
Competitive compensation
Medical, dental, vision, mental health insurance – with premiums fully paid by Ascent
401K offered
Unlimited PTO and Bank Holidays
Flexible work schedule
As much RAM as you can fit in a Macbook Pro
Professional development stipend
Top floor office in Prudential Plaza with an amazing view of the park/lake and Pedway access
The opportunity to work with smart people on challenging problems!
",https://www.builtinchicago.org/job/product/product-manager/65289
JOB64629033948,Data Engineer,Data Engineer,,,"
We are currently looking for a Data Programmer to join a leading company based in the central London area. As the Data Programmer you will be part of the data science team ensuring they are delivering quality products to the business
KEY DUTIES AND RESPONSIBILITIES:
Your duties as the Data Programmer will be varied however the key duties and responsibilities are as follows:
1. You will support the data science team by helping to package, deploy, and
monitor machine learning models in production environments
2. You will need to use your skills in Python or R to develop in an AWS or Azure platform
3. You will work with various parts of the business to identify appropriate automation
applications and be responsible for developing the solutions.
4. You will own the testing and monitoring processes, ensuring the Data Science team deliver quality products.
ROLE REQUIREMENTS:
To be successful in your application to this exciting opportunity as the Data Programmer we are looking to identify the following on your profile and past history:
1. Azure and/or AWS cloud platform deployment, resource management and templating (Azure
preferred)
2. Programming experience in open source technology such as Python or R
3. A strong sense of curiosity that wants to work collaboratively as part of a wider data science team
Key Words: Data Engineer, Data, Data Science, Python, R, AWS, Azure
Hyper Recruitment Solutions Ltd (HRS) is an Equal Opportunities employer who are certified by Investors in People for talent development. We therefore welcome applications for any interested parties who fulfil the role requirements for this position. HRS is a company exclusively supporting the science and technology sectors, and is made up of a collaboration of recruitment professionals and scientists. We look forward to helping you with your next career moves.
",https://jobs.newscientist.com/job/1401665118/data-engineer/
JOB65746535187,Data Engineer,Data Engineer,"Bachelor’s Degree in Computer Science or related field,1+ years of experience in Data Platform Administration/Engineering","Designs and develops data-ingestion frameworks, real-time processing solutions, and data processing and transformation frameworks.,Deploys application codes and analytical models. Provides support for deployed data applications and analytical models.","
Discover. A more rewarding way to work.
At Discover Financial Services, you’ll find yourself in the company of some of the industry’s smartest and most reliable professionals. And at a company that rewards dedication, values innovation and supports growth.
Thrive in an environment that promotes teamwork and shared success. Build on a foundation of mutual respect. Join the company that understands rewarding careers like no other, with this exceptional opportunity:
Job Description:
At Discover, be part of a culture where diversity, teamwork and collaboration reign. Join a company that is just as employee-focused as it is on its customers and is consistently awarded for both. We’re all about people, and our employees are why Discover is a great place to work. Be the reason we help millions of consumers build a brighter financial future and achieve yours along the way with a rewarding career.
Responsible for designing and developing data-driven platforms and next generation analytic technologies.
Responsibilities
Designs and develops data-ingestion frameworks, real-time processing solutions, and data processing and transformation frameworks.
Deploys application codes and analytical models. Provides support for deployed data applications and analytical models.
Skills:
Minimum Qualifications
At a minimum, here’s what we need from you:
Bachelor’s Degree in Computer Science or related field
Preferred Qualifications
If we had our say, we’d also look for:
1+ years of experience in Data Platform Administration/Engineering
What are you waiting for? Apply today!
And by the way, while you’re waiting to hear from us, don’t forget to check out the great benefits Discover offers.
Discover Financial Services is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, protected veteran status, among other things, or as a qualified individual with a disability.
So, what are you waiting for? Apply today!
",https://www.builtinchicago.org/job/data/data-engineer/70305
JOB66963565565,Data Engineer,Data Engineer,"Strong knowledge of SQL, Python/Bash,Expert in database design,Experience with Git,General knowledege of Linux server administration,BS/MS in Computer Science or Engineering,Experience with Google Cloud Platform,Experience with Spark or Hadoop stack,Interest in data science/machine learning,Career in rapidly growing IT;,Official employment according to the Labor Code of the Russian Federation with “white salary”;,Flexible working day start (between 9.00 and 12.00 am) with 5 working days (Mn-Fr);,Comfortable and cosy office;,Friendly employees;,Corporate education (trainings, seminars, conferences);,Fitness compensation (up to 50%);,Medical insurance.","Provide design and support of the data warehouse,Maintain the acquisition of data,Conduct data migration tasks to transform and join data,Pertform montoring and testing of ETL jobs,Provide documentation for designed warehouses","SEMrush is an online marketing toolbox that contains indispensable data for developing SEO, advertising, and link-building strategies. It helps digital marketing professional and business owners realize how important online strategies are for reaching business goals. SEMrush was designed to help speed up and facilitate daily online marketing activities, and easily monitor website’s performance.
To keep up with our rapid growth, SEMrush is looking for experienced and motivated individuals to join our expanding team!
We are currently looking for data engineer who will work with analytics team
Key Activities:
Provide design and support of the data warehouse
Maintain the acquisition of data
Conduct data migration tasks to transform and join data
Pertform montoring and testing of ETL jobs
Provide documentation for designed warehouses
Qualifications:
Strong knowledge of SQL, Python/Bash
Expert in database design
Experience with Git
General knowledege of Linux server administration
BS/MS in Computer Science or Engineering
As a plus:
Experience with Google Cloud Platform
Experience with Spark or Hadoop stack
Interest in data science/machine learning
We offer:
Career in rapidly growing IT;
Official employment according to the Labor Code of the Russian Federation with “white salary”;
Flexible working day start (between 9.00 and 12.00 am) with 5 working days (Mn-Fr);
Comfortable and cosy office;
Friendly employees;
Corporate education (trainings, seminars, conferences);
Fitness compensation (up to 50%);
Medical insurance.
",https://spb.hh.ru/vacancy/22046420
JOB75067914599,Big Data Engineer / Data Scientist – Turkey,Big Data Engineer / Data Scientist – Turkey,,"Strong academic background,Excellent experience in Big Data Engineering,Demonstrable programming experience e.g. Python, Scala, MapReduce, Java, C++,Knowledge of SQL,Familiarity with Hadoop, Spark, NoSQL.,Good understanding of visualisation tools such as Tableau, D3, Qlik,Interest in Machine Learning,Excellent understanding of manipulation and analysis of large, complex data sets.","
Big Data Engineer / Data Scientist – Turkey
Nakama Global are retained by one of the world’s leading technology companies to find an experienced Big Data Engineer with a strong understanding of Data Science. The company are renowned for their innovative thinking and ability to continually evolve and create products that appeal to people across their global network. One of their key focuses
The successful candidate is an ambitious person with superb communication skills (including fluent verbal and written English). They will be a keen problem solver with a great eye for detail. This role will offer the successful candidate excellent experience in one of the world’s most well-known companies with exceptional room for professional development.
Key Skills:
Strong academic background
Excellent experience in Big Data Engineering
Demonstrable programming experience e.g. Python, Scala, MapReduce, Java, C++
Knowledge of SQL
Familiarity with Hadoop, Spark, NoSQL.
Good understanding of visualisation tools such as Tableau, D3, Qlik
Interest in Machine Learning
Excellent understanding of manipulation and analysis of large, complex data sets.
Location: Istanbul, Turkey
Salary: ₺20000 per month
For more information on this role, please contact Eimear at Nakama London ewalsh@nakamalondon.com
EW22403
",https://jobs.theguardian.com/job/6447745/big-data-engineer-data-scientist-turkey-/
JOB82670459519,Data Engineer,Data Engineer,,,"Our Client are currently recruiting Data Engineers based in Aberdeen
Cable Pulling - trunking - COAX Minimum Requirement - CSCS As long as they have good Data Engineer experience.
Qualifications required to carry out the role: Essential: Solid Data Engineering background CAT5/ 6 Installation Fluke Tester operation
Skills
Not Specified
The role will involve working with a team of engineers and technicians in the completion of cradle to grave installations and modifications to plant and systems as part of a project investment delivery programme. Such responsibilities will include: Undertake all work as instructed by the Site Super ...Posted 4 hours agoJob
Field Service Technician - Worldwide Location: traveling worldwide but you need to live near Blackburn Salary: annual earnings £40,000 - 60,000 + pension + 25 holidays Hours: 12 hours shifts when on site. You will be away 50% of the month. typically 7 - 12 days at a time. The remainder of the tim ...Posted 5 hours agoJob
Job Mechanical Maintenance Technician - HV Rotating Machines (motors / generators) Location Culham Science Centre, Abingdon, Oxfordshire Position Permanent Salary £32000 - £34000/year (possibly a little more) + paid overtime + company contribution pension, gym subsidy, 25 days holidays and sick p ...
Oxfordshire Oxfordshire GB Permanent £32000.00 - £36000.00 per annum + overtime + T&S
Posted 22 hours agoJob
Our client is looking for up to x 3 Planning Engineers for positions based in Dublin. Candidates must have at least 7 years experience in a Planning position and be competent in the use of Primavera P6. Competitive Rate on offer, working Monday - Friday. Skills Not Specified
Dublin Dublin IE Contract £400.00 - £500.00 per day + Negotiable
Posted 1 day agoJob
The position would suit an individual motivated to succeed and comfortable working in a team environment. The role will involve working with a team of engineers and technicians in the completion of cradle to grave installations and modifications to plant and systems as part of a project investment d ...
Dunbar East Lothian GB Contract £0.00 per annum + Negotiable
Posted 1 day agoJob
",https://oilvoice.com/Job/3438/Data-Engineer
JOB84739039109,Senior Quality Assurance Data Engineer,Senior Quality Assurance Data Engineer,"Extensive experience with SQL, Ruby, and web services. Big Data skills appreciated.,Experience testing multi-tier, consumer-facing web applications at more than just the UI level,Experience testing batch / streaming ETL processes using Spark, Beam, etc.,Parsing and analysis of free-form and fixed form data sets,Good problem solving and debugging skills,Comfortable working in Agile development environment,Experience executing API tests,Broad experience designing and maintaining automated tests for whitebox and blackbox testing,Experience with unit testing frameworks: RSpec (preferred), Minitest/Test::Unit or similar,Experience with libraries used to implement browser automation: Watir (preferred), Selenium, Capybara, etc.,Knowledge of best practices for the Software Development Life Cycle (SLDC),Working knowledge of JIRA or other issues and project tracking software.,Experience with Git or other distributed revision control and source code management systems.,Background in payments desirable but not required,Experience in platforms non-functional requirements and operating systems,Experience in performance testing and/or security testing","Data Validation - Develop automated procedures to ensure data accuracy and integrity of complex data exports and reports,Test the ETL process and business logic that drives our in-app reporting features,Define, develop, and implement quality assurance practices and procedures, test plans and perform other QA assessments for all data related code changes,Develop automated tests using open source tools,Configure and maintain test automation environments,Create scripts, test sequences, and implement manual procedures to ensure proper test coverage,Work closely with other QA team members to understand and validate upstream application changes and impacts on data, exports, and reports,Work closely with Development, Product team and other organizations in the company to promote software quality standards,Work closely with Customer Support to replicate customer issues and product field use cases,Participate in test team activities including requirements analysis, test planning, tracking, reporting, and support of test cycles.,Engage in test case execution including defect documentation and tracking, resolution support, and fix verification","
Description
The data team at Recurly is committed to providing high-quality insights for our customers via in-app reports, visualizations, and exports on key subscription indicators. We are looking for a Senior Data QA Engineer with great working knowledge of functional, unit, automation, and data testing. We will rely on you to generate well-articulated data-oriented test cases and determine the positive, negative and boundary cases from working with our cross-functional teams in fast-paced, agile, and release driven environment.
Responsibilities:
Data Validation - Develop automated procedures to ensure data accuracy and integrity of complex data exports and reports
Test the ETL process and business logic that drives our in-app reporting features
Define, develop, and implement quality assurance practices and procedures, test plans and perform other QA assessments for all data related code changes
Develop automated tests using open source tools
Configure and maintain test automation environments
Create scripts, test sequences, and implement manual procedures to ensure proper test coverage
Work closely with other QA team members to understand and validate upstream application changes and impacts on data, exports, and reports
Work closely with Development, Product team and other organizations in the company to promote software quality standards
Work closely with Customer Support to replicate customer issues and product field use cases
Participate in test team activities including requirements analysis, test planning, tracking, reporting, and support of test cycles.
Engage in test case execution including defect documentation and tracking, resolution support, and fix verification
Technical Requirements:
Extensive experience with SQL, Ruby, and web services. Big Data skills appreciated.
Experience testing multi-tier, consumer-facing web applications at more than just the UI level
Experience testing batch / streaming ETL processes using Spark, Beam, etc.
Parsing and analysis of free-form and fixed form data sets
Good problem solving and debugging skills
Comfortable working in Agile development environment
Experience executing API tests
Broad experience designing and maintaining automated tests for whitebox and blackbox testing
Experience with unit testing frameworks: RSpec (preferred), Minitest/Test::Unit or similar
Experience with libraries used to implement browser automation: Watir (preferred), Selenium, Capybara, etc.
Knowledge of best practices for the Software Development Life Cycle (SLDC)
Working knowledge of JIRA or other issues and project tracking software.
Experience with Git or other distributed revision control and source code management systems.
A Plus, but not Required:
Background in payments desirable but not required
Experience in platforms non-functional requirements and operating systems
Experience in performance testing and/or security testing
About Recurly
Recurly is an enterprise-class subscription management platform that cuts through the complexity of subscription management to optimize and automate revenue growth. Founded in 2009, Recurly uses an open platform approach to easily connect with a broad variety of back-office systems. In addition to enabling lightweight and flexible custom integrations, Recurly also has powerful out-of-the-box integrations with enterprise solutions like Salesforce, NetSuite, and Avalara to provide efficiencies through end-to-end automation of billing events throughout the customer lifecycle.
Recurly's flexible architecture, coupled with deep expertise in the payments industry is validated by the billions of dollars in transactions the company processes each year. Thousands of companies worldwide depend on Recurly to manage and optimize their rapidly-growing subscription businesses.
",https://www.builtincolorado.com/job/data/senior-qa-data-engineer/44412
JOB84809922908,Big Data Engineer / Data Scientist,Big Data Engineer / Data Scientist,"Excellent understanding of manipulation and analysis of large, complex data sets.","Strong academic background,Excellent experience in Big Data Engineering,Demonstrable programming experience e.g. Python, Scala, MapReduce, Java, C++,Knowledge of SQL,Familiarity with Hadoop, Spark, NoSQL.,Good understanding of visualisation tools such as Tableau, D3, Qlik,Interest in Machine Learning","
Nakama Global are retained by one of the world’s leading technology companies to find an experienced Big Data Engineer with a strong understanding of Data Science. The company are renowned for their innovative thinking and ability to continually evolve and create products that appeal to people across their global network. One of their key focuses
The successful candidate is an ambitious person with superb communication skills (including fluent verbal and written English). They will be a keen problem solver with a great eye for detail. This role will offer the successful candidate excellent experience in one of the world’s most well-known companies with exceptional room for professional development.
Key Skills
Strong academic background
Excellent experience in Big Data Engineering
Demonstrable programming experience e.g. Python, Scala, MapReduce, Java, C++
Knowledge of SQL
Familiarity with Hadoop, Spark, NoSQL.
Good understanding of visualisation tools such as Tableau, D3, Qlik
Interest in Machine Learning
Excellent understanding of manipulation and analysis of large, complex data sets.
Location: Dusseldorf, Germany
Salary: €95,000 per annum
For more information on this role, please contact Eimear at Nakama London ewalsh@nakamalondon.com
EW22429
",https://jobs.theguardian.com/job/6448634/big-data-engineer-data-scientist-/
JOB89111700592,Data Engineer,Data Engineer,,,"
My client are looking for an individual with a technical mind to work alongside the deployment teams as a specialist resource where you will be managing the migration and deployment of customer data.
My client are looking for an individual with a technical mind to work alongside the deployment teams as a specialist resource where you will be managing the migration and deployment of customer data.
The role:
• Helping customers understand their legacy and target data models and recommending actions to assist in effective migration
• Analysis of customer data and production of data quality reports outlining data quality issues and recommending “quick wins” for fix and highlighting issues.
• Accurate Data mapping
• Test and final load of data sets into customer environments in such a way as to give confidence in completeness and accuracy, minimising business impact
• Working with customers to support them in getting the most out of Salesforce.com and 3rd party reporting and dashboarding tools, feeding back to product teams where data model adjustments would be beneficial
• Managing your own time whilst working within the project constraints
• Taking part in project planning exercises and ensuring data concerns are given full consideration
Required:
• A minimum of 12 months experience using your choice of tooling (MS Excel, MS Access, SQL, or relevant databases) to extract, transform and load data between systems.
• Comfortable and organised whilst working across several projects simultaneously
• A proven ability to plan, organise, prioritise, manage and track numerous concurrent activities to successful outcomes
• Calm working to customer deadlines.
• A passion towards data handling
Desired:
• If you have experience working with/in the public sector this would hold in good stood as these organisations share a number of common challenges and obligations.
• A working knowledge of data modelling techniques would be a distinct advantage - For example being able to interpret and write.
• Salesforce and AWS familiarity
Start: Immediately
Duration: Temporary 4 weeks +
Location: Cambridge, Cambridgeshire
Hours: Full time - flexible
Hourly Rate: £competitive
If you have not received a response within 3-5 working days, unfortunately your application has been unsuccessful. aspire cambridge ltd is acting as an employment agency for this temporary vacancy.
Apply now
",http://www.cambridgenetwork.co.uk/recruitment-gateway/agency/74454/
JOB93071793274,"Data Engineer, Senior","Data Engineer, Senior",,,"
Data Engineer, Senior
Job Number: R0028942
Data Engineer, Senior
Key Role:
Provide a combination of data science and data analytics and programmatic support to the Department of Homeland Security (DHS). Provide logistics and planning support related to mission-critical focus groups and operational field assessments for emerging and commercial technologies, as needed. Maintain responsibility for the creation and maintenance of analytics infrastructure. Support the development, construction, maintenance. and testing of architectures, including databases and large-scale processing systems. Support the creation of data set processes used in modeling, mining, acquisition, and verification. Provide support on data analytics-related efforts, including user acceptance tests of data acquisition and analysis solutions to be used for investigations and intelligence gathers. Consult on the application of data science strategies and processes across a logical grouping of programs to ensure strategic alignment with agency objectives and reduce investment overlaps. Work under limited supervision and provide data science and analysis and program support across the Research and Development (R&D) program planning life cycle.
Basic Qualifications:
-Experience with the development, construction, maintenance, and testing of architectures, including databases and large-scale processing systems
-Experience with common scripting languages and tools, including R, programming languages, including Python, such as pandas, numpy, or scikit, SQL, MongoDB, Palantir, IBM Enterprise Insight Analysis (i2), Tableau, ArcGIS, or ArcMap
-Ability to create data set processes used in modeling, mining, acquisition, and verification
-Ability to comprehend and manipulate XML, KML, JSON, or HTM
-Ability to provide analysis of data sets resulting from test and evaluation events and operational exercises and summarize analysis to enable decision making, stakeholder engagement, or program planning and initiation
-Ability to manage program files and program management documentation with appropriate tagging and indexing for reference and records management
-Ability to research and investigate new or improved business and management practices for application to agency programs or operations and develop project plans, tasks, milestone dates, and schedules to ensure proper sequencing of budgets throughout program and project life cycles
-Ability to obtain a security clearance
-BA or BS degree
-Completion of Data Science and Analytics Certification and Training
Additional Qualifications:
-DHS Suitability clearance preferred
Clearance:
Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information.
We're an EOE that empowers our people--no matter their race, color, religion, sex, gender identity, sexual orientation, national origin, disability, or veteran status--to fearlessly drive change.
JHT
",https://www.clearancejobs.com/jobs/2979477/data-engineer-senior
JOB93308335363,Data Engineer,Data Engineer,,,"Description
First People Solutions are working on behalf of a leading building support services provider who are looking for experienced Data Cabling Engineers to join their team in London.
The main duties will include but is not limited to:
Data Cabling - Installation of Cat5E, Cat6, Cat6a. Testing cabling using Fluke DTX & DSX.
Fibre Cabling - Installation of fibre cabling. Ability to test fibre cabling using Fluke DTX & DSZ using multimode/single mode tester.
Voice Cabling - Ability to terminate/jumpering voice cabling within 237A Krone strips. Ability to test fibre cabling using Fluke DTX & DSZ data tester
Cabinet & Containment - Ability to install data cabinets & carry out containment.
General - Knowledge of Krone, Systimax, Brand-Rex etc
You must have the ability to work to your own initiative and be able to successfully complete tasks within given timescales. You must have a ECS Grade Card and hold a full clean driving licence.
If interested in the position please apply by attaching your CV or contact Rebecca on 0141 270 5130.
Type
Contract Length
Telephone
Job Reference
Job ID
",https://www.cv-library.co.uk/job/206241487/Data-Engineer
JOB93358970198,Data Engineer,Data Engineer,modern tech tools and hi-tech equipment.,"strong knowledge of SQL,,above average knowledge about statistical methods and predictive analysis,,experience in working with Big Data driven projects,,familiarity with data and text mining,,very meticulous, diligent and creative attitude to your work,,fluency in English is a must,,degree in a field related to data science (IT, mathematics, statistics, etc.),,high degree of individual initiative, strong analytical skills for understanding complex issues and, last but not least, the ability to challenge the status quo and proactively tackle problem areas.,you will translate your knowledge on topics such as data extraction and transformation, data modeling, data mining, crawling, parsing and predictive analytics into modern, customer-oriented solutions,,you develop the solution portfolio and the data universe for the kantwert-BusinessGraph with currently more than 100 million relationships between 5 million people and institutions,,you will be responsible for and implement Big Data projects for demanding customers from various industries within the framework of agreed quality, time and budget targets,,in coordination with Sales, Product, IT and Data Science, you play a decisive role in the data acquisition and maintenance processes and the international expansion of the data pool.,comfortable employment contract (you choose the type of agreement),,healthy work – life balance: home office, flexible working hours, 30 minutes lunch break included in 8 - hours working day,,medical care, gym card,,modern office in the center of Poznan,,integration events, fresh fruits, cookies and breakfast cereals, dining discount card,,time for self – development, German lessons, skilled and helpful team,,startup culture atmosphere with mature business approach,","
kantwert is a German start-up founded in 2014 which develops the social graph of European companies and the network of their decision makers. The information from public sources is consolidated to derive a ""who-knows-who"" application which is to help companies identify valuable relations within their existing customers.
Help us to achieve our objectives by using exciting technologies such as column-based data stores, graph databases and the message driven system. Be part of a young and motivated team, which uses the newest technologies and makes them reliable for economic use.
We are currently looking for a:
Data Engineer
Location: Poznań
Job requirements:
strong knowledge of SQL,
above average knowledge about statistical methods and predictive analysis,
experience in working with Big Data driven projects,
familiarity with data and text mining,
very meticulous, diligent and creative attitude to your work,
fluency in English is a must,
degree in a field related to data science (IT, mathematics, statistics, etc.),
high degree of individual initiative, strong analytical skills for understanding complex issues and, last but not least, the ability to challenge the status quo and proactively tackle problem areas.
Key responsibilities:
you will translate your knowledge on topics such as data extraction and transformation, data modeling, data mining, crawling, parsing and predictive analytics into modern, customer-oriented solutions,
you develop the solution portfolio and the data universe for the kantwert-BusinessGraph with currently more than 100 million relationships between 5 million people and institutions,
you will be responsible for and implement Big Data projects for demanding customers from various industries within the framework of agreed quality, time and budget targets,
in coordination with Sales, Product, IT and Data Science, you play a decisive role in the data acquisition and maintenance processes and the international expansion of the data pool.
We offer/Benefits we are provide:
comfortable employment contract (you choose the type of agreement),
healthy work – life balance: home office, flexible working hours, 30 minutes lunch break included in 8 - hours working day,
medical care, gym card,
modern office in the center of Poznan,
integration events, fresh fruits, cookies and breakfast cereals, dining discount card,
time for self – development, German lessons, skilled and helpful team,
startup culture atmosphere with mature business approach,
modern tech tools and hi-tech equipment.
Check our website and join us!
If you are willing to discuss the post, please send your application documents via ""Aplikuj""
Ogłoszenie archiwalne
","https://www.pracuj.pl/praca/data-engineer-poznan,oferta,7171407"
JOB96062158329,Data Engineer,Data Engineer,,,"
About the Role:
My client is one of the leading telecoms companies and they are looking for an experienced Engineer to Join their team on a project in Azerbaijan.
Requirements:
- HP Openview NMS Experience
- Duration 2 - 6 weeks
- 6 day working Sunday day of rest
- All flights and expenses covered
- Laptop and terminal cable
- Previous experience with BP
- Offshore certification
Please send your CV to: robert.mackie@spencer-ogden.com or call on: 0207 268 9263
For more information about this role please contact our London office
",https://www.epmag.com/node/1547951
JOB99276354634,Big Data Engineer,Big Data Engineer,Employee referral bonuses so you’ll get the opportunity to work with friends (and get some extra cash in your pocket!).,"Design and implement complex Big Data Platform based on requirements with possible technical solutions.,Willing to learn and understand business logic, and use that to continue to optimize/improve Big Data Platform to better support data processing requirements.,Discover any feasible new technologies lied in Big Data ecosystem, share them to team with your professional perspectives, apply them to production piece by piece for continue improvement, make it happen.,Be comfortable conducting detailed discussions with Data Analyst, other Big Data Engineers regarding specific questions related to specific new platform requirement.,Communicate well and clearly with teams oversea in both oral and written English.,A proficient engineer with minimal 1 year Linux or Big Data operation experience,Experience and knowledge of Cloud (AWS/Azure/Google Cloud/Ali), Virtualization or Containerization,Experience and knowledge of Big Data ecosystem (Hadoop/Hive/Pig/Spark/Presto/Storm/Heron/Flink and so on),Experience and knowledge of Operation Automation (Any of Salt/Puppet/Chef/Ansible),Experience and knowledge of Docker and K8S (is plus),Experience and knowledge of Monitoring & Logging system (is plus),Experience and knowledge of Security (is plus),Experience and knowledge of Database (MySQL/PostgreSQL/Redis/… is plus),Experience and knowledge of Distributed Storage (is plus),Experience and knowledge of CI/CD (is plus),Good English spoken and written skills (is plus),Good ability of communication.,Energy and creativity are key characteristics that describe you and the projects you are involved. You make it happen. Boom!,You’re an app fanatic, positively curious and a technology enthusiast.,Competitive compensation.,All the tech tools you need to succeed,Free breakfast & lunch, snacks, fruit, good coffee and other delicious treats to keep you well fed.,16 days of paid leave, so long as you promise to come back!,Great social & labor insurance packages to fit your needs to ensure you’re happy and healthy.,Commuter benefits that make getting to and from work a breeze.,Working a little later? We’ll cover your dinner and ride home.","
App Annie delivers data and insights to succeed in the app economy.
What can you tell your friends when they ask you what you do?
We’re looking for an experienced senior Big Data engineer who can create advanced Big Data platform to support innovative new products in the analytics and data space. You will participate to Big Data Infrastructure development that supports the world's #1 app stores analytics service. Together with the team you will build out advanced new data platform using agile methodologies and open source technologies. You will work directly with Big Data Architect, Staff Big Data Engineers and will be on the front lines of coding new and exciting analytics and data mining platform. You will be on the cutting edge of Big Data domain, have a chance to know and use any new possible technical stack.You should be passionate about what you do and excited to join an entrepreneurial start-up.
How will you be doing this?
As a Sr. Big Data Engineer, we will need you to be in charge of our data platform projects and to build clean, robust and maintainable Big Data Platform that can support projects processing PB-size data daily, this includes
Design and implement complex Big Data Platform based on requirements with possible technical solutions.
Willing to learn and understand business logic, and use that to continue to optimize/improve Big Data Platform to better support data processing requirements.
Discover any feasible new technologies lied in Big Data ecosystem, share them to team with your professional perspectives, apply them to production piece by piece for continue improvement, make it happen.
Be comfortable conducting detailed discussions with Data Analyst, other Big Data Engineers regarding specific questions related to specific new platform requirement.
Communicate well and clearly with teams oversea in both oral and written English.
What will you bring to the team?
A proficient engineer with minimal 1 year Linux or Big Data operation experience
Experience and knowledge of Cloud (AWS/Azure/Google Cloud/Ali), Virtualization or Containerization
Experience and knowledge of Big Data ecosystem (Hadoop/Hive/Pig/Spark/Presto/Storm/Heron/Flink and so on)
Experience and knowledge of Operation Automation (Any of Salt/Puppet/Chef/Ansible)
Experience and knowledge of Docker and K8S (is plus)
Experience and knowledge of Monitoring & Logging system (is plus)
Experience and knowledge of Security (is plus)
Experience and knowledge of Database (MySQL/PostgreSQL/Redis/… is plus)
Experience and knowledge of Distributed Storage (is plus)
Experience and knowledge of CI/CD (is plus)
Good English spoken and written skills (is plus)
Good ability of communication.
Energy and creativity are key characteristics that describe you and the projects you are involved. You make it happen. Boom!
You’re an app fanatic, positively curious and a technology enthusiast.
What are employees saying about App Annie?
“App Annie gives me a big imagination in mobile internet and my career development.”
“App Annie is like our home, we all feel comfortable and free to work here.”
What do we offer?
Competitive compensation.
All the tech tools you need to succeed
Free breakfast & lunch, snacks, fruit, good coffee and other delicious treats to keep you well fed.
16 days of paid leave, so long as you promise to come back!
Great social & labor insurance packages to fit your needs to ensure you’re happy and healthy.
Commuter benefits that make getting to and from work a breeze.
Working a little later? We’ll cover your dinner and ride home.
Employee referral bonuses so you’ll get the opportunity to work with friends (and get some extra cash in your pocket!).
Why choose App Annie?
App Annie delivers the most trusted app market data and insights for your business to succeed in the global app economy. Over 1 million registered members rely on App Annie to better understand the app market, their businesses and the opportunities around them. The company is headquartered in San Francisco with 450 employees across 15 global offices. App Annie has received $157 million in financing, including from investors such as Sequoia Capital, Institutional Venture Partners, IDG Capital Partners, e.ventures, Greenspring Associates, and Greycroft Partners.
App Annie does not accept unsolicited agency resumes. Any unsolicited agency resumes received will be treated as the property of App Annie, and App Annie will not be responsible for any fees related to such resumes.
App Annie is an equal opportunity employer. App Annie values diversity, and all employment decisions are made on the basis of job requirements and individual qualifications.
Yes, I want this job!
",https://boards.greenhouse.io/appannie/jobs/1407158
JOB103653192803,Data Engineer,Data Engineer,"A commitment to an open, inclusive, and diverse work culture","Competitive salary,Company equity,Health insurance (100% paid for individuals, 70% for families),401K,Generous vacation policy, plus company holidays,Flexible schedules","
Help Us Create the Future of Media
Axios is an early-stage news startup built around a simple proposition: Deliver the cleanest, smartest, most efficient and trustworthy experience for readers and advertisers alike. We have a leadership team of successful industry veterans with deep experience turning big ideas into reality. We're looking for a Data Engineer to join our small team to help us use data-driven methodologies to inform decisions and strategy, build robust scalable products and identify opportunities for innovation across the company.
Some more about you:
You want to create something new
The idea of coming in on the ground floor and getting to shape a new product from scratch gets your creative juices flowing. If you’re already in the media industry, maybe you see what’s not working well and would love the opportunity to make it better and introduce radically new ideas. You put emphasis on smart experimentation, agility and having fun.
You think deeply about possibilities and limitations of data
You are excited about the process of translating data into insights and know how to connect the details of a back-end data infrastructure to key performance indicators. You consistently evaluate data to drive progress. You are equally comfortable connecting to an API as you are communicating data-driven recommendations to cross-functional teams.
You have a box full of tools
You've been around a few challenging projects before, and have built up a set of skills along the way. You'll be gluing together systems that, in some cases, don't have clean and simple APIs available, so you've got a few different tricks up your sleeves to make everything work and to manage everything simply. These might include, but not be limited to: Python, bash/sh, R, DFP, AWS, SQL, and NoSQL databases like Cassandra and Mongo. You also have some experience with commercial measurement products like Google Analytics, Omniture, ComScore, or Chartbeat.
You are a patient teacher
You'll be the driving force behind creating and documenting our practices for analytics, measurement and audience development, and will collaborate across editorial, business, design and technology teams to engineer solutions to answer their most pressing questions. We won't do it all exactly right every time, so you'll need to be kind enough to guide us while being firm about how best to approach a solution.
You are a fast learner
You have a core set of technical skills, have shown you can use them in professional settings, and probably have a few favorite languages, frameworks, and methods. You also are totally willing to jump in, feet first, to evaluate and deploy new tools with which you're unfamiliar. You're eager to learn, a quick study, and can turn what you learned into clear documentation for others to build on.
You like working with other thoughtful people
You're the kind of technologist who loves the process of collecting, interpreting and disseminating data to translate questions into methodical frameworks and products. You enjoy working on distributed teams and are a fantastic communicator across every medium, from Slack to in-person. You thrive on new ideas and perspectives, because you know that a great team can accomplish so much more than one person can, no matter how talented they are.
Some more about us:
We are a small, flexible technology team who are building a whole new way of creating and distributing news. We're composed of veterans from marquee media companies and are excited to build a new one from the ground up. This opportunity is a unique one to have responsibility and oversight in a quickly-growing group.
We are a stable company. We have a large series A from top-flight VCs, and an A-list leadership team in place. We are serious about success and are looking for the best talent to join us on this journey.
Benefits:
Competitive salary
Company equity
Health insurance (100% paid for individuals, 70% for families)
401K
Generous vacation policy, plus company holidays
Flexible schedules
A commitment to an open, inclusive, and diverse work culture
",https://boards.greenhouse.io/axios/jobs/648236
JOB108303313871,Big Data Engineer-Scientist / Эксперт по большим данным,Big Data Engineer-Scientist / Эксперт по большим данным,"Upper intermediate knowledge of English;,Proficiency in R/Java/Python (numpy, scipy, matplotlib, pandas, sklearn).,Hands on experience with Kafka/ActiveMQ/RabbitMQ/Kestrel (or other message brokers) and Cassandra.,Understanding of Hadoop and/or MapReduce (or MPP systems), Apache Storm and Spark, Amazon AWS.,Knowledge of one or several NewSQL solutions - Drawntoscale, VoltDB, SpliceMachine, SQLFire, Impala, Redshift, Clustrix, NuoDB, Hadapt or other.,Skills in analysis of multi-dimensional datasets on production performance,Experience in predictive analytics, statistical analysis solutions development and data mining.,Knowledge of machine learning (k-NN, Naive Bayes, SVM, GBM, etc.) and artificial intelligence (AI).,Experience with common data science toolkits, such as R, Weka, Scikit-learn, Pandas.,Proficiency in NoSQL is strongly desired.,Proficiency in data lakes, enterprise data models.,Hands-on experience in digital twins of production processes.,Proficient in Linux, relational database design and methods for efficiently retrieving data,A degree in applied mathematics, computer science, physics or comparable fields.,Solid experience in custom ETL design, implementation and maintenance.,Great business sense (understanding of business metrics) and communication skills.,Experience in relevant positions is a strong plus.,Knowledge of scrum/agile/waterfall methodologies.,Ability to handle situations with numerous unknowns and set questions and tasks with little or no guidance.,Willingness to dive deep into the unstructured material to find an answer to a yet unknown question.,Ability to clearly communicate findings orally, in written and visually and come up with suggestions and advices.,Be able to work in fast-paced environment.,График работы 5/2;,Официальное трудоустройство, Cоцпакет;,Условия по заработной плате будут установлены по результатам собеседования.","В первую очередь - Team leader – Team leader группы инженеров/аналитиков big data, data-scientist’ов, создателей инструментов предиктивной аналитики. При этом нам нужен не просто менеджер-администратор, а человек, который сможет самостоятельно решать самые сложные задачи, связанные с big data, предиктивной аналитикой, data mining’ом;,Евангелиста цифровых технологий, просто и интересно рассказывающего о сложных вещах;,Start up - manager, запускающего пилотные проекты для апробации революционных идей (proof of concept);,Ключевого участника проекта создания первого в мире облака приложений (AppStore) для управления нефтепереработкой «под ключ» с использованием инструментов анализа больших данных, предсказательной аналитики, искусственного интеллекта (AI) и машинного обучения (ML);","
www.gazprom-neft.ru
ЭТА ПОЗИЦИЯ ДЛЯ ""ЧЕЛОВЕКА-ОРКЕСТРА"", КОТОРОМУ ПРЕДСТОИТ ВЫСТУПИТЬ В РОЛИ:
В первую очередь - Team leader – Team leader группы инженеров/аналитиков big data, data-scientist’ов, создателей инструментов предиктивной аналитики. При этом нам нужен не просто менеджер-администратор, а человек, который сможет самостоятельно решать самые сложные задачи, связанные с big data, предиктивной аналитикой, data mining’ом;
Евангелиста цифровых технологий, просто и интересно рассказывающего о сложных вещах;
Start up - manager, запускающего пилотные проекты для апробации революционных идей (proof of concept);
Ключевого участника проекта создания первого в мире облака приложений (AppStore) для управления нефтепереработкой «под ключ» с использованием инструментов анализа больших данных, предсказательной аналитики, искусственного интеллекта (AI) и машинного обучения (ML);
Мы ищем в свою команду людей, которые являются хорошими управленцами, что позволит им охватить проблему целиком, при этом являются специалистами в своей узкой предметной области. Перечень требований – модель компетенций идеального кандидата, но не обязательно знать все перечисленные технологии в совершенстве, по многим пунктам требований достаточно иметь базовые знания.
Requirements:
Upper intermediate knowledge of English;
Proficiency in R/Java/Python (numpy, scipy, matplotlib, pandas, sklearn).
Hands on experience with Kafka/ActiveMQ/RabbitMQ/Kestrel (or other message brokers) and Cassandra.
Understanding of Hadoop and/or MapReduce (or MPP systems), Apache Storm and Spark, Amazon AWS.
Knowledge of one or several NewSQL solutions - Drawntoscale, VoltDB, SpliceMachine, SQLFire, Impala, Redshift, Clustrix, NuoDB, Hadapt or other.
Skills in analysis of multi-dimensional datasets on production performance
Experience in predictive analytics, statistical analysis solutions development and data mining.
Knowledge of machine learning (k-NN, Naive Bayes, SVM, GBM, etc.) and artificial intelligence (AI).
Experience with common data science toolkits, such as R, Weka, Scikit-learn, Pandas.
Proficiency in NoSQL is strongly desired.
Proficiency in data lakes, enterprise data models.
Hands-on experience in digital twins of production processes.
Proficient in Linux, relational database design and methods for efficiently retrieving data
A degree in applied mathematics, computer science, physics or comparable fields.
Solid experience in custom ETL design, implementation and maintenance.
Great business sense (understanding of business metrics) and communication skills.
Experience in relevant positions is a strong plus.
Knowledge of scrum/agile/waterfall methodologies.
Personal traits:
Ability to handle situations with numerous unknowns and set questions and tasks with little or no guidance.
Willingness to dive deep into the unstructured material to find an answer to a yet unknown question.
Ability to clearly communicate findings orally, in written and visually and come up with suggestions and advices.
Be able to work in fast-paced environment.
Условия:
График работы 5/2;
Официальное трудоустройство, Cоцпакет;
Условия по заработной плате будут установлены по результатам собеседования.
",https://spb.hh.ru/vacancy/22416650
JOB109705361743,Clinical Data Engineer,Clinical Data Engineer,,"Read Codes and Clinical Terms Version 3,SNOMED CT,ICD10 and OPCS4,MedDRA,LOINC,Information Resources – performing upgrades to code editions or cross-maps.,Communications and Leadership – ability to provide and receive complex technical information instruction and advice relevant to the role, be courteous and provide effective service to support NWEH, clinical trial sponsors and other stakeholders in various projects.,Work with the Technical Architect to define the scope and content of data coding services and work with Database Administrators to produce automated ETLs, coding improvements and business intelligence reports to deliver the required outputs.,Assist IT support staff in troubleshooting data and coding issues in NWEH applications.,Partnership working – liaise with other members of NWEH technical, clinical and operational teams as necessary to ensure the data coding services are fit for purpose and available as required.,Analysis and data management – ensure the data coding updates and ETL processes are properly documented and understood, that systems are designed and in place to monitor data quality and categorisation against agreed targets and that the Data Dictionary and Mapper is properly documented to enable any problems to be quickly identified and corrected.,Research, Development and Audits – participate in audits of performance, quality, regulatory and operational effectiveness.,Degree in IT related field or equivalent experience,Experience of mapping between different clinical coding systems.,Experience of working with NHS medical data.,Experience of any relational database system.,Basic knowledge DML and SQL programming.,Basic knowledge of database modelling including referential integrity and DDL.,May be required to handle heavy objects infrequently,Required to use a VDU for long periods during the working day,Required to undertake prolonged concentration,Experience creating ETL (Extract, Transform and Load) processes.,Experience with data presentation models used on clinical trials e.g. CDISC SDTM,Experience with data standardisation models used in clinical data analytics e.g. OMOP Common Data Model.,Experience using R,Understanding of clinical governance/data handling/safety monitoring and reporting,Experience working on Computer System Validation.,Modern offices in Central Manchester,Competitive Salary,Flexible working hours,The ability to work from home,Child care vouchers,Excellent pension benefits,Access to training resources,27 day’s annual leave","
Clinical Data Engineer Job Description
Salary:
£31,000 – £40,000
Location: City Labs, Nelson St, Manchester M13 9NQ
Northwest EHealth (NWEH) are currently undergoing a significant expansion and are looking for talented, innovative and passionate data engineers. This is the chance to join an organisation who are at the forefront of pioneering how electronic healthcare data can be utilised to unlock the value of health and care data for the benefit of patients whilst enabling informed decision making to support and empower new models of clinical service delivery.
NorthWest EHealth (NWEH) is a limited company formed following a successful partnership between the University of Manchester, Salford Royal Foundation Trust and Salford Clinical Commissioning Group. Our customers are pharmaceutical companies and technology partners as well as NHS and government. We work collaboratively with partners to develop innovative ways of delivering improvements in health care and research. Major projects have included recruiting patients to studies, enabling ground-breaking real-world clinical trials and delivering real-time drug safety monitoring throughout trials. NWEH provides a highly creative and collaborative work environment, where knowledge sharing and team work are key to success. NWEH models its structure on a flat organisation, in which every voice is heard and collaboration across teams is key.
You will be joining our innovative and dynamic technical IT team, and will be responsible for supporting, developing and expanding the Data Dictionary and Mapper component of the NWEH Data Platform.
NWEH are looking for a Clinical Data Engineer with the ability to work independently without direct supervision, and be an adaptable and flexible team player. Out-of-hours emergency/urgent work may sometimes be required; you must be good at problem solving, have an eye for detail, and can plan, organise and prioritise work to meet deadlines.
As a Clinical Data Engineer, you will be responsible for maintaining and developing the systems that update the Data Dictionary, automating these processes and expanding the Data Dictionary to include new coding editions or other coding requirements. You will investigate coding issues in NWEH applications and develop processes that report issues proactively. You will be a good communicator and will work closely with the database, software development and statistician teams. You will take the lead in evaluating data standards, coding editions and implementation guides, both national and international. You will be familiar with the following coding systems:
Read Codes and Clinical Terms Version 3
SNOMED CT
ICD10 and OPCS4
MedDRA
LOINC
Other responsibilities:
Information Resources – performing upgrades to code editions or cross-maps.
Communications and Leadership – ability to provide and receive complex technical information instruction and advice relevant to the role, be courteous and provide effective service to support NWEH, clinical trial sponsors and other stakeholders in various projects.
Work with the Technical Architect to define the scope and content of data coding services and work with Database Administrators to produce automated ETLs, coding improvements and business intelligence reports to deliver the required outputs.
Assist IT support staff in troubleshooting data and coding issues in NWEH applications.
Partnership working – liaise with other members of NWEH technical, clinical and operational teams as necessary to ensure the data coding services are fit for purpose and available as required.
Analysis and data management – ensure the data coding updates and ETL processes are properly documented and understood, that systems are designed and in place to monitor data quality and categorisation against agreed targets and that the Data Dictionary and Mapper is properly documented to enable any problems to be quickly identified and corrected.
Research, Development and Audits – participate in audits of performance, quality, regulatory and operational effectiveness.
Required skills:
Degree in IT related field or equivalent experience
Experience of mapping between different clinical coding systems.
Experience of working with NHS medical data.
Experience of any relational database system.
Basic knowledge DML and SQL programming.
Basic knowledge of database modelling including referential integrity and DDL.
May be required to handle heavy objects infrequently
Required to use a VDU for long periods during the working day
Required to undertake prolonged concentration
Desirable but not essential skills include:
Experience creating ETL (Extract, Transform and Load) processes.
Experience with data presentation models used on clinical trials e.g. CDISC SDTM
Experience with data standardisation models used in clinical data analytics e.g. OMOP Common Data Model.
Experience using R
Understanding of clinical governance/data handling/safety monitoring and reporting
Experience working on Computer System Validation.
Benefits:
Modern offices in Central Manchester
Competitive Salary
Flexible working hours
The ability to work from home
Child care vouchers
Excellent pension benefits
Access to training resources
27 day’s annual leave
",https://jobs.theguardian.com/job/6489787/clinical-data-engineer/?LinkSource=PremiumListing
JOB109974042978,Data Engineer,Data Engineer,,"Previous experience as a Data Engineer working in a fast-paced agile development environment, ideally within a digital organisation.,Be an expert in deploying the appropriate data design techniques to solve a wide range of complicated problems and will understand industry best practices around web traffic data.,Significant database design and data modelling experience on multiple platforms (Oracle, MySQL, Teradata, Vertica, and Redshift) and possess the ability to work well with technical partners and business end users.,Strong interpersonal, leadership and customer service skills and will be a proven team player with an enthusiasm for new technologies and keeping up to date within your field.","
Data Engineer
King's Cross, Central London
Competitive Salary
Education Level: Postgraduate degree (senior business/technical)
Guardian News & Media Ltd. is one of the most successful and innovative media organisations in the world, renowned for leading edge journalism, product and commercial development, and famous for nurturing talented individuals.
The Guardian is committed to a ""digital-first"" strategy and in order to contribute towards this strategy, we're seeking an experienced Data Engineer to be responsible for supporting, building and enhancing the core enterprise-wide data platform and supporting the needs of the Data & Insights Team.
On a daily basis you’ll be responsible for the development of the AWS Redshift-based data gathering and analysis platform as well as directing the prioritisation and allocation of data engineering resources. You will work with the team to create and drive innovation in the areas of data transformation and load, cloud based data base work and efficient front end reporting.
You’ll have
Previous experience as a Data Engineer working in a fast-paced agile development environment, ideally within a digital organisation.
Be an expert in deploying the appropriate data design techniques to solve a wide range of complicated problems and will understand industry best practices around web traffic data.
Significant database design and data modelling experience on multiple platforms (Oracle, MySQL, Teradata, Vertica, and Redshift) and possess the ability to work well with technical partners and business end users.
Strong interpersonal, leadership and customer service skills and will be a proven team player with an enthusiasm for new technologies and keeping up to date within your field.
And, of course, you’ll have a genuine desire to contribute to the Guardian’s future success, and share in our goals and values.
Does this all sound like you? Then we’d love to hear from you!
To apply, please upload your latest CV and a cover letter that outlines why you’d like to take on this role, and why you’re a great match for what we’re looking for.
We value and respect all differences in all people (seen and unseen) at the Guardian. We aspire to inclusive working experiences and an environment that reflects the audience we serve, where our people have equal access to career development opportunities, their voices are heard and can contribute to our future.
About GUARDIAN NEWS AND MEDIA
Guardian News & Media (GNM) publishes theguardian.com, one of the largest English-speaking quality newspaper websites in the world. Since launching US and Australian digital editions in 2011 and 2013 respectively, traffic from outside of the UK now represents over two-thirds of the Guardian's total digital audience.
In the UK, GNM publishes the Guardian newspaper six days a week, first published in 1821, and the world's oldest Sunday newspaper, The Observer.
GNM is the core business of Guardian Media Group (GMG), whose sole shareholder is The Scott Trust Ltd. The core purpose of The Scott Trust is to secure the financial and editorial independence of the Guardian in perpetuity.
",https://jobs.theguardian.com/job/6842619/data-engineer/
JOB111325404240,Apply to: Specialized Software/Data Engineer,Apply to: Specialized Software/Data Engineer,,,"
Employer: NES Associates, LLC
To apply for this job, please check the box below. This step helps prevent unfair use of automated programs. To avoid this in the future, please either log in with your existing credentials or register with ClearanceJobs.com.
",https://www.clearancejobs.com/jobs/2256615/apply
JOB111477345222,Principal Data Engineer,Principal Data Engineer,"Bachelors degree in Computer Engineering, Computer Science or related discipline, Masters Degree preferred,10+ years of ETL design, development, and performance tuning on Microsoft SSIS in SQL Server 2012 and above (2016 preferable) in a multi-dimensional Data Warehousing environment,10+ years of SSAS design, development, maintenance and performance tuning on Microsoft SQL Server 2012 and above (2016 preferable), with expert MDX and DAX skills,10+ years of advanced SQL Programming: PL/SQL, T-SQL, U-SQL,7+ years of Enterprise Data & Analytics solution architecture,2+ years of Power BI experience including mobile solutions,2+ years of strong and extensive hands on experience in Azure, preferably data heavy / analytics applications leveraging relational and NoSQL databases, Data Warehouse and Big Data,Experience with Azure Data Lake, Azure SQL Data Warehouse, Data Catalog, Azure Analysis Services, Data Bricks, Storage Account Gen2, Azure SQL Database, Azure DNS, Virtual Network, DocumentDB, Azure App Service, Data Factory,Experience with Big Data Technologies such as: Hadoop, Sqoop, Hive, Kafka, Spark, Pyspark, Python, Scala or Pig,Experience with Big Data Management (BDM) for relational and non-relational data (formats like json, xml, avro, parquet, copybook, etc.),Experience with setting up and operating data pipelines using Python or SQL,Strong analytical abilities and a strong intellectual curiosity","Advises management and customers on scalable enterprise analytics solutions that provide the business with a competitive advantage.,Works on unusually complex technical problems and provides solutions which are highly innovative and ingenious.,Design and build a modern data warehouse in the cloud,Design and build a customer 360,Implement a flexible and audible data pipeline,Enhance data collection procedures to build analytic systems.,Process, cleanse, and verify the integrity of data used for analysis.,Perform ad-hoc analysis and present results in a clear and user friendly manner,Perform testing, resolve issues and automate unit tests.,Develop proof-of-concept (POC) solutions to help business units better visualize their business needs and to clarify requirements for development.","
For 70 years, Charles River employees have worked together to assist in the discovery, development and safe manufacture of new drug therapies. When you join our family, you will have a significant impact on the health and well-being of people across the globe. Whether your background is in life sciences, finance, IT, sales or another area, your skills will play an important role in the work we perform. In return, well help you build a career that you can feel passionate about.
Job Summary
We are seeking an experienced Principal Data Engineer for our IT Analytics Delivery Team located in Wilmington, MA.
Theres never been a more exciting time to be on the Analytics team at Charles River Labs! We are on an exciting journey to modernize the data landscape. If you are an engineer who enjoys cloud technologies, data warehousing, data analytics, and designing innovative analytical solutions, this job may be for you!
The team is seeking top notch talent in the Microsoft Azure full data stack and modern data toolset. If you are interested in using your leadership, expertise and innovative skills to build something brand new, enjoy making architectural decisions, are a thought leader in the data space, have a passion for data and analytics, and like to mentor others, then we want to talk to you! A truly exciting and unique opportunity awaits you!
This role will work collaboratively, in a consultative way, across the business units and IT, building modern analytics solutions, supporting and mentoring engineering teams, as well as advising on best approaches to leveraging Azure in the most effective and efficient manner.
The following are responsibilities related to the Principal Data Engineer:
Advises management and customers on scalable enterprise analytics solutions that provide the business with a competitive advantage.
Works on unusually complex technical problems and provides solutions which are highly innovative and ingenious.
Design and build a modern data warehouse in the cloud
Design and build a customer 360
Implement a flexible and audible data pipeline
Enhance data collection procedures to build analytic systems.
Process, cleanse, and verify the integrity of data used for analysis.
Perform ad-hoc analysis and present results in a clear and user friendly manner
Perform testing, resolve issues and automate unit tests.
Develop proof-of-concept (POC) solutions to help business units better visualize their business needs and to clarify requirements for development.
Qualifications
The following are minimum requirements related to the Principal Data Engineer position:
Bachelors degree in Computer Engineering, Computer Science or related discipline, Masters Degree preferred
10+ years of ETL design, development, and performance tuning on Microsoft SSIS in SQL Server 2012 and above (2016 preferable) in a multi-dimensional Data Warehousing environment
10+ years of SSAS design, development, maintenance and performance tuning on Microsoft SQL Server 2012 and above (2016 preferable), with expert MDX and DAX skills
10+ years of advanced SQL Programming: PL/SQL, T-SQL, U-SQL
7+ years of Enterprise Data & Analytics solution architecture
2+ years of Power BI experience including mobile solutions
2+ years of strong and extensive hands on experience in Azure, preferably data heavy / analytics applications leveraging relational and NoSQL databases, Data Warehouse and Big Data
The following are strongly desired:
Experience with Azure Data Lake, Azure SQL Data Warehouse, Data Catalog, Azure Analysis Services, Data Bricks, Storage Account Gen2, Azure SQL Database, Azure DNS, Virtual Network, DocumentDB, Azure App Service, Data Factory
Experience with Big Data Technologies such as: Hadoop, Sqoop, Hive, Kafka, Spark, Pyspark, Python, Scala or Pig
Experience with Big Data Management (BDM) for relational and non-relational data (formats like json, xml, avro, parquet, copybook, etc.)
Experience with setting up and operating data pipelines using Python or SQL
Strong analytical abilities and a strong intellectual curiosity
About Corporate Functions
The Corporate Functions provide operational support across Charles River in areas such as Human Resources, Finance, IT, Legal, Sales, Quality Assurance, Marketing, and Corporate Development. They partner with their colleagues across the company to develop and drive strategies and to set global standards. The functions are essential to providing a bridge between strategic vision and operational readiness, to ensure ongoing functional innovation and capability improvement.
About Charles River
Charles River is an early-stage contract research organization (CRO). We have built upon our foundation of laboratory animal medicine and science to develop a diverse portfolio of discovery and safety assessment services, both Good Laboratory Practice (GLP) and non-GLP, to support clients from target identification through preclinical development. Charles River also provides a suite of products and services to support our clients clinical laboratory testing needs and manufacturing activities. Utilizing this broad portfolio of products and services enables our clients to create a more flexible drug development model, which reduces their costs, enhances their productivity and effectiveness to increase speed to market.
With over 14,000 employees within 80 facilities in 20 countries around the globe, we are strategically positioned to coordinate worldwide resources and apply multidisciplinary perspectives in resolving our clients unique challenges. Our client base includes global pharmaceutical companies, biotechnology companies, government agencies and hospitals and academic institutions around the world. And in 2018, revenue increased by 22% to $2.27 billion from $1.86 billion in 2017.
At Charles River, we are passionate about our role in improving the quality of peoples lives. Our mission, our excellent science and our strong sense of purpose guide us in all that we do, and we approach each day with the knowledge that our work helps to improve the health and well-being of many across the globe. We have proudly supported the development of ~85% of the drugs approved by the FDA in 2018.
Equal Employment Opportunity
Charles River Laboratories is an Equal Opportunity Employer - M/F/Disabled/Vet
",https://jobs.newscientist.com/job/1401675531/-principal-data-engineer-/
JOB114080098687,Junior Big Data Engineer/Developer,Junior Big Data Engineer/Developer,,"Assembling large, complex data sets that meet business requirements,Identifying, designing, and implementing internal process improvements: including process automation, optimizing data delivery, etc.,Designing optimal ETL infrastructures from variety of data sources,Building analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.,Big Data, including the Hadoop Ecosystem, NoSQL approaches and Cloud Data Management.,Data warehousing and BI (incl. SQL / Data Modelling, Data Integration, Data Governance),Thorough understanding of the capabilities of commercial Apache Hadoop distributions such as e.g. Hortonworks, Cloudera, or MapR,Experience in estimating, planning and managing data integration aspects of implementation projects.,At least 2 years of overall relevant IT experience.,At least 1 years experience with Big Data projects (using Hadoop, SQL, ETL, and/or similar technologies),At least 1 year experience with data engineering / data integration in the Big Data, Analytics, Business Intelligence and/or Data Warehousing domain,Experience with custom application development/enhancements using relevant technologies (i.e. Python, JSON, SQL, NoSQL, Unix/Linux scripting, Hadoop, HortonWorks, Cloudera, etc),Experience of a data warehouse environment and knowledge of existing and emerging data integration approaches,Experience with Watson Discovery/Conversation/Knowledge Studio,Experience with SSIS,Custom application development using technologies such as Python, JSON, SQL, NoSQL, Unix/Linux scripting, Hadoop, HortonWorks, Cloudera, Hibench, etc,Data architecture experience of designing and developing data models- Understanding of -Distributed computing design patterns and algorithms and data structures and security protocols,Involved primarily in coding, debugging and unit testing of applications,API experience, multithreading is a plus,May be involved in conceptual technology phase","
IBM Global Business Services (GBS) is a team of business, strategy and technology consultants enabling enterprises to make smarter decisions and providing unparalleled client and consumer experiences in cognitive, data analytics, cloud technology and mobile app development. With global reach, outcome-focused methodologies and deep industry expertise, IBM GBS empowers clients to digitally reinvent their business and get the competitive edge in the cognitive era in over 170 countries.
Bottom line? We outthink ordinary. Discover what you can do at IBM.
As a Big Data Engineer, you will work with various technology assets and frameworks built on open source and enterprise Big Data technologies by IBM Global Business Services (GBS) and apply them to projects that create high business impact. You will gain valuable knowledge and insights from thought leaders on cognitive technologies.
The role focuses on the elements required to manage data and information (both structured and unstructured) from business requirements to logical and physical design. You will be delivering solutions in the Big Data, Analytics, Business Intelligence and/or Data Warehousing domain at our clients. The Data Engineer defines data integration best practices in the critical evaluation and selection and/or development of the software components of the solution. Data Engineers are also responsible for the distribution of data and designing centralized and/or distributed systems that both address the business requirements and perform efficiently and effectively.
Responsibilities will likely include:
Assembling large, complex data sets that meet business requirements
Identifying, designing, and implementing internal process improvements: including process automation, optimizing data delivery, etc.
Designing optimal ETL infrastructures from variety of data sources
Building analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Working with executive, LOB, design and IT stakeholders on data-related technical issues and infrastructure needs
Experience from system integration projects based on the leading software products in the big data, business intelligence and analytics area is needed e.g.:
Big Data, including the Hadoop Ecosystem, NoSQL approaches and Cloud Data Management.
Data warehousing and BI (incl. SQL / Data Modelling, Data Integration, Data Governance)
Thorough understanding of the capabilities of commercial Apache Hadoop distributions such as e.g. Hortonworks, Cloudera, or MapR
Experience in estimating, planning and managing data integration aspects of implementation projects.
Experience with technologies such as: Spark, Sqoop, Pig, Hive, Kafka, Hibench, YCSB, Informatica, Ab Inititio, Talend, etc
IBM is market leader in the data & analytics space. We offer a dynamic, innovative and international environment which is fueled by projects with leading clients, unique capabilities such as IBM Research & Development and IBM Watson, and a growing ecosystem of partnerships such as those with Apple and Twitter. If you think you have the skill and the attitude to change the way that business is conducted – IBM is the place for you and will offer you numerous opportunities for growth across the company.
Successful candidates for these positions will work onsite at the IBM Client Innovation Center in Baton Rouge. The IBM Client Innovation Center is an in-bound delivery model where we support our clients from our Baton Rouge center. However, some travel is expected and all candidates must be willing and able to travel to meet our client needs across the US. Travel is typically related to knowledge transfer and training at the client site (Monday thru Friday). You are expected to travel up to 50% of the time. This is a traditional office position. You must live in, or be willing to relocate to, Louisiana. The work location is 100 North Street Baton Rouge, LA 70802. This is not a work from home position.
BENEFITS
Health Insurance. Paid time off. Corporate Holidays. Sick leave. Family planning. Financial Guidance. Competitive 401K. Training and Learning. We continue to expand our benefits and programs, offering some of the best support, guidance and coverage for a diverse employee population.
CAREER GROWTH
Our goal is to be essential to the world, which starts with our people. Company wide we kicked off an internal talent strategy program called Go Organic. At our core, we are committed to believing and investing in our workforce through:
Skill development: helping our employees grow their foundational skills
Finding the dream job at IBM: navigating our company with the potential for many careers by channeling an employee’s strengths and career aspirations
Diversity of people: Diversity of thought driving collective innovation
In 2015, Go Organic filled approximately 50% of our open positions with internal talent that were promoted into the role.
CORPORATE CITIZENSHIP
With an employee population of 375,000 in over 170 countries, amazingly we connect, collaborate, and care. IBMers drive a corporate culture of shared responsibility. We love grand challenges and everyday improvements for our company and for the world. We care about each other, our clients, and the communities we live, work, and play in!
No Visa sponsorship opportunities exist for this position.
gbscicbr
Required Technical and Professional Expertise
At least 2 years of overall relevant IT experience.
At least 1 years experience with Big Data projects (using Hadoop, SQL, ETL, and/or similar technologies)
At least 1 year experience with data engineering / data integration in the Big Data, Analytics, Business Intelligence and/or Data Warehousing domain
Experience with custom application development/enhancements using relevant technologies (i.e. Python, JSON, SQL, NoSQL, Unix/Linux scripting, Hadoop, HortonWorks, Cloudera, etc)
Experience of a data warehouse environment and knowledge of existing and emerging data integration approaches
Integration of Big Data to a traditional data architecture
Preferred Technical and Professional Experience
Experience with Watson Discovery/Conversation/Knowledge Studio
Experience with SSIS
Custom application development using technologies such as Python, JSON, SQL, NoSQL, Unix/Linux scripting, Hadoop, HortonWorks, Cloudera, Hibench, etc
Data architecture experience of designing and developing data models- Understanding of -Distributed computing design patterns and algorithms and data structures and security protocols
Involved primarily in coding, debugging and unit testing of applications
API experience, multithreading is a plus
May be involved in conceptual technology phase
Would be an Additional Plus: Quality control and assurance services for custom applications for e.g. (test case development and execution for unit, functional, system and regression testing)
Up to 50% or 3 days a week (home on weekends - based on project requirements)
Skill-keywords
Big Data, SQL, hadoop, squoop, pig, python, data engineer, hortonworks, cloudera, business intelligence, cognitive, analytics, Watson
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
",https://krb-sjobs.brassring.com/TGnewUI/Search/home/HomeWithPreLoad?PageType=JobDetails&partnerid=26059&siteid=5016&Areq=191430BR
JOB115024594677,Data Engineer,Data Engineer,"Ability to work with large amounts of data,Experience with map-reduce frameworks - Hive, Hadoop and Spark (Elastic Map Reduce would be a plus),Strong grasp of statistics, data modelling and designing algorithms,Cloud service credits (AWS, Google Cloud, Azure, Digital Ocean),Public Transit allowance,Mobile data allowance,Flex days,Tea/Coffee Bar,In-office Snacks","Understand our current data sets and models and help us discovering new ways to enrich the data,Creatively extracting real-world behaviour and trends out of the location data,Monitor and build processes for cleaning up inbound data,Dream up a solution, perform the R&D and deploy to production within our fluid work environment","Data engineering at EQ means you're working in the hottest areas of today's technology landscape; machine learning, big data engineering and rich (location) data sets. You will be coming up with solutions to derive actionable insights about behaviour, demographics, and personality out of our multi-terabyte dataset of location data. Examples of the type of analysis we do include; understanding what university students do during summer holidays, predicting if someone is about to buy a house based on places they visit or trying to understand someone at the airport is a business or leisure traveller.
Your role will involve working very closely with our CTO, data scientists and the extended product team. With EQ leading the pack when it comes to location ad analytics in Canada and a top North American player - this role would let you define and shape the standards in this very vibrant and evolving industry.
Understand our current data sets and models and help us discovering new ways to enrich the data
Creatively extracting real-world behaviour and trends out of the location data
Monitor and build processes for cleaning up inbound data
Dream up a solution, perform the R&D and deploy to production within our fluid work environment
Requirements
Ability to work with large amounts of data
Experience with map-reduce frameworks - Hive, Hadoop and Spark (Elastic Map Reduce would be a plus)
Strong grasp of statistics, data modelling and designing algorithms
Benefits
Cloud service credits (AWS, Google Cloud, Azure, Digital Ocean)
Public Transit allowance
Mobile data allowance
Flex days
Tea/Coffee Bar
In-office Snacks
",https://ca.indeed.com/viewjob?jk=ef9fe866b1ba2506&q=EQ+Works&l=Ontario&tk=1cnafoj380mpu24u&from=web&vjs=3
JOB117116002223,Senior Data Engineer,Senior Data Engineer,Hackathons,"Hands-on leadership, influence, and development of all things data services.,Develop modern data architectural approaches for business intelligence reporting and analytics, including that for machine learning models and data science, ensuring effectiveness, scalability, and reliability.,Design, develop, implement, and optimize existing ETL processes that merge data from disparate sources for consumption by data analysts and scientists, business owners, and decisions makers.,Complete current evaluation of new ETL software options, propose recommendations, and implement the solution.,Facilitate data transformation, normalization, cleansing, aggregation, workflow management, and business rule application.,Detect data quality issues, identify their root causes, implement fixes, and design data audits to capture issues.,Distill technical requirements into the product development and operational process via continuous collaboration with product, engineering, and analytics team members.,Influence and communicate with all levels of stakeholders including analysts, developers, business users, and executives.,Use analytics to influence product development, surfacing data around product usage and customer behavior.,ETL tool evaluation and implementation to prepare for scaling and efficiency.,2+ years of hands-on experience in collection, mining, reporting, and analysis of large amounts of data,Experience designing and implementing database tables, as well as performance profiling and tuning of database processes and table usage,Experience in a variety of data storage platforms (MySQL, Postgres, Oracle, Redshift, RDS),Experience as a Data Engineer or related role (Data Warehouse Developer, ETL Developer, Business Intelligence Analytics, Software Engineer) with a track record of manipulating, processing and extracting value from datasets,Advanced proficiency in SQL,Experience designing and developing ETL processes in a variety of platforms (Pentaho, Microstrategy, Talend, CloverETL, FiveTran, Stitch),Experience with analytics platforms (Google Analytics, Mixpanel, etc.),Experience with log aggregation and extraction (Elasticsearch) and Business Intelligence reporting tools (Tableau, etc.) a plus,Proven track record of innovation and expertise in data engineering,Tenure in architecting and delivering complex projects,Deep understanding and application of modern data processing technology and real-time/low-latency data pipeline and ETL architectures,Strong stakeholder interaction and influence experience at executive, business stakeholder, and engineering team levels,Blinker Inc. does not currently provide Visa sponsorship,Competitive pay + equity,Paid/flexible time off,Comprehensive medical, dental, vision, disability, life insurance, and parental leave benefits,401K Plan,Paid covered parking in Tabor Center garage or RTD transportation,Fully stocked kitchen with free snacks, beverages, & cold brew coffee on tap,Regularly recurring, company-side social activities (e.g. BBQ lunches on patio and afternoon happy hours)","
Why work with us:
Blinker is a Denver-based mobile app that puts people in control of car ownership. We started our company because we believe the used car market has a major consumer problem – each year, twenty eight million people in the US buy or sell a car at the dealership and lose thousands of dollars in every transaction. Blinker is the only company that allows anyone to sell a car with a lien, buy a car with financing or refinance a car, all on their own with their mobile device.
Our CEO, Rod Buscher, founded Blinker in 2013. Today, Blinker's leadership team carries 170 years of collective automotive and lending experience. Blinker has received over 100,000 downloads and originated millions of dollars in auto loans. We’ve also won a 2017 SXSW Interactive Innovation Award, Colorado Biz Top Company Award, Telly Award, as well as been named a “Gazelle” by the Denver Office of Economic Development and a Colorado Company to Watch.
We’re looking for talented people to help us scale our business and serve a nationwide audience from our headquarters in downtown Denver. We’re a passionate, smart, and driven group, working together to cause some major market disruption. You could be part of that. If you’re eager and ready to work alongside inspiring teammates and make a major, positive impact on our business each and every day, we want you to join us.
Summary of what you'll do:
As a senior data engineer, you will own and architect Blinker’s data landscape. You will combine product usage, behavioral, transactional, business systems, and third-party data into the analytics pipeline. You will work closely with our analytics and engineering teams to implement solutions to answer complex questions and drive business decisions.
What is expected of you:
Hands-on leadership, influence, and development of all things data services.
Develop modern data architectural approaches for business intelligence reporting and analytics, including that for machine learning models and data science, ensuring effectiveness, scalability, and reliability.
Design, develop, implement, and optimize existing ETL processes that merge data from disparate sources for consumption by data analysts and scientists, business owners, and decisions makers.
Complete current evaluation of new ETL software options, propose recommendations, and implement the solution.
Facilitate data transformation, normalization, cleansing, aggregation, workflow management, and business rule application.
Detect data quality issues, identify their root causes, implement fixes, and design data audits to capture issues.
Distill technical requirements into the product development and operational process via continuous collaboration with product, engineering, and analytics team members.
Influence and communicate with all levels of stakeholders including analysts, developers, business users, and executives.
Use analytics to influence product development, surfacing data around product usage and customer behavior.
ETL tool evaluation and implementation to prepare for scaling and efficiency.
Your skills and experience:
2+ years of hands-on experience in collection, mining, reporting, and analysis of large amounts of data
Experience designing and implementing database tables, as well as performance profiling and tuning of database processes and table usage
Experience in a variety of data storage platforms (MySQL, Postgres, Oracle, Redshift, RDS)
Experience as a Data Engineer or related role (Data Warehouse Developer, ETL Developer, Business Intelligence Analytics, Software Engineer) with a track record of manipulating, processing and extracting value from datasets
Advanced proficiency in SQL
Experience designing and developing ETL processes in a variety of platforms (Pentaho, Microstrategy, Talend, CloverETL, FiveTran, Stitch)
Experience with analytics platforms (Google Analytics, Mixpanel, etc.)
Experience with log aggregation and extraction (Elasticsearch) and Business Intelligence reporting tools (Tableau, etc.) a plus
Proven track record of innovation and expertise in data engineering
Tenure in architecting and delivering complex projects
Deep understanding and application of modern data processing technology and real-time/low-latency data pipeline and ETL architectures
Strong stakeholder interaction and influence experience at executive, business stakeholder, and engineering team levels
Additional Information:
Blinker Inc. does not currently provide Visa sponsorship
What we offer to you:
Competitive pay + equity
Paid/flexible time off
Comprehensive medical, dental, vision, disability, life insurance, and parental leave benefits
401K Plan
Paid covered parking in Tabor Center garage or RTD transportation
Fully stocked kitchen with free snacks, beverages, & cold brew coffee on tap
Regularly recurring, company-side social activities (e.g. BBQ lunches on patio and afternoon happy hours)
Hackathons
",https://www.builtincolorado.com/job/data/senior-data-engineer/42477
JOB117786868085,Senior Software Developer (Senior Data Engineer),Senior Software Developer (Senior Data Engineer),,"develop data processing software, including designing, coding and testing,work collaboratively in a cross-functional team to deliver quality software,mentor others, sharing technical knowledge and providing guidance and support,communicate effectively with managers, peer developers, testers, business analysts, product owners and scrum masters,experience with distributed data-processing technologies such as Apache Hadoop, Apache Spark and key-value stores,experience in open-source technologies including JVM languages and Python,experience of cloud architecture,a good understanding of ETL/ELT data-processing pipelines,experience of developing multiple large-scale data-processing solutions,a good understanding of NoSQL data stores,experience of data modelling with RDBMS and NoSQL data stores","
We're looking for a Senior Software Developer with experience in data projects to join the Software Development team at Wellcome.
About the role
In this role, you will lead a team to design and build products which use data to evidence the success of Wellcome's funding and identify new opportunities to achieve Wellcome's aims. You will work with a strong cross-functional product team to provide innovative technical solutions to meet the needs of the organisation.
You will:
develop data processing software, including designing, coding and testing
work collaboratively in a cross-functional team to deliver quality software
mentor others, sharing technical knowledge and providing guidance and support
communicate effectively with managers, peer developers, testers, business analysts, product owners and scrum masters
About you
To succeed, you'll need:
experience with distributed data-processing technologies such as Apache Hadoop, Apache Spark and key-value stores
experience in open-source technologies including JVM languages and Python
experience of cloud architecture
a good understanding of ETL/ELT data-processing pipelines
experience of developing multiple large-scale data-processing solutions
a good understanding of NoSQL data stores
experience of data modelling with RDBMS and NoSQL data stores
About us
We believe great ideas can change the world and improve health for everyone. At Wellcome, we help great ideas to thrive by supporting scientists and researchers, taking on big problems, fuelling imaginations and sparking debate.
Wellcome isn't just a supporter of great ideas; it's a great place to work. We offer excellent benefits and help our employees to develop in an open, respectful culture where differences are valued.
",https://jobs.theguardian.com/job/6627201/senior-software-developer-senior-data-engineer-/
JOB119659100498,Senior Data Engineer,Senior Data Engineer,,,"
Plan International UK is a global children’s charity. We work to give every child the same chance in life.
Our IT department supports our mission by providing the right technologies and information services across our fundraising, campaigns, communications, policy and programming teams and for our support services. The department is responsible for the overall use of information and technology in the organisation and it delivers a portfolio of high-quality IT services as well as an ambitious technology development programme to support business optimisation, innovation and growth.
We are recruiting a Senior Data Engineer to join the team and lead the development of quality solutions to meet business needs. In the role, you will act as technical lead on organisation projects, leading the design and development of data structures, processes and solutions that improve the use of business systems and deliver a better supporter experience. You will oversee the development standards used by the rest of the team, implement data handling processes, and support the effective use of reports and data sets.
You will have experience of administering SQL Server databases, SQL query tuning and optimisation plus knowledge of Share Point, Power Pivot and solution development frameworks such as TOGAF. You will be able to abstract user requirements into technical deliverables that incorporate the principles of data legislation, and explain technical concepts to technical and non-technical audiences at all levels.
The deadline for applications is 9:00am on Tuesday 12 March 2019.
First round interviews will take place on Wednesday 27 March 2019.
Second round interviews will take place on Friday 29 March 2019.
Due to the nature of our work with children, we follow rigorous child protection policies and procedures in our recruitment process. As a result, some of our roles are subject to an Enhanced Disclosure by the Disclosure and Barring Service. A criminal record will not necessarily bar you from joining us as an employee or volunteer; this will depend on the circumstances of any offences.
",https://jobs.theguardian.com/job/6866730/senior-data-engineer/
JOB120695634274,Big Data Engineer - Cambridge,Big Data Engineer - Cambridge,,,"
A world renowned game development company have retained Nakama London to help them find an experienced Data Engineer. The company have an excellent reputation within their industry and have been growing steadily over many years. At present, there is an exceptional Data Science Team in place. This role would sit alongside that team and help architect and implement robust scalable pipelines.
Key Skills:
- Python
- Java
- SQL
- Experience with AWS
- Interest in gaming hugely beneficial
Location: Cambridgeshire
Salary: Up to £65k per annum
For more information, please get in touch with Eimear Walsh at Nakama London ewalsh@nakamalondon.com.
",https://jobs.theguardian.com/job/6454991/big-data-engineer-cambridge/
JOB121983580524,Senior Data Engineer,Senior Data Engineer,"Analysing problem domains to identify entities and data flows,Designing and implementing efficient & scalable data models,Automating the provisioning and management of data platforms,Familiarity with RDBMS, NoSQL and Distributed data technologies,End-to-end involvement in software delivery,Working with production systems,Ownership of a product or set of features within a product,A range of software delivery tools (source control, agile tools, CI etc.),Implementing and following best practices,Effective prioritisation of tasks and personal time management,Producing estimates for self and others,Demonstrating initiative,Coaching and mentoring more junior team members,Interacting with clients and/or product owners,Degree in computer science related discipline,Delivering in a highly collaborative agile environment,Understanding of blockchain technologies",,"
Who we are looking for
At PwC you’ll get to work with the largest, most recognisable clients in the world.
We are rapidly building out our team of digital product delivery specialists and we are looking for individuals who will play a key role in achieving our mission of helping clients thrive in the digital age.
We're looking for people who will think outside the box, not settling for the status quo and who will look to create impact from day one.
About the role
As a senior data engineer within PwC you will form an integral part in the delivery of digital solutions to meet the needs of our clients. In PwC’s agile delivery team, you will be designing and building solutions, which keep our clients at the forefront of digital technologies and ahead of their competitors.
You will utilise best practices such as Polyglot Persistence, Continuous Integration, Continuous Delivery, Test-Driven Development and peer review, and be involved in end-to-end software delivery.
A senior data engineer will be able to lead small teams of engineers to design and build highly-performing, resilient and scalable data platforms to meet business requirements. The desire to learn, understand and act to build systems that efficiently harness data in its various forms is key.
Some level of travel will be required for this role.
Requirements:
The Senior Data Engineer should have experience of:
Analysing problem domains to identify entities and data flows
Designing and implementing efficient & scalable data models
Automating the provisioning and management of data platforms
Familiarity with RDBMS, NoSQL and Distributed data technologies
End-to-end involvement in software delivery
Working with production systems
Ownership of a product or set of features within a product
A range of software delivery tools (source control, agile tools, CI etc.)
Implementing and following best practices
Effective prioritisation of tasks and personal time management
Producing estimates for self and others
Demonstrating initiative
Coaching and mentoring more junior team members
Interacting with clients and/or product owners
Desirable experience:
Degree in computer science related discipline
Delivering in a highly collaborative agile environment
Understanding of blockchain technologies
Location: Belfast, London
Consulting
In Consulting we deliver practical, far-sighted advice that gets straight to the heart of clients’ business issues and delivers amazing results by helping our clients improve the way they operate, reduce costs, manage risks, leverage talent or fundamentally change the way they do business, the work you do will be all about helping organisations of all shapes and sizes work smarter and grow faster. You could find yourself working with household names in a diverse range of industries – everyone from big-name broadcasters and high-street banks to multinational telecoms operators and energy companies.
The skills we look for in future employees
All our people need to demonstrate the skills and behaviours that support us in delivering our business strategy. This is important to the work we do for our business, and our clients. These skills and behaviours make up our global leadership framework, ‘The PwC Professional’ and are made up of five core attributes; whole leadership, technical capabilities, business acumen, global acumen and relationships.
Diversity
We work in a changing world which offers great opportunities for people with diverse backgrounds and experiences. We seek to attract and employ the best people from the widest talent pool, as well as those who reflect the diverse nature of our society. And we aim to encourage a culture where people can be themselves and be valued for their strengths. Creating value through diversity is what makes us strong as a business and as an organisation with an increasingly agile workforce, we're open to flexible working arrangements where appropriate.
",https://jobs.theguardian.com/job/6747857/senior-data-engineer/
JOB124786203765,Data Engineer - All Levels,Data Engineer - All Levels,,,"
Data Engineer - All Levels
At DataSync Technologies, our data engineering professionals touch every area of our company. Their insights drive our decisions and their innovations fuel projects. When you join our team of data experts, you're helping DataSync's customers make better, smarter and faster decisions every day. See how you can help us solve some our customer's most challenging data problems while you grow your skills and build your own future.
Job Description
DataSync Technologies is seeking Data Engineers to support a mission critical program within the Intelligence Community.
Requirement:
* ONLY CANDIDATES WITH ACTIVE GOVERNMENT SECURITY CLEARANCES AND APPROPRIATE POLY WILL BE CONSIDERED. MUST BE A U.S. CITIZEN.
Responsibilities will vary by specific data engineer role - Data Architect, Data Scientist, Database Engineer, Data Governance to include the following:
* Design and develop methods, processes, and systems to consolidate and analyze structured and unstructured data from diverse sources including ""big data"" sources.
* Develop and use advanced software programs, algorithms, query techniques, model complex business problems, and automated processes to cleanse, integrate, and evaluate datasets.
* Analyze the requirements and evaluate technologies for data science capabilities including one or more of the following: Natural Language Processing, Machine Learning, predictive modeling, statistical analysis and hypothesis testing.
* Develop information tools, algorithms, dashboards, and queries to monitor and improve business performance. Maintain awareness of emerging analytics and big-data technologies.
* Designs, implement, and maintain standard data interfaces for data ingest including Extract/Transform/Load (ETL) methodology and implementation, APIs, RESTful Web Services, data quality, and data cleansing.
* Provide data services, data administration, data management, and ""Big Data"" support in client/server, virtual machine, Hadoop, and cloud infrastructure environment and/or migrations between these environments.
* Database installation, configuration, and the upgrading of database server software and related products, backup and recovery policies and procedures, database implementation, security, optimization, multi-domain operation, and performance management.
* Hadoop, cloud, and other technologies associated with data storage, processing, management, and use.
* The migration/transition of database capability into cloud based technologies and/or creation of interfaces between classic relational databases and key indexes to cloud based columnar databases and map reduce index capabilities.
Preferred Qualifications (All not required):
* Databases/Data Stores: Oracle, MySQL, HIVE, HBASE, and HDFS
* Frameworks: Hadoop, Rails, JavaScript Frameworks, SOA/WebServices, JSP
* Indexing: SOLR and Lucine
* Development/Scripting Languages: JAVA (J2EE), Python, Ruby, JavaScript, MapReduce, Pig, XML, SQL, JAQL, HTML, CSS, XML, BASH, ANT, and Perl
________________________
What makes DataSync Technologies different?
Leadership Training: We provide employees with a variety of learning opportunities, including access to exclusive classes, professional growth training and more.
Feedback & Mentoring: We believe in talking--often. So we have one-on-one feedback sessions for every employee.
Community Service: We believe in helping the community where we work. DataSync and its employees donate time and services on a regular basis to local military charities. We believe in helping, both inside and outside of the office.
Social Events: We plan social events on a regular basis to help our employees relax and socialize so we get to know one another outside of our job titles.
DataSync is an EEO and Affirmative Action Employer of Female/Minorities/Veterans/Individuals with Disabilities.
Equal Employment Opportunity
All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law
Information about Equal Employment Opportunity (EEO) and Employee Polygraph Act (EPPA) provisions in addition to other Federal labor laws can be found at http://webapps.dol.gov/dolfaq/go-dol-faq.asp?faqid=537
DataSync is committed to providing veteran employment opportunities to our service men and women.
www.datasynctech.com
www.facebook.com/DatasyncTechnologies
www.twitter.com/Jobs at DataSync (@DatasyncJobs)
www.twitter.com/datasynctech
#datasynctech on Instagram
Interested in Joining Our Team? - Check out this YouTube video!
#CJ
",https://www.clearancejobs.com/jobs/3105125/data-engineer-all-levels
JOB127673465178,Senior Software Developer (Senior Data Engineer),Senior Software Developer (Senior Data Engineer),,,"
We're looking for a Senior Software Developer with experience in data projects to join the Software Development team at Wellcome.
About the role
In this role, you will lead a team to design and build products which use data to evidence the success of Wellcome’s funding and identify new opportunities to achieve Wellcome’s aims. You will work with a strong cross-functional product team to provide innovative technical solutions to meet the needs of the organisation.
You will:
• develop data processing software, including designing, coding and testing
• work collaboratively in a cross-functional team to deliver quality software
• mentor others, sharing technical knowledge and providing guidance and support
• communicate effectively with managers, peer developers, testers, business analysts, product owners and scrum masters
See full job description
Experience & Skills
About you
To succeed, you’ll need:
• experience with distributed data-processing technologies such as Apache Hadoop, Apache Spark and key-value stores
• experience in open-source technologies including JVM languages and Python
• experience of cloud architecture
• a good understanding of ETL/ELT data-processing pipelines
• experience of developing multiple large-scale data-processing solutions
• a good understanding of NoSQL data stores
• experience of data modelling with RDBMS and NoSQL data stores
About us
We believe great ideas can change the world and improve health for everyone. At Wellcome, we help great ideas to thrive by supporting scientists and researchers, taking on big problems, fuelling imaginations and sparking debate.
Wellcome isn't just a supporter of great ideas; it's a great place to work. We offer excellent benefits and help our employees to develop in an open, respectful culture where differences are valued.
",https://jobs.theguardian.com/apply/6627201/senior-software-developer-senior-data-engineer-/?LinkSource=JobDetails&countrycode=GB
JOB129768053313,Data Engineer,Data Engineer,,,"Our Client are looking for Data Engineers based in Edinburgh
Duties include -
- Installation, termination and testing of Cat6/Cat6A copper cabling. Recent experience of Systimax cabling an advantage.
- Installation, cleaning and testing of fibre cabling. Splicing experience not essential as we install pre-term solutions. Engineers need to know how to handle fibre and test. IPAF qualification an advantage as installations at high level.
- Knowledge of Fluke test equipment, DTX/DSX testers.
- Experience of working in a data centre environment an advantage but not essential.
Would prefer engineers from the Edinburgh area or within an hours travel of the sites. Engineers need to have their own transport to get to these sites, i.e. a driving licence and car as the locations are not easy to get to and from with public transport during the times they are working.
The engineers are required to work nightshift, 4 nights Mon-Thurs 17:30-04:00. This is a 10.5 hour shift with 1 hour break so 4 x 9.5hrs, 38hrs. There is also optional overtime available most weekends, day shift Sat & Sun normally 08:00-16:30, 8hr shifts.
The engineers will need to pass a screening process which includes Disclosure Scotland. Engineers need to provide proof of identity, proof of address and pass a credit check.
The contract would be for 12-16 weeks initially but for the right candidates could be extended indefinitely.
Skills
Not Specified
",https://www.oilvoice.com/Job/2092/Data-Engineer
JOB130409923354,Arity - Senior Data Engineer,Arity - Senior Data Engineer,"Bachelor’s degree in a field such as Computer Science, Mathematics, Data Architecture, or equivalent experience or skills,Strong development knowledge and experience in key languages and environments such as Python, Scala, and SQL and noSQL databases,Advanced data sourcing and content management skills,Experience in time and task management,Strong attention to detail,Good written and verbal communication skills including the ability to collaborate across teams,Experience mentoring junior team members,Master’s degree in Computer Science or other technical field,Strong development knowledge and experience in Hadoop big data stack (e.g. HDFS, Hive, Spark, etc.),Demonstrated capability to learn new technologies and follow industry trends","Develop and deliver data sources and infrastructure to support the needs of predictive modeling and analytics as part of a cross-functional team,Connect raw data to business meaning and understand data generation and flows in the context of business impact. Communicate anomalies and work towards resolution,Execute rapid development of new data and analytic work tracks with fast iteration over quick sprints,Oversee the development of new concepts and proof of concept designs of moderate complexity,Ensure prototypes meet the organization standards to allow transfer to production, if applicable,Solve problems with a multidisciplinary approach, combining technical expertise with business knowledge","
Founded by The Allstate Corporation in 2016, Arity is a data and analytics company focused on improving transportation. We collect and analyze enormous amounts of data, using predictive analytics to build solutions with a single goal in mind: to make transportation smarter, safer and more useful for everyone.
At the heart of that mission are the people that work here—the dreamers, doers and difference-makers that call this place home. As part of that team, your work will showcase both your intelligence and your creativity as you tackle real problems and put your talents towards transforming transportation.
That’s because at Arity, we believe work and life shouldn’t be at odds with one another. After all, we know that your unique qualities give you a unique perspective. We don’t just want you to see yourself here. We want you to be yourself here.
The Data Science and Analytics Team
Arity Data Science & Analytics combines technical knowledge in fields such as mathematics, computer programming, and data engineering with business expertise. We’re passionate about learning new disciplines and techniques to deliver top-notch analytics products. Armed with billions of miles of driving data, we constantly challenge ourselves to seek out opportunities for new products and ways to make our existing offerings better. Our purpose is to extract meaning from data to make Arity’s vision of safer, smarter, and more useful transportation a reality.
The Role
Data Engineers at Arity work closely with Data Scientists, Engineers, and Product Managers to develop infrastructure for our massive repository of data. As part of a product team, you’ll execute new ETL work tracks from inception to solution, supporting technical expertise with strong business acumen. You’ll also be responsible for data manipulation and interpretation to help bring business solutions to scale. Success in this highly dynamic role depends on your ability to be flexible, curious, and quick to adapt.
Responsibilities
Develop and deliver data sources and infrastructure to support the needs of predictive modeling and analytics as part of a cross-functional team
Connect raw data to business meaning and understand data generation and flows in the context of business impact. Communicate anomalies and work towards resolution
Execute rapid development of new data and analytic work tracks with fast iteration over quick sprints
Oversee the development of new concepts and proof of concept designs of moderate complexity
Ensure prototypes meet the organization standards to allow transfer to production, if applicable
Solve problems with a multidisciplinary approach, combining technical expertise with business knowledge
Qualifications
Required:
Bachelor’s degree in a field such as Computer Science, Mathematics, Data Architecture, or equivalent experience or skills
Strong development knowledge and experience in key languages and environments such as Python, Scala, and SQL and noSQL databases
Advanced data sourcing and content management skills
Experience in time and task management
Strong attention to detail
Good written and verbal communication skills including the ability to collaborate across teams
Experience mentoring junior team members
Preferred:
Master’s degree in Computer Science or other technical field
Strong development knowledge and experience in Hadoop big data stack (e.g. HDFS, Hive, Spark, etc.)
Demonstrated capability to learn new technologies and follow industry trends
Heads up: when you click “apply now” you’ll be directed to the Allstate careers site. You’re still looking at an Arity job, but because we were founded by Allstate, we share the same application system.
",https://www.builtinchicago.org/job/data/senior-data-engineer/64643
JOB131875076459,Senior Data Engineer,Senior Data Engineer,,"Bachelors degree in IT, or similar experience,Extensive Data integration and data orchestration experience with Microsoft Azure,In-depth experience of designing and implementing data flows and pipelines,Deep experience as a Data Engineer is highly desirable,Experience of working in an Agile (ideally SCRUM) team,Comfortable being hands on with data, data modelling, query techniques,Background in the Data management Space,Experience of the FMCG/CPG industry,A good understanding of and adherence to data security standards","
This is an exciting time at Mars. We’re using digital, data and user insights to transform our business by finding answers to problems that we’ve often never asked ourselves before. From joining the dots to improve our Petcare data ecosystem, to streamlining the efficiency and automation of our supply chain and quality operations, we’re already seeing some brilliant results. In fact, we’ve built so much momentum that we’re now looking for industry leaders in Business Translation, Data Science and Data Engineering with different and complementary skills to influence how we operate and grow beyond anything we’ve achieved before. Join us, and discover a company set up to develop your capabilities and ambitions and a group of colleagues ready to support and inspire you. Working together, we’ll create a better world for our planet, our communities and our pets.
What you’ll do
Keeping the data flowing and readily available to solve problems as and when they need solving is core to what you’ll do. You might do that through Agile sprints or self-service analytics - it’s up to you. The day-to-day? You’ll be working within a sprint team building both new data pipelines and establishing or improving new platform capabilities. Without people in this crucial role treating data as an asset, we won’t be able to become the business we want to be.
Working in a small Agile team alongside Global Analytics, Data, Source Systems, Business Translation and Integration colleagues, you’ll partner with Product Owners to establish and maintain the data pipelines (ETL/Batch/Streaming) within and between different technology platforms, such as SAP/SAP BW and Microsoft Azure. You’ll also work closely with users from our segments and markets around the world as part of SCRUM teams. This exposure will also give you the exciting opportunity to influence and contribute true ‘firsts’. That’s new and emerging approaches that Mars, and maybe even the industry, hasn’t seen before.
Data integration, orchestration and automation – you’ll build data flow components of MVP analytic solutions. And you’ll do it across the entire Mars data landscape. That’s on premises, cloud, internal, external, formal & informal data. You’ll look to the future too. That means thinking about how data assets yet to come can be integrated into the end-to-end Mars data landscape.
In everything you do, you’ll be thinking about the bigger business picture and making sure your solutions address specific business challenges. On top of that, you’ll work closely with the Enterprise Architecture function and other Mars Digital Technologies capabilities to ensure alignment with the Enterprise Architecture initiatives and capacity and infrastructure planning.
What you’ll need
To do all this, you’ll need:
Bachelors degree in IT, or similar experience
Extensive Data integration and data orchestration experience with Microsoft Azure
In-depth experience of designing and implementing data flows and pipelines
Deep experience as a Data Engineer is highly desirable
Experience of working in an Agile (ideally SCRUM) team
Comfortable being hands on with data, data modelling, query techniques
Background in the Data management Space
Experience of the FMCG/CPG industry
A good understanding of and adherence to data security standards
So, if you’ve got the skills we need and you’re looking for the opportunity to really make a mark in a world-renowned and supportive business going through a period of fast and massive digital transformation, this could be the role you’ve been waiting for.
",https://jobs.theguardian.com/job/6776678/senior-data-engineer/
JOB132285553457,Senior Data Engineer - Madrid province,Senior Data Engineer - Madrid province,,,"
Features
Advertiser Note:
I am advertising the job vacancy for a client or third party
",https://www.thinkspain.com/job-in-spain/25255
JOB132911298905,Data Engineer,Data Engineer,,"Maintain the development infrastructure supporting the marketing organization,Development and maintenance of data processing on our new Marketing data platform,Leading contributor in the team in terms of working knowledge of big data technologies,Work with the technology and business community to turn business requirements into technical solutions.,Work autonomously from specifications and produce high quality, accurate, efficient and well documented code. Ensure accurate estimating for work based on detailed requirements.,Undertake maintenance and ‘bug fix’ development activities for existing applications.,Construct and execute unit and system testing.,Undertake peer-to-peer code reviews of colleagues’ development tasks.,Ensure clear and early communication, in particular ensuring that that line manager and/or relevant parties are kept informed of progress, issues and difficulties.,Proactively work to mitigate risks, improve quality in an efficient manner and resolve problems that arise.,Lead adherence to best practice solutions across the team,Ability to manage ongoing project work alongside business as usual support and maintenance.,Provide estimates of duration and effort required to complete development tasks from high-level or loosely-defined requirements.,Create robust system-level design for assigned development activities with a solid grasp of business and commercial drivers to produce designs that clearly meet customer/user needs and feedback is positive,Undertake a thorough impact analysis of all assigned development activities, understanding the impact of own work on other tasks and areas of the system,Share process expertise across the team in order to enhance team effectiveness,Contribute to the marketing systems roadmap bringing technical leadership and oversight,Solid working knowledge of the following:,One or more of Python, Java,Performance tuning of both MapReduce queries and relational databases,Working knowledge of the following technologies:,AWS technologies,Big data technologies such as Spark,Analytical platforms such as Databricks, Blue Insight,Interpersonal Skills:,Excellent verbal and written communication skills,Team player able to work under own initiative,Customer focused and service-oriented,Confident in establishing good working relationships other IT teams (internal and external),Knowledge of the following technologies advantageous:,Marketing automation tools, including campaign management and workflow (Adobe Campaign preferred, other examples Eloqua, Aprimo),Web analytics: Adobe Analytics, SiteCatalyst/Google Analytics/Webtrends,Experience using a recognized development methodology, e.g. Agile Experience and understanding of the role of the developer in the full SDLC,Proven track record of feature level design,Knowledge of service management and ITIL framework,Previous experience with marketing, publishing and analytics preferred.,Able to create imaginative solutions that move the platform forward in features, maintainability and cost-effectiveness","
Role: Data Engineer – Marketing Technology
Business: Elsevier Technology
Reporting to: Transformation Lead, Marketing Technology
Term: Permanent
Elsevier is a global information analytics company that helps institutions and professionals progress science, advance healthcare and improve performance for the benefit of humanity.
We serve the research, academic, and clinical communities through the application of technology and analytics to content. In this way, we empower those communities to contribute to social progress, enhance human well-being, and to share and expand the breadth of human knowledge.
This is an exciting opportunity to play a role in transforming the way marketing automation is delivered across Elsevier. We are seeking a talented and self-motivated Big Data Engineer with solid experience in developing and supporting big data platforms within a cross-functional product development environment and who want to develop their career within Marketing Tech.
Working across Elsevier’s global marketing teams the role will support many complex and challenging assigned projects aimed at delivering Marketing solutions and services that meet company cost, quality, and strategic targets.
Key Responsibilities:
Maintain the development infrastructure supporting the marketing organization
Development and maintenance of data processing on our new Marketing data platform
Leading contributor in the team in terms of working knowledge of big data technologies
Work with the technology and business community to turn business requirements into technical solutions.
Work autonomously from specifications and produce high quality, accurate, efficient and well documented code. Ensure accurate estimating for work based on detailed requirements.
Undertake maintenance and ‘bug fix’ development activities for existing applications.
Construct and execute unit and system testing.
Undertake peer-to-peer code reviews of colleagues’ development tasks.
Ensure clear and early communication, in particular ensuring that that line manager and/or relevant parties are kept informed of progress, issues and difficulties.
Proactively work to mitigate risks, improve quality in an efficient manner and resolve problems that arise.
Lead adherence to best practice solutions across the team
Ability to manage ongoing project work alongside business as usual support and maintenance.
Provide estimates of duration and effort required to complete development tasks from high-level or loosely-defined requirements.
Create robust system-level design for assigned development activities with a solid grasp of business and commercial drivers to produce designs that clearly meet customer/user needs and feedback is positive
Undertake a thorough impact analysis of all assigned development activities, understanding the impact of own work on other tasks and areas of the system
Share process expertise across the team in order to enhance team effectiveness
Contribute to the marketing systems roadmap bringing technical leadership and oversight
Technical Skills:
Solid working knowledge of the following:
One or more of Python, Java
Performance tuning of both MapReduce queries and relational databases
Working knowledge of the following technologies:
AWS technologies
Big data technologies such as Spark
Analytical platforms such as Databricks, Blue Insight
Interpersonal Skills:
Excellent verbal and written communication skills
Team player able to work under own initiative
Customer focused and service-oriented
Confident in establishing good working relationships other IT teams (internal and external)
Knowledge of the following technologies advantageous:
Marketing automation tools, including campaign management and workflow (Adobe Campaign preferred, other examples Eloqua, Aprimo)
Web analytics: Adobe Analytics, SiteCatalyst/Google Analytics/Webtrends
Experience using a recognized development methodology, e.g. Agile Experience and understanding of the role of the developer in the full SDLC
Proven track record of feature level design
Knowledge of service management and ITIL framework
Previous experience with marketing, publishing and analytics preferred.
Able to create imaginative solutions that move the platform forward in features, maintainability and cost-effectiveness
",https://jobs.theguardian.com/job/6751990/data-engineer/
JOB135022623084,Data Engineer,Data Engineer,,"IoT data development and management.,Data Engineering or BI Development experience,At least 1 years’ experience of modern programming language (Python, Java, C#, Scala),ETL experience,Experience in NoSQL/Big Data technologies (Redshift, Cassandra, MongoDB, BigQuery, Hadoop or similar),Experience in Cloud platforms (AWS, GCP, Azure, Oracle),Agile experience nice to have","
Design, build and support data-intensive platforms.
IoT data development and management.
Architecture migration using modern technologies.
This firm is currently transitioning from batch-processing architecture to a streamed-based model and they require a Data Engineer to come in as part of the IoT Data team. This team collates information from their variety of IoT connected devices into the cloud and make it available to the Data Analysts and Data Scientists. This firm is continuously adapting to the latest techniques and available technologies to deliver total connectivity.
They are open to Junior, Mid-level and Senior candidates.
What you’ll be doing
The successful Data Engineer will come on board to support the migration from a batch-processing Big Data platform to a real-time serverless platform.
Working closely with the Data Architects and the wider Data Engineering teams, you will ensure that the infrastructure is in place to analyse the huge amounts of data generated by this company. As a result, you’ll drive improvements to the scalability, efficiency and the continuous deployment environment.
This is a great opportunity for ambitious Data Engineers to gain experience on a variety of modern data technologies across cloud ecosystems.
What experience you’ll need to apply
Data Engineering or BI Development experience
At least 1 years’ experience of modern programming language (Python, Java, C#, Scala)
ETL experience
Experience in NoSQL/Big Data technologies (Redshift, Cassandra, MongoDB, BigQuery, Hadoop or similar)
Experience in Cloud platforms (AWS, GCP, Azure, Oracle)
Agile experience nice to have
DevOps experience nice to have
What you’ll get in return for your experience
A competitive salary of up to £57000 based on experience with excellent bonuses and benefits package. Grow with a global leading company and work with the most modern data technology on the market.
What’s next?
Please get in touch with Scott with an up to date CV today. Don’t hesitate to call/email to discuss the job in further detail.
",https://jobs.theguardian.com/job/6843535/data-engineer/
JOB135083194179,Senior Data Engineer,Senior Data Engineer,,"Work with Data Engineering Lead and key stakeholders to design and develop Reify's next-generation Kappa-style data architecture in a functional programming environment using Kafka, Kubernetes, PostgreSQL and potentially additional tooling from the AWS/Confluent Ecosystems (e.g. EKS, Athena, Confluent Operator, etc.),Take responsibility for the day-to-day maintenance, upgrades, orchestration, and troubleshooting of our data architecture and tooling.,Use a combination of Clojure (functional programmers welcome!), Python, and SQL to support analytics work (statistical modeling, machine learning) and develop/integrate analytics insights into our data products,Become intimately familiar with HIPAA, GDPR, and other applicable regulatory frameworks and how they influence our architecture and development decisions,Rapidly learn new tools, techniques, and languages as we scale and encounter additional data challenges,Frequently communicate your results to Data Engineering Lead and other technical/non-technical stakeholders in clear written, verbal, or presentation form,Live our data philosophy, which focuses on ethical decision making, being aware of how biased data (and assumptions) can affect results (and people), and being laser-focused on business needs,Extensive experience with DevOps, systems engineering/orchestration, and strong ability to understand and work with distributed systems,While this is primarily a data engineering role (70+%), the ideal candidate will also have the ability to handle analytical challenges as well (30+%),Understanding the nuances of testing in distributed/probabilistic systems,Experience with applied statistics (particularly of the Bayesian flavor), supervised/unsupervised learning techniques,Masters degree or greater in a relevant field,Relevant published work (academic, blog posts, open-source contributions),Previous experience with functional programming languages/philosophy (or existing Clojure chops!),Experience in a startup environment (as a remote employee, if you’d like to work remotely),Competitive Salary and Stock Options: Compensation varies from mid-level to very senior and is commensurate with your experience.,Comprehensive Health and Wellness Coverage: 100% premium coverage for you (and >50% for your dependents) for: a top-tier health plan covering you in all 50 states (with option of HSA for medical expenses and as investment vehicle) dental, vision, disability (short-term and long-term), and basic term life insurance (for your entire tenure at Reify). We enable 24/7 access to doctor by phone or online via telemedicine coverage.,Company-provided Workstation: You have the option of getting a brand new Macbook Pro (or similar, if desired) laptop if you’d like to use a separate computer for work.","At Reify Health, we are building a more creative healthcare system. We envision a world where every potential therapy, if safe and effective, is available to the patients who can benefit.
Our healthcare system relies on clinical trials to develop new, potentially life-saving treatments for patients. But clinical trials continue to be slow, unpredictable, and expensive. Reify Health’s product helps both the research leaders driving forward clinical trials and the doctors and nurses who care for the patient participants.
As we scale adoption of our product domestically and internationally, we will accelerate world-class clinical research and unlock innovation. By joining our data team, you will support the growth of an empathetic, data-driven culture at Reify and play a foundational role in designing and building a novel data architecture and intelligence features.
Your Responsibilities
Work with Data Engineering Lead and key stakeholders to design and develop Reify's next-generation Kappa-style data architecture in a functional programming environment using Kafka, Kubernetes, PostgreSQL and potentially additional tooling from the AWS/Confluent Ecosystems (e.g. EKS, Athena, Confluent Operator, etc.)
Take responsibility for the day-to-day maintenance, upgrades, orchestration, and troubleshooting of our data architecture and tooling.
Use a combination of Clojure (functional programmers welcome!), Python, and SQL to support analytics work (statistical modeling, machine learning) and develop/integrate analytics insights into our data products
Become intimately familiar with HIPAA, GDPR, and other applicable regulatory frameworks and how they influence our architecture and development decisions
Rapidly learn new tools, techniques, and languages as we scale and encounter additional data challenges
Frequently communicate your results to Data Engineering Lead and other technical/non-technical stakeholders in clear written, verbal, or presentation form
Live our data philosophy, which focuses on ethical decision making, being aware of how biased data (and assumptions) can affect results (and people), and being laser-focused on business needs
Work with the Data Engineering Lead to support the growth of a talented data team and incorporate the work of future data scientists into our data architecture
What Will Make You Stand Out
Extensive experience with DevOps, systems engineering/orchestration, and strong ability to understand and work with distributed systems
While this is primarily a data engineering role (70+%), the ideal candidate will also have the ability to handle analytical challenges as well (30+%)
Understanding the nuances of testing in distributed/probabilistic systems
Experience with applied statistics (particularly of the Bayesian flavor), supervised/unsupervised learning techniques
Masters degree or greater in a relevant field
Relevant published work (academic, blog posts, open-source contributions)
Previous experience with functional programming languages/philosophy (or existing Clojure chops!)
Experience in a startup environment (as a remote employee, if you’d like to work remotely)
Relevant experience in a healthcare/health-tech company
Compensation & Benefits
Competitive Salary and Stock Options: Compensation varies from mid-level to very senior and is commensurate with your experience.
Comprehensive Health and Wellness Coverage: 100% premium coverage for you (and >50% for your dependents) for: a top-tier health plan covering you in all 50 states (with option of HSA for medical expenses and as investment vehicle) dental, vision, disability (short-term and long-term), and basic term life insurance (for your entire tenure at Reify). We enable 24/7 access to doctor by phone or online via telemedicine coverage.
Company-provided Workstation: You have the option of getting a brand new Macbook Pro (or similar, if desired) laptop if you’d like to use a separate computer for work.
Location Flexibility & Transportation: For those working out of Boston, we provide: a free monthly public transportation pass (and are located 2-3 minutes from South Station); unlimited coffee, infused water, and more (provided by WeWork); flexibility to work from home as needed. For those working remotely: you can work from anywhere in the U.S. compatible with an EST work schedule. Additionally, we’ll fly remoters in for our quarterly “remoters’ week”, filled with fun activities, good food, and many opportunities to get to know your colleagues better.
We value diversity and believe the unique contributions each of us brings drives our success. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.
We also completely eschew the “bro culture” sometimes found at startups.
Note: We are currently only considering US citizens or Green Card holders. Thanks!
",https://jobs.lever.co/reifyhealth/258735ad-71d0-4ebe-b551-fbbcf2f3213c?lever-origin=applied&lever-source%5B%5D=Hacker%20News
JOB135580039492,Data Engineer / Scientist,Data Engineer / Scientist,,,"
This is an early-stage technology company based in the centre of Leeds; they are building advanced software for the Data Centre (DC) and Cloud industry using AI/ML techniques to recognise and learn the behavioural patterns of machines, software containers, and users inside DCs.
They are looking for a Data Engineer/Scientist to play an important role in the development of an innovative SaaS product for behavioural analytics in the data centre industry.
This will involve working closely with team members to solve difficult challenges in a wide range of areas, from state-of-the-art machine-learning to big data processing/storage and hardware monitoring.
ROLE
Working as an important member of their R&D team, the successful candidate will liaise with their Development team to help realise prototypes and data driven insights in their SaaS-based solution. This will involve working with large-amounts of existing data from data centre trace logs and collected metrics to train machine learning models and inform further research and development.
The candidate will also be defining and running experiments on their partner's world-leading data centre platform. Data centre industry experience and understanding of low-level server hardware would be beneficial but is not essential.
The successful applicant will from time to time have the opportunity to attend (or present at) conferences and industry events (both national and international) and work with development partners.
MINIMUM REQUIREMENTS
- Strong programming ability
- Strong mathematics and statistics background
- Experience working with large datasets (Big Data)
- Experience in machine-learning
- A good working knowledge of Linux system environments
- Experience using version control (Git)
- Strong teamwork skills
- Excellent communication and presentation skills
- BSc degree in Computer Science or a related field
DESIRABLE SKILLS
- Experience in deep reinforcement learning
- Experience in development using Python or Golang
- Experience using distributed processing frameworks (such as MapReduce)
- Experience with deep learning frameworks (Tensorflow, PyTorch, etc.)
- Experience with container management systems (Kubernetes, etc.)
- Data centre domain knowledge
- An MSc degree (or higher) in Computer Science or a related field
COMPANY BACKGROUND
They use these patterns to drive patented resource scheduling algorithms, allowing the monitoring and forecasting of system behaviour and greatly improving management, utilisation, and efficiency.
They are a small, friendly team of developers and academics. As well as the opportunity to be involved in leading-edge development, working with some of the best people in the industry, they offer the following benefits:
- Personal development / training opportunities
- Stock options
- Childcare voucher scheme
- Cycle to work scheme
- Employee benefits scheme
- Pension scheme
",https://jobs.theguardian.com/job/6800949/data-engineer-scientist/
JOB136289127415,Data Engineer job with Hyper Recruitment Solutions (HRS) | 1401665118,Data Engineer job with Hyper Recruitment Solutions (HRS) | 1401665118,,,,https://jobs.newscientist.com/en-au/job/1401665118/data-engineer/
JOB136350335747,Senior Data Engineer,Senior Data Engineer,Work with data science teams to deliver metrics to consumers,"Implement ETL jobs for various functions,Support and maintain daily ETL jobs,Support the development teams by optimizing data access,Work with data science teams to deliver metrics to consumers,Implement ETL jobs for various functions,Support and maintain daily ETL jobs,Support the development teams by optimizing data access","
Summary:
We are fast-paced, forward thinking and driven by data.
We are accelerating the used car industry.
We are looking for creative, talented, hard-working individuals to join us.
Buckle up. It's going to be a great ride.
Based in Chicago, DRIVIN is accelerating the used car industry by bringing data and technology together in a spectacular, first-of-its-kind fashion to help dealers acquire the right cars, at the right price, right now. We are committed to delivering data-driven solutions with a high-touch, personalized level of service to each of our clients. We are looking for people that will help us create a culture that is exciting, empowering, motivating and challenging. Are you interested in learning more?
Job Description:
DRIVIN is looking to expand our data team as we continue to grow our data platform. The candidate should have a strong background with Python and SQL. As a member of the data team the main responsibilities are implementing/maintaining ETL jobs, using Python to ingest external data sources into the Data Warehouse, and working closely with the Product and Data Science teams to deliver data in useable formats and to the appropriate data sources.
DRIVIN has a polyglot data model using many cutting-edge data platforms. We are currently using MPP Postgres (Greenplum, Netezza, DBX) as our Data Warehouse, Elastic Search for location based searching, Postgres for transactional data.
This candidate should be a self-starter who is interested in learning new systems/environments and building new solutions.
The candidate should also work closely with the Data Science team to identify interesting data points for use by the Data Science team.
DRIVIN tech stack is very cutting edge. MPP Postgres drives the Data Warehouse, ElasticSearch enables our location based searching/metrics, and Apache Spark is used to train our models. All environments are run on AWS EC2/RDS/S3 and data processing framework is written in Python.
RESPONSIBILITIES:
Implement ETL jobs for various functions
Support and maintain daily ETL jobs
Support the development teams by optimizing data access
Work with data science teams to deliver metrics to consumers
RESPONSIBILITIES:
Implement ETL jobs for various functions
Support and maintain daily ETL jobs
Support the development teams by optimizing data access
Work with data science teams to deliver metrics to consumers
",https://www.builtinchicago.org/job/data/senior-data-engineer/60893
JOB137633553020,Data Engineer,Data Engineer,,,"Our Client are currently recruiting Data Engineers based in Aberdeen
Cable Pulling - trunking - COAX Minimum Requirement - CSCS As long as they have good Data Engineer experience.
Qualifications required to carry out the role: Essential: Solid Data Engineering background CAT5/ 6 Installation Fluke Tester operation
Skills
Not Specified
",https://www.oilvoice.com/Job/3438/Data-Engineer
JOB138471636805,Data Engineer jobs from H1B Visa Sponsors | MyVisaJobs.com,Data Engineer jobs from H1B Visa Sponsors | MyVisaJobs.com,,,"
Sr Data Engineer, Data Science
work visa from Twitter all jobs from Twitter Seattle, WA
......Sr Data Engineer, Data Science Twitter Twitter engineers run hundreds of experiments; We are trying to improve Twitter. Twitter is an equal opportunity employer....... apply now save alert all jobs from Twitter
updated: 10/7/2020 5:23:00 AM
Azure Data Engineer
work visa from Imcs Group all jobs from Imcs Group Redmond, WA
......Azure Data Engineer Imcs Group As a Data Engineer, you will be. Creating/Maintaining and Enhance Big Data Pipeline. Perform extensive data validation/quality assurance analysis within large…...... apply now save alert all jobs from Imcs Group
updated: 10/6/2020 11:02:00 PM
Data Engineer
work visa from Cognizant Technology Solutions all jobs from Cognizant Technology Solutions Charlotte, NC
......Data Engineer Cognizant Technology Solutions Cognizant Technology Solutions will not be able to provide sponsorship for this role now or in the future. Cognizant is one of the world's leading professional…...... apply now save alert all jobs from Cognizant Technology Solutions
updated: 10/6/2020 7:45:00 PM
Data Engineer
work visa from Slalom Consulting all jobs from Slalom Consulting Detroit, MI
......Data Engineer Slalom Consulting What Data Engineering Looks Like at Slalom. Slalom is a modern consulting firm focused on strategy, technology, and business transformation....... apply now save alert all jobs from Slalom Consulting
updated: 10/6/2020 6:30:00 PM
Big Data Engineer
work visa from KPIT Technologies all jobs from KPIT Technologies Moline, IL
......Big Data Engineer KPIT Technologies This is a Full Time only position with KPIT Technologies*. Description of the major duties performed in this job. Education (or equivalent work experience)*....... apply now save alert all jobs from KPIT Technologies
updated: 10/6/2020 1:54:00 PM
Data Engineering Sr Manager
work visa from eBay Inc. all jobs from eBay Inc. San Jose, CA
......Data Engineering Sr Manager eBay Inc. Be a cultural fit for eBay. At eBay, we employ extraordinary people who do meaningful work that has a tangible impact on the lives of individuals all over the…...... apply now save alert all jobs from eBay Inc.
updated: 10/6/2020 8:11:00 AM
Data Engineer
work visa from Kairos Technologies all jobs from Kairos Technologies McLean, VA
......Data Engineer Kairos Technologies Kalyan | Lead Executive-TAG | Kairos Technologies Inc. Building ETL pipelines, Spark, Python, AWS*. Collaborating as part of a cross-functional Agile team to…...... apply now save alert all jobs from Kairos Technologies
updated: 10/6/2020 7:20:00 AM
Lead Data Engineer, Profitability and Margin Analytics
work visa from Nike all jobs from Nike Beaverton, OR
......Lead Data Engineer, Profitability and Margin Analytics Nike NIKE is a technology company. Become a Part of the NIKE, Inc. No matter the location, or the role, every Nike employee shares one galvanizing mission:...... apply now save alert all jobs from Nike
updated: 10/6/2020 2:00:00 AM
Vehicle Data Engineer
work visa from General Motors all jobs from General Motors Warren, MI
......Vehicle Data Engineer General Motors There’s never been a more exciting time to work for General Motors. General Motors is committed to being a workplace that is not only free of discrimination,…...... apply now save alert all jobs from General Motors
updated: 10/5/2020 9:52:00 PM
Data Engineer I
work visa from Medical University of South Carolina all jobs from Medical University of South Carolina Charleston, SC
......Data Engineer I Medical University of South Carolina The Medical University of South Carolina is an Equal Opportunity Employer. The Data Engineer I reports to the Manager of Data Engineering in support of MUSC’s…...... apply now save alert all jobs from Medical University of South Carolina
updated: 10/5/2020 7:34:00 PM
",https://www.myvisajobs.com/visa-job-title/Data-Engineer.htm
JOB139965598711,Senior Data Engineer,Senior Data Engineer,"PhD in a related discipline with at least 6 years of experience; Master’s degree with 12 years of experience; or Bachelor’s degree with experience in biomedical data management, data engineering, quality assurance, assay development, specimen data management or related discipline,Demonstrated proficiency with molecular biology concepts; and ability to support, develop and deploy laboratory and other research data management processes and procedures as they apply to complex, high dimensional data sets,Demonstrated ability to understand and translate high-level scientific datasets and results into data curation and management strategies and the underlying structures, curation processes and infrastructure required.,Strong understanding of LIMS systems and systematic, relational approaches to data integration and data processing workflows,Familiarity with Amazon Web Services (AWS).,Excellent skills in R programming and experience in additional computer languages such as Perl, Python, PHP, S-PLUS or Java (or C/C++),Extensive practical experience in working with diverse but highly-connected scientific knowledge collections and their query interfaces to enable research hypotheses around compound targets, mechanisms of action, and patient response,Proven ability to work in a team environment with clinical personnel, study monitors, computational biologists, biostatisticians, programmers, and medical writers,Knowledge of FDA/ICH guidelines and industry standard practices regarding data management are helpful but not required,Detailed knowledge and experience in case report form design, central laboratories, programming databases, query resolution, data validation,Computer skills: detailed knowledge of at least one data management system (Oracle Clinical or Clintrial preferred), experience with SAS data sets and conversion procedures required; knowledge of MS Office program suite required,Knowledge of distributed database design and implementation, LAMP/ MySQL, etc. with capability to perform/direct/assess implementation of such databases,Working knowledge of both Windows and Linux operating systems is required,Along with programming proficiency must have creativity, and show a strong capacity for independent thinking and the ability to grasp underlying biological questions,Must thrive in a complex, dynamic environment while adapting to dynamically changing priorities,Must have excellent time management and organizational skills","Develop, enhance, and automate processes for queuing and prioritizing data management and curation requests,Implement a quality control (QC) process to evaluate compliance with data models and taxonomies to ensure cohesion of curated data across time as data models and configurations evolve,Create a rapid means to remediate data that fail to meet curation specifications,Empower scientists with tools, processes and data structures needed to support project objectives,Ensure accurate, complete and timely collection, delivery and tracking of analytical information from translational, CRO or collaborating laboratories for curation, ingestion and delivery to computational scientists,Help define, deliver and implement R/ED, collaborator and partner laboratory analytical data management systems, processes and procedures,Work with R/ED study teams to develop R/ED information management plans that outline data capture, data flow, data queries, manual checks, and data listings needed to ensure data integrity,Participate in comprehensive data review activities in coordination with project and study teams,Work with computational biologists, computational scientists, biostatisticians and study scientists to resolve data quality issues,Make data, including raw/interim data, available to R/ED department personnel as required,Collaborate with users to enable data access and ingestion,Acquire user feedback to inform business requirements for future development.","
Description
Celgene is a global biopharmaceutical company leading the way in medical innovation to help patients live longer, better lives. Our purpose as a company is to discover and develop therapies that will change the course of human health. We value our passion for patients, quest for innovation, spirit of independence and love of challenge. With a presence in more than 70 countries - and growing - we look for talented people to grow our business, advance our science and contribute to our unique culture.
Summary/Scope: Celgene seeks a talented, results and achievement oriented individual to contribute to our informatics and data management initiatives in Research and Early Development (R&ED). This hands-on role interfaces with programs spanning both discovery and translational sciences where processing and interpreting multi-platform and multi-dimensional ‘omic’ data in pre-clinical and clinical settings is being employed to identify molecular drug targets, characterize MOA, prioritize clinical indications and generate patient selection hypotheses. We are seeking an individual with extensive experience managing, processing, and applying quality control metrics and processes to a wide range of data types in support of R&ED clinical trials and drug development experiments while working in close collaboration with basic research, translational and computational scientists.
Responsibilities include, but are not limited to, the following:
Develop, enhance, and automate processes for queuing and prioritizing data management and curation requests
Implement a quality control (QC) process to evaluate compliance with data models and taxonomies to ensure cohesion of curated data across time as data models and configurations evolve
Create a rapid means to remediate data that fail to meet curation specifications
Empower scientists with tools, processes and data structures needed to support project objectives
Ensure accurate, complete and timely collection, delivery and tracking of analytical information from translational, CRO or collaborating laboratories for curation, ingestion and delivery to computational scientists
Help define, deliver and implement R/ED, collaborator and partner laboratory analytical data management systems, processes and procedures
Work with R/ED study teams to develop R/ED information management plans that outline data capture, data flow, data queries, manual checks, and data listings needed to ensure data integrity
Participate in comprehensive data review activities in coordination with project and study teams
Work with computational biologists, computational scientists, biostatisticians and study scientists to resolve data quality issues
Make data, including raw/interim data, available to R/ED department personnel as required
Collaborate with users to enable data access and ingestion
Acquire user feedback to inform business requirements for future development.
Qualifications
PhD in a related discipline with at least 6 years of experience; Master’s degree with 12 years of experience; or Bachelor’s degree with experience in biomedical data management, data engineering, quality assurance, assay development, specimen data management or related discipline
Demonstrated proficiency with molecular biology concepts; and ability to support, develop and deploy laboratory and other research data management processes and procedures as they apply to complex, high dimensional data sets
Demonstrated ability to understand and translate high-level scientific datasets and results into data curation and management strategies and the underlying structures, curation processes and infrastructure required.
Strong understanding of LIMS systems and systematic, relational approaches to data integration and data processing workflows
Familiarity with Amazon Web Services (AWS).
Excellent skills in R programming and experience in additional computer languages such as Perl, Python, PHP, S-PLUS or Java (or C/C++)
Extensive practical experience in working with diverse but highly-connected scientific knowledge collections and their query interfaces to enable research hypotheses around compound targets, mechanisms of action, and patient response
Proven ability to work in a team environment with clinical personnel, study monitors, computational biologists, biostatisticians, programmers, and medical writers
Knowledge of FDA/ICH guidelines and industry standard practices regarding data management are helpful but not required
Detailed knowledge and experience in case report form design, central laboratories, programming databases, query resolution, data validation
Computer skills: detailed knowledge of at least one data management system (Oracle Clinical or Clintrial preferred), experience with SAS data sets and conversion procedures required; knowledge of MS Office program suite required
Knowledge of distributed database design and implementation, LAMP/ MySQL, etc. with capability to perform/direct/assess implementation of such databases
Working knowledge of both Windows and Linux operating systems is required
Along with programming proficiency must have creativity, and show a strong capacity for independent thinking and the ability to grasp underlying biological questions
Must thrive in a complex, dynamic environment while adapting to dynamically changing priorities
Must have excellent time management and organizational skills
Celgene is committed to equal opportunity in the terms and conditions of employment for all employees and job applicants without regard to race, color, religion, sex, sexual orientation, age, gender identity or gender expression, national origin, disability or veteran status.
Celgene complies with all applicable national, state and local laws governing nondiscrimination in employment as well as employment eligibility verification requirements of the Immigration and Nationality Act. All applicants must have authorization to work for Celgene in the U.S.
*LI-MG2
BIO-US
",https://jobs.newscientist.com/en-gb/job/1401626409/senior-data-engineer/
JOB143648736060,Lead Data Engineer,Lead Data Engineer,"7+ years of experience in software engineering or a related field,Extensive experience working with our stack (Python, PostgreSQL, AWS) or something similar,BA/BS degree in computer science or other engineering degree,Ability to quickly learn, understand and work with new emerging technologies, methodologies, and solutions,Experience building and managing production-quality ML models a plus,Growth-company DNA – thrives in a fast-paced environment and shares an excitement to lead change!","Partnering with cross-functional stakeholders to identify and plan for new data related business requirements, ensuring the details of those requirements are adequately fleshed out before development begins,Accountability for the consistent and effective flow of work for the Data Engineering team,Positioning yourself as the go-to expert with internal stakeholders and seen as deeply aware of, and able to address, their technical needs,Working with our devops and product teams to ensure our data engineers are positioned to satisfy their sprint commitments,Executing against the ‘technical vision’ for data, ensuring that all data engineering efforts are building toward long-term success,Reviewing pull requests, troubleshooting tough performance issues, and fostering our pair-programming and team-wide knowledge sharing efforts,Helping to develop and maintain code standards and accountability to them","
What you will be doing:
The Data Engineering Lead is responsible for directing the activities of our multidisciplinary Data Engineering team. The current team includes several backend software engineers, a Database Administrator and one or more Data Scientists. As Data Engineering Lead, you’ll work closely with the leaders of our product, platform engineering and devops teams to support our ambitious product goals. You’ll be responsible for setting direction for our database infrastructure and providing platform-wide architectural guidance. At Lumere, Data Engineering also owns application optimization, prediction models, and provides guidance and support to a separate Data Operations (ETL) team.
The Data Engineering Lead has outstanding backend technical experience and the ability to successfully coach other engineers as they develop their skills and their careers. The successful candidate will be an effective communicator with a focus on listening to the team. They also share a passion with their teammates for delivering a market-leading, web-based solution used to transform healthcare. This position reports directly to the Chief Technology Officer.
Responsibilities include:
Partnering with cross-functional stakeholders to identify and plan for new data related business requirements, ensuring the details of those requirements are adequately fleshed out before development begins
Accountability for the consistent and effective flow of work for the Data Engineering team
Positioning yourself as the go-to expert with internal stakeholders and seen as deeply aware of, and able to address, their technical needs
Working with our devops and product teams to ensure our data engineers are positioned to satisfy their sprint commitments
Executing against the ‘technical vision’ for data, ensuring that all data engineering efforts are building toward long-term success
Reviewing pull requests, troubleshooting tough performance issues, and fostering our pair-programming and team-wide knowledge sharing efforts
Helping to develop and maintain code standards and accountability to them
Qualifications:
7+ years of experience in software engineering or a related field
Extensive experience working with our stack (Python, PostgreSQL, AWS) or something similar
BA/BS degree in computer science or other engineering degree
Ability to quickly learn, understand and work with new emerging technologies, methodologies, and solutions
Experience building and managing production-quality ML models a plus
Growth-company DNA – thrives in a fast-paced environment and shares an excitement to lead change!
",https://www.builtinchicago.org/job/data/data-engineering-lead/62913
JOB143851572195,Senior Data Engineer,Senior Data Engineer,"PhD in a related discipline with at least 6 years of experience; Master’s degree with 12 years of experience; or Bachelor’s degree with experience in biomedical data management, data engineering, quality assurance, assay development, specimen data management or related discipline,Demonstrated proficiency with molecular biology concepts; and ability to support, develop and deploy laboratory and other research data management processes and procedures as they apply to complex, high dimensional data sets,Demonstrated ability to understand and translate high-level scientific datasets and results into data curation and management strategies and the underlying structures, curation processes and infrastructure required.,Strong understanding of LIMS systems and systematic, relational approaches to data integration and data processing workflows,Familiarity with Amazon Web Services (AWS).,Excellent skills in R programming and experience in additional computer languages such as Perl, Python, PHP, S-PLUS or Java (or C/C++),Extensive practical experience in working with diverse but highly-connected scientific knowledge collections and their query interfaces to enable research hypotheses around compound targets, mechanisms of action, and patient response,Proven ability to work in a team environment with clinical personnel, study monitors, computational biologists, biostatisticians, programmers, and medical writers,Knowledge of FDA/ICH guidelines and industry standard practices regarding data management are helpful but not required,Detailed knowledge and experience in case report form design, central laboratories, programming databases, query resolution, data validation,Computer skills: detailed knowledge of at least one data management system (Oracle Clinical or Clintrial preferred), experience with SAS data sets and conversion procedures required; knowledge of MS Office program suite required,Knowledge of distributed database design and implementation, LAMP/ MySQL, etc. with capability to perform/direct/assess implementation of such databases,Working knowledge of both Windows and Linux operating systems is required,Along with programming proficiency must have creativity, and show a strong capacity for independent thinking and the ability to grasp underlying biological questions,Must thrive in a complex, dynamic environment while adapting to dynamically changing priorities,Must have excellent time management and organizational skills","Develop, enhance, and automate processes for queuing and prioritizing data management and curation requests,Implement a quality control (QC) process to evaluate compliance with data models and taxonomies to ensure cohesion of curated data across time as data models and configurations evolve,Create a rapid means to remediate data that fail to meet curation specifications,Empower scientists with tools, processes and data structures needed to support project objectives,Ensure accurate, complete and timely collection, delivery and tracking of analytical information from translational, CRO or collaborating laboratories for curation, ingestion and delivery to computational scientists,Help define, deliver and implement R/ED, collaborator and partner laboratory analytical data management systems, processes and procedures,Work with R/ED study teams to develop R/ED information management plans that outline data capture, data flow, data queries, manual checks, and data listings needed to ensure data integrity,Participate in comprehensive data review activities in coordination with project and study teams,Work with computational biologists, computational scientists, biostatisticians and study scientists to resolve data quality issues,Make data, including raw/interim data, available to R/ED department personnel as required,Collaborate with users to enable data access and ingestion,Acquire user feedback to inform business requirements for future development.","
Description
Celgene is a global biopharmaceutical company leading the way in medical innovation to help patients live longer, better lives. Our purpose as a company is to discover and develop therapies that will change the course of human health. We value our passion for patients, quest for innovation, spirit of independence and love of challenge. With a presence in more than 70 countries - and growing - we look for talented people to grow our business, advance our science and contribute to our unique culture.
Summary/Scope: Celgene seeks a talented, results and achievement oriented individual to contribute to our informatics and data management initiatives in Research and Early Development (R&ED). This hands-on role interfaces with programs spanning both discovery and translational sciences where processing and interpreting multi-platform and multi-dimensional ‘omic’ data in pre-clinical and clinical settings is being employed to identify molecular drug targets, characterize MOA, prioritize clinical indications and generate patient selection hypotheses. We are seeking an individual with extensive experience managing, processing, and applying quality control metrics and processes to a wide range of data types in support of R&ED clinical trials and drug development experiments while working in close collaboration with basic research, translational and computational scientists.
Responsibilities include, but are not limited to, the following:
Develop, enhance, and automate processes for queuing and prioritizing data management and curation requests
Implement a quality control (QC) process to evaluate compliance with data models and taxonomies to ensure cohesion of curated data across time as data models and configurations evolve
Create a rapid means to remediate data that fail to meet curation specifications
Empower scientists with tools, processes and data structures needed to support project objectives
Ensure accurate, complete and timely collection, delivery and tracking of analytical information from translational, CRO or collaborating laboratories for curation, ingestion and delivery to computational scientists
Help define, deliver and implement R/ED, collaborator and partner laboratory analytical data management systems, processes and procedures
Work with R/ED study teams to develop R/ED information management plans that outline data capture, data flow, data queries, manual checks, and data listings needed to ensure data integrity
Participate in comprehensive data review activities in coordination with project and study teams
Work with computational biologists, computational scientists, biostatisticians and study scientists to resolve data quality issues
Make data, including raw/interim data, available to R/ED department personnel as required
Collaborate with users to enable data access and ingestion
Acquire user feedback to inform business requirements for future development.
Qualifications
PhD in a related discipline with at least 6 years of experience; Master’s degree with 12 years of experience; or Bachelor’s degree with experience in biomedical data management, data engineering, quality assurance, assay development, specimen data management or related discipline
Demonstrated proficiency with molecular biology concepts; and ability to support, develop and deploy laboratory and other research data management processes and procedures as they apply to complex, high dimensional data sets
Demonstrated ability to understand and translate high-level scientific datasets and results into data curation and management strategies and the underlying structures, curation processes and infrastructure required.
Strong understanding of LIMS systems and systematic, relational approaches to data integration and data processing workflows
Familiarity with Amazon Web Services (AWS).
Excellent skills in R programming and experience in additional computer languages such as Perl, Python, PHP, S-PLUS or Java (or C/C++)
Extensive practical experience in working with diverse but highly-connected scientific knowledge collections and their query interfaces to enable research hypotheses around compound targets, mechanisms of action, and patient response
Proven ability to work in a team environment with clinical personnel, study monitors, computational biologists, biostatisticians, programmers, and medical writers
Knowledge of FDA/ICH guidelines and industry standard practices regarding data management are helpful but not required
Detailed knowledge and experience in case report form design, central laboratories, programming databases, query resolution, data validation
Computer skills: detailed knowledge of at least one data management system (Oracle Clinical or Clintrial preferred), experience with SAS data sets and conversion procedures required; knowledge of MS Office program suite required
Knowledge of distributed database design and implementation, LAMP/ MySQL, etc. with capability to perform/direct/assess implementation of such databases
Working knowledge of both Windows and Linux operating systems is required
Along with programming proficiency must have creativity, and show a strong capacity for independent thinking and the ability to grasp underlying biological questions
Must thrive in a complex, dynamic environment while adapting to dynamically changing priorities
Must have excellent time management and organizational skills
Celgene is committed to equal opportunity in the terms and conditions of employment for all employees and job applicants without regard to race, color, religion, sex, sexual orientation, age, gender identity or gender expression, national origin, disability or veteran status.
Celgene complies with all applicable national, state and local laws governing nondiscrimination in employment as well as employment eligibility verification requirements of the Immigration and Nationality Act. All applicants must have authorization to work for Celgene in the U.S.
*LI-MG2
BIO-US
",https://jobs.newscientist.com/en-au/job/1401626409/senior-data-engineer/
JOB144077996830,Data Engineer,Data Engineer,Experience with integration of data from multiple data sources,"Is Service-Centric: Someone who desires to make an impact in and outside of our office. We look for service minded people to support our customers, each other and our community.,Has a Growth Mindset: Driven to own your individual learning and development (We’ll help you - we have a team dedicated to training you and providing extra educational resources).,Rocks Impact: Thinks two steps ahead to ensure the work we do will solve problems and make a difference.,Will be a StrataPro: Accountable. Prepared. Positive. Core to who we are and how we treat one another.,Participate in the full life-cycle of development, from definition, design, implementation, and testing,Work with our Data Science team on transitioning a proof-of-concept to a real product,Selecting and integrating any Data tools and frameworks required to provide requested capabilities,Be an advocate for developing best practices in the organization, and bring in knowledge of new technologies to the team,Monitoring performance and advising any necessary infrastructure changes,Regularly contribute to ongoing improvements in engineering process and product development ecosystem,Give technical presentations to both development, product, and leadership teams,Work on building proof of concept architectures that have an eye towards production.,Participates in architecting and building large distributed systems that scale well,Work closely with our current engineering team to integrate data architectures into our existing data platform.,Support business decisions with ad hoc analysis as needed.,Expected to cross train team members on areas of technical expertise,Develop tools and utilities to maintain high system availability, monitor data quality, and provide statistics,Develop understanding of healthcare & finance terminology and workflows.,5+ Years of experience as a data/software engineer,Experience with SaaS/Cloud based offerings/products,Worked with big data and data warehousing technologies,Strong understanding of ETL processes and data flow architectures and tools,Experience building decoupled infrastructures,Proficient understanding of distributed computing principles,Experience building infrastructures that process large amounts of structured and unstructured data,Experience building tools for technical teams,Advanced knowledge of SQL or other relational databases,Intermediate to advanced knowledge in Unix and Linux command line tools and scripting,Experience programming in a highly regulated industry (healthcare or finance preferred).","
We are committed to our mission to help heal healthcare. Our unique culture is driven by a social, hardworking environment full of talented people solving problems together. We embrace learning, cross-team collaboration, and continuous career growth. Lifting each other to lift our clients, our product, our company. If being part of a fun, fast-moving, innovative team is what you seek? Keep reading.
We look for someone who:
Is Service-Centric: Someone who desires to make an impact in and outside of our office. We look for service minded people to support our customers, each other and our community.
Has a Growth Mindset: Driven to own your individual learning and development (We’ll help you - we have a team dedicated to training you and providing extra educational resources).
Rocks Impact: Thinks two steps ahead to ensure the work we do will solve problems and make a difference.
Will be a StrataPro: Accountable. Prepared. Positive. Core to who we are and how we treat one another.
What you’ll do in this role:
As a Data Engineer, you will have the opportunity to work on technical infrastructures that will help many of the nation’s leading healthcare providers in utilizing their financial, operational, and clinical data to drive their mission of providing world-class care, while improving their financial health.
Participate in the full life-cycle of development, from definition, design, implementation, and testing
Work with our Data Science team on transitioning a proof-of-concept to a real product
Selecting and integrating any Data tools and frameworks required to provide requested capabilities
Be an advocate for developing best practices in the organization, and bring in knowledge of new technologies to the team
Monitoring performance and advising any necessary infrastructure changes
Regularly contribute to ongoing improvements in engineering process and product development ecosystem
Give technical presentations to both development, product, and leadership teams
Work on building proof of concept architectures that have an eye towards production.
Participates in architecting and building large distributed systems that scale well
Work closely with our current engineering team to integrate data architectures into our existing data platform.
Support business decisions with ad hoc analysis as needed.
Expected to cross train team members on areas of technical expertise
Develop tools and utilities to maintain high system availability, monitor data quality, and provide statistics
Develop understanding of healthcare & finance terminology and workflows.
Your accomplishments include:
5+ Years of experience as a data/software engineer
Experience with SaaS/Cloud based offerings/products
Worked with big data and data warehousing technologies
Strong understanding of ETL processes and data flow architectures and tools
Experience building decoupled infrastructures
Proficient understanding of distributed computing principles
Experience building infrastructures that process large amounts of structured and unstructured data
Experience building tools for technical teams
Advanced knowledge of SQL or other relational databases
Intermediate to advanced knowledge in Unix and Linux command line tools and scripting
Experience programming in a highly regulated industry (healthcare or finance preferred).
Experience with integration of data from multiple data sources
",https://www.builtinchicago.org/job/data/data-engineer/63449
JOB147638027046,"PySpark Data Engineer, Analytics","PySpark Data Engineer, Analytics","Healthy - Wellness programs, competitive medical benefit offerings,Happy – Recognition programs, a confidential employee assistance program, Perkspot/employee discount program and potentially flexible work arrangements such as staggered start times,Enriched – Tuition reimbursement, training and learning programs, and leadership development opportunities",,"
Job Description Summary
The Enterprise Analytics team at CCC has an open position for a Big Data Engineer. The team builds platforms to provide insights to internal and external clients of CCC businesses in auto property damage and repair, medical claims and telematics data. Our solutions include analytical applications against claim processing, workflow productivity, financial performance, client and consumer satisfaction, and industry benchmarks.
Our data engineers use big data technology to create best-in-industry analytics capability. This position is an opportunity to use Hadoop and Spark ecosystem tools and technology for micro-batch and streaming analytics. Data behaviors include ingestion, standardization, metadata management, business rule curation, data enhancement, and statistical computation against data sources that include relational, XML, JSON, streaming, REST API, and unstructured data. The role has responsibility to understand, prepare, process and analyze data to drive operational, analytical and strategic business decisions.
The Big Data Engineer will work closely with product owners, information engineers, data scientists, data modelers, infrastructure support and data governance positions. We look for engineers who start with a base of big data skills but who also love to learn new tools and techniques in a big data landscape that is endlessly changing.
Job Duties
* Build end to end data flows from sources to fully curated and enhanced data sets. This can include the effort to locate and analyze source data, create data flows to extract, profile, and store ingested data, define and build data cleansing and imputation, map to a common data model, transform to satisfy business rules and statistical computations, and validate data content.
* Produce data building blocks, data models, and data flows for varying client demands such as dimensional data, data feeds, dashboard reporting, and data science research & exploration
* Modify and maintain complex SQL and PL/SQL for Oracle ETL and BI/DW data flows * Produce automated tests of data flow components
* Use knowledge of the business to automate business-specific tests for data content quality
* Automate code deployment and promotion
* Build automated orchestration and error handling for use by production operation teams
* Provide technical expertise to diagnose errors from production support teams
* Collaborate with team members in an Agile team (e.g., Scrum)
* Participate as both leader and learner in team tasks for architecture, design and analysis
* Coordinate within collocated on-site teams as well as with work plans for off-shore resources
Qualifications
Qualifications
* Bachelor’s Degree or Two Year Technical Program with a Programming Specialization
* 3+ years’ experience with complex data flows
* Unix commands and scripting
* Hadoop fundamentals and architecture: HDFS, map-reduce, job performance
* Open source big data tools such as Hive, HBase, parquet, Spark SQL
* Advanced SQL for data profiling and data validation
* Programming in a language such as Python (preferred), Scala, etc.
Preferred Requirements:
* Familiar with open source monitoring and orchestration tools such as Ambari, Oozie
* Advanced transformations and statistical computations using Spark-SQL and Hive programming
* Experience with development of metadata-driven and fully parameterized data processing tools
* Programming in streaming-data tools such Spark-Scala, NIFI and Stream Analytics Manager
Why Choose CCC:
We promote a healthy work-life balance and offer generous benefit plans and resources designed with employee satisfaction in mind.
What we value is simple - customers, employee commitment, collaboration and clear communication.
We hire people who will embrace the company’s goals and productively contribute in ways that help us serve the customer, innovate, and stay strong.
We make it a priority to keep employees healthy, happy and enriched.
Our corporate headquarters is located in downtown Chicago within the historic Merchandise Mart—a certified LEED (Leadership in Energy and Environmental Design) building.
Please Note: Contingent Workers, Field Inventory Representatives and Interns are not eligible for the benefits above.
CCC Information Services was recognized by Forbes as one of America’s Best Mid-Sized Employers in 2018 and ranked #17 in the Top 100 Digital Companies in Chicago in 2017 by Built In Chicago.
CCC is ready to help you shift your career into high gear. Let's get started!
Healthy - Wellness programs, competitive medical benefit offerings
Happy – Recognition programs, a confidential employee assistance program, Perkspot/employee discount program and potentially flexible work arrangements such as staggered start times
Enriched – Tuition reimbursement, training and learning programs, and leadership development opportunities
",https://www.builtinchicago.org/job/data/pyspark-data-engineer-analytics/64883
JOB147879992415,Data Engineer (Big Data),Data Engineer (Big Data),,,"
Title: Data Engineer (Big Data)
Clearance: TS/SCI
Work Location: Quantico, VA
Responsibilities
• Support the Marine Corps Intelligence Activity (MCIA) Weapons and Technology Division (WTD) in Science & Technology Intelligence (S&TI) analysis of foreign basic and applied research and engineering, prototyping, technology transfer, developmental and operational testing military fielding and Integration of technologies
• Conduct S&TI research, analysis and produce finished (S&TI) assessments on information systems and emerging and disruptive technologies (E&DT) that will likely affect US Marine Corps operations.
Minimum Requirements
Required Experience
• STEM degree related to labor cat subject matter
• 3 years experience performing S&TI analysis or waivered with a demonstrated proficiency in analyzing, summarizing, and writing. MCIA will provide guidance for a writing sample related to the topic area
Desired Requirements
• Working knowledge of S&TI within the DoD including S&TI production centers and responsibilities
Mission Essential considers all applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status. Mission Essential is an EEO/AA employer and a VEVRAA Federal Contractor. Read our Privacy Policy
",https://www.clearancejobs.com/jobs/3129621/data-engineer-big-data
JOB148728083719,"Big Data Engineer, Python, Opensource, Apache, Storm","Big Data Engineer, Python, Opensource, Apache, Storm",,,"Description
My Client who is a Gaming/Streaming Tech company based in London
is looking for a Big Data Engineer/Developer for a 6 month contract up to £600/day.
The ideal candidate should be well versed in:
-Big Data
-Opensource
-AWS
-Python
-Apache
-Storm
-Kafka
-Scala
My client is looking for someone who can start within 2-3 weeks from now.
Do get in contact if you see this role to be a fit for you.
Type
Start Date
Contract Length
Telephone
Job Reference
Job ID
Applications
",https://www.careerjet.co.uk/clk/10e1c0dc06e71fd2977ce5ad13fc515a.html
JOB152668961128,Clinical Data Engineer,Clinical Data Engineer,,"Read Codes and Clinical Terms Version 3,SNOMED CT,ICD10 and OPCS4,MedDRA,LOINC,Information Resources – performing upgrades to code editions or cross-maps.,Communications and Leadership – ability to provide and receive complex technical information instruction and advice relevant to the role, be courteous and provide effective service to support NWEH, clinical trial sponsors and other stakeholders in various projects.,Work with the Technical Architect to define the scope and content of data coding services and work with Database Administrators to produce automated ETLs, coding improvements and business intelligence reports to deliver the required outputs.,Assist IT support staff in troubleshooting data and coding issues in NWEH applications.,Partnership working – liaise with other members of NWEH technical, clinical and operational teams as necessary to ensure the data coding services are fit for purpose and available as required.,Analysis and data management – ensure the data coding updates and ETL processes are properly documented and understood, that systems are designed and in place to monitor data quality and categorisation against agreed targets and that the Data Dictionary and Mapper is properly documented to enable any problems to be quickly identified and corrected.,Research, Development and Audits – participate in audits of performance, quality, regulatory and operational effectiveness.,Degree in IT related field or equivalent experience,Experience of mapping between different clinical coding systems.,Experience of working with NHS medical data.,Experience of any relational database system.,Basic knowledge of database modelling including referential integrity and DDL.,May be required to handle heavy objects infrequently,Required to use a VDU for long periods during the working day,Required to undertake prolonged concentration,Experience creating ETL (Extract, Transform and Load) processes.,Experience with data presentation models used on clinical trials e.g. CDISC SDTM,Experience with data standardisation models used in clinical data analytics e.g. OMOP Common Data Model.,Experience using R,Understanding of clinical governance/data handling/safety monitoring and reporting,Experience working on Computer System Validation.,Modern offices in Central Manchester,Competitive Salary,Flexible working hours,The ability to work from home,Child care vouchers,Excellent pension benefits,Access to training resources,27 day’s annual leave","
Clinical Data Engineer Job Description
Salary:
£31,000 – £40,000
Location: City Labs, Nelson St, Manchester M13 9NQ
Northwest EHealth (NWEH) are currently undergoing a significant expansion and are looking for talented, innovative and passionate data engineers. This is the chance to join an organisation who are at the forefront of pioneering how electronic healthcare data can be utilised to unlock the value of health and care data for the benefit of patients whilst enabling informed decision making to support and empower new models of clinical service delivery.
NorthWest EHealth (NWEH) is a limited company formed following a successful partnership between the University of Manchester, Salford Royal Foundation Trust and Salford Clinical Commissioning Group. Our customers are pharmaceutical companies and technology partners as well as NHS and government. We work collaboratively with partners to develop innovative ways of delivering improvements in health care and research. Major projects have included recruiting patients to studies, enabling ground-breaking real-world clinical trials and delivering real-time drug safety monitoring throughout trials. NWEH provides a highly creative and collaborative work environment, where knowledge sharing and team work are key to success. NWEH models its structure on a flat organisation, in which every voice is heard and collaboration across teams is key.
You will be joining our innovative and dynamic technical IT team, and will be responsible for supporting, developing and expanding the Data Dictionary and Mapper component of the NWEH Data Platform.
NWEH are looking for a Clinical Data Engineer with the ability to work independently without direct supervision, and be an adaptable and flexible team player. Out-of-hours emergency/urgent work may sometimes be required; you must be good at problem solving, have an eye for detail, and can plan, organise and prioritise work to meet deadlines.
As a Clinical Data Engineer, you will be responsible for maintaining and developing the systems that update the Data Dictionary, automating these processes and expanding the Data Dictionary to include new coding editions or other coding requirements. You will investigate coding issues in NWEH applications and develop processes that report issues proactively. You will be a good communicator and will work closely with the database, software development and statistician teams. You will take the lead in evaluating data standards, coding editions and implementation guides, both national and international. You will be familiar with the following coding systems:
Read Codes and Clinical Terms Version 3
SNOMED CT
ICD10 and OPCS4
MedDRA
LOINC
Other responsibilities:
Information Resources – performing upgrades to code editions or cross-maps.
Communications and Leadership – ability to provide and receive complex technical information instruction and advice relevant to the role, be courteous and provide effective service to support NWEH, clinical trial sponsors and other stakeholders in various projects.
Work with the Technical Architect to define the scope and content of data coding services and work with Database Administrators to produce automated ETLs, coding improvements and business intelligence reports to deliver the required outputs.
Assist IT support staff in troubleshooting data and coding issues in NWEH applications.
Partnership working – liaise with other members of NWEH technical, clinical and operational teams as necessary to ensure the data coding services are fit for purpose and available as required.
Analysis and data management – ensure the data coding updates and ETL processes are properly documented and understood, that systems are designed and in place to monitor data quality and categorisation against agreed targets and that the Data Dictionary and Mapper is properly documented to enable any problems to be quickly identified and corrected.
Research, Development and Audits – participate in audits of performance, quality, regulatory and operational effectiveness.
Required skills:
Degree in IT related field or equivalent experience
Experience of mapping between different clinical coding systems.
Experience of working with NHS medical data.
Experience of any relational database system.
Basic knowledge DML and SQL programming.
Basic knowledge of database modelling including referential integrity and DDL.
May be required to handle heavy objects infrequently
Required to use a VDU for long periods during the working day
Required to undertake prolonged concentration
Desirable but not essential skills include:
Experience creating ETL (Extract, Transform and Load) processes.
Experience with data presentation models used on clinical trials e.g. CDISC SDTM
Experience with data standardisation models used in clinical data analytics e.g. OMOP Common Data Model.
Experience using R
Understanding of clinical governance/data handling/safety monitoring and reporting
Experience working on Computer System Validation.
Benefits:
Modern offices in Central Manchester
Competitive Salary
Flexible working hours
The ability to work from home
Child care vouchers
Excellent pension benefits
Access to training resources
27 day’s annual leave
",https://jobs.theguardian.com/job/6489787/clinical-data-engineer/
JOB154336492832,Senior Data Engineer / Lead Data Engineer,Senior Data Engineer / Lead Data Engineer,"BS/BA (MS is a plus) in Computer Science, Information Systems, Engineering or related field and 10 years experience or equivalent training.,Experience working with enterprise and cloud database systems like MySQL, MongoDB, Oracle, MSSQL, Hadoop.,In-depth knowledge of Mac OS X system,Strong proficiency in PHP, preferable 5 years of hands on experience.,Fluency in bash and python scripting languages, with significant automation experience.,Proficient in scripting languages, such as PHP, Python, Ruby on Rails, NodeJS, Java etc.,Experience designing, developing and programming API solutions for integration from various client end points, including native applications,Desire to build and lead a rapid development team from project definition, scoping, estimating, planning, development, testing and launch. Strong preference in someone who has done this before,Up-to-date on current industry trends, third party integration, and open source tools with regard to database design, integration, data storage, analysis, security, and implementation,Strong analytical skills,Excellent work ethic and meticulous attention to detail","Entrepreneurial full-stack engineer who can Design, model and architect data and data-automation systems.,Develop and refine parsing, munging, and integrations from existing and future datasets to refine, clean, transform and apply through core systems channels.,Fluency in bash and python scripting languages, with significant automation experience.,Strong understanding Database development/implementation, and relational databases.,Proficiency in Salesforce and/or similar structural CRM and relational database systems.,The understanding and/or proficiencies in the following are a plus, but not required:,Define and apply best practices for building scalable and secure systems internationally,Self-manage, team lead and be able to manage partner interactions and coordinate on delivery for multiple ongoing projects.,Manage internal and cloud-based systems,Performance tune and optimize data systems,Define specifications for functional and technical deliverables,Personal network of highly skilled engineers and experience hiring.,Extensive experience developing and instituting team processes, including those around testing, revision control, deployment, and release forecasting.,Strong familiarity with data science and data munging.,Eagerness to communicate technical concepts to nontechnical team members, especially in the context of strategy and development prioritization discussions.,Leading edge awareness of new ideas and trends in Silicon Valley and the larger technology industry.,Experience in the financial services industry.,Comfortable in a decisive leadership role.","
Job Description
Desired Qualities:
Entrepreneurial full-stack engineer who can Design, model and architect data and data-automation systems.
Develop and refine parsing, munging, and integrations from existing and future datasets to refine, clean, transform and apply through core systems channels.
Fluency in bash and python scripting languages, with significant automation experience.
Strong understanding Database development/implementation, and relational databases.
Proficiency in Salesforce and/or similar structural CRM and relational database systems.
The understanding and/or proficiencies in the following are a plus, but not required:
Define and apply best practices for building scalable and secure systems internationally
Self-manage, team lead and be able to manage partner interactions and coordinate on delivery for multiple ongoing projects.
Manage internal and cloud-based systems
Performance tune and optimize data systems
Define specifications for functional and technical deliverables
Personal network of highly skilled engineers and experience hiring.
Extensive experience developing and instituting team processes, including those around testing, revision control, deployment, and release forecasting.
Strong familiarity with data science and data munging.
Eagerness to communicate technical concepts to nontechnical team members, especially in the context of strategy and development prioritization discussions.
Leading edge awareness of new ideas and trends in Silicon Valley and the larger technology industry.
Experience in the financial services industry.
Comfortable in a decisive leadership role.
Located in the South Bay.
Requirements:
BS/BA (MS is a plus) in Computer Science, Information Systems, Engineering or related field and 10 years experience or equivalent training.
Experience working with enterprise and cloud database systems like MySQL, MongoDB, Oracle, MSSQL, Hadoop.
In-depth knowledge of Mac OS X system
Strong proficiency in PHP, preferable 5 years of hands on experience.
Fluency in bash and python scripting languages, with significant automation experience.
Proficient in scripting languages, such as PHP, Python, Ruby on Rails, NodeJS, Java etc.
Experience designing, developing and programming API solutions for integration from various client end points, including native applications
Desire to build and lead a rapid development team from project definition, scoping, estimating, planning, development, testing and launch. Strong preference in someone who has done this before
Up-to-date on current industry trends, third party integration, and open source tools with regard to database design, integration, data storage, analysis, security, and implementation
Strong analytical skills
Excellent work ethic and meticulous attention to detail
Preferred experience with Business Intelligence reporting, AWS RDS Services, Java, database scaling, and high availability/high performance design
Company Description
We are a privately funded and organically grown, profitable, technology-driven company that has stealthily grown into a leader of our space in under 2 years. We have a brilliant and seasoned team with over 25 years of combined experience coupled with a technology platform that has truly given us an unfair trading advantage in our massively fragmented space.
San Francisco, CA
7d46fbc315
Thu, 23 Feb 2017 14:02:30 PST
PI96944129
",https://careers.insidehighered.com/job/1332329/senior-data-engineer-lead-data-engineer/
JOB154507852144,Senior Data Engineer,Senior Data Engineer,,," • Great time to join a Leading Green Energy business.
• Data-driven strategy
• Progression opportunities to become Head of Data Engineering.
Our client is moving from a legacy to a cloud-based environment which requires changing the way they process their data. They are a data-driven organisation, it guides their strategic decision-making and service/product development. As a result, they need a Senior Data Engineer with experience in data architecture and data strategy to drive the organisation forward. The company is expanding so this type of role provides progression to become the Head of Data Engineering.
What you’ll be doing
As the Senior Data Engineer, you will be influential in supporting the migration from a legacy platform to a modern, scalable cloud-based, real-time streaming data infrastructure. This position will require working with a combination of small and Big Data Technologies.
You will support the design, roll-out and execution of the data strategy across various business units. You will collaborate with other engineering and data teams to ensure that the data is integrated and accessible.
This role requires a range of Data Engineering activities including; prototype development, ETL pipelines, architecture, process automation, data strategy and more.
What experience you’ll need to apply
• Solid ETL pipeline experience
• Python, Scala or Java development experience
• Experience of working on Big Data solutions
• Messaging broker platform such as Kafka, Kinesis, RabbitMQ or similar
• Experience of using either Spark, BigQuery, Hive, Hadoop, HDFS, Hydra
• Cloud Data Platform service migration or maintenance (GCP, AWS, Azure or Oracle)
What you’ll get in return for your experience
A competitive salary with excellent bonuses and benefits package. Grow with a leading company and have the potential to become the Head of Data Engineering.
What’s next?
Please get in touch with Scott with an up to date CV today. Don’t hesitate to call/email to discuss the job in further detail.
",https://jobs.theguardian.com/job/6881720/senior-data-engineer/
JOB158997283879,Data Engineer,Data Engineer,,,"
Data Engineer
Job ID: 126192
Store ID:
Brand: Global Custom Commerce
Location: Houston, TX
Job Type: Corporate/Other
Category: E-Commerce
Apply
POSITION PURPOSE
Congrats! You re learning about an exciting new role with The Home Depots Global Custom Commerce (GCC) team that will revitalize and invigorate the way we manage and view data. For this role, we are looking for some one who can develop, implement, test and maintain data pipelines (batch & streaming) and data structures within a cloud based column-oriented data store. This person will support the GCC BI and Data Science strategic initiatives to drive better customer experiences and more profitable outcomes
Why work here? Our entrepreneurial roots and maverick mentality, coupled with the resources and backing of the #1 home improvement retailer in the world, The Home Depot, is a unique opportunity for you to be a transformative retail disrupter. Plus, GCC is the world s largest online window covering company, and we ve got a demonstrably awesome 20-year track record. From our open-floor office to our open-door ethos, our culture is rooted in improving, evolving, and having fun (we re pretty serious about cake, cook-offs, ping pong, meaningful work and exciting projects). Most importantly, our team members are always inspired, engaged, and ready for growth. That means you ll have the resources and the runway to create truly magical, out-of-the-box work. Moreover, you will play an important role in leveraging our culture, people, systems, processes, and technology ultimately to provide incredible customer experiences, while growing business for GCC and The Home Depot. This is your chance to be part of something big, in a small start-up environment. We re ranked as one of The Top 5 Workplaces in Texas and have consistently won the following awards:The Best Place to Work in Houston (Houston Business Journal), Houston s Top Workplaces (Houston Chronicle) and Houston s Best and Brightest.
MAJOR TASKS, RESPONSIBILITES AND KEY ACCOUNTABILITIES
20%- Implement a real time streaming data ingestion and processing pipeline using Google Dataflow (Apache Beam)
20%- Interface with business intelligence analyts and others in IT (i.e. data engineers, architects, WebOps) in frequent whiteboard sessions to dicsucuss the design, implementation, and testing of data pipleines
20%- Maintain data architecture standards and ETL/ELT best practices consistent with a column oritented data store in an analytic use case
20%- Active and engaged particitpation in the Scrum delivery process
20%- Support solutions in production
NATURE AND SCOPE
This role reports to the Sr. Manager of EDW.
This role has no direct reports.
ENVIRONMENTAL JOB REQUIREMENTS
Environment:
Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.
Travel:
Typically requires overnight travel less than 10% of the time.
MINIMUM QUALIFICATIONS
Must be eighteen years of age or older.
Must be legally permitted to work in the United States.
Education Required:
The knowledge, skills and abilities typically acquired through the completion of a bachelor’s degree program or equivalent degree in a field of study related to the job.
Years of Relevant Work Experience: 6 years
Physical Requirements:
Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.
Preferred Qualifications:
Familiarity with Agile methodologies
Experience with Spark dataframes, SparkSQL, Kafka, KSQL, real-time streaming, and message bus technologies
Experience with data science technologies such as SAS, R, Matlab, or similar
Experience with data warehousing and dimensional modeling
Knowledge, Skills, Abilities and Competencies:
Experience in building real time streaming data ingestion and processing pipeline using Apache Beam (running on either Google Datflow or Apache (Apex, Flink, or Spark) or Kafka in an analytics or data science use case
Experience with data processing tools (e.g. Hadoop, Spark, Dataflow, etc.)
Experience building ETL/ELT pipelines
Experience with column-oriented databases (e.g Redhift, BigQuery, Vertica)
Ability to go from whiteboard discussion to code
Ability to effectively communicate with technical and non-technical audiences
Strong programming ability
Success in a highly dynamic environment and ability to shift priorities with agility
Ability to act independently with minimal supervision
Willingness to explore and implement new ideas and technologies
Experience working directly with subject matter experts in both business and technology domains
Experience as a team lead
",https://careers.homedepot.com/job/9136570/
JOB163084700645,Senior Data Engineer,Senior Data Engineer,"Bachelors degree in Computer Engineering, Computer Science or related discipline, Masters Degree preferred,7+ years of ETL design, development, and performance tuning on Microsoft SSIS in SQL Server 2012 and above (2016 preferable) in a multi-dimensional Data Warehousing environment,7+ years of SSAS design, development, maintenance and performance tuning on Microsoft SQL Server 2012 and above (2016 preferable), with expert MDX and DAX skills,7+ years of advanced SQL Programming: PL/SQL, T-SQL, U-SQL,5+ years of Enterprise Data & Analytics solution architecture,2+ years of Power BI experience including mobile solutions,2+ years of strong and extensive hands on experience in Azure, preferably data heavy / analytics applications leveraging relational and NoSQL databases, Data Warehouse and Big Data,Experience with Azure Data Lake, Azure SQL Data Warehouse, Data Catalog, Azure Analysis Services, Data Bricks, Storage Account Gen2, Azure SQL Database, Azure DNS, Virtual Network, DocumentDB, Azure App Service, Data Factory,Experience with Big Data Technologies such as: Hadoop, Sqoop, Hive, Kafka, Spark, Pyspark, Python, Scala or Pig,Experience with Big Data Management (BDM) for relational and non-relational data (formats like json, xml, avro, parquet, copybook, etc.),Experience with setting up and operating data pipelines using Python or SQL,Strong analytical abilities and a strong intellectual curiosity","Interacts with senior level customers to consult on scalable enterprise analytics solutions that provide the business with a competitive advantage.,Develops technical solutions to complex problems which require the regular use of ingenuity and creativity.,Works on unusually complex technical problems and provides solutions which are highly innovative and ingenious.,Design and build a modern data warehouse in the cloud,Design and build a customer 360,Implement a flexible and audible data pipeline,Enhance data collection procedures to build analytic systems.,Process, cleanse, and verify the integrity of data used for analysis.,Perform ad-hoc analysis and present results in a clear and user friendly manner,Perform testing, resolve issues and automate unit tests.,Develop proof-of-concept (POC) solutions to help business units better visualize their business needs and to clarify requirements for development.","
For 70 years, Charles River employees have worked together to assist in the discovery, development and safe manufacture of new drug therapies. When you join our family, you will have a significant impact on the health and well-being of people across the globe. Whether your background is in life sciences, finance, IT, sales or another area, your skills will play an important role in the work we perform. In return, well help you build a career that you can feel passionate about.
Job Summary
We are seeking an experienced Senior Data Engineer for our IT Analytics Delivery Team located in Wilmington, MA.
Theres never been a more exciting time to be on the Analytics team at Charles River Labs! We are on an exciting journey to modernize the data landscape. If you are an engineer who enjoys cloud technologies, data warehousing, data analytics, and designing innovative analytical solutions, this job may be for you!
The team is seeking top notch talent in the Microsoft Azure full data stack and modern data toolset. If you are interested in using your leadership, expertise and innovative skills to build something brand new, enjoy making architectural decisions, are a thought leader in the data space, have a passion for data and analytics, and like to mentor others, then we want to talk to you! A truly exciting and unique opportunity awaits you!
This role will work collaboratively, in a consultative way, across the business units and IT, building modern analytics solutions, supporting and mentoring engineering teams, as well as advising on best approaches to leveraging Azure in the most effective and efficient manner.
The following are responsibilities related to the Senior Data Engineer:
Interacts with senior level customers to consult on scalable enterprise analytics solutions that provide the business with a competitive advantage.
Develops technical solutions to complex problems which require the regular use of ingenuity and creativity.
Works on unusually complex technical problems and provides solutions which are highly innovative and ingenious.
Design and build a modern data warehouse in the cloud
Design and build a customer 360
Implement a flexible and audible data pipeline
Enhance data collection procedures to build analytic systems.
Process, cleanse, and verify the integrity of data used for analysis.
Perform ad-hoc analysis and present results in a clear and user friendly manner
Perform testing, resolve issues and automate unit tests.
Develop proof-of-concept (POC) solutions to help business units better visualize their business needs and to clarify requirements for development.
Qualifications
The following are minimum requirements related to the Senior Data Engineer position:
Bachelors degree in Computer Engineering, Computer Science or related discipline, Masters Degree preferred
7+ years of ETL design, development, and performance tuning on Microsoft SSIS in SQL Server 2012 and above (2016 preferable) in a multi-dimensional Data Warehousing environment
7+ years of SSAS design, development, maintenance and performance tuning on Microsoft SQL Server 2012 and above (2016 preferable), with expert MDX and DAX skills
7+ years of advanced SQL Programming: PL/SQL, T-SQL, U-SQL
5+ years of Enterprise Data & Analytics solution architecture
2+ years of Power BI experience including mobile solutions
2+ years of strong and extensive hands on experience in Azure, preferably data heavy / analytics applications leveraging relational and NoSQL databases, Data Warehouse and Big Data
The following are strongly desired:
Experience with Azure Data Lake, Azure SQL Data Warehouse, Data Catalog, Azure Analysis Services, Data Bricks, Storage Account Gen2, Azure SQL Database, Azure DNS, Virtual Network, DocumentDB, Azure App Service, Data Factory
Experience with Big Data Technologies such as: Hadoop, Sqoop, Hive, Kafka, Spark, Pyspark, Python, Scala or Pig
Experience with Big Data Management (BDM) for relational and non-relational data (formats like json, xml, avro, parquet, copybook, etc.)
Experience with setting up and operating data pipelines using Python or SQL
Strong analytical abilities and a strong intellectual curiosity
About Corporate Functions
The Corporate Functions provide operational support across Charles River in areas such as Human Resources, Finance, IT, Legal, Sales, Quality Assurance, Marketing, and Corporate Development. They partner with their colleagues across the company to develop and drive strategies and to set global standards. The functions are essential to providing a bridge between strategic vision and operational readiness, to ensure ongoing functional innovation and capability improvement.
About Charles River
Charles River is an early-stage contract research organization (CRO). We have built upon our foundation of laboratory animal medicine and science to develop a diverse portfolio of discovery and safety assessment services, both Good Laboratory Practice (GLP) and non-GLP, to support clients from target identification through preclinical development. Charles River also provides a suite of products and services to support our clients clinical laboratory testing needs and manufacturing activities. Utilizing this broad portfolio of products and services enables our clients to create a more flexible drug development model, which reduces their costs, enhances their productivity and effectiveness to increase speed to market.
With over 14,000 employees within 80 facilities in 20 countries around the globe, we are strategically positioned to coordinate worldwide resources and apply multidisciplinary perspectives in resolving our clients unique challenges. Our client base includes global pharmaceutical companies, biotechnology companies, government agencies and hospitals and academic institutions around the world. And in 2018, revenue increased by 22% to $2.27 billion from $1.86 billion in 2017.
At Charles River, we are passionate about our role in improving the quality of peoples lives. Our mission, our excellent science and our strong sense of purpose guide us in all that we do, and we approach each day with the knowledge that our work helps to improve the health and well-being of many across the globe. We have proudly supported the development of ~85% of the drugs approved by the FDA in 2018.
Equal Employment Opportunity
Charles River Laboratories is an Equal Opportunity Employer - M/F/Disabled/Vet
",https://jobs.newscientist.com/job/1401675530/-senior-data-engineer-/
JOB163200113733,Data Scientist/Data Engineer (19521),Data Scientist/Data Engineer (19521),,,"
Position Description
Novetta is seeking a Data Engineer or Data Scientist interested in creating scalable ETL solutions and solving analytical challenges! You will be part of a team of dedicated professionals solving our customers' most challenging problems.
In this role you will:
Create scalable ETL and search applications focused on semantic analysis
Identify important and interesting questions surrounding our customer's challenges, then translate those questions into concrete analytical tasks
Assemble/refine, a scalable extract, transform, load (ETL) pipeline for novel applications.
Develop strategies to extract, resolve, and unify information of various types from numerous disparate data sources
Organize and mine massive data sets of both structured and unstructured data
Provide thought-leadership in the area of analytics/data science
Basic Qualifications:​
​3+ years experience in system/software solution development and delivery
Master’s Degree or higher with a quantitative or computational focus
Computer Science, Computational Linguistics, Math, Physics, Statistics, Computer Science, Engineering, Economics, Operations Research, or similar
Prior experience with:
Statistical and topic modeling
Data mining or machine learning
Technologies:
Linux
Python
R, Matlab, Pig or SQL
Java, Scala or C++
Familiarity with the Apache Hadoop ecosystem
Version control systems (GIT)
Desired Skills:
Interest in:
Latent semantic analysis and natural language processing
Predictive and prescriptive modelling
Statistical analysis
Hypothesis testing
Experience:
Delivering big data solutions
Application development, systems administration/engineering or other technical disciplines
With commercial or government cloud solutions (AWS, Openstack, etc)
With DevOps (configuration management, application deployment, etc)
Comfortable with:
Recommending strategies for design implementation during the development process
Setting customer or team expectations in regards to project timelines
Algorithm development
Security Clearance:
Must have an active US Government Secret clearance
Company Description
So what does Novetta do?
We focus on three core areas: Cyber, Entity, and Multi-Int Analytics. Our products are focused on processing and analyzing vast amounts of data in these core areas. Our services are focused on helping our customers move from complexity to clarity. At Novetta, we bridge the gap between what our customers think they can do and what they aspire to achieve.
Our culture is shaped by a commitment to our Core Values:
Integrity: We hold ourselves accountable to the highest standards of integrity and ethics.
Customer Mission Success: Customer mission success drives our daily efforts—we strive always to exceed customer expectations and focus on mission success beyond contractual commitments.
Employee Focus: We value our employees and demonstrate our commitment to them by providing clear communications, outstanding benefits, career development, and opportunities to work on problems and technical challenges of national significance.
Innovation: We believe that innovation is critical to our success – that discovering new and more effective ways to achieve customer mission success is what makes us a great company.
",https://www.clearancejobs.com/jobs/2322584/data-scientistdata-engineer-19521
JOB164862823416,Senior Data Engineer,Senior Data Engineer,"PhD in a related discipline with at least 6 years of experience; Master’s degree with 12 years of experience; or Bachelor’s degree with experience in biomedical data management, data engineering, quality assurance, assay development, specimen data management or related discipline,Demonstrated proficiency with molecular biology concepts; and ability to support, develop and deploy laboratory and other research data management processes and procedures as they apply to complex, high dimensional data sets,Demonstrated ability to understand and translate high-level scientific datasets and results into data curation and management strategies and the underlying structures, curation processes and infrastructure required.,Strong understanding of LIMS systems and systematic, relational approaches to data integration and data processing workflows,Familiarity with Amazon Web Services (AWS).,Excellent skills in R programming and experience in additional computer languages such as Perl, Python, PHP, S-PLUS or Java (or C/C++),Extensive practical experience in working with diverse but highly-connected scientific knowledge collections and their query interfaces to enable research hypotheses around compound targets, mechanisms of action, and patient response,Proven ability to work in a team environment with clinical personnel, study monitors, computational biologists, biostatisticians, programmers, and medical writers,Knowledge of FDA/ICH guidelines and industry standard practices regarding data management are helpful but not required,Detailed knowledge and experience in case report form design, central laboratories, programming databases, query resolution, data validation,Computer skills: detailed knowledge of at least one data management system (Oracle Clinical or Clintrial preferred), experience with SAS data sets and conversion procedures required; knowledge of MS Office program suite required,Knowledge of distributed database design and implementation, LAMP/ MySQL, etc. with capability to perform/direct/assess implementation of such databases,Working knowledge of both Windows and Linux operating systems is required,Along with programming proficiency must have creativity, and show a strong capacity for independent thinking and the ability to grasp underlying biological questions,Must thrive in a complex, dynamic environment while adapting to dynamically changing priorities,Must have excellent time management and organizational skills","Develop, enhance, and automate processes for queuing and prioritizing data management and curation requests,Implement a quality control (QC) process to evaluate compliance with data models and taxonomies to ensure cohesion of curated data across time as data models and configurations evolve,Create a rapid means to remediate data that fail to meet curation specifications,Empower scientists with tools, processes and data structures needed to support project objectives,Ensure accurate, complete and timely collection, delivery and tracking of analytical information from translational, CRO or collaborating laboratories for curation, ingestion and delivery to computational scientists,Help define, deliver and implement R/ED, collaborator and partner laboratory analytical data management systems, processes and procedures,Work with R/ED study teams to develop R/ED information management plans that outline data capture, data flow, data queries, manual checks, and data listings needed to ensure data integrity,Participate in comprehensive data review activities in coordination with project and study teams,Work with computational biologists, computational scientists, biostatisticians and study scientists to resolve data quality issues,Make data, including raw/interim data, available to R/ED department personnel as required,Collaborate with users to enable data access and ingestion,Acquire user feedback to inform business requirements for future development.","
Description
Celgene is a global biopharmaceutical company leading the way in medical innovation to help patients live longer, better lives. Our purpose as a company is to discover and develop therapies that will change the course of human health. We value our passion for patients, quest for innovation, spirit of independence and love of challenge. With a presence in more than 70 countries - and growing - we look for talented people to grow our business, advance our science and contribute to our unique culture.
Summary/Scope: Celgene seeks a talented, results and achievement oriented individual to contribute to our informatics and data management initiatives in Research and Early Development (R&ED). This hands-on role interfaces with programs spanning both discovery and translational sciences where processing and interpreting multi-platform and multi-dimensional ‘omic’ data in pre-clinical and clinical settings is being employed to identify molecular drug targets, characterize MOA, prioritize clinical indications and generate patient selection hypotheses. We are seeking an individual with extensive experience managing, processing, and applying quality control metrics and processes to a wide range of data types in support of R&ED clinical trials and drug development experiments while working in close collaboration with basic research, translational and computational scientists.
Responsibilities include, but are not limited to, the following:
Develop, enhance, and automate processes for queuing and prioritizing data management and curation requests
Implement a quality control (QC) process to evaluate compliance with data models and taxonomies to ensure cohesion of curated data across time as data models and configurations evolve
Create a rapid means to remediate data that fail to meet curation specifications
Empower scientists with tools, processes and data structures needed to support project objectives
Ensure accurate, complete and timely collection, delivery and tracking of analytical information from translational, CRO or collaborating laboratories for curation, ingestion and delivery to computational scientists
Help define, deliver and implement R/ED, collaborator and partner laboratory analytical data management systems, processes and procedures
Work with R/ED study teams to develop R/ED information management plans that outline data capture, data flow, data queries, manual checks, and data listings needed to ensure data integrity
Participate in comprehensive data review activities in coordination with project and study teams
Work with computational biologists, computational scientists, biostatisticians and study scientists to resolve data quality issues
Make data, including raw/interim data, available to R/ED department personnel as required
Collaborate with users to enable data access and ingestion
Acquire user feedback to inform business requirements for future development.
Qualifications
PhD in a related discipline with at least 6 years of experience; Master’s degree with 12 years of experience; or Bachelor’s degree with experience in biomedical data management, data engineering, quality assurance, assay development, specimen data management or related discipline
Demonstrated proficiency with molecular biology concepts; and ability to support, develop and deploy laboratory and other research data management processes and procedures as they apply to complex, high dimensional data sets
Demonstrated ability to understand and translate high-level scientific datasets and results into data curation and management strategies and the underlying structures, curation processes and infrastructure required.
Strong understanding of LIMS systems and systematic, relational approaches to data integration and data processing workflows
Familiarity with Amazon Web Services (AWS).
Excellent skills in R programming and experience in additional computer languages such as Perl, Python, PHP, S-PLUS or Java (or C/C++)
Extensive practical experience in working with diverse but highly-connected scientific knowledge collections and their query interfaces to enable research hypotheses around compound targets, mechanisms of action, and patient response
Proven ability to work in a team environment with clinical personnel, study monitors, computational biologists, biostatisticians, programmers, and medical writers
Knowledge of FDA/ICH guidelines and industry standard practices regarding data management are helpful but not required
Detailed knowledge and experience in case report form design, central laboratories, programming databases, query resolution, data validation
Computer skills: detailed knowledge of at least one data management system (Oracle Clinical or Clintrial preferred), experience with SAS data sets and conversion procedures required; knowledge of MS Office program suite required
Knowledge of distributed database design and implementation, LAMP/ MySQL, etc. with capability to perform/direct/assess implementation of such databases
Working knowledge of both Windows and Linux operating systems is required
Along with programming proficiency must have creativity, and show a strong capacity for independent thinking and the ability to grasp underlying biological questions
Must thrive in a complex, dynamic environment while adapting to dynamically changing priorities
Must have excellent time management and organizational skills
Celgene is committed to equal opportunity in the terms and conditions of employment for all employees and job applicants without regard to race, color, religion, sex, sexual orientation, age, gender identity or gender expression, national origin, disability or veteran status.
Celgene complies with all applicable national, state and local laws governing nondiscrimination in employment as well as employment eligibility verification requirements of the Immigration and Nationality Act. All applicants must have authorization to work for Celgene in the U.S.
*LI-MG2
BIO-US
",https://jobs.newscientist.com/job/1401626409/senior-data-engineer/
JOB165237651814,Data Engineer and Analyst – Family Nurse Partnership programme,Data Engineer and Analyst – Family Nurse Partnership programme,,,"
Data Engineer and Analyst – Family Nurse Partnership programme
Hours of work: 37.5 hours per week
Contract: Permanent
Do you have a passion for data? Can you help us make an impact for thousands of young parents and their babies in England?
We are looking for an enthusiastic and experienced data engineer and analyst to join the FNP National Unit, based at the Tavistock and Portman NHS Foundation Trust.
The FNP National Unit leads the national delivery and strategic oversight of FNP, an innovative, internationally recognised home visiting programme, which is currently delivered by specially trained nurses to around 6,000 first time young mothers and their babies in England. It has been developed through more than 40 years of research in the United States and demonstrably improves health, social and educational outcomes and delivers substantial cost savings.
The role involves building data pipelines to construct, manage and analyse complex datasets for a national programme to identify trends and opportunities for quality improvement. The role requires well developed programming and statistical analysis skills and will involve working with a variety of stakeholders and partners to support the development and implementation of high quality analytical processes within the National Unit’s quality improvement and research activities.
We are looking for an experienced Data Engineer and Analyst who is proficient in Python programming, has advanced knowledge of SPSS Syntax and data warehousing and SQL.The postholder will support our vision to make best use of data in order to meet our strategic objectives by leading on the data infrastructure work and on a range of data analytics solutions such as data visualisations and reports presenting clinical data using business intelligence tools such as Tableau, Power BI and Microsoft Excel with VBA.
TO APPLY: please go NHS Jobs or Health Jobs at our websites via the button below.
For further details / informal visits contact:
Andreea Moise, Principal Analyst, FNP National Unit, Tavistock & Portman NHS Foundation Trust on 07966 566617
Closing date: 24 March 2019
Interview date: w/c 1 April 2019
Job Reference: 260-1911-IMW
",https://jobs.theguardian.com/job/6878857/data-engineer-and-analyst-family-nurse-partnership-programme/
JOB166575397474,Data Engineer,Data Engineer,,,"Our Client are looking for Structured Cabling Engineers based in Edinburgh
Duties include -
- Installation, termination and testing of Cat6/Cat6A copper cabling. Recent experience of Systimax cabling an advantage.
- Installation, cleaning and testing of fibre cabling. Splicing experience not essential as we install pre-term solutions. Engineers need to know how to handle fibre and test. IPAF qualification an advantage as installations at high level.
- Knowledge of Fluke test equipment, DTX/DSX testers.
- Experience of working in a data centre environment an advantage but not essential.
Would prefer engineers from the Edinburgh area or within an hours travel of the sites. Engineers need to have their own transport to get to these sites, i.e. a driving licence and car as the locations are not easy to get to and from with public transport during the times they are working.
The engineers are required to work nightshift, 4 nights Mon-Thurs 17:30-04:00. This is a 10.5 hour shift with 1 hour break so 4 x 9.5hrs, 38hrs. There is also optional overtime available most weekends, day shift Sat & Sun normally 08:00-16:30, 8hr shifts.
The engineers will need to pass a screening process which includes Disclosure Scotland. Engineers need to provide proof of identity, proof of address and pass a credit check.
The contract would be for 12-16 weeks initially but for the right candidates could be extended indefinitely.
Skills
Not Specified
",https://www.oilvoice.com/Job/3141/Data-Engineer
JOB166582425807,Big Data Engineer (Hadoop suite),Big Data Engineer (Hadoop suite),,,"Information about the position
Job description, responsibilities and duties
Tasks:
• Design, construct, and deliver transformation of large data sets leveraging MapReduce, streaming, and other emerging technologies
• Leverage Kafka, HBase, Elasticsearch, etc. to ingest transformed data at scale
• Integrate new data management technologies and software engineering tools into existing structures
• Ensure systems meet business requirements and industry practices
• Implement high-volume data integration solutions
• Learn and apply new tools and technologies
• Collaborate with data architects, data engineers, data scientists and IT team members on project goals
• Produce and maintain high-quality technical documentation
Employee perks, benefits
• interesting and challenging project at one of the largest Austrian Mobile operators
• day by day use of the most emerging technologies in a real world projects
• potential of career and technical growth
• very attractive salary/payment conditions
• workplace partially Vienna, Austria
Requirements for the employee
Candidates with education suit the position
Educational Specialization
Language skills
English - Advanced (C1) or
Personality requirements and skills
Combination of some of the listed skills/experiences is a must:
• Degree in computer science, software/computer engineering, or related field and experience commensurate with the requested level in software engineering; if no degree, equivalent experience in software engineering.
• Experience with object oriented software development creating applications in Java
• Experience with Scala and/or Python
• Experience with messaging systems, such as Kafka
• Experience with building stream-processing systems, using solutions such as Spark-Streaming
• Proficiency of Hadoop–Ecosystems (Spark, Hadoop v2, MapReduce, HDFS, Impala, Storm, etc.)
• Good knowledge of Big Data querying tools, such as Pig, Hive,
• Experience with SQL databases and No-SQL databases (e.g. HBase, MongoDB)
• Good understanding of Lambda Architecture, along with its advantages and drawbacks
• Experience with Big Data ML toolkits, SparkML, or H2O ..
• Experience with Ranger and Knox
• Experience with Hortonworks
• Track record of developing technology to enable large scale data transformation
• Experience with integration of data from multiple data sources.
• Knowledge of various ETL techniques and frameworks, such as Flume
• Knowledge of software engineering best practices
• Proficient understanding of distributed computing principles
• Passion for solving hard problems and exploring new technologies
• Communication and technical documentation skills
• Experience in designing and implementing high-availability/high-scale production systems
• Quickly learn new development languages if required. Have a very good understanding of software programming and the ability to “pick up” new programming languages quickly
• Nice to have
o Ability to solve any ongoing issues with operating the cluster
o Management of Hadoop cluster, with all included services
Brief description of the company
Economical. Personal. Portable. These three attributes we have written in ITSDONE on the flags. Because that's how we operate for our customers.
We are an IT service provider with a very extensive and specialized know-how. We support customers of various industries and sizes with outsourcing, IT project management and services on time and material basis.
Due to our great success, we are expanding our team..
Number of employees
Company address
Contact
",http://www.profesia.sk/praca/itsdone/O3118401
JOB172277184350,Data Engineer,Data Engineer,,"Building data infrastructure and back-end services to support user-facing and internal-use applications,Identifying, researching, and analyzing new data sources,Developing and maintaining REST APIs for Amne's back-end services,Managing and developing ETL pipelines to ensure and improve the accuracy, quality and usability of data across Amne's infrastructure.,Improving and maintaining industry-leading home valuation models and methodologies using millions of real-estate transactions and complementary data sets.,Collaborating with Software Engineers, Product Managers, and Product Designers,Maintaining development best practices, including test coverage, continuous integration, A/B testing, and documentation,Strong Python programming skills, including experience with NumPy, SciPy, Pandas, and scikit-learn,Familiarity with common Python web frameworks (Flask, Django, etc.),Experience with the AWS ecosystem (S3, Elastic Beanstalk, EC2, etc.) and application deployment,Ability to write clean, re-usable, and production-ready code.,Ability to translate complex data-oriented challenges into solutions for business objectives, and vice versa.,Experience with databases, statistics, web services, algorithms, and Python,Strong communication skills,Experience building modular, scalable, cloud-based systems,An interest in learning new technologies and taking the lead on the integration of new technologies into Amne's stack.","As a Data Engineer at Amne, you’ll join a young, growing team as we build the world’s fastest and simplest home transaction experience.
Responsibilities will include:
Building data infrastructure and back-end services to support user-facing and internal-use applications
Identifying, researching, and analyzing new data sources
Developing and maintaining REST APIs for Amne's back-end services
Managing and developing ETL pipelines to ensure and improve the accuracy, quality and usability of data across Amne's infrastructure.
Improving and maintaining industry-leading home valuation models and methodologies using millions of real-estate transactions and complementary data sets.
Collaborating with Software Engineers, Product Managers, and Product Designers
Maintaining development best practices, including test coverage, continuous integration, A/B testing, and documentation
Becoming a domain expert in real-estate
Required Skills and Abilities
Strong Python programming skills, including experience with NumPy, SciPy, Pandas, and scikit-learn
Familiarity with common Python web frameworks (Flask, Django, etc.)
Experience with the AWS ecosystem (S3, Elastic Beanstalk, EC2, etc.) and application deployment
Ability to write clean, re-usable, and production-ready code.
Ability to translate complex data-oriented challenges into solutions for business objectives, and vice versa.
Well-developed SQL skills, preferably including experience with PostgreSQL and PostGIS.
Desirable Skills and Experience
We’re looking for individuals who bring:
Experience with databases, statistics, web services, algorithms, and Python
Strong communication skills
Experience building modular, scalable, cloud-based systems
An interest in learning new technologies and taking the lead on the integration of new technologies into Amne's stack.
A willingness to learn new technologies and a whatever-it-takes attitude towards building the best possible home buying and selling experiences for our users
Amne is currently hiring for our Austin office. Amne team members are thoughtful listeners, fast learners, results driven, self-motivated, self-aware, and self-disciplined.
",https://jobs.lever.co/amne/53006592-1b97-4677-b018-a87040cb558e
JOB175947528518,Lead Data Engineer,Lead Data Engineer,,,"
Lead Data Engineer
£60,000-£65,000
London
Are you a data engineering specialist and would like the chance to work for an exciting media agency?
The Company:
This fast-growing, innovative media agency who pride themselves on delivering the very best service and solutions to their clients are looking for a Data Engineer to join their team. You will take ownership for architectural decisions for the agency's data systems. You will benefit from this being a completely new opportunity within the company which will give you the chance to really put your stamp on the role as well as receiving a competitive salary package.
The Role:
* Take ownership of the agency's data reporting systems and lead the data onboarding for new clients.
* Be the go to person for all things data engineering to advise both clients and internal teams.
* Mentor team members within the data & analytics team whilst providing a bridge to the wider technology teams.
* Enable the use of sophisticated data science projects through defining a roadmap for data analytics technology.
The Candidate:
* Proven experience working within a Data Engineering capacity to ensure you hit the ground running in the role.
* Ability to use coding languages such as SQL and Python manipulation and interacting with API's.
* Knowledge of DoubleClick stack and ad serving and how it is utilised within a media agency.
* Experience in managing, leading a mentoring a team.
If this role sounds like a great opportunity for the next stage of your career, click the apply button now!
",https://jobs.theguardian.com/job/6734465/lead-data-engineer/
JOB177987156339,Data Engineer,Data Engineer,,"Build industry-leading big data architecture,Support real-time analytics,Solid programming skills in Python, Scala or Java,Good experience of big data tools e.g. Spark, Kafka, Hadoop or similar,Experience of building onto Cloud platforms,Experience with SQL and NoSQL technologies and data modelling,Exposure to DevOps environments"," International Scale-up Technology Firm
Build industry-leading big data architecture
Support real-time analytics
Design and implement modern technology
This firm is building an industry leading real-time analytics platform to acquire, analyse and process the vast amount of business-critical data they create. They require an experienced Data Engineer to enable the transformation of big data into insight.
What you’ll be doing
You’ll need to be passionate about Big Data and want to build complex, robust architecture. Designing and implementing this infrastructure will support the real-time analytics platform and progress data science projects in business.
You’ll be comfortable with various data engineering technologies and will be able to transform the business through data accessibility. This will include designing various data models and building tools to continuously improve the technology platform and pioneer new technologies.
What experience you’ll need to apply
Solid programming skills in Python, Scala or Java
Good experience of big data tools e.g. Spark, Kafka, Hadoop or similar
Experience of building onto Cloud platforms
Experience with SQL and NoSQL technologies and data modelling
Exposure to DevOps environments
Degree in Computer Science, Electrical Engineering, Physics or similar
What you’ll get in return for your experience
A competitive salary based on experience, bonus and benefits including the opportunity for flexible working.
What’s next
Please apply now or get in touch with Scott with an up to date CV today. Don’t hesitate to call/email to discuss the finer details.
",https://jobs.theguardian.com/job/6866067/data-engineer/
JOB178700040512,Data Engineer (Grade 7),Data Engineer (Grade 7),,,"
Data Engineer (Grade 7)
Salary £39,754 to £42,731
London
Secretly we’re just like you.
MI6 is the UK's foreign human intelligence agency. In our world, sophisticated technology and innovative techniques enable global covert operations. These strengthen our approach to gathering secret intelligence overseas. And our culture is where creativity, curiosity, insight and intuition are used to face ever-evolving challenges. To ensure we remain ahead of the game, we're looking for the country's brightest Data Engineers.
The role
Joining our Data Ingestion team, you’ll analyse and process raw data which comes from a wide variety of sources. You’ll prepare it so it’s ready for advanced analysis using internal systems. You’ll also analyse, cleanse and adapt the varied data by using software into agreed standard forms.
About you
As an experienced data engineer, you’ll be familiar with coding languages (including Python and SQL) and use them with at least basic programming and coding skills. It is your flexibility that’ll help you to quickly adapt to new tools and evolving requirements. As well as this, you’ll use your excellent communication skills to help customers validate their data and help them analyse it, manage it and experiment with it.
Apply
Our roles are as individual as you are. Find out more and apply via our website.
To apply to MI6 you must be a born or naturalised British citizen, over 21 years old and normally have been based in the UK for six of the last ten years. You should not discuss your application with anyone other than your partner or a close family member providing that they are British. They should also be made aware of the importance of discretion.
MI6 strives for diversity in the workplace and is committed to the creation and maintenance of a climate in which all staff are treated fairly on the grounds of merit and ability.
",https://jobs.theguardian.com/job/6891293/data-engineer-grade-7-/
JOB180678722339,"Senior Associate, Data Engineer- IHM","Senior Associate, Data Engineer- IHM",,,"
Discover. A more rewarding way to work.
At Discover Financial Services, you’ll find yourself in the company of some of the industry’s smartest and most reliable professionals. And at a company that rewards dedication, values innovation and supports growth.
Thrive in an environment that promotes teamwork and shared success. Build on a foundation of mutual respect. Join the company that understands rewarding careers like no other, with this exceptional opportunity:
Job Description:
TITLE: Senior Associate, Data Engineer
DUTIES: DFS Corporate Services LLC seeks Senior Associate, Data Engineer in Riverwoods, Illinois to work with business clients to design, develop, test and deliver solutions that meet customer requirements. Develop data driven solutions with current and next generation big data technologies to meet evolving business needs. Develop Greenfield capabilities leveraging open source next-generation technologies. Code and integrate open source solutions into an enterprise Hadoop ecosystem. Utilize multiple development languages/tools such as Python, SPARK, Hive, R, and Java. Participate in prototype solutions by integrating various open source components. Operationalize open source data-analytic tools for enterprise use. Provide support for deployed data applications and analytical models by being a trusted advisor to Data Scientists and other data consumers by identifying data problems and guiding issue resolution with partner Data Engineers and data providers. Provide subject matter expertise in the analysis, preparation of specifications and plans for the development of data processes. Ensure proper data governance policies are followed by architecting and building data lineage, quality checks, and data classification systems and frameworks. Promote a risk-aware culture, ensure efficient and effective risk and compliance management practices by adhering to required standards and processes
Skills:
REQUIREMENTS : Master’s degree or foreign equivalent in Computer Science, Mathematics, Computer Engineering or a related field and one (1) year of experience in job offered or related position: coding and integrating open source solutions into an enterprise Hadoop ecosystem; developing real-time data ingestion and stream-analytic solutions using technologies including Kafka, Apache Spark, NIFI, Python, HBase and Hadoop; utilizing multiple development languages and tools including Python, SPARK, Hive, R, Java; and utilizing technologies including SAS, SQL and Tableau.
Discover Financial Services is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, protected veteran status, among other things, or as a qualified individual with a disability.
So, what are you waiting for? Apply today!
",https://www.builtinchicago.org/job/data/senior-associate-data-engineer-ihm/69360
JOB181786592004,Data Engineer - Python,Data Engineer - Python,"Live the GoHealth Culture and ensure it is represented within the team.,Design, develop and deploy optimal extraction, transformation, and loading of data from various GoHealth and external data sources.,Monitor, execute and report on all data pipeline tasks while working with appropriate teams to take corrective action quickly, in case of,issues.,Perform unit testing, system integration testing and assist with user acceptance testing.,Adapt data components to accommodate changes in source data and new business requirements.,Create and maintain documentation of the technical detail design, operational support and maintenance procedures for all data pipeline,tasks.,Ensure data quality and compliance with development, architecture, reporting, and regulatory standards throughout entire data pipeline.,Collaborate with the rest of the Data Engineering Team, subject matter experts and department leaders to understand, analyze, build and,deliver new data-related processes and/or reports.,Ability to work with the rest of the Data Engineering Team to cross-train and provide support for various data engineering tasks.,Bachelor’s Degree in computer science or equivalent experience required.,2+ years of experience in the design and development of data pipelines and tasks.,Strong analytical and problem solving ability with strong attention to detail and accuracy.,Good understanding of data warehousing concepts and dimensional data modeling.,Hands-on experience with troubleshooting performance issues and fine tuning SQL queries.,Experience in Python including in modules/libraries such as pandas, numpy, Flask, scikit-learn, and sci-py.,Proven experience extracting data from structured data sources (SQL, Excel, CSV files, Couchbase) and unstructured data sources,(Splunk, log files) both on-premise and in the cloud.,Experience consuming data from web services, REST and SOAP, HTML, XML and JSON.,Knowledge of version control systems using Git, Bitbucket, SVN, or Team Foundation.,Ability to handle multiple tasks and adapt to evolving business and technical environments.,Self-starter with the ability to work independently, take initiative, and learn new skills.,Excellent written and oral communication skills, with the ability to articulate complex processes to individuals of varying technical abilities,Experience in software engineering practices is required.,Experience in Microsoft SQL Server, SSIS, SSRS, Power BI, or Azure is preferred but not required.,Familiar with other data warehouse platforms like AWS Redshift or AWS Data Pipeline.,Join the team's daily meeting the includes other data engineers, data scientists, and data analysts.,Review open git pull requests, JIRA tickets, and Airflow DAG runs.,Work with the Data Engineering team and various teams on the following: Analyzing, designing, and implementing Airflow DAGs and Operators, RESTful services, integration with external and internal,RESTful services (e.g. Hubspot, Five9, etc.),Troubleshooting issues and resolving them – Airflow, SSIS, Tableau, SQL Server, SSRS, AWS, MySQL, Couchbase, etc.,Design, implement, and evolve GoHealth's data pipelines, Tableau data sources and data extracts, build and test automation (Jenkins, python, bash, gradle), etc.,Participate or lead Demo Wednesdays and Release Thursdays.,Join the weekly Data Engineering team meeting to review the roadmap and progress on projects.,Open vacation policy,401k match program,Medical, life, dental, and vision benefits,Flexible spending accounts,Subsidized gym memberships,Commuter and transit benefits,Professional growth opportunities,Casual dress code,Generous employee referral bonuses,Happy hours, ping-pong tournaments, and more company-sponsored events,GoHealth is an Equal Opportunity Employer",,"
Company Description
GoHealth has an ambitious mission: to improve the health care system in America. Achieving this mission relies on hiring and developing great people, which is why our team is our top priority. We encourage employees to do their best work through innovation and risk taking. Our environment is fun yet constructive, thanks to leaders whose doors are always open. And most importantly, we’ll never stop investing in you and your career.
Job Description
GoHealth is looking for Data Engineers who will be responsible for the design, development, and delivery of data transformation tasks used in transforming data into a format that can be easily analyzed. We are seeking candidates who have experience in data analysis, collection, and optimization for the purpose of informing business decisions. The Data Engineer will work with other team members in owning data pipelines
including execution, documentation, maintenance, and metadata management. They will also support the development of the data infrastructure necessary for full scale data science, predictive analytics and machine learning.
Qualifications
Live the GoHealth Culture and ensure it is represented within the team.
Design, develop and deploy optimal extraction, transformation, and loading of data from various GoHealth and external data sources.
Monitor, execute and report on all data pipeline tasks while working with appropriate teams to take corrective action quickly, in case of
issues.
Perform unit testing, system integration testing and assist with user acceptance testing.
Adapt data components to accommodate changes in source data and new business requirements.
Create and maintain documentation of the technical detail design, operational support and maintenance procedures for all data pipeline
tasks.
Ensure data quality and compliance with development, architecture, reporting, and regulatory standards throughout entire data pipeline.
Collaborate with the rest of the Data Engineering Team, subject matter experts and department leaders to understand, analyze, build and
deliver new data-related processes and/or reports.
Ability to work with the rest of the Data Engineering Team to cross-train and provide support for various data engineering tasks.
Qualifications
Bachelor’s Degree in computer science or equivalent experience required.
2+ years of experience in the design and development of data pipelines and tasks.
Strong analytical and problem solving ability with strong attention to detail and accuracy.
Good understanding of data warehousing concepts and dimensional data modeling.
Hands-on experience with troubleshooting performance issues and fine tuning SQL queries.
Experience in Python including in modules/libraries such as pandas, numpy, Flask, scikit-learn, and sci-py.
Proven experience extracting data from structured data sources (SQL, Excel, CSV files, Couchbase) and unstructured data sources
(Splunk, log files) both on-premise and in the cloud.
Experience consuming data from web services, REST and SOAP, HTML, XML and JSON.
Knowledge of version control systems using Git, Bitbucket, SVN, or Team Foundation.
Ability to handle multiple tasks and adapt to evolving business and technical environments.
Self-starter with the ability to work independently, take initiative, and learn new skills.
Excellent written and oral communication skills, with the ability to articulate complex processes to individuals of varying technical abilities
Experience in software engineering practices is required.
Experience in Microsoft SQL Server, SSIS, SSRS, Power BI, or Azure is preferred but not required.
Familiar with other data warehouse platforms like AWS Redshift or AWS Data Pipeline.
Typical Day
Join the team's daily meeting the includes other data engineers, data scientists, and data analysts.
Review open git pull requests, JIRA tickets, and Airflow DAG runs.
Work with the Data Engineering team and various teams on the following: Analyzing, designing, and implementing Airflow DAGs and Operators, RESTful services, integration with external and internal
RESTful services (e.g. Hubspot, Five9, etc.)
Troubleshooting issues and resolving them – Airflow, SSIS, Tableau, SQL Server, SSRS, AWS, MySQL, Couchbase, etc.
Design, implement, and evolve GoHealth's data pipelines, Tableau data sources and data extracts, build and test automation (Jenkins, python, bash, gradle), etc.
Participate or lead Demo Wednesdays and Release Thursdays.
Join the weekly Data Engineering team meeting to review the roadmap and progress on projects.
Additional Information
Open vacation policy
401k match program
Medical, life, dental, and vision benefits
Flexible spending accounts
Subsidized gym memberships
Commuter and transit benefits
Professional growth opportunities
Casual dress code
Generous employee referral bonuses
Happy hours, ping-pong tournaments, and more company-sponsored events
GoHealth is an Equal Opportunity Employer
",https://www.builtinchicago.org/job/data/data-engineer-python/65748
JOB184063001380,Data Engineer,Data Engineer,Track record of successfully executing projects with multiple partners,"Built and implemented a data profiling tool to reverse engineer data schemas from new data sources facilitating normalization of the data into our data model.,Built the logic to combine real-time messaging and batch query processing so there is a single, accurate source of truth from a source system.,Analyzed and designed the best ways to expand our data model to incorporate more data that’s mission critical.,A real passion for problem solving and learning new technology,Vision to balance speed and maintainability in solution design,Strong analytical and technical skills,The ability to handle multiple, concurrent projects,Excellent ability to craft and implement requirements, keep projects on track, and engage partners,Challenging the status quo to improve our processes and tools,Communicate complex technical details in meaningful business context,A low ego and humility; an ability to gain trust by doing what you say you will do,Own ten projects working multi-functionally with the Physician Success and Analytics teams to design and implement best-in-class data processing enabling clean data flow directly to our data model,Work with an HIE, engineering, analytics, and operations to design and implement an integration that streamlines our transitional care management workflows,Design a new concept within our data model to meet a new operational or analytical need,Build an app to send data anomalies to operations,2+ years of full-time experience,Experience building information pipelines utilizing Python or Java (willingness to expand knowledge of Python is required),High degree of comfort with relational data structures required,Knowledge of, and/or willingness to learn, non-relational data structures and other technologies (eg Postgres, Redshift, Cassandra, MongoDB, Neo4j, S3, etc.),BS/MS in computer science, math, engineering, or other related fields is required.","
Description
Data Engineers at VillageMD build distributed components, pipelines, and tools that enable our organization to make analytical, data-driven decisions. We're in a unique position to impact everyone in primary care from independent, family-owned practices to world-class health systems. We aggregate, process, and deliver rich datasets to improve the effectiveness of primary care for our doctors and patients.
We built our technology by standing on the shoulders of tech giants. We leverage proven, open-source technologies developed at Airbnb, Amazon, and Facebook. We participate in the open-source ecosystem and OHDSI. As a member of our team, you would spend time designing new data pipelines and democratizing data access at our company.
What are examples of work that Data Engineers have done at VillageMD?
Built and implemented a data profiling tool to reverse engineer data schemas from new data sources facilitating normalization of the data into our data model.
Built the logic to combine real-time messaging and batch query processing so there is a single, accurate source of truth from a source system.
Analyzed and designed the best ways to expand our data model to incorporate more data that’s mission critical.
What will make you successful here?
A real passion for problem solving and learning new technology
Vision to balance speed and maintainability in solution design
Strong analytical and technical skills
The ability to handle multiple, concurrent projects
Excellent ability to craft and implement requirements, keep projects on track, and engage partners
Challenging the status quo to improve our processes and tools
Communicate complex technical details in meaningful business context
A low ego and humility; an ability to gain trust by doing what you say you will do
What you might do in your first year:
Own ten projects working multi-functionally with the Physician Success and Analytics teams to design and implement best-in-class data processing enabling clean data flow directly to our data model
Work with an HIE, engineering, analytics, and operations to design and implement an integration that streamlines our transitional care management workflows
Design a new concept within our data model to meet a new operational or analytical need
Build an app to send data anomalies to operations
The following experience is relevant to us:
2+ years of full-time experience
Experience building information pipelines utilizing Python or Java (willingness to expand knowledge of Python is required)
High degree of comfort with relational data structures required
Knowledge of, and/or willingness to learn, non-relational data structures and other technologies (eg Postgres, Redshift, Cassandra, MongoDB, Neo4j, S3, etc.)
BS/MS in computer science, math, engineering, or other related fields is required.
Track record of successfully executing projects with multiple partners
At VillageMD, we see diversity and inclusion as a source of strength in transforming healthcare. We believe building trust and innovation are best achieved through diverse perspectives. To us, acceptance and respect are rooted in an understanding that people do not experience things in the same way, including our healthcare system. Individuals seeking employment at VillageMD are considered without regard to race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.
",https://www.builtinchicago.org/job/data/data-engineer/67015
JOB185963657570,Data Engineer,Data Engineer,,"Build industry-leading big data architecture,Support real-time analytics,Solid programming skills in Python, Scala or Java,Good experience of big data tools e.g. Spark, Kafka, Hadoop or similar,Experience of building onto Cloud platforms,Experience with SQL and NoSQL technologies and data modelling,Exposure to DevOps environments"," International Scale-up Technology Firm
Build industry-leading big data architecture
Support real-time analytics
Design and implement modern technology
This firm is building an industry leading real-time analytics platform to acquire, analyse and process the vast amount of business-critical data they create. They require an experienced Data Engineer to enable the transformation of big data into insight.
What you’ll be doing
You’ll need to be passionate about Big Data and want to build complex, robust architecture. Designing and implementing this infrastructure will support the real-time analytics platform and progress data science projects in business.
You’ll be comfortable with various data engineering technologies and will be able to transform the business through data accessibility. This will include designing various data models and building tools to continuously improve the technology platform and pioneer new technologies.
What experience you’ll need to apply
Solid programming skills in Python, Scala or Java
Good experience of big data tools e.g. Spark, Kafka, Hadoop or similar
Experience of building onto Cloud platforms
Experience with SQL and NoSQL technologies and data modelling
Exposure to DevOps environments
Degree in Computer Science, Electrical Engineering, Physics or similar
What you’ll get in return for your experience
A competitive salary based on experience, bonus and benefits including the opportunity for flexible working.
What’s next
Please apply now or get in touch with Scott with an up to date CV today. Don’t hesitate to call/email to discuss the finer details.
",https://jobs.theguardian.com/job/6835548/data-engineer/
JOB186499931212,Developer Ops Software/Data Engineer,Developer Ops Software/Data Engineer,,,"
Developer Ops Software/Data Engineer
Title
Developer Operations Software/Data Engineer, Information Services
Overview of RAND
The RAND Corporation is a research organization that develops solutions to public policy challenges to help make communities throughout the world safer and more secure, healthier and more prosperous. RAND-s research and analysis address issues that impact people everywhere, including security, health, education, sustainability, growth, and development. Headquartered in Santa Monica, California, RAND has close to 1,800 people from approximately 50 countries working in offices in North America, Europe, and Australia, with annual revenues of more than $308 million.
RAND is nonprofit, nonpartisan, and committed to the public interest. Our research is sponsored by government agencies, charitable trusts, and community nonprofits. In addition, we rely on philanthropic support to pursue visionary ideas; address critical problems that are under-researched; shape emerging policy debates; and devise innovative approaches for solving acute, complex, or provocative policy challenges. RAND values objectivity and integrity in both its research processes and internal interactions. We emphasize a collegial environment that respects the contributions and dignity of all staff.
Position Description
The cloud data engineer will be an integral member of the cloud service delivery and emerging technology team. The engineer will support research projects in the adoption and execution of scalable analytics using RAND-s suite of cloud services. Beyond this, the role will also look to facilitate RAND-s traditional IT services transition from infrastructure to relational databases to platforms into using cloud services.
The position will work closely with research programmers, principle investigators and others in the execution of research projects to both educate and train them on the use of cloud services and cloud automation. The engineer will provide automation solutions to streamline the research project efforts through a combination of orchestration tools, pipeline resources and packaging systems. Critical to this role is the cost and time optimization of the use of cloud services, securing the services to the needs of the information being processed, and continuously assess the maturity of services as they relate to research project needs.
Qualifications
Essentials Skills
* AWS compute & storage services (EC2, ECS, S3, RDS, Lambda, etc.)
* AWS security and logging services (IAM, CloudTrail, CloudWatch, etc.)
* Docker, Kubernetes
* Coding / Scripting (Python, PowerShell, Javascript, or similar etc.)
* Operating System (Windows, Linux)
Significant Plus
* Some statistical programming
* Build Tools (e.g., Maven, NPM, MSBuild)
* Continuous Integration and Deployment Tools (e.g., Jenkins)
Required Experience
* 2+ years Cloud Experience in Amazon Web Services preferred; Azure or other public cloud provider accepted
* 3+ years coding/scripting in two of the following (Python, PowerShell, Javascript, or similar etc.)
* 2+ years Infrastructure automation (Chef, Cloud Formation, Ansible, Puppet, etc.)
* Experience in two of the following web application frameworks (Node.js, Apache, Microsoft IIS, Nginx)
* Strong knowledge of information security best practices and standards
Education Requirements
Bachelor's degree - equivalent experience in-lieu of degree is acceptable.
Experience
* 2+ years Cloud Experience in Amazon Web Services preferred; Azure or other public cloud provider accepted
* 3+ years coding/scripting in two of the following (Python, PowerShell, Javascript, or similar etc.)
* 2+ years Infrastructure automation (Chef, Cloud Formation, Ansible, Puppet, etc.)
* Experience in two of the following web application frameworks (Node.js, Apache, Microsoft IIS, Nginx)
* Strong knowledge of information security best practices and standards
Security Clearance
U.S. Citizenship is required to obtain a security clearance.
Location
Santa Monica
Positions Open
One
",https://www.clearancejobs.com/jobs/2476736/developer-ops-softwaredata-engineer
JOB188401101152,Big Data Engineer/Developer,Big Data Engineer/Developer,,"Assembling large, complex data sets that meet business requirements,Identifying, designing, and implementing internal process improvements: including process automation, optimizing data delivery, etc.,Designing optimal ETL infrastructures from variety of data sources,Building analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.,Big Data, including the Hadoop Ecosystem, NoSQL approaches and Cloud Data Management.,Data warehousing and BI (incl. SQL / Data Modelling, Data Integration, Data Governance),Thorough understanding of the capabilities of commercial Apache Hadoop distributions such as e.g. Hortonworks, Cloudera, or MapR,Experience in estimating, planning and managing data integration aspects of implementation projects.,At least 3 years of overall relevant IT experience.,At least 2 years experience with Big Data projects (using Hadoop, SQL, ETL, and/or similar technologies),At least 1 year experience with data engineering / data integration in the Big Data, Analytics, Business Intelligence and/or Data Warehousing domain,Experience with custom application development/enhancements using relevant technologies (i.e. Python, JSON, SQL, NoSQL, Unix/Linux scripting, Hadoop, HortonWorks, Cloudera, etc),Experience of a data warehouse environment and knowledge of existing and emerging data integration approaches,Experience with Watson Discovery/Conversation/Knowledge Studio,Experience with SSIS,Custom application development using technologies such as Python, JSON, SQL, NoSQL, Unix/Linux scripting, Hadoop, HortonWorks, Cloudera, Hibench, etc,Data architecture experience of designing and developing data models- Understanding of -Distributed computing design patterns and algorithms and data structures and security protocols,Involved primarily in coding, debugging and unit testing of applications,API experience, multithreading is a plus,May be involved in conceptual technology phase","
IBM Global Business Services (GBS) is a team of business, strategy and technology consultants enabling enterprises to make smarter decisions and providing unparalleled client and consumer experiences in cognitive, data analytics, cloud technology and mobile app development. With global reach, outcome-focused methodologies and deep industry expertise, IBM GBS empowers clients to digitally reinvent their business and get the competitive edge in the cognitive era in over 170 countries.
Bottom line? We outthink ordinary. Discover what you can do at IBM.
As a Big Data Engineer, you will work with various technology assets and frameworks built on open source and enterprise Big Data technologies by IBM Global Business Services (GBS) and apply them to projects that create high business impact. You will gain valuable knowledge and insights from thought leaders on cognitive technologies.
The role focuses on the elements required to manage data and information (both structured and unstructured) from business requirements to logical and physical design. You will be delivering solutions in the Big Data, Analytics, Business Intelligence and/or Data Warehousing domain at our clients. The Data Engineer defines data integration best practices in the critical evaluation and selection and/or development of the software components of the solution. Data Engineers are also responsible for the distribution of data and designing centralized and/or distributed systems that both address the business requirements and perform efficiently and effectively.
Responsibilities will likely include:
Assembling large, complex data sets that meet business requirements
Identifying, designing, and implementing internal process improvements: including process automation, optimizing data delivery, etc.
Designing optimal ETL infrastructures from variety of data sources
Building analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Working with executive, LOB, design and IT stakeholders on data-related technical issues and infrastructure needs
Experience from system integration projects based on the leading software products in the big data, business intelligence and analytics area is needed e.g.:
Big Data, including the Hadoop Ecosystem, NoSQL approaches and Cloud Data Management.
Data warehousing and BI (incl. SQL / Data Modelling, Data Integration, Data Governance)
Thorough understanding of the capabilities of commercial Apache Hadoop distributions such as e.g. Hortonworks, Cloudera, or MapR
Experience in estimating, planning and managing data integration aspects of implementation projects.
Experience with technologies such as: Spark, Sqoop, Pig, Hive, Kafka, Hibench, YCSB, Informatica, Ab Inititio, Talend, etc
IBM is market leader in the data & analytics space. We offer a dynamic, innovative and international environment which is fueled by projects with leading clients, unique capabilities such as IBM Research & Development and IBM Watson, and a growing ecosystem of partnerships such as those with Apple and Twitter. If you think you have the skill and the attitude to change the way that business is conducted – IBM is the place for you and will offer you numerous opportunities for growth across the company.
Successful candidates for these positions will work onsite at the IBM Client Innovation Center in Baton Rouge. The IBM Client Innovation Center is an in-bound delivery model where we support our clients from our Baton Rouge center. However, some travel is expected and all candidates must be willing and able to travel to meet our client needs across the US. Travel is typically related to knowledge transfer and training at the client site (Monday thru Friday). You are expected to travel up to 50% of the time. This is a traditional office position. You must live in, or be willing to relocate to, Louisiana. The work location is 100 North Street Baton Rouge, LA 70802. This is not a work from home position.
BENEFITS
Health Insurance. Paid time off. Corporate Holidays. Sick leave. Family planning. Financial Guidance. Competitive 401K. Training and Learning. We continue to expand our benefits and programs, offering some of the best support, guidance and coverage for a diverse employee population.
CAREER GROWTH
Our goal is to be essential to the world, which starts with our people. Company wide we kicked off an internal talent strategy program called Go Organic. At our core, we are committed to believing and investing in our workforce through:
Skill development: helping our employees grow their foundational skills
Finding the dream job at IBM: navigating our company with the potential for many careers by channeling an employee’s strengths and career aspirations
Diversity of people: Diversity of thought driving collective innovation
In 2015, Go Organic filled approximately 50% of our open positions with internal talent that were promoted into the role.
CORPORATE CITIZENSHIP
With an employee population of 375,000 in over 170 countries, amazingly we connect, collaborate, and care. IBMers drive a corporate culture of shared responsibility. We love grand challenges and everyday improvements for our company and for the world. We care about each other, our clients, and the communities we live, work, and play in!
No Visa sponsorship opportunities exist for this position.
gbscicbr
Required Technical and Professional Expertise
At least 3 years of overall relevant IT experience.
At least 2 years experience with Big Data projects (using Hadoop, SQL, ETL, and/or similar technologies)
At least 1 year experience with data engineering / data integration in the Big Data, Analytics, Business Intelligence and/or Data Warehousing domain
Experience with custom application development/enhancements using relevant technologies (i.e. Python, JSON, SQL, NoSQL, Unix/Linux scripting, Hadoop, HortonWorks, Cloudera, etc)
Experience of a data warehouse environment and knowledge of existing and emerging data integration approaches
Integration of Big Data to a traditional data architecture
Preferred Technical and Professional Experience
Experience with Watson Discovery/Conversation/Knowledge Studio
Experience with SSIS
Custom application development using technologies such as Python, JSON, SQL, NoSQL, Unix/Linux scripting, Hadoop, HortonWorks, Cloudera, Hibench, etc
Data architecture experience of designing and developing data models- Understanding of -Distributed computing design patterns and algorithms and data structures and security protocols
Involved primarily in coding, debugging and unit testing of applications
API experience, multithreading is a plus
May be involved in conceptual technology phase
Would be an Additional Plus: Quality control and assurance services for custom applications for e.g. (test case development and execution for unit, functional, system and regression testing)
Up to 50% or 3 days a week (home on weekends - based on project requirements)
Skill-keywords
Big Data, SQL, hadoop, squoop, pig, python, data engineer, hortonworks, cloudera, business intelligence, cognitive, analytics, Watson
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
",https://krb-sjobs.brassring.com/TGnewUI/Search/home/HomeWithPreLoad?PageType=JobDetails&partnerid=26059&siteid=5016&Areq=180156BR
JOB191487804569,Data Engineer,Data Engineer,Knowledge-sharing activities,"Work with the most innovative and most scalable data processing technologies,Build innovative state-of-the-art solutions with our customers,Work closely with our tech partners: Google Cloud Platform, Tableau, Looker,Work in an agile and dynamic environment together with a small team with our data scientists, machine learning experts, data analysts and data engineers,Strong programming and architectural experience, ideally in Python and/or Java, and SQL,2+ years of experience building (big) data solutions,Working experience with Google Cloud Platform (GCP) or Amazon Web Services (AWS),Extremely passionate about data and analytics,Experience with ETL tools, Hadoop-based technologies (e.g. Spark) and/or data pipelines (e.g. Beam, Flink),Experience building scalable and high-performant code,Experience in producing tested, resilient and well documented applications,The ability to take ownership, end-to-end and finding creative solutions,Experience in architecting, building, maintaining and troubleshooting cloud infrastructure,Excellent interpersonal skills, verbal and written communication skills; a team player and keen learner who loves building great things together,BSc or MSc degree in Computer Science or a related technical field,Love for the command line with optional affinity for Linux scripting,Experience building scalable REST APIs using Python or similar technologies,Experience with Agile methodologies such as Scrum,Basic knowledge of and ideally some experience with data science topics like machine learning, data mining, statistics, and visualisation,Contributions to open source projects,25 days holiday plus bank holidays,Pension scheme,Situated in the innovation hub of Canary Wharf,Laptop of your choice,Monthly social events and team offsites,Generous desk budget,Free fruit, cookies, tea/coffee throughout the week,Regular networking events, mentoring events and conferences,Exposure to experts from a number of industries,Freedom to explore the latest tools and technologies","Does real-time processing of millions of rows per minute, working with petabytes of data and running large scale machine learning algorithms on thousands of CPUs sound like something you want to do? Do you enjoy a dynamic working environment with different challenges on a regular basis? Then become Datatonic’s next Data Engineer!You will be working on the data engineering and architecture part of our consulting projects, building robust pipelines and wrangling data in a way that it becomes easy to visualise and ready to be fed into our machine learning models. In addition to that, you will be helping us to build out the data engineering side of our next-generation machine learning products.
Furthermore, you will:
Work with the most innovative and most scalable data processing technologies
Build innovative state-of-the-art solutions with our customers
Work closely with our tech partners: Google Cloud Platform, Tableau, Looker
Work in an agile and dynamic environment together with a small team with our data scientists, machine learning experts, data analysts and data engineers
REQUIREMENTS
Strong programming and architectural experience, ideally in Python and/or Java, and SQL
2+ years of experience building (big) data solutions
Working experience with Google Cloud Platform (GCP) or Amazon Web Services (AWS)
Extremely passionate about data and analytics
Experience with ETL tools, Hadoop-based technologies (e.g. Spark) and/or data pipelines (e.g. Beam, Flink)
Experience building scalable and high-performant code
Experience in producing tested, resilient and well documented applications
The ability to take ownership, end-to-end and finding creative solutions
Experience in architecting, building, maintaining and troubleshooting cloud infrastructure
Excellent interpersonal skills, verbal and written communication skills; a team player and keen learner who loves building great things together
BSc or MSc degree in Computer Science or a related technical field
Bonus Points:
Love for the command line with optional affinity for Linux scripting
Experience building scalable REST APIs using Python or similar technologies
Experience with Agile methodologies such as Scrum
Basic knowledge of and ideally some experience with data science topics like machine learning, data mining, statistics, and visualisation
Contributions to open source projects
BENEFITS
25 days holiday plus bank holidays
Pension scheme
Situated in the innovation hub of Canary Wharf
Laptop of your choice
Monthly social events and team offsites
Generous desk budget
Free fruit, cookies, tea/coffee throughout the week
Regular networking events, mentoring events and conferences
Exposure to experts from a number of industries
Freedom to explore the latest tools and technologies
Knowledge-sharing activities
",https://www.level39.co/jobs/data-engineer-python/
JOB196087989036,Data Engineer,Data Engineer,"2+ years of data engineering or backend development experience in Python,Experience with technologies like Hadoop, Spark, Hive, Presto, NiFi, and Luigi,AWS experience preferred,Data modeling experience preferred,Scala or Java experience preferred,You’re a pragmatic engineer who will not only help execute, but also will provide a strong voice for technological direction of systems at Avant,You have a passion for data and empowering business with it,You are excited about evaluating and automating new technologies,You’re entrepreneurial, self-driven, and take pride in improving our user’s experiences,You have strong knowledge of Software Engineering & Data fundamentals as well as DevOps best practices,You thrive in a collaborative environment involving different stakeholders and subject matter experts and enjoys working with a diverse group of people with different expertise","Build data ingestion pipelines for various data sources including Postgres, SQLServer, and REST APIs,Participate in design and architecture planning for our infrastructure and code,Develop features to support dynamic ETL, automated data quality validation, and data delivery,Work with Data Management to build data pipelines in Spark,Automate operational data tasks,Perform periodic on-call duties","
Avant is revolutionizing the world of lending by lowering the costs and barriers of borrowing for everyday people. At our core, we are a technology company that builds advanced platforms and uses custom analytics. Today, we help underserved consumers, the majority of whom get fast funding on our online platform without having to talk to anyone. Tomorrow we plan to use our world class technology and underwriting capabilities to launch new products and bank partnerships that improve people’s financial lives.
JOB DESCRIPTION
Avant is looking for Data Services Engineers at all levels to help us build a robust and scalable data platform to support ETL, reporting, and data analysis as our business scales. We use cutting-edge technologies like Spark, NiFi, and Presto to deliver high-quality data to analysts, data scientists, and partners.
We’re looking for an engineer that takes ownership in their work, has a strong focus on quality, and enjoys working in a collaborative environment.
Responsibilities
Build data ingestion pipelines for various data sources including Postgres, SQLServer, and REST APIs
Participate in design and architecture planning for our infrastructure and code
Develop features to support dynamic ETL, automated data quality validation, and data delivery
Work with Data Management to build data pipelines in Spark
Automate operational data tasks
Perform periodic on-call duties
Qualifications
2+ years of data engineering or backend development experience in Python
Experience with technologies like Hadoop, Spark, Hive, Presto, NiFi, and Luigi
AWS experience preferred
Data modeling experience preferred
Scala or Java experience preferred
Why you are a fit for Avant
You’re a pragmatic engineer who will not only help execute, but also will provide a strong voice for technological direction of systems at Avant
You have a passion for data and empowering business with it
You are excited about evaluating and automating new technologies
You’re entrepreneurial, self-driven, and take pride in improving our user’s experiences
You have strong knowledge of Software Engineering & Data fundamentals as well as DevOps best practices
You thrive in a collaborative environment involving different stakeholders and subject matter experts and enjoys working with a diverse group of people with different expertise
Why Avant is a fit for you: At Avant, we believe our values make a difference:We value, support, and help each other growWe are committed to active inclusion and diversityWe are transparent and believe the best idea winsWe succeed when our customers succeedWe get sh!t done… responsiblyAnd we keep it fun! We believe that ideas are more important than titles, everything is more fun together, everyone drives change, and everyone is an owner. While we believe the perks and benefits that we offer are terrific, nothing excites us more than having the ability to collaborate with intelligent, highly-motivated and talented people on challenging problems as we work to change the face of online lending.
",https://www.builtinchicago.org/job/data/data-services-engineer/61183
JOB198174952424,Senior Data Engineer,Senior Data Engineer,"Bachelor’s degree in a relevant discipline with at least 14 years ’ experience, Master’s degree with at least 12 years’ experience or PhD with at least 6 years’ experience in biomedical data management, assay development, specimen data management or related discipline,Demonstrated proficiency with molecular biology assay concepts and ability to support, develop and deploy laboratory and other research data management processes and procedures as they apply to complex, high dimensional data sets,Extensive practical experience in curating and working with diverse but highly-connected scientific knowledge collections and their query interfaces to enable research hypotheses around compound targets, mechanisms of action, and patient response,Demonstrated ability to understand and translate high-level scientific datasets and results into data curation and management strategies,Proven ability to work in a team environment with clinical personnel, operational personnel, study monitors, computational biologists, biostatisticians, programmers, and medical writers,Demonstrated proficiency with current software engineering methodologies, such as Agile, source control, project management and issue tracking,Working knowledge of cloud computing. Preference will be given to candidates with AWS experience,Working knowledge of Rest APIs and container strategies strongly preferred.,Knowledge of distributed database design and implementation, LAMP/ MySQL, etc. with capability to perform/direct/assess implementation of such databases,Strong understanding of LIMS systems and systematic, relational approaches to data integration and data processing workflows,Excellent skills in R programming and experience in additional computer languages such as Perl, Python, PHP, S-PLUS or Java (or C/C++),Experience producing visualization of data sets (eg., R/shiny, Spotfire, etc),Working knowledge of both Windows and Linux operating systems is required,Along with programming proficiency must have creativity, and show a strong capacity for independent thinking and the ability to grasp underlying biological questions,Must thrive in a complex, dynamic environment while adapting to dynamically changing priorities,Must have excellent written and verbal communication and presentation skills,Must have excellent time management and organizational skills","Help develop, enhance, and automate processes for queuing and prioritizing data management and curation requests,Empower scientists with tools, processes and data structures needed to support project objectives, including data integration efforts that may span multiple studies or experiments,Ensure accurate, complete and timely collection, delivery and tracking of analytical information from internal or contract laboratory providers or collaborating laboratories for curation, ingestion and delivery to computational and translational scientists,Help define, deliver and implement R/ED, collaborator and partner laboratory analytical data management systems, processes and procedures,Work with R/ED study teams to develop R/ED information management plans that outline data capture, data flow, data queries, manual checks, and data listings needed to ensure data integrity and interpretability,Participate in comprehensive data review activities in coordination with project and study teams,Work with computational biologists, computational scientists, biostatisticians and study scientists to resolve data quality issues,Make data, including raw/interim data, available to R/ED department personnel as required,Acquire user feedback to inform business requirements for future data systems development.","
Description
Celgene is a global biopharmaceutical company leading the way in medical innovation to help patients live longer, better lives. Our purpose as a company is to discover and develop therapies that will change the course of human health. We value our passion for patients, quest for innovation, spirit of independence and love of challenge. With a presence in more than 70 countries - and growing - we look for talented people to grow our business, advance our science and contribute to our unique culture.
Summary/Scope
Celgene seeks a talented, results-oriented individual to contribute to our informatics and data management initiatives in Research and Early Development (R/ED). This hands-on role interfaces with programs spanning both discovery and translational sciences where processing and interpreting multi-platform and multi-dimensional ‘omic’ data in pre-clinical and clinical settings is being employed to identify molecular drug targets, characterize MOA, prioritize clinical indications and generate patient selection hypotheses. We are seeking an individual with extensive experience managing, processing, and applying quality control metrics and processes to a wide range of data types in support of R/ED clinical trials and drug development experiments while working in close collaboration with basic research, translational and computational scientists.
Responsibilities include, but are not limited to, the following:
Help develop, enhance, and automate processes for queuing and prioritizing data management and curation requests
Empower scientists with tools, processes and data structures needed to support project objectives, including data integration efforts that may span multiple studies or experiments
Ensure accurate, complete and timely collection, delivery and tracking of analytical information from internal or contract laboratory providers or collaborating laboratories for curation, ingestion and delivery to computational and translational scientists
Help define, deliver and implement R/ED, collaborator and partner laboratory analytical data management systems, processes and procedures
Work with R/ED study teams to develop R/ED information management plans that outline data capture, data flow, data queries, manual checks, and data listings needed to ensure data integrity and interpretability
Participate in comprehensive data review activities in coordination with project and study teams
Work with computational biologists, computational scientists, biostatisticians and study scientists to resolve data quality issues
Make data, including raw/interim data, available to R/ED department personnel as required
Acquire user feedback to inform business requirements for future data systems development.
Qualifications
Experience and Education
Bachelor’s degree in a relevant discipline with at least 14 years ’ experience, Master’s degree with at least 12 years’ experience or PhD with at least 6 years’ experience in biomedical data management, assay development, specimen data management or related discipline
Demonstrated proficiency with molecular biology assay concepts and ability to support, develop and deploy laboratory and other research data management processes and procedures as they apply to complex, high dimensional data sets
Extensive practical experience in curating and working with diverse but highly-connected scientific knowledge collections and their query interfaces to enable research hypotheses around compound targets, mechanisms of action, and patient response
Demonstrated ability to understand and translate high-level scientific datasets and results into data curation and management strategies
Proven ability to work in a team environment with clinical personnel, operational personnel, study monitors, computational biologists, biostatisticians, programmers, and medical writers
Demonstrated proficiency with current software engineering methodologies, such as Agile, source control, project management and issue tracking
Working knowledge of cloud computing. Preference will be given to candidates with AWS experience
Working knowledge of Rest APIs and container strategies strongly preferred.
Knowledge of distributed database design and implementation, LAMP/ MySQL, etc. with capability to perform/direct/assess implementation of such databases
Strong understanding of LIMS systems and systematic, relational approaches to data integration and data processing workflows
Excellent skills in R programming and experience in additional computer languages such as Perl, Python, PHP, S-PLUS or Java (or C/C++)
Experience producing visualization of data sets (eg., R/shiny, Spotfire, etc)
Working knowledge of both Windows and Linux operating systems is required
Along with programming proficiency must have creativity, and show a strong capacity for independent thinking and the ability to grasp underlying biological questions
Must thrive in a complex, dynamic environment while adapting to dynamically changing priorities
Must have excellent written and verbal communication and presentation skills
Must have excellent time management and organizational skills
Celgene is committed to equal opportunity in the terms and conditions of employment for all employees and job applicants without regard to race, color, religion, sex, sexual orientation, age, gender identity or gender expression, national origin, disability or veteran status.
Celgene complies with all applicable national, state and local laws governing nondiscrimination in employment as well as employment eligibility verification requirements of the Immigration and Nationality Act. All applicants must have authorization to work for Celgene in the U.S.
*LI-MG2
BIO-US
",https://jobs.newscientist.com/job/1401632435/senior-data-engineer/
JOB201467885932,Senior Big Data Engineer,Senior Big Data Engineer,"Ingestion pipelines and ETL using technologies like Kafka, Apache Spark,Experience with big data technologies such as Hadoop, Kafka, Akka, Mesos or similar highly desirable,Microservices design and implementation with REST / JSON a must,Experience with ElasticSearch highly desirable,Experience with Semantic Web, RDF, OWL, SPARQL & Linked Data highly desirable,Experience with large-scale production databases,Experience with a graph database highly desirable - Neo4J or Neptune,Any experience of other commercial search engines may be advantageous,Pair programming experience,Scrum agile experience,Kanban agile experience,JIRA experience,Release of search applications into a cloud environment, ideally blue-green deployments,Experience of working across a matrixed and distributed international organization,AWS system administration,Release processes and dev-ops","Solid Java programming skills, with more than one production release under your belt,Solid experience in building high performance services for backend and mid-tier systems","
Senior Engineer (Big Data/ Scala/ Java)
Elsevier is in the midst of a transformation, evolving from a publishing company that assures quality control in scientific output (although this will remain important) into a researcher productivity & analytics company that assures better outcomes in every interaction within the scientific world. We are focused on building an integrated, social and personal toolset that delivers differential value to researchers and research entities in helping them with the challenges they face. The linking of our traditional strengths of our publishing business to leading edge technology is critical to our success.
Our innovative technology platforms and smart content solutions operate at the cutting edge of big data, semantic web and cloud technology, enabling faster more effective critical decision-making daily across the globe.
We are looking for a number of roles at the moment from Senior Data Engineer, Lead Data Engineer to Senior Architect.
What you must have:
Solid Java programming skills, with more than one production release under your belt
Solid experience in building high performance services for backend and mid-tier systems
Requirements
Ingestion pipelines and ETL using technologies like Kafka, Apache Spark
Experience with big data technologies such as Hadoop, Kafka, Akka, Mesos or similar highly desirable
Microservices design and implementation with REST / JSON a must
Experience with ElasticSearch highly desirable
Experience with Semantic Web, RDF, OWL, SPARQL & Linked Data highly desirable
Experience with large-scale production databases
Experience with a graph database highly desirable - Neo4J or Neptune
Desirable additional experience:
Any experience of other commercial search engines may be advantageous
Pair programming experience
Scrum agile experience
Kanban agile experience
JIRA experience
Release of search applications into a cloud environment, ideally blue-green deployments
Experience of working across a matrixed and distributed international organization
AWS system administration
Release processes and dev-ops
",https://jobs.theguardian.com/job/6801506/senior-big-data-engineer/
JOB201499261291,Senior Data Engineer,Senior Data Engineer,,"Build data pipelines and deploy machine-learning algorithms.,Minimum 3 years’ experience in Data Engineering,Modern programming experience with Python, Java, Scala or similar,Solid ETL experience (Design, implementation and maintenance),Cloud ecosystem experience in Azure, AWS, GCP, Oracle or similar,DevOps experience in Kubernetes, Docker or similar desirable,Application of machine-learning methods Desirable,Degree in Computer Science, Physics, Mathematics or similar,Stakeholder engagement and project experience","
Work with modern cloud and programming applications.
Build data pipelines and deploy machine-learning algorithms.
Work alongside a team of Data Scientists.
This firm are driving the application of ML methods company-wide, so this is an exciting opportunity for an experienced Data Engineer to work on end-to-end ML model building and deployment as part of a team of Data Scientists and Data Engineers.
This Data Team acts as a consultancy within the business so there will be plenty of varied projects which will give incoming hire a diverse range of modern data engineering technologies to work with and develop.
What you’ll be doing
The Senior Data Engineer you work closely with the Team of Data Scientist and build and implement the required ML solutions including building and deployment. You will also be required to bring this all together by creating robust ETL pipelines that feed the data into the cloud.
As a senior hire, you will collaborate with the wider business to understand their relevant data needs and liaise with stakeholders regularly. You’ll be responsible for automating processes where possible and integrating data so that it can be provided to analytics users in the appropriate format.
What you’ll need to apply
Minimum 3 years’ experience in Data Engineering
Modern programming experience with Python, Java, Scala or similar
Solid ETL experience (Design, implementation and maintenance)
Cloud ecosystem experience in Azure, AWS, GCP, Oracle or similar
DevOps experience in Kubernetes, Docker or similar desirable
Application of machine-learning methods Desirable
Degree in Computer Science, Physics, Mathematics or similar
Stakeholder engagement and project experience
What you’ll get in return for your experience
A competitive salary dependent on experience plus bonus and benefits with the chance to work with modern data engineering technologies and machine-learning methods.
What’s next?
Please get in touch with Scott with an up to date CV today, don’t hesitate to call/email to discuss the role in more detail.
",http://jobs.theguardian.com/job/6862220/senior-data-engineer/
JOB201500075085,Data Engineer,Data Engineer,,,"
My client are looking for an individual with a technical mind to work alongside the deployment teams as a specialist resource where you will be managing the migration and deployment of customer data.
My client are looking for an individual with a technical mind to work alongside the deployment teams as a specialist resource where you will be managing the migration and deployment of customer data.
The role:
• Helping customers understand their legacy and target data models and recommending actions to assist in effective migration
• Analysis of customer data and production of data quality reports outlining data quality issues and recommending “quick wins” for fix and highlighting issues.
• Accurate Data mapping
• Test and final load of data sets into customer environments in such a way as to give confidence in completeness and accuracy, minimising business impact
• Working with customers to support them in getting the most out of Salesforce.com and 3rd party reporting and dashboarding tools, feeding back to product teams where data model adjustments would be beneficial
• Managing your own time whilst working within the project constraints
• Taking part in project planning exercises and ensuring data concerns are given full consideration
Required:
• A minimum of 12 months experience using your choice of tooling (MS Excel, MS Access, SQL, or relevant databases) to extract, transform and load data between systems.
• Comfortable and organised whilst working across several projects simultaneously
• A proven ability to plan, organise, prioritise, manage and track numerous concurrent activities to successful outcomes
• Calm working to customer deadlines.
• A passion towards data handling
Desired:
• If you have experience working with/in the public sector this would hold in good stood as these organisations share a number of common challenges and obligations.
• A working knowledge of data modelling techniques would be a distinct advantage - For example being able to interpret and write.
• Salesforce and AWS familiarity
Start: Immediately
Duration: Temporary 4 weeks +
Location: Cambridge, Cambridgeshire
Hours: Full time - flexible
Hourly Rate: £competitive
If you have not received a response within 3-5 working days, unfortunately your application has been unsuccessful. aspire cambridge ltd is acting as an employment agency for this temporary vacancy.
Apply now
",https://www.cambridgenetwork.co.uk/recruitment-gateway/agency/74454/
JOB203110650798,Big Data Engineer Job Description Template,Big Data Engineer Job Description Template,"Proficient understanding of distributed computing principles,Management of Hadoop cluster, with all included services {{unless you are going to have specific Big Data DevOps roles for this}},Ability to solve any ongoing issues with operating the cluster {{unless you are going to have specific Big Data DevOps roles for this}},Proficiency with Hadoop v2, MapReduce, HDFS,Experience with building stream-processing systems, using solutions such as Storm or Spark-Streaming {{if stream-processing is relevant for the role}},Good knowledge of Big Data querying tools, such as Pig, Hive, and Impala,Experience with Spark {{if you are including or planning to include it}},Experience with integration of data from multiple data sources,Experience with NoSQL databases, such as HBase, Cassandra, MongoDB,Knowledge of various ETL techniques and frameworks, such as Flume,Experience with various messaging systems, such as Kafka or RabbitMQ,Experience with Big Data ML toolkits, such as Mahout, SparkML, or H2O {{if you are going to integrate Machine Learning in your Big Data infrastructure}},Good understanding of Lambda Architecture, along with its advantages and drawbacks,Experience with Cloudera/MapR/Hortonworks {{you can specify the distribution you are currently using or planning to use here}},{{List any other technologies you are using or planning to use. Most Big Data Engineers will know some of the ones listed here: The Hadoop Ecosystem Table}},{{List education level or certification you require}}","s,s,s,Selecting and integrating any Big Data tools and frameworks required to provide requested capabilities,Implementing ETL process {{if importing data from existing data sources is relevant}},Monitoring performance and advising any necessary infrastructure changes,Defining data retention policies,{{Add any other responsibility that is relevant}}","A Big Data Engineer is a person who creates and manages a company’s Big Data infrastructure and tools, and is someone that knows how to get results from vast amounts of data quickly.
The actual definition of this role varies, and often mixes with the Data Scientist role. Here, we will assume that it is a role focused on engineering, without statistics and strong machine learning skills required.
The world of Big Data has grown significantly during the last decade; therefore, the skills started to be more specific. While in the majority of cases it is built around Hadoop, there are many tools that have become very significant on their own. We have covered some common cases in the following sample description.
Big Data Engineer - Job Description and Ad Template
{{Write a short and catchy paragraph about your company. Make sure to provide information about the company culture, perks, and benefits. Mention office hours, remote working possibilities, and everything else you think makes your company interesting. Big Data Engineers like to work on huge problems - mentioning the scale (or the potential) can help gain the attention of top talent.}}
We are looking for a Big Data Engineer that will work on the collecting, storing, processing, and analyzing of huge sets of data. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.
Selecting and integrating any Big Data tools and frameworks required to provide requested capabilities
Implementing ETL process {{if importing data from existing data sources is relevant}}
Monitoring performance and advising any necessary infrastructure changes
Defining data retention policies
{{Add any other responsibility that is relevant}}
Proficient understanding of distributed computing principles
Management of Hadoop cluster, with all included services {{unless you are going to have specific Big Data DevOps roles for this}}
Ability to solve any ongoing issues with operating the cluster {{unless you are going to have specific Big Data DevOps roles for this}}
Proficiency with Hadoop v2, MapReduce, HDFS
Experience with building stream-processing systems, using solutions such as Storm or Spark-Streaming {{if stream-processing is relevant for the role}}
Good knowledge of Big Data querying tools, such as Pig, Hive, and Impala
Experience with Spark {{if you are including or planning to include it}}
Experience with integration of data from multiple data sources
Experience with NoSQL databases, such as HBase, Cassandra, MongoDB
Knowledge of various ETL techniques and frameworks, such as Flume
Experience with various messaging systems, such as Kafka or RabbitMQ
Experience with Big Data ML toolkits, such as Mahout, SparkML, or H2O {{if you are going to integrate Machine Learning in your Big Data infrastructure}}
Good understanding of Lambda Architecture, along with its advantages and drawbacks
Experience with Cloudera/MapR/Hortonworks {{you can specify the distribution you are currently using or planning to use here}}
{{List any other technologies you are using or planning to use. Most Big Data Engineers will know some of the ones listed here: The Hadoop Ecosystem Table}}
{{List education level or certification you require}}
",http://www.toptal.com/big-data/job-description
JOB208866008971,Senior Data Engineer,Senior Data Engineer,"Hadoop/Spark/Google Cloud Dataflow,Kafka/Kinesis (AWS)/Google Pub/Sub (GCP),Elasticsearch/BigQuery,Other distributed SQL/NoSSQL databases,Python, Scala, Golang and R,3+ year(s) experience with provisioned and on-demand cloud computing platforms GCP/AWS/Azure,3+ year(s) experience with standard development tooling (e.g. Git, Jira, etc.),Knowledge of distributed computing fundamentals and the ability to design for scalability on Linux platforms,Some experience with machine learning algorithms and libraries (e.g. scikit-learn),A bachelor’s degree in relevant technical field of Computer Science, Mathematics/Statistics, or similarly relevant engineering or computational discipline.,Data analytics/modeling experience,Strong mathematical/statistical analysis skills","Leverage modern analytics stacks and cloud platforms to design, implement and maintain scalable infrastructure for ingesting, processing and persisting large volumes of batched and streaming data.,Contribute to multiple production code bases in a continuous delivery (CI/CD) environment.,Write, debug, maintain and constructively review code on a highly collaborative software engineering team.,Develop production quality software for interacting with distributed data pipelines, data stores and data models.,Provide thought leadership and advocate for best practices regarding big data and scalable processing and storage infrastructure.","
Overview
LogRhythm is the pioneer in Next Generation SIEM and Threat Lifecycle ManagementTM (TLM) technology, empowering organizations on six continents to rapidly detect, respond to and neutralize damaging cyberthreats. Our TLM platform unifies leading-edge data lake technology, artificial intelligence and security analytics to serve as the foundation for the AI-enabled security operations center. We are consistently recognized as a leader in the security intelligence domain and have been placed in Gartner’s SIEM Magic Quadrant for 6 consecutive years.
The LogRhythm Data Science team is seeking a qualified Senior Data Engineer with the requisite experience and passion for designing, implementing and delivering data-driven analytics products to support our customers need for advanced cyber threat detection and mitigation. The qualified individual is an experienced engineer who has demonstrated expertise with modern, scalable and distributed analytics platforms in a highly collaborative engineering environment. The Senior Data Engineer is expected to be a key contributor on a growing Data Science team.
Responsibilities
Leverage modern analytics stacks and cloud platforms to design, implement and maintain scalable infrastructure for ingesting, processing and persisting large volumes of batched and streaming data.
Contribute to multiple production code bases in a continuous delivery (CI/CD) environment.
Write, debug, maintain and constructively review code on a highly collaborative software engineering team.
Develop production quality software for interacting with distributed data pipelines, data stores and data models.
Provide thought leadership and advocate for best practices regarding big data and scalable processing and storage infrastructure.
Requirements
3+ years of experience with one or more of the following technologies and platforms:
Hadoop/Spark/Google Cloud Dataflow
Kafka/Kinesis (AWS)/Google Pub/Sub (GCP)
Elasticsearch/BigQuery
Other distributed SQL/NoSSQL databases
3+ years of experience with one or more of the following high-level programming languages
Python, Scala, Golang and R
3+ year(s) experience with provisioned and on-demand cloud computing platforms GCP/AWS/Azure
3+ year(s) experience with standard development tooling (e.g. Git, Jira, etc.)
Knowledge of distributed computing fundamentals and the ability to design for scalability on Linux platforms
Some experience with machine learning algorithms and libraries (e.g. scikit-learn)
Valued Skills/Qualifications
A bachelor’s degree in relevant technical field of Computer Science, Mathematics/Statistics, or similarly relevant engineering or computational discipline.
Data analytics/modeling experience
Strong mathematical/statistical analysis skills
LogRhythm is proud to be an equal opportunity employer. We are committed to equal opportunity regardless of race, color, ancestry, religion, gender, gender identity, genetic information, parental or pregnancy status, national origin, sexual orientation, age, citizenship, marital status, disability, or Veteran status.
",https://www.builtincolorado.com/job/data/senior-data-engineer/41324
JOB210924703899,54 Data Engineer Jobs,54 Data Engineer Jobs,,,"
",https://www.analytictalent.datasciencecentral.com/jobs/data-engineer-30708517-b
JOB211656416378,Data Engineer 4- TS/SCI,Data Engineer 4- TS/SCI,,,"
Data Engineer 4- TS/SCI
Northrop Grumman Mission Systems Sector is seeking a junior to mid-level data engineer for a program that provides research opportunities for data acquisition and new uses for existing data. The successful candidate will be responsible for building high-performance algorithms, prototypes, predictive models and proof of concepts. This position is located at Bolling AFB, Washington DC. Responsibilities:
* Design, construct, install, test and maintain highly scalable data management systems
* Ensure systems meet business requirements and industry practices
* Develop data set processes for data modeling, mining and production
* Integrate new data management technologies and software engineering tools into existing structures
* Create custom software components (e.g. specialized UDFs) and analytics applications
* Employ a variety of languages and tools (e.g. scripting languages) to marry systems together
* Recommend ways to improve data reliability, efficiency and quality
* Collaborate with data architects, modelers and IT team members on project goals
Required Qualifications (Must have):
* Bachelor degree in areas of Science, Technology, Engineering, or Mathematics (STEM) * 10 years of work related experience
* Basic understanding of front-end technologies such as JavaScript, HTML, and CSS3
* Experience with querying, analyzing, and visualizing large data sets
* Possess strong unit test and debugging skills
* Must possess strong troubleshooting and problem solving skills
* Must demonstrate strong client relations skills
* Proven track record for working successfully in a team oriented environment with frequent customer interaction
* Must be able to operate independently
* Must possess an active TSSCI clearance Preferred Qualifications (Nice to have):
* Familiar with Python, JAVA, Pig
* Familiar with various operating systems including Window, Linux, Unix
* Familiar with working with applications in a cloud-based environment
* Familiar with Mathematica, REST APIs
* Knowledge of user authentication and authorization between multiple systems, servers, and environments
* Have domain knowledge of the Defense Intelligence Agency (DIA) * Experience in System Administration and Database administration (a plus) * Preferred candidate traits include: focused self-starter; excellent time management, team building skills; excellent verbal and written communication skills and a reputation for establishing good customer relationships Northrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.
Shift: 1st Shift
Relocation Assistance: Yes
US Citizenship Required for this Position: No relocation assistance available
Business Sector: United States-District of Columbia-Bolling AFB
Shift: 1st Shift
Relocation Assistance: Yes
US Citizenship Required for this Position: No relocation assistance available
Business Sector: United States-District of Columbia-Bolling AFB
",https://www.clearancejobs.com/jobs/2364705/data-engineer-4-tssci
JOB215489215777,Data Engineer - Office of the CIO (112822),Data Engineer - Office of the CIO (112822),"2 years of experience in data engineering constructing and maintaining databases and data pipelines.,1 year of experience creating and supporting production databases,1 year of experience with working with a data lake environment,Experience collecting, transforming and storing large amounts of data.,Bachelor’s degree and experience working in data engineering OR Bachelor’s degree or Master’s degree from a computer science field such as Computer Science, Information Sciences, or Informatics.,Experience creating data pipelines for machine learning,Data management certifications.,Strong knowledge of SQL and NoSQL database technologies.,Strong knowledge of at least one scripting language such as Java, Python.,Knowledge of Hadoop, Spark or other big data processing frameworks,Submit the Staff Vacancy Application.,Submit the Voluntary Self-Identification of Disability forms.,Upload your cover letter, resume (months and years of employment must be included), and academic credentials (unofficial transcripts or diploma may be acceptable) and names/contact information for three references.","Consult with campus researchers, faculty and staff to understand data questions and needs.,Develop prototypes and proof of concepts for the possible solutions.,Create and maintain optimal data lake and pipeline infrastructure.,Build the infrastructure required for optimal extraction, transformation, and loading of data from a variety of data sources using SQL, NoSQL and cloud ‘big data’ technologies.,Code, test, and document new or modified data systems to create robust and scalable applications.,Assemble large, complex data sets that meet functional / non-functional business requirements.,Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability.,Work with data and analytics experts to strive for greater functionality in our data systems.,Develop, refine and scale data management and analytics procedures, systems, workflows, and best practices.,Contribute to efforts in creating, refining, managing and enforcing data management policies, procedures, conventions and standards.,Collaborate with other members of formal and informal groups in the pursuit of common missions, vision, values and mutual goals.,Understand the overall processes and procedures of the organization and make recommendations in the continual improvement of those processes and procedures, providing for management analysis and recommendations on continuous improvement.","
Job description
Description:
Data Engineer
Technology Services
University of Illinois at Urbana-Champaign
Illinois is a world leader in research, teaching, and public engagement. We serve the state, the nation, and the world by creating knowledge, preparing students for lives of impact, and addressing critical societal needs through the transfer and application of knowledge. Illinois is the place where we embrace difference. We embrace it because we value it. Illinois is especially interested in candidates who can contribute, through their research, teaching, and/or service, to the diversity and excellence of the Illinois community.
An ideal candidate will have a deep understanding of data lake and database solutions. They will have experience designing and building robust storage solutions for data analytics. This position will require working with many cross functional groups so an ideal candidate will also be a great team player with strong interpersonal skills.
Position Summary:
Consult with campus researchers, faculty and staff to design and enact innovative data compute and storage solutions. Responsible for designing, building and supporting the data infrastructure for Technology Services and other campus projects. The data engineer will own these projects with assistance from the Innovation team. These projects will be pursued with the goal of collecting and making data easily available and usable for data analytics and research.
Duties and Responsibilities:
Data Engineering:
Consult with campus researchers, faculty and staff to understand data questions and needs.
Develop prototypes and proof of concepts for the possible solutions.
Create and maintain optimal data lake and pipeline infrastructure.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a variety of data sources using SQL, NoSQL and cloud ‘big data’ technologies.
Code, test, and document new or modified data systems to create robust and scalable applications.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability.
Work with data and analytics experts to strive for greater functionality in our data systems.
Develop, refine and scale data management and analytics procedures, systems, workflows, and best practices.
Contribute to efforts in creating, refining, managing and enforcing data management policies, procedures, conventions and standards.
Diagnose problems using formal problem-solving tools and techniques from multiple angles and probe underlying issues to generate multiple potential solutions. Proactively anticipate and prevent problems.
Ensure excellent customer service throughout the data analytics unit:
Collaborate with other members of formal and informal groups in the pursuit of common missions, vision, values and mutual goals.
Understand the overall processes and procedures of the organization and make recommendations in the continual improvement of those processes and procedures, providing for management analysis and recommendations on continuous improvement.
Partner with the Technology Services Help Desk by setting and managing the expectations of customers.
Required Qualifications:
2 years of experience in data engineering constructing and maintaining databases and data pipelines.
1 year of experience creating and supporting production databases
1 year of experience with working with a data lake environment
Experience collecting, transforming and storing large amounts of data.
Experience with AWS or other cloud compute/storage technologies.
Experience may be concurrent.
Education Preferred:
Bachelor’s degree and experience working in data engineering OR Bachelor’s degree or Master’s degree from a computer science field such as Computer Science, Information Sciences, or Informatics.
Experience Preferred:
Experience creating data pipelines for machine learning
Experience working in a higher education environment.
Training, Licenses or Certifications Preferred:
Data management certifications.
Successful Candidates will have:
Strong knowledge of SQL and NoSQL database technologies.
Strong knowledge of at least one scripting language such as Java, Python.
Knowledge of Hadoop, Spark or other big data processing frameworks
Understanding of machine learning and its applications.
SALARY AND APPOINTMENT INFORMATION:
This is a full-time Civil Service IT Technical Associate position appointed on a 12-month service basis. The expected start date is as soon as possible after the posting closes. Salary is commensurate with experience.
TO APPLY:
Applications must be received by May 22, 2019. Apply for this position using the “Apply for Position” button below. If you have not applied before, you must create your candidate profile at http://jobs.illinois.edu. If you already have a profile, you will be redirected to that existing profile via email notification. To complete the application process:
Submit the Staff Vacancy Application.
Submit the Voluntary Self-Identification of Disability forms.
Upload your cover letter, resume (months and years of employment must be included), and academic credentials (unofficial transcripts or diploma may be acceptable) and names/contact information for three references.
In order to be considered as a transfer candidate, you must apply for this position using the “Apply for Position” button below. Applications not submitted through this website will not be considered. For further information about this specific position, contact Rhonda Miller at 217-333-4222. For questions about the application process, please contact 217-333-2137.
The University of Illinois conducts criminal background checks on all job candidates upon acceptance of a contingent offer.
The University of Illinois is an Equal Opportunity, Affirmative Action employer. Minorities, women, veterans and individuals with disabilities are encouraged to apply. For more information, visit http://go.illinois.edu/EEO.
College Name or Administrative Unit:Office of the CIO Category:8-Technical Title:Data Engineer - Office of the CIO (112822) Open Date:04/25/2019 Close Date:05/22/2019 Organization Name:Ofc of the Chief Info Officer
Share this job with your network:
AAUP COMPENSATION SURVEY DATA
View more
",https://careers.insidehighered.com/job/1775466/data-engineer-office-of-the-cio-112822-/
JOB215561828674,"Senior Data Engineer (Python, Big Data)","Senior Data Engineer (Python, Big Data)",,"Maintain the development infrastructure supporting the marketing organization,Development and maintenance of data processing on our new Marketing data platform,Leading contributor in the team in terms of working knowledge of big data technologies,Work with the technology and business community to turn business requirements into technical solutions.,Work autonomously from specifications and produce high quality, accurate, efficient and well documented code. Ensure accurate estimating for work based on detailed requirements.,Undertake maintenance and ‘bug fix’ development activities for existing applications.,Construct and execute unit and system testing.,Undertake peer-to-peer code reviews of colleagues’ development tasks.,Ensure clear and early communication, in particular ensuring that that line manager and/or relevant parties are kept informed of progress, issues and difficulties.,Proactively work to mitigate risks, improve quality in an efficient manner and resolve problems that arise.,Lead adherence to best practice solutions across the team,Ability to manage ongoing project work alongside business as usual support and maintenance.,Provide estimates of duration and effort required to complete development tasks from high-level or loosely-defined requirements.,Create robust system-level design for assigned development activities with a solid grasp of business and commercial drivers to produce designs that clearly meet customer/user needs and feedback is positive,Undertake a thorough impact analysis of all assigned development activities, understanding the impact of own work on other tasks and areas of the system,Share process expertise across the team in order to enhance team effectiveness,Contribute to the marketing systems roadmap bringing technical leadership and oversight,One or more of Python, Java,Performance tuning of both MapReduce queries and relational databases,AWS technologies,Big data technologies such as Spark,Analytical platforms such as Databricks, Blue Insight,Excellent verbal and written communication skills,Team player able to work under own initiative,Customer focused and service-oriented,Confident in establishing good working relationships other IT teams (internal and external),Marketing automation tools, including campaign management and workflow (Adobe Campaign preferred, other examples Eloqua, Aprimo),Web analytics: Adobe Analytics, SiteCatalyst/Google Analytics/Webtrends,Experience using a recognized development methodology, e.g. Agile Experience and understanding of the role of the developer in the full SDLC,Proven track record of feature level design,Knowledge of service management and ITIL framework,Previous experience with marketing, publishing and analytics preferred.,Able to create imaginative solutions that move the platform forward in features, maintainability and cost-effectiveness.","
Elsevier is a global information analytics company that helps institutions and professionals progress science, advance healthcare and improve performance for the benefit of humanity.
We serve the research, academic, and clinical communities through the application of technology and analytics to content. In this way, we empower those communities to contribute to social progress, enhance human well-being, and to share and expand the breadth of human knowledge.
This is an exciting opportunity to play a role in transforming the way marketing automation is delivered across Elsevier. We are seeking a talented and self-motivated Big Data Engineer with solid experience in developing and supporting big data platforms within a cross-functional product development environment and who want to develop their career within Marketing Tech.
Working across Elsevier’s global marketing teams the role will support many complex and challenging assigned projects aimed at delivering Marketing solutions and services that meet company cost, quality, and strategic targets.
Key Responsibilities:
Maintain the development infrastructure supporting the marketing organization
Development and maintenance of data processing on our new Marketing data platform
Leading contributor in the team in terms of working knowledge of big data technologies
Work with the technology and business community to turn business requirements into technical solutions.
Work autonomously from specifications and produce high quality, accurate, efficient and well documented code. Ensure accurate estimating for work based on detailed requirements.
Undertake maintenance and ‘bug fix’ development activities for existing applications.
Construct and execute unit and system testing.
Undertake peer-to-peer code reviews of colleagues’ development tasks.
Ensure clear and early communication, in particular ensuring that that line manager and/or relevant parties are kept informed of progress, issues and difficulties.
Proactively work to mitigate risks, improve quality in an efficient manner and resolve problems that arise.
Lead adherence to best practice solutions across the team
Ability to manage ongoing project work alongside business as usual support and maintenance.
Provide estimates of duration and effort required to complete development tasks from high-level or loosely-defined requirements.
Create robust system-level design for assigned development activities with a solid grasp of business and commercial drivers to produce designs that clearly meet customer/user needs and feedback is positive
Undertake a thorough impact analysis of all assigned development activities, understanding the impact of own work on other tasks and areas of the system
Share process expertise across the team in order to enhance team effectiveness
Contribute to the marketing systems roadmap bringing technical leadership and oversight
Technical Skills:
Solid working knowledge of the following:
One or more of Python, Java
Performance tuning of both MapReduce queries and relational databases
Working knowledge of the following technologies:
AWS technologies
Big data technologies such as Spark
Analytical platforms such as Databricks, Blue Insight
Interpersonal Skills:
Excellent verbal and written communication skills
Team player able to work under own initiative
Customer focused and service-oriented
Confident in establishing good working relationships other IT teams (internal and external)
Knowledge of the following technologies advantageous:
Marketing automation tools, including campaign management and workflow (Adobe Campaign preferred, other examples Eloqua, Aprimo)
Web analytics: Adobe Analytics, SiteCatalyst/Google Analytics/Webtrends
Experience using a recognized development methodology, e.g. Agile Experience and understanding of the role of the developer in the full SDLC
Proven track record of feature level design
Knowledge of service management and ITIL framework
Previous experience with marketing, publishing and analytics preferred.
Able to create imaginative solutions that move the platform forward in features, maintainability and cost-effectiveness.
",https://jobs.theguardian.com/job/6800124/senior-data-engineer-python-big-data-/
JOB216209717577,Senior Data Engineer,Senior Data Engineer,Relevant degree or work experience,"work to architect and develop data pipelines and storage to enable insight from Wellcome's data,work collaboratively in a cross-functional team to deliver quality software,mentor others, sharing technical knowledge and providing guidance and support,communicate effectively with managers, scientists, peer developers, testers, business analysts, product owners and scrum master,experience with distributed data processing technologies such as Apache Hadoop, Apache Spark,experience with language(s) commonly used in data science e.g. Python, JVM languages etc.,experience of Cloud Architecture,an understanding of ETL/ELT data processing pipelines,experience developing data processing solutions,experience data modelling with RDBMS and NoSQL data stores","
We are seeking an experienced Senior Data Engineer with experience in data projects to join the Software Development team at Wellcome.
About the job
To succeed in this role, you will:
In this role, you will be responsible for leading a team to design and build product(s) which focus on using data to evidence the success of Wellcome's funding and identify new opportunities to support Wellcome's mission in the future. You will work inside Wellcome Data Labs with a strong cross-functional product team of developers and data scientists to provide innovative technical solutions to meet the needs of the organisation.
work to architect and develop data pipelines and storage to enable insight from Wellcome's data
work collaboratively in a cross-functional team to deliver quality software
mentor others, sharing technical knowledge and providing guidance and support
communicate effectively with managers, scientists, peer developers, testers, business analysts, product owners and scrum master
About you
To succeed in this role, you'll need to have:
experience with distributed data processing technologies such as Apache Hadoop, Apache Spark
experience with language(s) commonly used in data science e.g. Python, JVM languages etc.
experience of Cloud Architecture
an understanding of ETL/ELT data processing pipelines
experience developing data processing solutions
experience data modelling with RDBMS and NoSQL data stores
Education & Qualifications
Relevant degree or work experience
",https://jobs.theguardian.com/job/6710953/senior-data-engineer/
JOB218720148557,Data Engineer,Data Engineer,,,"
Data Engineer
Coverent is seeking a Data Engineer / Data Scientist to lead quantitative research and program evaluation activities for a client in the US Intelligence Community. In this role, you will apply advanced analytic capabilities to answer complex questions related to client mission. You'll have the opportunity to demonstrate your intellectual agility by leading methodology selection, data collection and/or generation, and rigorous analysis. You'll be asked to help clients leverage data to enable smart decision making and action.
Why Coverent?
Coverent is a specialized consulting services firm focused on developing innovative solutions to the most challenging problems facing our nation. We are growing quickly, but focused on maintaining our commitment to fantastic results and a fair, flexible, and fun culture:
*
Are you interested in working for a boutique firm who sees its employees as more than just a number?
*
Are you intrigued by the notion of joining a small team of talented, passionate consultants with a clear vision to help our clients achieve their missions better, smarter, faster?
*
Does a company culture that emphasizes outcomes, fairness, and flexibility sound appealing?
*
Would you like to be rewarded for your contributions, via programs like annual bonuses and company profit sharing?
*
Would you appreciate having a choice of options from top-notch benefit providers for medical and retirement plans?
*
Are you interested in a learning culture that is forward-leaning regarding training, education, and professional development?
If you answer YES to these questions, Coverent could be the employer of choice for you.
Position Responsibilities
*
Develop tailored analytical solutions and products for social media analysis
*
Code and automate existing bulk social media data analysis
*
Collaborate with clients to understand their technical requirements, expectations, timelines, constraints, and resources
*
Conduct hypothesis testing
*
Conduct statistical analyses; may include definition of sampling plans as well as identification of data capture strategies and modeling
*
Prepare visual presentations of data and analysis
*
Prepare reports and presentations for senior leadership based on research plans, activities, findings and recommendations
*
Brief senior level customers on research plans, activities, findings and recommendations
Required Qualifications
* U.S. Citizenship
* Active TS/SCI clearance with Full-Scope Polygraph
* Must have a Bachelor's degree in a field that uses advanced analytics and a minimum of 4 years' related work experience
* Experience and/or familiarity with social media, analytic, statistical software and data visualization tools such as Python and/or R including relevant packages.
* Demonstrated experience managing bulk data from databases and other systems using SQL queries or scripts
* Excellent oral and written communication skills, including visual representation of data using charts and graphs
* Advanced proficiency with MS Excel and PowerPoint
* Ability to perform in an individual contributor role while also excelling in a team environment
Desired Qualifications
*
Experience with Extract Transform Load (ETL) tools
*
Experience developing dashboards for real time online metrics
*
Experience with Natural Language Processing and foreign language text manipulation
*
Experience with machine learning algorithms including feature selection and implementation
*
Experience performing the setup and configuration of Integrated Development Environments (IDEs) and using code versioning software
*
Ability to gather and draft software requirements from users
*
Experience with web scraping and DOM manipulation
*
Experience with Elasticsearch or Solr
",https://www.clearancejobs.com/jobs/2237132/data-engineer
JOB220330997597,Data Engineer,Data Engineer,,"Develop, construct, test and maintain architectures, such as databases and large-scale processing systems,Ensure data architecture that supports the requirements of the business,Discover opportunities for data acquisition,Develop data set processes for data modeling, mining, and production,Employ a variety of languages and tools (e.g scripting languages) to marry the systems together,Identity, recommend and implement ways to improve data reliability, quality,4+ years of experience working as a Data Engineer,Experience with building Data Architecture,Experience in PostgreSQL or similar SQL-like database, Redis, Hive, and Sqoop Experience with NoSQL databases such as Cassandra or MongoDB,Development experience with Scala or any other functional or object-oriented language such as Python, Perl, Java, etc.,Have experience building a full stack data pipelines and data infrastructure,Live/work in the San Francisco Bay Area,Have a passion for education,Have previous experience at a growth stage internet/software company","Lambda School is on a mission to pioneer a new model of accessible higher education with no upfront costs and where the school invests in the students instead of the other way around. We are rethinking learning so that we can address the needs of both students and employers in tandem. We’re a progressive alternative to traditional college and fast track bootcamps. Lambda is an intensive program and an immersive live, online curriculum that teaches people the hard and soft skills they need to launch a new tech career. We offer both full time and part time courses to our students.
Lambda has successfully completed funding rounds with premier tier venture investors and we have students in almost every State across the United States. We’re looking for passionate, talented people who want to change the way the world thinks about higher education and unlock human potential, regardless of circumstance.
If that sounds exciting to you, let’s talk. Our success depends on building teams who can challenge each other's assumptions with fresh perspectives. To that end, we don’t just accept differences – we celebrate them. Lambda School welcomes a diverse pool of applicants, including those from historically marginalized groups and non-traditional backgrounds who can appreciate the diverse student communities that we serve and are looking to grow into. This includes women, people with disabilities, people of color, formerly incarcerated people, individuals who are lesbian, gay, bisexual, transgender, queer and/or gender nonconforming, first and second generation immigrants, veterans, and people from different socioeconomic backgrounds.
What You Will Do:
Develop, construct, test and maintain architectures, such as databases and large-scale processing systems
Ensure data architecture that supports the requirements of the business
Discover opportunities for data acquisition
Develop data set processes for data modeling, mining, and production
Employ a variety of languages and tools (e.g scripting languages) to marry the systems together
Identity, recommend and implement ways to improve data reliability, quality
Define and manage SLA’s for all data sets and processes running in production.
What You Will Need:
4+ years of experience working as a Data Engineer
Experience with building Data Architecture
Experience in PostgreSQL or similar SQL-like database, Redis, Hive, and Sqoop Experience with NoSQL databases such as Cassandra or MongoDB
Development experience with Scala or any other functional or object-oriented language such as Python, Perl, Java, etc.
Experience with data sets and data visualization tools.
Bonus If You:
Have experience building a full stack data pipelines and data infrastructure
Live/work in the San Francisco Bay Area
Have a passion for education
Have previous experience at a growth stage internet/software company
Have a non-traditional story. Many of our students have beaten a unique path to their new jobs. We like team members who have done the same
The position is a full-time, salaried role with medical benefits.
Lambda School is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, age, physical or mental disability, pregnancy, genetic information, sex, sexual orientation, gender identity or expression, marital status, familial status, domestic violence victim status, veteran or military status, or any other legally recognized protected basis under federal, state or local laws. Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
Lambda School is committed to providing reasonable accommodations for qualified individuals with disabilities in our job application procedures. Please let us know if you need assistance or an accommodation due to a disability.
Jobs powered by
",https://jobs.lever.co/lambdaschool/32dc678f-9a26-495c-9d63-b727ddf93502
JOB221153655109,Data Engineer Jobs,Data Engineer Jobs,,,"
We use cookies to improve your experience on our site and to show you relevant advertising.
To find out more, read our updated privacy policy.
",https://jobs.theguardian.com/landingpage/6729602/data-engineer-jobs/
JOB226021655342,Data Engineer,Data Engineer,This is a full time exempt position,"Database maintenance,Building and analyzing dashboards and reports,Evaluating and defining metrics and perform exploratory analysis,Monitoring key product metrics and understanding root causes of changes in metrics,Empower and assist operation and product teams through building key data sets and data-based recommendations,Automating analyses and authoring pipelines via SQL/python based ETL framework,Superb SQL programming skill.,Understanding of ETL tools and database architecture.,Advanced knowledge of data warehousing.,Demonstrable familiarity with code and programming concepts. Experience with Python is preferred but not required.,A product mindset - you ask and address the most important analytical questions with a view on enhancing product impact.,Passionate and attentive self-starters, great communicators.,1-3 years of experience in quantitative analysis experience.,Bachelor's degree in Computer Science, Statistics, Math or other technical field required. Graduate degrees preferred.","
The Data Engineer is responsible for applying your expertise in quantitative analysis, database and data warehousing, partnered with operation and product teams, to solve problems and identify trends and opportunities. The Data Engineer role has to work across the following areas:
Database maintenance
Building and analyzing dashboards and reports
Evaluating and defining metrics and perform exploratory analysis
Monitoring key product metrics and understanding root causes of changes in metrics
Empower and assist operation and product teams through building key data sets and data-based recommendations
Automating analyses and authoring pipelines via SQL/python based ETL framework
Key Competencies
Superb SQL programming skill.
Understanding of ETL tools and database architecture.
Advanced knowledge of data warehousing.
Demonstrable familiarity with code and programming concepts. Experience with Python is preferred but not required.
A product mindset - you ask and address the most important analytical questions with a view on enhancing product impact.
Passionate and attentive self-starters, great communicators.
Education and Experience
1-3 years of experience in quantitative analysis experience.
Bachelor's degree in Computer Science, Statistics, Math or other technical field required. Graduate degrees preferred.
Job Classification
This is a full time exempt position
SMS Assist is an Equal Opportunity Employer (EOE) that welcomes and encourages all applicants to apply regardless of age, race, color, religion, sex, sexual orientation, gender identify and/or expression, national origin, disability, veteran status, marital or parental status, ancestry, citizenship status, pregnancy or other reasons prohibited by law.
",https://www.builtinchicago.org/job/data/data-analyst/71292
JOB226042678264,Scientific Data Engineer,Scientific Data Engineer,,"Responsibility for the handling, processing and integration of data into the ChEMBL database.,Facilitating the deposition of datasets directly into ChEMBL by working closely with external collaborators.,Applying text- & data-mining techniques for the development of effective large-scale curation strategies.,Developing methods for the application and maintenance of ontologies in ChEMBL.,Working with other teams to facilitate the integration of data between different EBI resources.,A BSc (or equivalent) in a life-science subject (e.g. biological or biomedical sciences).,3+ years of postgraduate experience in scientific data integration, database development or text- & data-mining, with a demonstrable track record of achievement.,Proficient in at least one programming/scripting language (Python knowledge is highly desirable).,Good knowledge of relational databases, data modelling, SQL and PL/SQL, and RESTful web-services.,Good understanding of a range of bioinformatics tools and resources (e.g., BLAST, Pfam, PDB, UniProt).,Experience in integrating diverse data sets.,Knowledge of good practice in software engineering and good code documentation.,Good knowledge of UNIX systems.,Team player, ability to work both as part of a team and independently.,Self-motivated with a driver for quality.,Good communication (verbal and presentational).,Higher degree (e.g., MSc/PhD) or equivalent in life-sciences, computer science, or related discipline.,Formal training in programming, data/entity-relationship modeling, text- & data-mining.,Familiarity with Python, Java and Perl.,Knowledge of drug discovery and development.,Experience working with chemogenomic and pharmaceutical data.,Knowledge of cheminformatics methods (e.g., chemical structure representations, substructure & similarity searching).,Apply now"," Scientific Data Engineer
Location: EMBL-EBI, Hinxton near Cambridge, UK
Staff Category: Staff Member
Contract Duration: 3 years
Grading: 5 or 6 (monthly salary starting at £2,632 or £2,944.48 after tax).
Closing Date: 23 September 2018
Reference Number: EBI01278
The ChEMBL Team at the European Bioinformatics Institute (EMBL-EBI) is looking for a talented Scientist with a passion for data integration to manage the incorporation of drug discovery data into the ChEMBL database. ChEMBL is a world-leading chemogenomics resource, providing open bioactivity data and associated tools to the scientific community. We have a considerable number of users from academia and industry. You will work in a team-oriented environment, collaborating closely with fellow scientists and technical experts, chemo- and bio-informaticians and software engineers across EMBL-EBI and with our many external partners from the UK and internationally. You will contribute to the development of robust, production data pipelines as well as prototyping novel scientific solutions. You will have excellent communication skills, able to interact with technical experts as well as scientists seeking solutions to their ""real world"" problems.
Your role
Reporting to the ChEMBL team leader, the job responsibilities will include:
Responsibility for the handling, processing and integration of data into the ChEMBL database.
Facilitating the deposition of datasets directly into ChEMBL by working closely with external collaborators.
Applying text- & data-mining techniques for the development of effective large-scale curation strategies.
Developing methods for the application and maintenance of ontologies in ChEMBL.
Working with other teams to facilitate the integration of data between different EBI resources.
You have
A BSc (or equivalent) in a life-science subject (e.g. biological or biomedical sciences).
3+ years of postgraduate experience in scientific data integration, database development or text- & data-mining, with a demonstrable track record of achievement.
Proficient in at least one programming/scripting language (Python knowledge is highly desirable).
Good knowledge of relational databases, data modelling, SQL and PL/SQL, and RESTful web-services.
Good understanding of a range of bioinformatics tools and resources (e.g., BLAST, Pfam, PDB, UniProt).
Experience in integrating diverse data sets.
Knowledge of good practice in software engineering and good code documentation.
Good knowledge of UNIX systems.
Team player, ability to work both as part of a team and independently.
Self-motivated with a driver for quality.
Good communication (verbal and presentational).
You might also have
Higher degree (e.g., MSc/PhD) or equivalent in life-sciences, computer science, or related discipline.
Formal training in programming, data/entity-relationship modeling, text- & data-mining.
Familiarity with Python, Java and Perl.
Knowledge of drug discovery and development.
Experience working with chemogenomic and pharmaceutical data.
Knowledge of cheminformatics methods (e.g., chemical structure representations, substructure & similarity searching).
Why join us
At EMBL-EBI, we help scientists realise the potential of ‘big data’ in biology by enabling them to exploit complex information to make discoveries that benefit mankind. Working for EMBL-EBI gives you an opportunity to apply your skills and energy for the greater good. As part of the European Molecular Biology Laboratory (EMBL), we are a non-profit, intergovernmental organisation funded by 22 member states and two associate member states. We are located on the Wellcome Genome Campus near Cambridge in the UK, and our 600 staff are engineers, technicians, scientists and other professionals from all over the world.
EMBL is an inclusive, equal opportunity employer offering attractive conditions and benefits appropriate to an international research organisation. The remuneration package comprises a competitive salary, a comprehensive pension scheme and health insurance, educational and other family related benefits where applicable, as well as financial support for relocation and installation. For more information about pay and benefits click here
We have an informal culture, international working environment and excellent professional development opportunities but one of the really amazing things about us is the concentration of technical and scientific expertise – something you probably won’t find anywhere else.
If you’ve ever visited the campus you’ll have experienced first-hand our friendly, collegial and supportive atmosphere, set in the beautiful Cambridgeshire countryside. Our staff also enjoy excellent sports facilities including a gym, a free shuttle bus, an on-site nursery, cafés and restaurant and a library.
What else do I need to know
To apply please submit a covering letter and CV, with two referees, through our online system.
Applications are welcome from all nationalities - visa information will be discussed in more depth with applicants selected for interview.
EMBL-EBI is committed to achieving gender balance and strongly encourages applications from women, who are currently under-represented at all levels. Appointment will be based on merit alone.
The initial contract is for a period of three years with the possibility of a fixed-term extension.
Applications will close at 23:00 BST on the date listed above. More Software Development and Engineering jobs
Apply now
",https://jobs.newscientist.com/en-au/job/1401652831/scientific-data-engineer/
JOB227741801553,Data Scientist / Data Engineer,Data Scientist / Data Engineer,,,"
Coverent is seeking a Data Engineer / Data Scientist to lead quantitative research and program evaluation activities for a client in the US Intelligence Community. In this role, you will apply advanced analytic capabilities to answer complex questions related to client mission. You’ll have the opportunity to demonstrate your intellectual agility by leading methodology selection, data collection and/or generation, and rigorous analysis. You’ll be asked to help clients leverage data to enable smart decision making and action.
POSITION RESPONSIBILITIES
Develop tailored analytical solutions and products for social media analysis
Code and automate existing bulk social media data analysis
Collaborate with clients to understand their technical requirements, expectations, timelines, constraints, and resources
Conduct hypothesis testing
Conduct statistical analyses; may include definition of sampling plans as well as identification of data capture strategies and modeling
Prepare visual presentations of data and analysis
Prepare reports and presentations for senior leadership based on research plans, activities, findings and recommendations
Brief senior level customers on research plans, activities, findings and recommendations
REQUIRED QUALIFICATIONS
U.S. Citizenship
Active TS/SCI clearance with Full-Scope Polygraph
Must have a Bachelor’s degree in a field that uses advanced analytics and a minimum of 4 years' related work experience
Experience and/or familiarity with social media, analytic, statistical software and data visualization tools such as Python and/or R including relevant packages.
Demonstrated experience managing bulk data from databases and other systems using SQL queries or scripts
Excellent oral and written communication skills, including visual representation of data using charts and graphs
Advanced proficiency with MS Excel and PowerPoint
Ability to perform in an individual contributor role while also excelling in a team environment
DESIRED QUALIFICATIONS
Experience with Extract Transform Load (ETL) tools
Experience developing dashboards for real time online metrics
Experience with Natural Language Processing and foreign language text manipulation
Experience with machine learning algorithms including feature selection and implementation
Experience performing the setup and configuration of Integrated Development Environments (IDEs) and using code versioning software
Ability to gather and draft software requirements from users
Experience with web scraping and DOM manipulation
Experience with Elasticsearch or Solr
Company Description
Why Coverent?
Coverent is a specialized consulting services firm focused on developing innovative solutions to the most challenging problems facing our nation. We are growing quickly, but focused on maintaining our commitment to fantastic results and a fair, flexible, and fun culture:
Are you interested in working for a boutique firm who sees its employees as more than just a number?
Are you intrigued by the notion of joining a small team of talented, passionate consultants with a clear vision to help our clients achieve their missions better, smarter, faster?
Does a company culture that emphasizes outcomes, fairness, and flexibility sound appealing?
Would you like to be rewarded for your contributions, via programs like annual bonuses and company profit sharing?
Would you appreciate having a choice of options from top-notch benefit providers for medical and retirement plans?
Are you interested in a learning culture that is forward-leaning regarding training, education, and professional development?
If you answer YES to these questions, Coverent could be the employer of choice for you.
",https://www.clearancejobs.com/jobs/2384368/data-scientist-data-engineer
JOB228146715242,Data Engineer,Data Engineer,,,"Our Client are currently recruiting Data Engineers based in Aberdeen
Cable Pulling - trunking - COAX Minimum Requirement - CSCS As long as they have good Data Engineer experience.
Qualifications required to carry out the role: Essential: Solid Data Engineering background CAT5/ 6 Installation Fluke Tester operation
Skills
Not Specified
We currently have an opportunity for a Civil Engineer to join our clients growing team based in Leeds office. The office undertakes a wide variety of major and challenging infrastructure projects for the private and public sector. They seek to provide integrated solutions incorporating state of the ...
Leeds West Yorkshire GB Permanent £0.00 per annum
Posted 1 hour agoJob
My clients Civil Engineering team have an exciting opportunity for an ambitious and experienced Civil Engineer/Senior Civil Engineer to join the team in the Leeds office and contribute to project delivery for our major clients. The team work on a variety of development and infrastructure projects ...
Leeds West Yorkshire GB Permanent £0.00 per annum
Posted 1 hour agoJob
HR Coordinator Fixed Term Contract - 3 months Salary: £20,000.00 - £25,000.00 per annum Location: Central London The role My client is a technical services and solutions provider with key capabilities in specialist technical and critical engineering services. Due to the natural growth ...
London London GB Contract £20000.00 - £25000.00 per annum + £20,000.00 - £23,000.00 per annum
Posted 2 hours agoJob
HR Manager Permanent Location: Central London Salary: £45,000.00 per annum plus benefits Duties and responsibilities My client is a technical services and solutions provider with key capabilities in specialist technical and critical engineering services. Due the natural growth of the ...
London London GB Permanent £40000.00 - £45000.00 per annum + £40,000.00 - £45,000.00 per annum
Posted 3 hours agoJob
Location : Prestwick, South Ayrshire Hourly rate : £14.65 Ltd Contract : full-time 6 months+ Start date : ASAP End client : One of the world's largest independent producers of commercial aerostructures. Their core products include fuselages, pylons, nacelles and wing components. They al ...Posted 4 hours agoJob
",https://www.oilvoice.com/Job/4091/Data-Engineer
JOB230543865675,Data Engineer,Data Engineer,,"An environment where it matters to make the right design decisions the first time. ""Move fast and break things"" doesn't really work for the type of system that we build. We take less technical debt than other companies.,At Brex, engineers make the product decisions with input from business people, instead of business / product people making decisions with input from engineers,We'd rather have one strong, well-compensated engineer instead of having 5 mediocre engineers. Our customers are fine with fewer features, but are not ok with broken features.,Small, accountable and autonomous teams of amazing people, eager to learn, teach and constantly improve our way of working.,Exceptional technical background.,Strong sense of ownership and accountability for what you're building. What you build today will be the foundation for dozens of other systems in the future.,Frankness on discussing technical matters. If you disagree with how things are being done, we encourage you to speak up. You can attack an idea without attacking the person behind it.","Brex is revolutionizing corporate payments and expense management. We are rebuilding payment systems from scratch with an eye focused on critical accounting principles and the needs of finance teams.
Our founders--Henrique Dubugras and Pedro Franceschi--are engineers and proven entrepreneurs who founded pagar.me (a Brazilian payments company) and scaled it to USD $2B in volume in less than three years. They moved to San Francisco to start Brex with backing from Ribbit Capital and Y-Combinator; and personal investments from Peter Thiel and Max Levchin (Co-founders of PayPal), Carl Pascarella (former CEO of Visa), Yuri Milner (Facebook investor), and the founders of 3G Capital.
Our team is committed to creating a driven, fun, and diverse company with brilliant people from wide-ranging backgrounds that are all focused on building the best products possible. We are based in a beautiful office in San Francisco and have raised substantial venture funding.
What we bring
An environment where it matters to make the right design decisions the first time. ""Move fast and break things"" doesn't really work for the type of system that we build. We take less technical debt than other companies.
At Brex, engineers make the product decisions with input from business people, instead of business / product people making decisions with input from engineers
We'd rather have one strong, well-compensated engineer instead of having 5 mediocre engineers. Our customers are fine with fewer features, but are not ok with broken features.
Small, accountable and autonomous teams of amazing people, eager to learn, teach and constantly improve our way of working.
We believe that great individual contributors generate as much (or more!) value as engineering managers, and we compensate them accordingly.
What you bring
Exceptional technical background.
Strong sense of ownership and accountability for what you're building. What you build today will be the foundation for dozens of other systems in the future.
Frankness on discussing technical matters. If you disagree with how things are being done, we encourage you to speak up. You can attack an idea without attacking the person behind it.
Passion for code. We love people that take pride in and love programming, especially if they've done so since a very young age.
Does Brex sound like home? We'd love to meet you! Please share with us details of what you've worked on and what matters to you (personally and from a technical standpoint). Don't worry too much about your resumé. Be genuine, not official.
",https://jobs.lever.co/brex/9780f95c-8ada-4389-8f5f-3e2f11d39051?lever-origin=applied&lever-source%5B%5D=Linkedin+Paid&lever-source=LinkedInJobs
JOB230877400027,Scientific Data Engineer,Scientific Data Engineer,,"Responsibility for the handling, processing and integration of data into the ChEMBL database.,Facilitating the deposition of datasets directly into ChEMBL by working closely with external collaborators.,Applying text- & data-mining techniques for the development of effective large-scale curation strategies.,Developing methods for the application and maintenance of ontologies in ChEMBL.,Working with other teams to facilitate the integration of data between different EBI resources.,A BSc (or equivalent) in a life-science subject (e.g. biological or biomedical sciences).,3+ years of postgraduate experience in scientific data integration, database development or text- & data-mining, with a demonstrable track record of achievement.,Proficient in at least one programming/scripting language (Python knowledge is highly desirable).,Good knowledge of relational databases, data modelling, SQL and PL/SQL, and RESTful web-services.,Good understanding of a range of bioinformatics tools and resources (e.g., BLAST, Pfam, PDB, UniProt).,Experience in integrating diverse data sets.,Knowledge of good practice in software engineering and good code documentation.,Good knowledge of UNIX systems.,Team player, ability to work both as part of a team and independently.,Self-motivated with a driver for quality.,Good communication (verbal and presentational).,Higher degree (e.g., MSc/PhD) or equivalent in life-sciences, computer science, or related discipline.,Formal training in programming, data/entity-relationship modeling, text- & data-mining.,Familiarity with Python, Java and Perl.,Knowledge of drug discovery and development.,Experience working with chemogenomic and pharmaceutical data.,Knowledge of cheminformatics methods (e.g., chemical structure representations, substructure & similarity searching).,Apply now"," Scientific Data Engineer Location: EMBL-EBI, Hinxton near Cambridge, UK Staff Category: Staff Member Contract Duration: 3 years Grading: 5 or 6 Closing Date: 23 September 2018 Reference Number: EBI01278 The ChEMBL Team at the European Bioinformatics Institute (EMBL-EBI) is looking for a talented Scientist with a passion for data integration to manage the incorporation of drug discovery data into the ChEMBL database. ChEMBL is a world-leading chemogenomics resource, providing open bioactivity data and associated tools to the scientific community. We have a considerable number of users from academia and industry. You will work in a team-oriented environment, collaborating closely with fellow scientists and technical experts, chemo- and bio-informaticians and software engineers across EMBL-EBI and with our many external partners from the UK and internationally. You will contribute to the development of robust, production data pipelines as well as prototyping novel scientific solutions. You will have excellent communication skills, able to interact with technical experts as well as scientists seeking solutions to their ""real world"" problems.Your roleReporting to the ChEMBL team leader, the job responsibilities will include:
Responsibility for the handling, processing and integration of data into the ChEMBL database.
Facilitating the deposition of datasets directly into ChEMBL by working closely with external collaborators.
Applying text- & data-mining techniques for the development of effective large-scale curation strategies.
Developing methods for the application and maintenance of ontologies in ChEMBL.
Working with other teams to facilitate the integration of data between different EBI resources.
You have
A BSc (or equivalent) in a life-science subject (e.g. biological or biomedical sciences).
3+ years of postgraduate experience in scientific data integration, database development or text- & data-mining, with a demonstrable track record of achievement.
Proficient in at least one programming/scripting language (Python knowledge is highly desirable).
Good knowledge of relational databases, data modelling, SQL and PL/SQL, and RESTful web-services.
Good understanding of a range of bioinformatics tools and resources (e.g., BLAST, Pfam, PDB, UniProt).
Experience in integrating diverse data sets.
Knowledge of good practice in software engineering and good code documentation.
Good knowledge of UNIX systems.
Team player, ability to work both as part of a team and independently.
Self-motivated with a driver for quality.
Good communication (verbal and presentational).
You might also have
Higher degree (e.g., MSc/PhD) or equivalent in life-sciences, computer science, or related discipline.
Formal training in programming, data/entity-relationship modeling, text- & data-mining.
Familiarity with Python, Java and Perl.
Knowledge of drug discovery and development.
Experience working with chemogenomic and pharmaceutical data.
Knowledge of cheminformatics methods (e.g., chemical structure representations, substructure & similarity searching).
Why join usAt EMBL-EBI, we help scientists realise the potential of ‘big data’ in biology by enabling them to exploit complex information to make discoveries that benefit mankind. Working for EMBL-EBI gives you an opportunity to apply your skills and energy for the greater good. As part of the European Molecular Biology Laboratory (EMBL), we are a non-profit, intergovernmental organisation funded by 22 member states and two associate member states. We are located on the Wellcome Genome Campus near Cambridge in the UK, and our 600 staff are engineers, technicians, scientists and other professionals from all over the world.
EMBL is an inclusive, equal opportunity employer offering attractive conditions and benefits appropriate to an international research organisation. The remuneration package comprises a competitive salary, a comprehensive pension scheme and health insurance, educational and other family related benefits where applicable, as well as financial support for relocation and installation. For more information about pay and benefits click here
We have an informal culture, international working environment and excellent professional development opportunities but one of the really amazing things about us is the concentration of technical and scientific expertise – something you probably won’t find anywhere else.
If you’ve ever visited the campus you’ll have experienced first-hand our friendly, collegial and supportive atmosphere, set in the beautiful Cambridgeshire countryside. Our staff also enjoy excellent sports facilities including a gym, a free shuttle bus, an on-site nursery, cafés and restaurant and a library. What else do I need to knowTo apply please submit a covering letter and CV, with two referees, through our online system.
Applications are welcome from all nationalities - visa information will be discussed in more depth with applicants selected for interview.
EMBL-EBI is committed to achieving gender balance and strongly encourages applications from women, who are currently under-represented at all levels. Appointment will be based on merit alone.
The initial contract is for a period of three years with the possibility of a fixed-term extension.
Applications will close at 23:00 BST on the date listed above. More Software Development and Engineering jobs
Apply now
",https://jobs.newscientist.com/job/1401652165/scientific-data-engineer/
JOB232583971618,Data Engineer,Data Engineer,"Bonus points if you bring real world experience with AWS (EMR, E2, Kinesis, S3)","Work with data, analytics pros, and product managers to strive for greater functionality in our data systems.,Analyze and translate functional specifications and change requests into technical designs.,Design, develop, and implement streaming and near-real time data pipelines that feed systems that are the operational backbone of our business.,Execute unit tests and validating expected results; iterating until test conditions have passed,Ensure accuracy & integrity of data and applications through analysis, coding, writing clear documentation and problem resolution.,Identify and remediate issues impacting data pipelines.,Take care of the tools, techniques and components being used in the industry through research and apply this knowledge to the system(s) being developed.,Mentor and develop more junior engineers,Bachelor’s degree,You have hands-on experience with the full range of designing, developing, testing, and implementing low-latency big data pipelines,You have 5 years’ experience using Object Oriented Languages, such as Scala, Python, Java.,You have 3 years’ experience and working knowledge of Lambda and Kappa architecture in a cloud environment (AWS, Google, Azure),You have a deep understanding of SDLC, Agile methodologies, metadata, data modeling, and designing databases,Working knowledge on Linux/Unix Operating systems,Strong scripting skills - Python (a huge plus), Bash , Shell etc.,You're super comfortable with Gitflow","
Can taking care of petabytes of data really help local businesses grow?
Groupon’s mission is to become the daily habit in local commerce and fulfill our purpose of building strong communities through thriving small businesses by connecting people to a vibrant, global marketplace for local services, experiences and goods. In the process, we’re positively impacting the lives of millions of customers and merchants globally. Even with thousands of employees spread across multiple continents, we still maintain a culture that inspires innovation, rewards risk-taking and celebrates success. If you want to take more ownership of your career, then you're ready to be part of Groupon.
As a global company that works with both local businesses and consumers, Groupon has a wealth of data, which is tucked away in our Enterprise Data Warehouse. Learn more about the technical teams that call Chicago Engineeringhome.
As a Data Engineer, you will handle the full development life-cycle of Groupon data applications. By collaborating with data analysts, data scientists, product managers, and other data engineering teams, our Data Engineers avail significant data products for the business and enable consistently informed management decisions. You will build both batch and streaming data ingestion and metrics calculation processes, as well as design and develop storage and retrieval mechanisms for efficient reporting.
We're a ""best of both worlds"" kind of company. We're big enough to have resources and scale, but small enough that a single person has a surprising amount of autonomy and can make a meaningful impact. We're curious, fun, a little intense, and kind of obsessed with helping local businesses thrive. Does that sound like a compelling place to work?
You’ll spend time on the following:
Work with data, analytics pros, and product managers to strive for greater functionality in our data systems.
Analyze and translate functional specifications and change requests into technical designs.
Design, develop, and implement streaming and near-real time data pipelines that feed systems that are the operational backbone of our business.
Execute unit tests and validating expected results; iterating until test conditions have passed
Ensure accuracy & integrity of data and applications through analysis, coding, writing clear documentation and problem resolution.
Identify and remediate issues impacting data pipelines.
Take care of the tools, techniques and components being used in the industry through research and apply this knowledge to the system(s) being developed.
Mentor and develop more junior engineers
We’re excited about you if you have:
Bachelor’s degree
You have hands-on experience with the full range of designing, developing, testing, and implementing low-latency big data pipelines
You have 5 years’ experience using Object Oriented Languages, such as Scala, Python, Java.
You have 3 years’ experience and working knowledge of Lambda and Kappa architecture in a cloud environment (AWS, Google, Azure)
You have a deep understanding of SDLC, Agile methodologies, metadata, data modeling, and designing databases
Working knowledge on Linux/Unix Operating systems
Strong scripting skills - Python (a huge plus), Bash , Shell etc.
You're super comfortable with Gitflow
Bonus points if you bring real world experience with AWS (EMR, E2, Kinesis, S3)
Groupon provides a global marketplace where people can buy just about anything, anywhere, anytime. We’re enabling real-time commerce across an expanding range of categories including local businesses, travel destinations, consumer products, and live or lively events. At the same time, we are providing advertising options and tools that merchants can use to grow and manage their businesses. Culturally, we believe that great people make great companies and that starting with the customer and working backward moves us forward. Community matters to us on an internal, local and global scale—it’s fundamental to our company’s growth and to the well-being of the world at large. We also value self-awareness, candor, lunch and WiFi. If we match with you, please apply to join us.
",https://www.builtinchicago.org/job/data/data-engineer/67540
JOB232658730246,"CONSULTANT, IT (Academic Data Engineer / Instructor)","CONSULTANT, IT (Academic Data Engineer / Instructor)","Distributed computing principles,Legacy and modern database architectures,Hadoop-based technologies (e.g. MapReduce, Hive and Pig),SQL-based technologies (e.g. PostgreSQL and MySQL),NoSQL technologies (e.g. Cassandra and MongoDB),Stream-processing systems (e.g. Storm or Spark-Streaming),ETL tools and APIs,Optimizing data storage and retrieval for specific use cases,Testing and validating the accuracy of data transformations,Cloud computing architectures, preferably with specific expertise in Microsoft Azure and AWS,Creative problem-solving that is sensitive to available time and resource constraints,Effective listening and communication","Working with academic faculty to monitor and optimize current forms of data collection, and develop and integrate new forms of data collection,Working with academic faculty to optimize the transformation of collected data into formats appropriate for analysis,Working with academic faculty and IT developers to apply state-of-the-art approaches in cloud service, containerization and other techniques for scaling the remote staging, storage, computation and analysis of data sets, including at scale by hundreds or thousands of students in online courses,Providing expertise in data set hygiene to the institution, facilitating the cleanup and integration of potentially multiple incomplete, irregular, and partial data sources into interesting and useful data sources for analysis,Working with various offices to ensure that information is used complies with the regulatory and security policies in place,Teaching a Database Systems core course for the MIDS program and possibly other programs,Helping develop advanced courses in Data Engineering,Developing and running workshops for the campus community in different aspects of data management and wrangling,Advising student capstone projects in the MIDS and other programs on data engineering needs","
CONSULTANT, IT (Academic Data Engineer / Instructor)
Job description
CONSULTANT, IT (Academic Data Engineer / Instructor)
OIT Service-Based Metrics & Reporting
Duke University seeks an outstanding Academic Data Engineer and Instructor who will (a) facilitate new research projects through the creative integration of multiple data sources, (b) inspire students with the power of data engineering and (c) function as a central member of an emerging Data Analytics Practice at Duke that stimulates new uses of data analytics in instruction and research. As an integral part of Duke's Data Science community, the staff member will be expected to work closely with faculty, students, and other departments at Duke. The staff member should be passionate about engineering ways to use new types of data to solve world problems, detail-oriented, and self-motivated to learn new skills and subjects as technology changes.
The staff member will have a central role in working with faculty to identify and leverage commonalities in support of new data-intensive degree programs (Duke's Masters in Interdisciplinary Data Science (MIDS)) and other academic programs, both in the physical classroom and as online courses. Together with personnel and support from Duke's Office of Information Technology , the staff member will be part of a growing team focused on data analytics, and will bring to that team an emphasis on academic data analytics.
The staff member's responsibilities would include:
Working with academic faculty to monitor and optimize current forms of data collection, and develop and integrate new forms of data collection
Working with academic faculty to optimize the transformation of collected data into formats appropriate for analysis
Working with academic faculty and IT developers to apply state-of-the-art approaches in cloud service, containerization and other techniques for scaling the remote staging, storage, computation and analysis of data sets, including at scale by hundreds or thousands of students in online courses
Providing expertise in data set hygiene to the institution, facilitating the cleanup and integration of potentially multiple incomplete, irregular, and partial data sources into interesting and useful data sources for analysis
Working with various offices to ensure that information is used complies with the regulatory and security policies in place
Teaching a Database Systems core course for the MIDS program and possibly other programs
Helping develop advanced courses in Data Engineering
Developing and running workshops for the campus community in different aspects of data management and wrangling
Advising student capstone projects in the MIDS and other programs on data engineering needs
Helping evaluate capstone projects with program faculty
To meet these responsibilities, the candidate should be an innovative problem solver, team-focused, highly organized, have the ability to handle-multiple and simultaneous tasks, and demonstrate an ability to stay calm and focused in emergencies. The candidate should also enjoy working in collaborative relationships, and have an approachable and relatable demeanor that inspires trust and confidence in partners.
Requirements:
Master's degree in mathematics, statistics, computer science or related field or equivalent experience. Doctorate preferred.
At least 5 years of working experience as a database engineering support personnel or a database engineering administrator within a fast-paced, complex setting.
The applicant must have expertise in the following areas:
Distributed computing principles
Legacy and modern database architectures
Hadoop-based technologies (e.g. MapReduce, Hive and Pig)
SQL-based technologies (e.g. PostgreSQL and MySQL)
NoSQL technologies (e.g. Cassandra and MongoDB)
Stream-processing systems (e.g. Storm or Spark-Streaming)
ETL tools and APIs
Optimizing data storage and retrieval for specific use cases
Testing and validating the accuracy of data transformations
Cloud computing architectures, preferably with specific expertise in Microsoft Azure and AWS
Programming in multiple programming languages, including Python and Java
Due to the applicant's role interacting with students, faculty, and staff on projects, the applicant must also be able to demonstrate skills in:
Creative problem-solving that is sensitive to available time and resource constraints
Effective listening and communication
Project managing
Duke University and Durham are located in the Research Triangle, a region that encompasses one of the nation's premier concentrations of academic, corporate, and public research. The Triangle region is rated among the most desirable areas in North America to live and work and has been identified by Money magazine as one of the ""Best Places to Live"" in the U.S.
Trustworthiness, respect, diversity, learning and teamwork are the hallmarks of Duke's guiding principles. Our accomplishments are dependent on the dedication and expertise of all who work to support Duke's mission.
Requisition Number
401380222
Location
Durham
Duke Entity
CENTRAL ADMIN MANAGEMENT CTR
Job Code
2427 CONSULTANT, IT
Job Family Level
E
Exempt/Non-Exempt
Exempt
Full Time / Part Time
FULL TIME
Regular / Temporary
Regular
Shift
First/Day
Minimum Qualifications
Duke University is an Affirmative Action/Equal Opportunity Employercommitted to providing employment opportunity without regard to anindividual's age, color, disability, gender, gender expression, genderidentity, genetic information, national origin, race, religion, sex,sexual orientation, or veteran status.
Duke aspires to create a community built on collaboration, innovation,creativity, and belonging. Our collective success depends on the robustexchange of ideas—an exchange that is best when the rich diversity ofour perspectives, backgrounds, and experiences flourishes. To achievethis exchange, it is essential that all members of the community feelsecure and welcome, that the contributions of all individuals arerespected, and that all voices are heard. All members of our communityhave a responsibility to uphold these values.
Essential Physical Job Functions:Certain jobs at Duke University and Duke University Health System mayinclude essential job functions that require specific physical and/ormental abilities. Additional information and provision for requests forreasonable accommodation will be provided by each hiring department.
Education
Refer to Job Description
Auto req ID
97455BR
Duke University is an Affirmative Action/Equal Opportunity Employer committed to providing employment opportunity without regard to an individual's age, color, disability, genetic information, gender, gender expression, gender identity, national origin, race, religion, sexual orientation, or veteran status.
Essential Physical Job Functions: Certain jobs at Duke University and Duke University Health System may include essential job functions that require specific physical and/or mental abilities. Additional information and provision for requests for reasonable accommodation will be provided by each hiring department.
PI107055835
Share this job with your network:
AAUP COMPENSATION SURVEY DATA
View more
",https://careers.insidehighered.com/job/1704625/consultant-it-academic-data-engineer-instructor-/
JOB233201763095,Senior Data Engineer,Senior Data Engineer,Demonstrate strong understanding of development processes and agile methodologies,"Own the entire end-to-end execution from requirements gathering from key stakeholders to building scalable, efficient, and reliable data marts which provide our business partners with clarity into the complexities of our platform,Create maintainable, scalable data processing pipelines in PostgresSQL, Python, and other data processing language in the data platform running in AWS,Define, develop, and operate functional data marts/cubes with common open source and SaaS based data processing and management tools like embulk, airflow, rundeck, Spark, Informatica, etc.,Partner with cross-functional engineering peers as you take ownership of the entire analytics lifecycle including instrumentation, logging, data modeling, data warehousing, data delivery and dashboarding,Provide guidance on development and implementation of data quality rules and validation processes, leading initiatives to improve data quality and issue resolution,Partner with Sales and Enterprise teams in defining and executing their analytics and reporting roadmap,Function as the subject area expert in Sales and Enterprise data domain maintaining business specific metadata and data integration contracts with 3rd party vendors as well as internal data owners,8+ years combined experience in database application development, data management and governance in medium and large size companies,Experience with marketplace businesses, especially as it pertains to working with large datasets inherent to two-sided marketplaces,A proven record of taking large data projects from ideation to implementation,Expert in writing advanced SQL and performance tuning others’ SQL,Expert in designing, implementing, and operating efficient, scalable, and reliable data transformation pipelines,Strong analytical skills; ability to collect, organize, and analyze information,Solid experience in database modeling, architecture, design, and implementation,Familiar with sales process, sales commission attribution methodologies, and Salesforce.com application and data architecture,Fluent in data visualization techniques with tools such as Looker, Domo, or similar,Able to influence, lead, and communicate effectively across engineering teams, business units and other partners to negotiate priority, scope, and design solution,Excellent oral, written, and presentation skills, including the ability to work in person, virtually, and in a globally-staffed environment,Fluent and effective in working with a global distributed team","
Upwork is the world's largest freelancing website. Each year $1.5 billion of work happens through Upwork, allowing businesses to get more done and helping professionals break free of traditional time and place boundaries and work anytime, anywhere on projects they love. At Upwork, you'll help build on this momentum. Together, we'll create economic and social value on a global scale, providing a trusted online workplace for businesses to connect with extraordinary talent and work without limits.
Our Data Management team is tasked with building and supporting the business analytics infrastructure at Upwork that analysts and partners use on a daily basis to make critical business decisions. We are looking for a passionate engineer who has a love of data and analytics to empower our Sales, Marketing, and Enterprise teams in leveraging data to drive and measure impact. In this role, you will own the end-to-end analytics solution partnering with data infrastructure product and engineering to develop and operate the complete solution. You will have an instrumental role in ensuring that our analysts, business partners, and executive team have consistent and reliable data and insights at their fingertips.
Your Responsibilities:
Own the entire end-to-end execution from requirements gathering from key stakeholders to building scalable, efficient, and reliable data marts which provide our business partners with clarity into the complexities of our platform
Create maintainable, scalable data processing pipelines in PostgresSQL, Python, and other data processing language in the data platform running in AWS
Define, develop, and operate functional data marts/cubes with common open source and SaaS based data processing and management tools like embulk, airflow, rundeck, Spark, Informatica, etc.
Partner with cross-functional engineering peers as you take ownership of the entire analytics lifecycle including instrumentation, logging, data modeling, data warehousing, data delivery and dashboarding
Provide guidance on development and implementation of data quality rules and validation processes, leading initiatives to improve data quality and issue resolution
Partner with Sales and Enterprise teams in defining and executing their analytics and reporting roadmap
Function as the subject area expert in Sales and Enterprise data domain maintaining business specific metadata and data integration contracts with 3rd party vendors as well as internal data owners
What it takes to catch our eye:
8+ years combined experience in database application development, data management and governance in medium and large size companies
Experience with marketplace businesses, especially as it pertains to working with large datasets inherent to two-sided marketplaces
A proven record of taking large data projects from ideation to implementation
Expert in writing advanced SQL and performance tuning others’ SQL
Expert in designing, implementing, and operating efficient, scalable, and reliable data transformation pipelines
Strong analytical skills; ability to collect, organize, and analyze information
Solid experience in database modeling, architecture, design, and implementation
Familiar with sales process, sales commission attribution methodologies, and Salesforce.com application and data architecture
Fluent in data visualization techniques with tools such as Looker, Domo, or similar
Able to influence, lead, and communicate effectively across engineering teams, business units and other partners to negotiate priority, scope, and design solution
Excellent oral, written, and presentation skills, including the ability to work in person, virtually, and in a globally-staffed environment
Fluent and effective in working with a global distributed team
Demonstrate strong understanding of development processes and agile methodologies
Come change how the world works.
At Upwork you’ll help shape the future of work. From our offices in San Francisco, Mountain View and Chicago, together we’re creating exciting new opportunities for a world of professionals. You’ll be part of a vibrant culture built on shared values: Inspire a boundless future of work, Put our community first, Have a bias towards action, and Build amazing teams. Along the way you’ll have fun and enjoy the perks of a people-first company: Work from Home Wednesday's, daily breakfast and lunch, regular in-office happy hours, top-notch benefits … and more. Check out Upwork’s spotlight on The Muse for a glimpse of our daily work/life balance.
Upwork is proudly committed to recruiting and retaining a diverse and inclusive workforce. As an Equal Opportunity Employer, we never discriminate based on race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical condition), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.
",https://www.builtinchicago.org/job/data/senior-data-engineer/67795
JOB235189410941,Data Engineer,Data Engineer,,,"
Data Engineer
Qualifications:
• Bachelors or Masters degree in Computer Science (or equivalent)
• 5+ years of experience with large scale data distributed database systems
• Experience (or strong inclination to learn) in Hadoop Ecosystem (Hive/Pig/Impala, HBase, Oozie, Sqoop, Flume, Zookeeper, Cassandra, Spark etc.)
• 5+ yrs working with one of the following program languages: Java, Scala, Python
• Strong understanding of SQL and NoSQL databases and development paradigms
• Ability to develop quick prototypes on structured and unstructured data
• Hands on experience of JSON, BI concepts and processes (e.g. ETL, data aggregation and analysis)
• Good automation skills via scripting
• Flexible, self-motivated individual with a desire to work in a dynamic, fast-paced startup environment
Desired:
• Hadoop Administration and Monitoring experience a big plus
• Experience with ASW, Azure, Heroku or other cloud based provider
• Experience using version control systems such as Git and Mercurial
Company Description
Join our team of leading data scientists, software architects, and software developers who are building the next generation of SYNTASA™ real-time marketing analytics platform. We leverage proven streaming, machine learning, visualization, and big data technologies to process billions of records in real-time resulting in actionable intelligence that improves acquisition, conversion, and retention. This provides a unique opportunity to be a part of a growing team in a fast-paced and evolving environment that delivers business impacts from data driven recommendations.
",https://www.clearancejobs.com/jobs/2266936/data-engineer
JOB237118961508,Data Engineer,Data Engineer,"You have an undergraduate and / or graduate degree in computer science or a similar technical field, with a sound understanding of statistics,You have 1-2 years of industry experience as a data engineer,You have hands-on experience doing ETL and have written data pipelines in either Spark or MapReduce,You have a sound understanding of SQL or CQL,You have worked with data lakes such as S3 or HDFS,You have worked with various databases, such as Postgres, Cassandra, or Redshift before, and understand their pros and cons,You have a working knowledge of the following technologies, or are not afraid of picking them up on the fly: Mesos, Chronos/cron, Marathon, Jenkins,You are fluent in at least one scripting language (preferably NodeJS or python) and one compiled language (such as Scala, Java, or C),You have great communication skills and ability to work with others","Writing scheduled Spark pipelines that perform sophisticated query plans on the entirety of our datasets,Writing real-time pipelines that execute complex operations on incoming data,Synchronizing large amounts of data between unstructured and structured formats on various data sources,Creating testing and alerting for data pipelines,Building out our data infrastructure and managing dependencies between data pipelines","Hive is a full-stack deep learning platform helping to bring companies into the AI era. We take complex visual challenges and build custom machine learning models to solve them. For AI to work, companies need large volumes of high quality training data. We generate this data through Hive Data, our proprietary data labeling platform with over 500,000 globally distributed workers, generating millions of high quality pieces of data per day. We then use this training data to build machine learning models for verticals such as Media, Autonomous Driving, Security, and Retail. Today, we work with some of the largest companies in the world to redefine how they think about unstructured visual data. Together, we build solutions that incorporate AI into their businesses to completely transform industries.
We are fortunate that investors like Peter Thiel (Founders Fund), General Catalyst, 8VC, and others see Hive’s potential to be groundbreaking in AI business solutions. We have over 100 rock stars globally in our San Francisco and Delhi offices. Please reach out if you are interested in joining the AI revolution!
Data Engineer Role
In order to execute our vision, we need to grow our team of best-in-class data engineers. We are looking for developers who conduct impeccable data practices and implement high quality data infrastructures. We value hard workers who are comfortable improvising solutions to a stream of big data challenges while building a system that stands the test of time. Our ideal candidate has experience building data infrastructure from the ground up, contributes innovative ideas and ingenious implementations to the team, and is capable of planning out scalable, maintainable data pipelines.
As a data engineer, you would at first work primarily on our Hive Media product, taking real-time data from hundreds of television streams and turning them into a combination of real-time and scheduled outputs, especially our signature ads feed. Your work would improve the quality of our results while reducing computational cost and latency. Expect truly novel challenges.
Responsibilities
Writing scheduled Spark pipelines that perform sophisticated query plans on the entirety of our datasets
Writing real-time pipelines that execute complex operations on incoming data
Synchronizing large amounts of data between unstructured and structured formats on various data sources
Creating testing and alerting for data pipelines
Building out our data infrastructure and managing dependencies between data pipelines
Determining and implementing metrics that provide visibility into our data quality
Requirements
You have an undergraduate and / or graduate degree in computer science or a similar technical field, with a sound understanding of statistics
You have 1-2 years of industry experience as a data engineer
You have hands-on experience doing ETL and have written data pipelines in either Spark or MapReduce
You have a sound understanding of SQL or CQL
You have worked with data lakes such as S3 or HDFS
You have worked with various databases, such as Postgres, Cassandra, or Redshift before, and understand their pros and cons
You have a working knowledge of the following technologies, or are not afraid of picking them up on the fly: Mesos, Chronos/cron, Marathon, Jenkins
You are fluent in at least one scripting language (preferably NodeJS or python) and one compiled language (such as Scala, Java, or C)
You have great communication skills and ability to work with others
You are a strong team player, with a do-whatever-it-takes attitude
What We Offer You
We are a group of young and ambitious individuals passionate about creating a revolutionary machine learning company. At Hive, you will have a significant career development opportunity and a chance to contribute to one of the fastest growing AI startups in San Francisco. The work you will do here will have a noticeable and direct impact on the development of Hive.
Our benefits include competitive pay, equity, health / vision / dental insurance, catered lunch and dinner, and a corporate gym membership.
Thank you for your interest in Hive.
",https://jobs.lever.co/castleglobal/20beddea-8ceb-4dd3-8de4-ea554b77e7db
JOB243074210393,Data Engineer,Data Engineer,,,"Our Client are looking for Data Engineers based in Edinburgh
Duties include -
- Installation, termination and testing of Cat6/Cat6A copper cabling. Recent experience of Systimax cabling an advantage.
- Installation, cleaning and testing of fibre cabling. Splicing experience not essential as we install pre-term solutions. Engineers need to know how to handle fibre and test. IPAF qualification an advantage as installations at high level.
- Knowledge of Fluke test equipment, DTX/DSX testers.
- Experience of working in a data centre environment an advantage but not essential.
Would prefer engineers from the Edinburgh area or within an hours travel of the sites. Engineers need to have their own transport to get to these sites, i.e. a driving licence and car as the locations are not easy to get to and from with public transport during the times they are working.
The engineers are required to work nightshift, 4 nights Mon-Thurs 17:30-04:00. This is a 10.5 hour shift with 1 hour break so 4 x 9.5hrs, 38hrs. There is also optional overtime available most weekends, day shift Sat & Sun normally 08:00-16:30, 8hr shifts.
The engineers will need to pass a screening process which includes Disclosure Scotland. Engineers need to provide proof of identity, proof of address and pass a credit check.
The contract would be for 12-16 weeks initially but for the right candidates could be extended indefinitely.
Skills
Not Specified
",https://www.oilvoice.com/Job/2093/Data-Engineer
JOB245235424324,Sr. Data Engineer,Sr. Data Engineer,,,"
Sr. Data Engineer
Working at ICF
Working at ICF means applying a passion for meaningful work with intellectual rigor to help solve the leading issues of our day. Smart, compassionate, innovative, committed, ICF employees tackle unprecedented challenges to benefit people, businesses, and governments around the globe. We believe in collaboration, mutual respect, open communication, and opportunity for growth. If you’re seeking to make a difference in the world, visit www.icf.com/careers to find your next career. ICF—together for tomorrow.
Join ICF and support Department of Homeland Security (DHS) in protecting the integrity of our immigration system and combating criminal threats facing the nation by leveraging cutting edge data analytics tools and techniques. Apply your skills and expertise in increasing DHS's mission effectiveness and thereby make our nation safer and stronger. ICF is comprised of experienced professionals with the skills required to unlock the power of governed data discovery. Our staff provides deep technical and business support for data acquisition, data analysis/data science, and interactive data visualizations. Job Description: This is a cross functional position with significant responsibility and opportunity to shape the future direction of our team. The selected candidate will join our growing team of analytics experts. This position will be part of a small analytical team working on quantitative software products and services so experience working in a product development environment is desired. Successful candidates will be very analytical and detail-oriented to ensure a stable, repeatable, and accurate production data stream. Successful candidates will also enjoy a highly independent work environment where they can take a high level of ownership of their accomplishments. What you’ll be doing: - Create and maintain an optimal data pipeline architecture that include data ingestion, processing and storage with a focus on consistency, reliability, and accuracy - Design and code workflows and optimize production data pipelines to ensure data accuracy - Perform hands on data analysis to provide insights and uncover potential data issues - Map data feeds and combine them with third party content along with necessary data standardization - Develop and code operational processes to automatically report on data quality conditions and KPIs during processing - Be a part of fast moving development teams using agile methodologies - Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. - Work with data and analytics experts to strive for greater functionality in our data systems. Basic Qualifications: - 8+ years of ETL and database solution development supporting data integration, data warehousing, data lake and analytic pipelines - 2+ years of experience working within modern data architecture setup involving AWS or Azure and big data tools like Hadoop, Hive, Spark, Kafka etc - Strong Analytical and reasoning skills that result in clear, robust, and accurate solutions Strong data debugging skills - 5+ years of experience working within the full lifecycle SDLC as part of a software product and operations team environment - Strong experience developing SQL scripts, data processing processes, and performance tuning quantitative queries - Superior organizational and end to end delivery skills in an Agile environment - Ability to manage multiple tasks and shifting priorities with proactive communication in mind - Ability to maintain strong working relationships with development and business teams based on a proactive communication style Preferred Skills/Experience: - Experience with ETL tools like Talend, Pentaho etc - Experience with scripting Shell, Python, Java - Ability to work in a distributed team environment - Experience working on quantitative software products - An outstanding academic record with a focus on Science, Math, and Engineering or similar. Professional Skills: - Ability to obtain a Public Trust Clearance - Excellent listening, interpersonal, written, oral, and phone communication skills - Highly self-motivated and self-directed to solve complex technical problems - Ability to exercise independent judgment - Builds and maintains relationships with stakeholders to ensure buy-in and adoption of technology solutions - Self-motivated to continuously improve technical and professional skills - Ability to effectively prioritize and execute tasks ICF offers an excellent benefits package, an award winning talent development program, and fosters a highly skilled, energized and empowered workforce. ICF is an equal opportunity employer that values diversity at all levels. (EOE – Minorities/Females/Protected Veterans Status/Disability Status/Sexual Orientation/Gender Identity) Pay Transparency Statement: For more information, please click here: https://www.dol.gov/ofccp/pdf/pay-transp_formattedESQA508c.pdf About ICF ICF (NASDAQ:ICFI) is a global consulting and technology services provider with more than 5,000 professionals focused on making big things possible for our clients. We are business analysts, policy specialists, technologists, researchers, digital strategists, social scientists and creatives. Since 1969, government and commercial clients have worked with ICF to overcome their toughest challenges on issues that matter profoundly to their success. Come engage with us at icf.com.
Washington Client Office (WA88)
",https://www.clearancejobs.com/jobs/2927000/sr-data-engineer
JOB245706127719,Data Engineer,Data Engineer,,"Bachelors degree in IT, or similar experience,Data integration and data orchestration experience with Microsoft Azure,In-depth experience of designing and implementing data flows and pipelines,Experience as a Data Engineer is highly desirable,Experience of working in an Agile (ideally SCRUM) team,Comfortable being hands on with data, data modelling, query techniques,Background in the Data management Space,Experience of the FMCG/CPG industry,A good understanding of and adherence to data security standards","
This is an exciting time at Mars. We’re using digital, data and user insights to transform our business by finding answers to problems that we’ve often never asked ourselves before. From joining the dots to improve our Petcare data ecosystem, to streamlining the efficiency and automation of our supply chain and quality operations, we’re already seeing some brilliant results. In fact, we’ve built so much momentum that we’re now looking for industry leaders in Business Translation, Data Science and Data Engineering with different and complementary skills to influence how we operate and grow beyond anything we’ve achieved before. Join us, and discover a company set up to develop your capabilities and ambitions and a group of colleagues ready to support and inspire you. Working together, we’ll create a better world for our planet, our communities and our pets.
What you’ll do
Keeping the data flowing and readily available to solve problems as and when they need solving is core to what you’ll do. You might do that through Agile sprints or self-service analytics - it’s up to you. The day-to-day? You’ll be working within a sprint team building both new data pipelines and establishing or improving new platform capabilities. Without people in this crucial role treating data as an asset, we won’t be able to become the business we want to be.
Working in a small Agile team alongside Global Analytics, Data, Source Systems, Business Translation and Integration colleagues, you’ll partner with Product Owners to establish and maintain the data pipelines (ETL/Batch/Streaming) within and between different technology platforms, such as SAP/SAP BW and Microsoft Azure. You’ll also work closely with users from our segments and markets around the world as part of SCRUM teams. This exposure will also give you the exciting opportunity to influence and contribute true ‘firsts’. That’s new and emerging approaches that Mars, and maybe even the industry, hasn’t seen before.
Data integration, orchestration and automation – you’ll build data flow components of MVP analytic solutions. And you’ll do it across the entire Mars data landscape. That’s on premises, cloud, internal, external, formal & informal data. You’ll look to the future too. That means thinking about how data assets yet to come can be integrated into the end-to-end Mars data landscape.
In everything you do, you’ll be thinking about the bigger business picture and making sure your solutions address specific business challenges. On top of that, you’ll work closely with the Enterprise Architecture function and other Mars Digital Technologies capabilities to ensure alignment with the Enterprise Architecture initiatives and capacity and infrastructure planning.
What you’ll need
To do all this, you’ll need:
Bachelors degree in IT, or similar experience
Data integration and data orchestration experience with Microsoft Azure
In-depth experience of designing and implementing data flows and pipelines
Experience as a Data Engineer is highly desirable
Experience of working in an Agile (ideally SCRUM) team
Comfortable being hands on with data, data modelling, query techniques
Background in the Data management Space
Experience of the FMCG/CPG industry
A good understanding of and adherence to data security standards
So, if you’ve got the skills we need and you’re looking for the opportunity to really make a mark in a world-renowned and supportive business going through a period of fast and massive digital transformation, this could be the role you’ve been waiting for.
",https://jobs.theguardian.com/job/6776663/data-engineer/
JOB247874275026,data engineer jobs,data engineer jobs,,,"
",http://ca.indeed.com/jobs?q=data%20engineer&indpubnum=6943489856182715&chnl=9653_DataEngineer
JOB251413414699,Data Engineer II - Software,Data Engineer II - Software,"Data serialization such as JSON, avro, parquet","Experience building applications and RESTful APIs in production systems (Java or Python),ETL Pipeline and tooling experience,Experience with Big Data/HPC Concepts and Technologies such as Spark, MapReduce, HIVE, Hadoop, or Kafka,Familiarity with BI Tools such as Looker, Spotfire, or Google Analytics,Data Storage experience with MySQL, Redshift, Elasticsearch,Predictive Analytics: Machine Learning, Modeling, or Data Mining,Platform experience using Unix and AWS (ECS, EMR, S3. Route53),Containerization: Docker, Kubernetes,Data specific tooling and libraries: Jupyter Notebook, Zeppelin, numpy, pandas,Data oriented languages such as R and Julia,CI/CD: Jenkins, CircleCI, Travis","
The Opportunity
Vivid Seats is the largest independent online ticket marketplace, sending tens of millions of fans to live events. Experiences Matter- which is why we continue to grow year over year. Working at Vivid Seats puts you front and center at the opportunity to scale our best in class platform that allow our fans to sit closer and experience more.
At Vivid Seats, you will have the opportunity to work with the flexibility and speed of a startup; while operating at massive, profitable scale. We keep our teams lean, allowing each and every employee direct accountability to creating a positive ticket buying experience. We are relentless and move quickly to release new features and content to our applications daily. Good ideas are heard and implemented, and hard work rewarded. Being a part of our team means having the ability to drive impact and own the innovation that connects our tens of millions of unique monthly users to the memorable experiences that only live events create.
As a Data Engineer, you will build applications and tooling in support of Vivid Seats Data domain. You will help design and build data-oriented applications and services for both internal use and by our productions systems. You will be responsible for extracting data from multiple disparate sources, data cleansing/wrangling, batch processing and streaming of data feeds, and support the data science team in productionalizing models and analytical code. A software engineering background is preferred, with experience building / working with data and an understanding of modern data tools and trends.
To be successful, you'll need
Experience building applications and RESTful APIs in production systems (Java or Python)
ETL Pipeline and tooling experience
Experience with Big Data/HPC Concepts and Technologies such as Spark, MapReduce, HIVE, Hadoop, or Kafka
Familiarity with BI Tools such as Looker, Spotfire, or Google Analytics
Data Storage experience with MySQL, Redshift, Elasticsearch
Additional Experience of Interest
Predictive Analytics: Machine Learning, Modeling, or Data Mining
Platform experience using Unix and AWS (ECS, EMR, S3. Route53)
Containerization: Docker, Kubernetes
Data specific tooling and libraries: Jupyter Notebook, Zeppelin, numpy, pandas
Data oriented languages such as R and Julia
CI/CD: Jenkins, CircleCI, Travis
Data serialization such as JSON, avro, parquet
What We Offer
We are passionate about creating memorable experiences for our fans and the best in class experience for our employees. Vivid Seats offers competitive compensation levels, individual and team-based bonus opportunities, generous benefits package and Flex PTO policy plus a variety of workplace perks. The most exciting one: We offer our employees $100 worth of credits each month to spend on Vivid Seats tickets along with promotional discounts. At the heart of it, we are all fans of great live events. We want to help you get there more often.
Location
111 N Canal Suite #800
Chicago, IL 60606
",https://www.builtinchicago.org/job/data/data-engineer-ii-software/65417
JOB258272658178,Data Engineer,Data Engineer,Building Cube/Cube-like products,"Develop and extend in-house data toolkits based in Python and Java.,Consult and educate internal users on Hadoop technologies and assist them in finding and effectively utilizing the best solutions for their problem space.,Improve the performance of financial analytics platforms built around the Hadoop ecosystem.,IMC is on the cutting edge of financial applications of Hadoop, processing terabytes of data daily for mission critical trading systems.,We operate at the bleeding edge of technology. If something new can potentially bring an advantage we will adopt and incorporate the new technology.,The landscape is always changing creating new and exciting challenges. What we focus on today is very different than what we focused on two years ago.,We really believe in sharing knowledge and technology between the different offices. Much of our technology stack is shared globally between our offices, and we provide opportunities to travel between the regions both for personal growth and to assist where it has the biggest impact.,Working at IMC is a great way to gain exposure to and learn about financial markets and technology. We know from experience that a lot of people really enjoy learning about a field beyond their immediate area of expertise, it’s one of the things that makes this job more interesting than others.,We employ a broad range of people with varying backgrounds. What they have in common is their superior technical expertise, their extraordinary smarts and their collaborative approach.,3+ years of experience working with Hadoop 2 (YARN), cluster management experience preferable,3+ year of experience with Hadoop SQL interfaces including Hive and Impala,2+ years of experience developing solutions using Spark,Experience with common data-science toolkits, Python-based preferred,Strong Java, SQL, and Python development skills,Strong statistical analysis skills,Strong systems background, preferably including Linux administration,Unix scripting experience (bash, tcsh, zsh, python, etc),Experience with DevOps tools such as SALT and Puppet as part of a CI/CD development and deployment process.,Demonstrated ability to troubleshoot and conduct root-cause analysis,Developing with Apache Kafka,Containerization and Docker,OSS scheduling tools, preferably Luigi,Developing solutions in the Machine learning space, with an emphasis on Change/Anomaly detection","
IMC-Where Technology drives Trading
Trading nowadays happens in a highly competitive technological landscape; the best trading idea alone doesn’t cut it anymore. Instead, only the best trading ideas that are enabled via robust, scalable and fast technology win.
Do you enjoy the process of problem solving, a process where you recognize areas of improvement and iterate and innovate to improve? Does your curiosity and desire to learn drive you?
DATA ENGINEERING AT IMC:
As a data engineer at IMC, you’ll build and administer data workflows in an evolving, modern Hadoop-based environment. You’ll also:
Develop and extend in-house data toolkits based in Python and Java.
Consult and educate internal users on Hadoop technologies and assist them in finding and effectively utilizing the best solutions for their problem space.
Improve the performance of financial analytics platforms built around the Hadoop ecosystem.
WHAT MAKES IT FUN?
IMC is on the cutting edge of financial applications of Hadoop, processing terabytes of data daily for mission critical trading systems.
We operate at the bleeding edge of technology. If something new can potentially bring an advantage we will adopt and incorporate the new technology.
The landscape is always changing creating new and exciting challenges. What we focus on today is very different than what we focused on two years ago.
We really believe in sharing knowledge and technology between the different offices. Much of our technology stack is shared globally between our offices, and we provide opportunities to travel between the regions both for personal growth and to assist where it has the biggest impact.
Working at IMC is a great way to gain exposure to and learn about financial markets and technology. We know from experience that a lot of people really enjoy learning about a field beyond their immediate area of expertise, it’s one of the things that makes this job more interesting than others.
We employ a broad range of people with varying backgrounds. What they have in common is their superior technical expertise, their extraordinary smarts and their collaborative approach.
WHO YOU ARE:
3+ years of experience working with Hadoop 2 (YARN), cluster management experience preferable
3+ year of experience with Hadoop SQL interfaces including Hive and Impala
2+ years of experience developing solutions using Spark
Experience with common data-science toolkits, Python-based preferred
Strong Java, SQL, and Python development skills
Strong statistical analysis skills
Strong systems background, preferably including Linux administration
Unix scripting experience (bash, tcsh, zsh, python, etc)
Experience with DevOps tools such as SALT and Puppet as part of a CI/CD development and deployment process.
Demonstrated ability to troubleshoot and conduct root-cause analysis
Experience with the below (not required, but definitely desired):
Developing with Apache Kafka
Containerization and Docker
OSS scheduling tools, preferably Luigi
Developing solutions in the Machine learning space, with an emphasis on Change/Anomaly detection
Building Cube/Cube-like products
OUR CULTURE:
We are at the core a trading firm, however we value trading and technology equally and we believe that cooperation between traders and technologists is one of our great strengths. This is also reflected in our organizational and remuneration policies. We believe in fostering a truly flat environment in which great ideas can be recognized as well as put into practice from anybody within our organization
WHO WE ARE:
IMC Financial Markets is among the world’s leading proprietary trading firms, and a market maker in securities listed on exchanges across the globe. Our cutting-edge technology drives everything we do. High performance algorithms, smart strategies and collaborative teams are the core of our business.
Today, IMC Financial Markets is 500+ people working together to build software and trade financial products in our offices in Amsterdam, Chicago and Sydney. What does this mean for you? The chance to join a multi-national, multi-cultural team of exceptional individuals, focused on making IMC the world’s best trading firm.
",https://www.builtinchicago.org/job/data/data-engineer/64341
JOB261898748838,Data Engineer/ETL Developer,Data Engineer/ETL Developer,,"Gathering, documenting, examining and managing data integration and data management requirements in an Agile/Scrum development team,Build extensible data acquisition and integration solutions using various integration tools (Informatica, Pentaho, Ab>Initio, IBM DataStage, Kafka, Flume, etc.) and a variety of data environments (Hadoop, Oracle, Mongo, etc.),Optimize data integration platforms to provide optimal performance under increasing data volumes and complexity,Creating test plans and scripts for data integration/data model testing, ranging from unit to integration testing.,Expertise in different patterns and technologies around enterprise-level data integration, data management and data warehousing,Expertise in the design, development and optimisation/tuning of database technologies,Expertise in Hadoop and related NoSQL technologies,Experience with Agile principles and methodology,An applied knowledge of several data technologies, practices and analytical approaches, including: Data Integration (ETL/ELT, SOA/Middleware, Enterprise Service Bus), Relational Databases (OLTP, Analytical MPP Appliances), Data Preparation and Data Warehousing (SQL, ETL, Warehouse architecture, OLAP), Data Architecture (Logical & Physical Modelling, Policy and Rules Management), Programming (SQL, Unix Shell, Python),A grounding in Database / Data Warehouse / Data Mart design and development and be able to demonstrate structured approaches to problem solving in an Agile/Scrum development environment,Hands-on experience in two of the following disciplines and be an expert in one: Data Integration / Extract, Transform and Load, Data Management (incl. Data Quality Management), Data Warehousing, Data Virtualisation / Federation or Data Modelling,A creative data Technologist, passionate about data/information management and architectures,Innovative, creative, articulate and able to work and collaborate with a broad range of Stakeholders in a multi-site, multi-country global organisation,Able to demonstrate examples of previous successful deliveries and have a track record in an Agile-centric development environment, built on a foundation of hands-on development of Enterprise Data Services,An exceptional communicator (written and verbal) with internal teams and outside Consultants/Contractors/Suppliers,Goal oriented with structured thinking and effective organisational skills,Educated to Bachelor’s degree level, or have the equivalent experience or qualifications,A creative data technologist passionate about data/information management and architectures,Innovative, creative, articulate and able to work and collaborate with a broad range of stakeholders in a multi-site, multi-country global organization.","
Data Engineer/ETL Developer
Apply Now
Description
Our Client, a leading, global investment bank, currently has a job opening for a Data Engineer/ETL Developer.
Our Client, a leading, global investment bank, currently has a job opening for a Data Engineer/ETL Developer. If you are successful in your application for this Data Engineer job you will be joining one of the banks global centres for data innovation. This Data Engineer job opening is for a team that conducts highly sensitive investigations that are global in scale. We are unable to reveal specifics around the contents of the investigations, however you should think along the lines of this year’s panama papers leaks. The rest of the team you will be joining is mainly made up of data scientists, as such, if you have an interested in this area, there will be plenty of opportunity to get exposed to advanced data science and analytics techniques. This is a highly funded team, and the right data engineer will get access to many cutting edge technologies.
The ideal candidate will have a grounding in Database/Data Warehouse/Data Mart design and development and be able to demonstrate structured approaches to problem solving in an Agile/Scrum development environment. They will have hands-on experience in at two of the following disciplines and be an expert in one: Data Integration/ETL, Data Management (incl. Data Quality Management), Data Warehousing, Data Virtualization/Federation, and Data Modelling.
Responsibilities/Tasks:
Gathering, documenting, examining and managing data integration and data management requirements in an Agile/Scrum development team
Build extensible data acquisition and integration solutions using various integration tools (Informatica, Pentaho, Ab>Initio, IBM DataStage, Kafka, Flume, etc.) and a variety of data environments (Hadoop, Oracle, Mongo, etc.)
Optimize data integration platforms to provide optimal performance under increasing data volumes and complexity
Creating test plans and scripts for data integration/data model testing, ranging from unit to integration testing.
Liaising with other technical areas, conducting technology research, and evaluating software required for maintaining the data management environment
Experience/Exposure:
Expertise in different patterns and technologies around enterprise-level data integration, data management and data warehousing
Expertise in the design, development and optimisation/tuning of database technologies
Expertise in Hadoop and related NoSQL technologies
Experience with Agile principles and methodology
An applied knowledge of several data technologies, practices and analytical approaches, including: Data Integration (ETL/ELT, SOA/Middleware, Enterprise Service Bus), Relational Databases (OLTP, Analytical MPP Appliances), Data Preparation and Data Warehousing (SQL, ETL, Warehouse architecture, OLAP), Data Architecture (Logical & Physical Modelling, Policy and Rules Management), Programming (SQL, Unix Shell, Python)
A grounding in Database / Data Warehouse / Data Mart design and development and be able to demonstrate structured approaches to problem solving in an Agile/Scrum development environment
Hands-on experience in two of the following disciplines and be an expert in one: Data Integration / Extract, Transform and Load, Data Management (incl. Data Quality Management), Data Warehousing, Data Virtualisation / Federation or Data Modelling
A creative data Technologist, passionate about data/information management and architectures
Innovative, creative, articulate and able to work and collaborate with a broad range of Stakeholders in a multi-site, multi-country global organisation
Able to demonstrate examples of previous successful deliveries and have a track record in an Agile-centric development environment, built on a foundation of hands-on development of Enterprise Data Services
An exceptional communicator (written and verbal) with internal teams and outside Consultants/Contractors/Suppliers
Goal oriented with structured thinking and effective organisational skills
Educated to Bachelor’s degree level, or have the equivalent experience or qualifications
Deutsche Bank is an equal opportunity employer who seeks to recruit and appoint the best available person for a job regardless of marital / civil partnership status, sex (including pregnancy), age, religion, belief, race, nationality and ethnic or national origin, colour, sexual orientation or disability
Education/Certification:
Educated to degree level (or overseas equivalent)
Candidate will be:
A creative data technologist passionate about data/information management and architectures
Innovative, creative, articulate and able to work and collaborate with a broad range of stakeholders in a multi-site, multi-country global organization.
Able to demonstrate examples of previous successful deliveries and a track record in an agile-centric development environment, built on a foundation of hands on development of enterprise data services.
If you believe you, or somebody you know, could be the right Data Engineer/ETL Developer for this role, please do not hesitate to contact Stephen Waters. 016621000
",http://www.irishjobs.ie/Jobs/Data-Engineer-ETL-Developer-8010126.aspx
JOB262300805478,Senior Big Data Engineer/Developer,Senior Big Data Engineer/Developer,,"Assembling large, complex data sets that meet business requirements,Identifying, designing, and implementing internal process improvements: including process automation, optimizing data delivery, etc.,Designing optimal ETL infrastructures from variety of data sources,Building analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.,Big Data, including the Hadoop Ecosystem, NoSQL approaches and Cloud Data Management.,Data warehousing and BI (incl. SQL / Data Modelling, Data Integration, Data Governance),Thorough understanding of the capabilities of commercial Apache Hadoop distributions such as e.g. Hortonworks, Cloudera, or MapR,Experience in estimating, planning and managing data integration aspects of implementation projects.,Experience with Watson Discovery/Conversation/Knowledge Studio,SSIS experience,Custom application development,Data architecture experience of designing and developing data models,API experience, multithreading is a plus,May be involved in conceptual technology phase","
IBM Global Business Services (GBS) is a team of business, strategy and technology consultants enabling enterprises to make smarter decisions and providing unparalleled client and consumer experiences in cognitive, data analytics, cloud technology and mobile app development. With global reach, outcome-focused methodologies and deep industry expertise, IBM GBS empowers clients to digitally reinvent their business and get the competitive edge in the cognitive era in over 170 countries.
Bottom line? We outthink ordinary. Discover what you can do at IBM.
As a Big Data Engineer, you will work with various technology assets and frameworks built on open source and enterprise Big Data technologies by IBM Global Business Services (GBS) and apply them to projects that create high business impact. You will gain valuable knowledge and insights from thought leaders on cognitive technologies.
The role focuses on the elements required to manage data and information (both structured and unstructured) from business requirements to logical and physical design. You will be delivering solutions in the Big Data, Analytics, Business Intelligence and/or Data Warehousing domain at our clients. The Data Engineer defines data integration best practices in the critical evaluation and selection and/or development of the software components of the solution. Data Engineers are also responsible for the distribution of data and designing centralized and/or distributed systems that both address the business requirements and perform efficiently and effectively.
Responsibilities will likely include:
Assembling large, complex data sets that meet business requirements
Identifying, designing, and implementing internal process improvements: including process automation, optimizing data delivery, etc.
Designing optimal ETL infrastructures from variety of data sources
Building analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Working with executive, LOB, design and IT stakeholders on data-related technical issues and infrastructure needs
Experience from system integration projects based on the leading software products in the big data, business intelligence and analytics area is needed e.g.:
Big Data, including the Hadoop Ecosystem, NoSQL approaches and Cloud Data Management.
Data warehousing and BI (incl. SQL / Data Modelling, Data Integration, Data Governance)
Thorough understanding of the capabilities of commercial Apache Hadoop distributions such as e.g. Hortonworks, Cloudera, or MapR
Experience in estimating, planning and managing data integration aspects of implementation projects.
Experience with technologies such as: Spark, Sqoop, Pig, Hive, Kafka, Hibench, YCSB, Informatica, Ab Inititio, Talend, etc
IBM is market leader in the data & analytics space. We offer a dynamic, innovative and international environment which is fueled by projects with leading clients, unique capabilities such as IBM Research & Development and IBM Watson, and a growing ecosystem of partnerships such as those with Apple and Twitter. If you think you have the skill and the attitude to change the way that business is conducted – IBM is the place for you and will offer you numerous opportunities for growth across the company.
Successful candidates for these positions will work onsite at the IBM Client Innovation Center in Baton Rouge. The IBM Client Innovation Center is an in-bound delivery model where we support our clients from our Baton Rouge center. However, some travel is expected and all candidates must be willing and able to travel to meet our client needs across the US. Travel is typically related to knowledge transfer and training at the client site (Monday thru Friday). You are expected to travel up to 50% of the time. This is a traditional office position. You must live in, or be willing to relocate to, Louisiana. The work location is 100 North Street Baton Rouge, LA 70802. This is not a work from home position.
BENEFITS
Health Insurance. Paid time off. Corporate Holidays. Sick leave. Family planning. Financial Guidance. Competitive 401K. Training and Learning. We continue to expand our benefits and programs, offering some of the best support, guidance and coverage for a diverse employee population.
CAREER GROWTH
Our goal is to be essential to the world, which starts with our people. Company wide we kicked off an internal talent strategy program called Go Organic. At our core, we are committed to believing and investing in our workforce through:
Skill development: helping our employees grow their foundational skills
Finding the dream job at IBM: navigating our company with the potential for many careers by channeling an employee’s strengths and career aspirations
Diversity of people: Diversity of thought driving collective innovation
In 2015, Go Organic filled approximately 50% of our open positions with internal talent that were promoted into the role.
CORPORATE CITIZENSHIP
With an employee population of 375,000 in over 170 countries, amazingly we connect, collaborate, and care. IBMers drive a corporate culture of shared responsibility. We love grand challenges and everyday improvements for our company and for the world. We care about each other, our clients, and the communities we live, work, and play in!
gbscicbr
Preferred Technical and Professional Experience
Experience with Watson Discovery/Conversation/Knowledge Studio
SSIS experience
Custom application development
Data architecture experience of designing and developing data models
API experience, multithreading is a plus
May be involved in conceptual technology phase
Big Data Testing
Up to 50% or 3 days a week (home on weekends - based on project requirements)
Skill-keywords
Big Data, SQL, hadoop, squoop, pig, python, data engineer, hortonworks, cloudera, business intelligence, cognitive, analytics
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
",https://krb-sjobs.brassring.com/TGnewUI/Search/home/HomeWithPreLoad?PageType=JobDetails&partnerid=26059&siteid=5016&Areq=180152BR
JOB262469106000,Senior Data Engineer,Senior Data Engineer,,"Build data pipelines and deploy machine-learning algorithms.,Minimum 3 years’ experience in Data Engineering,Modern programming experience with Python, Java, Scala or similar,Solid ETL experience (Design, implementation and maintenance),Cloud ecosystem experience in Azure, AWS, GCP, Oracle or similar,DevOps experience in Kubernetes, Docker or similar desirable,Application of machine-learning methods Desirable,Degree in Computer Science, Physics, Mathematics or similar,Stakeholder engagement and project experience","
Work with modern cloud and programming applications.
Build data pipelines and deploy machine-learning algorithms.
Work alongside a team of Data Scientists.
This firm are driving the application of ML methods company-wide, so this is an exciting opportunity for an experienced Data Engineer to work on end-to-end ML model building and deployment as part of a team of Data Scientists and Data Engineers.
This Data Team acts as a consultancy within the business so there will be plenty of varied projects which will give incoming hire a diverse range of modern data engineering technologies to work with and develop.
What you’ll be doing
The Senior Data Engineer you work closely with the Team of Data Scientist and build and implement the required ML solutions including building and deployment. You will also be required to bring this all together by creating robust ETL pipelines that feed the data into the cloud.
As a senior hire, you will collaborate with the wider business to understand their relevant data needs and liaise with stakeholders regularly. You’ll be responsible for automating processes where possible and integrating data so that it can be provided to analytics users in the appropriate format.
What you’ll need to apply
Minimum 3 years’ experience in Data Engineering
Modern programming experience with Python, Java, Scala or similar
Solid ETL experience (Design, implementation and maintenance)
Cloud ecosystem experience in Azure, AWS, GCP, Oracle or similar
DevOps experience in Kubernetes, Docker or similar desirable
Application of machine-learning methods Desirable
Degree in Computer Science, Physics, Mathematics or similar
Stakeholder engagement and project experience
What you’ll get in return for your experience
A competitive salary dependent on experience plus bonus and benefits with the chance to work with modern data engineering technologies and machine-learning methods.
What’s next?
Please get in touch with Scott with an up to date CV today, don’t hesitate to call/email to discuss the role in more detail.
",https://jobs.theguardian.com/job/6862220/senior-data-engineer/
JOB266782391560,Data Engineer - National Center for Supercomputing Applications (A1600386),Data Engineer - National Center for Supercomputing Applications (A1600386),,"Apply technologies to solve big data problems and to develop innovative big data solutions.,Select, optimize and integrate data science tools and frameworks required to provide data science solutions for science teams.,Implement complex big data projects with a focus on collecting, parsing, managing, analyzing and visualizing large sets of data to turn information into insights using multiple platforms.,Collaborate effectively with other technology teams and architects to solve complex problems spanning their respective areas.,Develop, refine and scale data management and analytics procedures, systems, workflows, and best practices.,Develop analysis techniques for unstructured data.,Develop prototypes and proof of concepts for the selected solutions.,Enable big data and batch/real-time analytical solutions that leverage emerging technologies.,Code, test, and document new or modified data systems to create robust and scalable applications.,Lead efforts in creating, refining, managing and enforcing data management policies, procedures, conventions and standards.,Diagnose problems using formal problem-solving tools and techniques from multiple angles and probe underlying issues to generate multiple potential solutions. Proactively anticipate and prevent problems.,Collaborate with other members of formal and informal groups in the pursuit of common missions, vision, values and mutual goals.,Provide general and in-depth support/guidance for Blue Waters science teams in multiple areas of specialization.,Engage the data science community to improve the capability and performance of data science software on HPC systems.,Keep abreast of developments in the high-performance computing field, writing technical reports, conference and journal papers as appropriate, review scientific papers and proposals as appropriate.,Participate in writing joint proposals with Blue Waters staff and/or application teams.,BA/BS degree in engineering, mathematics, science, computer science, or related field. Alternative degree fields will be considered if accompanied by equivalent experience (depending on nature and depth of experience as it relates to current NCSA projects and technologies).,At least 1 year of experience working with real world data science applications.,Strong verbal and written communication skills.,Master's or Ph.D. in engineering, mathematics, science, computer science or related field highly preferred.,Expertise with exploring, understanding, cleaning, and wrangling big data.,Strong software engineering skills and a track record of contributing to software projects and collaborating with other developers.,Parallel programming experience on high-performance computers including development, porting, and evaluating the scalability of one or more parallel libraries or applications written in Fortran, C, and/or C++, and utilizing communication protocols such as MPI and OpenMP,Working knowledge of the Linux operating system, a programming or data analysis language (e.g., Python, R, Stata), and databases (e.g., MySQL, Oracle, NoSQL).,Ability to work both independently and as a team member.,Ability to manage multiple projects with competing priorities and deadlines, and an eagerness to take ownership of challenging and open-ended assignments.,Effective at communicating with audiences whose technical backgrounds vary widely.,Expertise with ETL processes, visualization tools, and web programming.,Experience developing and presenting technical training material and web-based technical documentation.","
National Center for Supercomputing Applications
Data Engineer
Search Extended
The National Center for Supercomputing Applications (NCSA) advances discovery and innovation through extreme-scale computing, science-enabling software, and the skills of our expert staff. The center is part of the flagship University of Illinois at Urbana-Champaign--a world leader in research, teaching, and public engagement-and is located in a micro-urban community that combines cultural vibrancy with affordability and quality of life.
NCSA is currently seeking one or more Data Engineers to join the Blue Waters Project and collaborate with top researchers and scientists utilizing high performance computing (HPC). The Blue Waters project provides high-performance computational and data facilities, as well as intellectual resources, that enable computational science of unprecedented scale. Blue Waters is a leading platform for accelerating open scientific discovery through computation by some of the world's most advanced teams addressing unique, ground-breaking computational and data science problems. The Data Engineer will lead support for data science problems on Blue Waters by deploying data science software and providing support to science teams. The incumbent will engage in the data science community to help improve the state of the art in data science tools on HPC platforms.
Key Responsibilities
Apply technologies to solve big data problems and to develop innovative big data solutions.
Select, optimize and integrate data science tools and frameworks required to provide data science solutions for science teams.
Implement complex big data projects with a focus on collecting, parsing, managing, analyzing and visualizing large sets of data to turn information into insights using multiple platforms.
Collaborate effectively with other technology teams and architects to solve complex problems spanning their respective areas.
Develop, refine and scale data management and analytics procedures, systems, workflows, and best practices.
Develop analysis techniques for unstructured data.
Develop prototypes and proof of concepts for the selected solutions.
Enable big data and batch/real-time analytical solutions that leverage emerging technologies.
Code, test, and document new or modified data systems to create robust and scalable applications.
Lead efforts in creating, refining, managing and enforcing data management policies, procedures, conventions and standards.
Diagnose problems using formal problem-solving tools and techniques from multiple angles and probe underlying issues to generate multiple potential solutions. Proactively anticipate and prevent problems.
Collaborate with other members of formal and informal groups in the pursuit of common missions, vision, values and mutual goals.
Provide general and in-depth support/guidance for Blue Waters science teams in multiple areas of specialization.
Engage the data science community to improve the capability and performance of data science software on HPC systems.
Keep abreast of developments in the high-performance computing field, writing technical reports, conference and journal papers as appropriate, review scientific papers and proposals as appropriate.
Participate in writing joint proposals with Blue Waters staff and/or application teams.
Required Education and Experience
BA/BS degree in engineering, mathematics, science, computer science, or related field. Alternative degree fields will be considered if accompanied by equivalent experience (depending on nature and depth of experience as it relates to current NCSA projects and technologies).
At least 1 year of experience working with real world data science applications.
Strong verbal and written communication skills.
Preferred Experience
Master's or Ph.D. in engineering, mathematics, science, computer science or related field highly preferred.
Expertise with exploring, understanding, cleaning, and wrangling big data.
Strong software engineering skills and a track record of contributing to software projects and collaborating with other developers.
Parallel programming experience on high-performance computers including development, porting, and evaluating the scalability of one or more parallel libraries or applications written in Fortran, C, and/or C++, and utilizing communication protocols such as MPI and OpenMP
Working knowledge of the Linux operating system, a programming or data analysis language (e.g., Python, R, Stata), and databases (e.g., MySQL, Oracle, NoSQL).
Ability to work both independently and as a team member.
Ability to manage multiple projects with competing priorities and deadlines, and an eagerness to take ownership of challenging and open-ended assignments.
Effective at communicating with audiences whose technical backgrounds vary widely.
Expertise with ETL processes, visualization tools, and web programming.
Experience developing and presenting technical training material and web-based technical documentation.
This is a regular academic professional position at NCSA and is an annually renewable, 12/12, 100%-time appointment with regular University benefits. Salary is commensurate with experience and start date will be as soon as possible after the close date of the search. Applicants must possess required education and experience by start date of position. Interviews and hires may occur before the closing date; however, all applications received by the closing date will receive full consideration. For further information regarding our application procedures, you may visit http://www.ncsa.illinois.edu or email hudgens2@illinois.edu.
To apply, please create your candidate profile at http://jobs.illinois.edu and upload your cover letter and CV/resume by the close date (3/16/17). Contact information for three references must be included on the application (letters maybe also be uploaded or sent to the contact below). For full consideration, candidates must complete the Hiretouch application process by the above date. The University of Illinois conducts criminal background checks on all job candidates upon acceptance of a contingent offer.
Illinois is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, religion, color, national origin, sex, sexual orientation, gender identity, age, status as a protected veteran, status as a qualified individual with a disability, or criminal conviction history. Illinois welcomes individuals with diverse backgrounds, experiences, and ideas who embrace and value diversity and inclusivity. (www.inclusiveillinois.illinois.edu).
Organization Name: Supercomputing Applications
College Name or Administrative Unit: Vice Chancellor for Research
Category: Academic Professional
Open Date: 08/09/2016
PI96522229
",https://careers.insidehighered.com/job/1312476/data-engineer-national-center-for-supercomputing-applications-a1600386-/
JOB266919707144,Big Data Engineer,Big Data Engineer,"Cluster managers (eg Docker, Apache Mesos, Kubernetes)","Hadoop - Proficiency in designing, running an troubleshooting Hadoop clusters (crucial),Strong understanding of Linux OS core principles, performance and tuning (crucial),Batch and streaming job frameworks - eg Spark, Storm,NoSQL databases - Hbase, Cassandra, MongoBD,Knowledge of Middlewares and messaging systems (eg Kafka, RabbitMQ, FTL),Automation via the use of configuration management and orchestration tools,Data collection and Querying (eg Flume, Sqoop, Hive),SSL certificates,Scalable distributed systems eg Splunk,SQL database administration and querying experience","My client, a leading Fintech organisation; are looking for a Big Data Engineer to join their growing Linux Platform Engineering team. You will help drive the expansion of Big Data technologies!
Inputs from engineers is highly valued at within my client's organisation. For the right individual, it is a great opportunity to really help shape the infrastructure of a leading FinTech firm, drive the adoption of big data technologies, build systems of high quality, with a focus on scalability, resiliency, security and automation.
Skills Required:
Hadoop - Proficiency in designing, running an troubleshooting Hadoop clusters (crucial)
Strong understanding of Linux OS core principles, performance and tuning (crucial)
Batch and streaming job frameworks - eg Spark, Storm
NoSQL databases - Hbase, Cassandra, MongoBD
Knowledge of Middlewares and messaging systems (eg Kafka, RabbitMQ, FTL)
Automation via the use of configuration management and orchestration tools
Advantageous Skill:
Data collection and Querying (eg Flume, Sqoop, Hive)
SSL certificates
Scalable distributed systems eg Splunk
SQL database administration and querying experience
Cluster managers (eg Docker, Apache Mesos, Kubernetes)
","https://www.jobserve.com/gb/en/search-jobs-in-london,-london,-united-kingdom/big-data-engineer-0f54069abb04830b/"
JOB268913685619,Senior Data Engineer,Senior Data Engineer,401k retirement savings plan,"You’ll evaluate, benchmark, and improve the scalability, robustness, and performance of our data platform and applications, making significant contributions to the architecture and design of our data processing platform,You’ll implement scalable, fault tolerant, and accurate ETLs,You’ll gather and process raw data at scale from diverse sources,You’ll collaborate with product management, data scientists, analysts, and other engineers on technical vision, design, and planning,You’ll implement and maintain a high level of data quality monitoring in our analytics ecosystem,You’ll train and collaborate with teammates effectively in data engineering best practices,You’ll be involved and supportive of agile sprint model of development, helping to implement the practice and the discipline,5+ years of experience as a software engineer and 3+ years of experience as a data engineer,Excellent communication and collaboration skills,Experience implementing data pipelines and improving the performance of ETL processes and SQL queries,Enthusiasm for working in an agile development environment,Strong database schema design and query optimization skills,Proficiency with relational databases and SQL queries (PostgreSQL preferred),Strong scripting skills in Python or Ruby,Experience in data modeling for OLTP and OLAP applications,Understanding of basic principles of data governance,Familiarity with workflow management tools (Airflow preferred),Familiarity with cloud-based data warehouses (Amazon Redshift preferred),Shown ability to understand automated testing concepts and ability to consistently apply those concepts,Experience with streaming technologies and concepts used with data warehouses,Experience in taking machine learning models from development to production,Experience working with visualization tools like Tableau,Experience working with sensitive data, i.e. PHI / PII,Application development experience,Competitive salary,Stock options + extended post termination option exercise window (for Omadans who are with us 3 years or more),Flexible vacation,Parental leave,Health, dental, and vision,Healthy snacks and meals,Wellness events (e.g. running club),Community volunteering","
Omada Health is on a mission to inspire and enable people everywhere to live free of chronic disease.
We are a San Francisco-based healthcare and technology company, and are looking for an experienced data engineer to join our growing team. Our program supports people in making lifestyle changes to improve their health, and ultimately, their lives. As a data engineer at Omada, you will be a key contributor in the collection and conversion of rich behavioral health inputs and their translation into data products that enable evidence-based decisions for cross functional teams.
As a key member of our data team, you will help design, build, and scale our data pipelines, data warehouse, and machine learning infrastructure. You should be motivated to learn new technologies and be ready to drive technical work. We use sustainable engineering practices: we work together using pair programming and test-driven development as much as possible, and value mindful collaboration and shipping.
How you can make an impact:
You’ll evaluate, benchmark, and improve the scalability, robustness, and performance of our data platform and applications, making significant contributions to the architecture and design of our data processing platform
You’ll implement scalable, fault tolerant, and accurate ETLs
You’ll gather and process raw data at scale from diverse sources
You’ll collaborate with product management, data scientists, analysts, and other engineers on technical vision, design, and planning
You’ll implement and maintain a high level of data quality monitoring in our analytics ecosystem
You’ll train and collaborate with teammates effectively in data engineering best practices
You’ll be involved and supportive of agile sprint model of development, helping to implement the practice and the discipline
What you need for this role:
5+ years of experience as a software engineer and 3+ years of experience as a data engineer
Excellent communication and collaboration skills
Experience implementing data pipelines and improving the performance of ETL processes and SQL queries
Enthusiasm for working in an agile development environment
Strong database schema design and query optimization skills
Proficiency with relational databases and SQL queries (PostgreSQL preferred)
Strong scripting skills in Python or Ruby
Experience in data modeling for OLTP and OLAP applications
Understanding of basic principles of data governance
Familiarity with workflow management tools (Airflow preferred)
Familiarity with cloud-based data warehouses (Amazon Redshift preferred)
Shown ability to understand automated testing concepts and ability to consistently apply those concepts
Bonus Points:
Experience with streaming technologies and concepts used with data warehouses
Experience in taking machine learning models from development to production
Experience working with visualization tools like Tableau
Experience working with sensitive data, i.e. PHI / PII
Application development experience
Technologies we use:
Redshift, Postgres, Python, Ruby, Airflow, Jenkins, Git, Docker, EC2, S3, SNS, SQS, Linux
Benefits:
Competitive salary
Stock options + extended post termination option exercise window (for Omadans who are with us 3 years or more)
Flexible vacation
Parental leave
Health, dental, and vision
Healthy snacks and meals
Wellness events (e.g. running club)
Community volunteering
401k retirement savings plan
About Omada Health: We’ve pioneered digital behavioural medicine: an innovative approach to tackling the growing epidemic of type 2 diabetes, heart disease, and obesity. Our online programs combine world-class science, technology, and design to inspire and enable people everywhere to live free of chronic disease. Named one of Fast Company’s “50 Most Innovative Companies in the World,” our team includes passionate and talented individuals. Our approach has been embraced by major employers across the country, including Costco and Iron Mountain, as well as leading health plans, such as Kaiser Permanente and BlueCross Blue Shield of Louisiana.
We carefully hire the best talent we can find, which means actively seeking diversity of beliefs, backgrounds, education, and ways of thinking. We strive to build an inclusive culture where differences are celebrated and leveraged to inform better design and business decisions. Omada is proud to be an equal opportunity workplace and affirmative action employer. We are committed to equal opportunity regardless of race, color, religion, sex, gender identity, national origin, ancestry, citizenship, age, physical or mental disability, legally protected medical condition, family care status, military or veteran status, marital status, domestic partner status, sexual orientation, or any other basis protected by local, state, or federal laws.
",https://boards.greenhouse.io/omadahealth/jobs/1205826
JOB272581893188,Data Scientist/Data Engineer (16721),Data Scientist/Data Engineer (16721),,,"
Position Description
Novetta is seeking a Data Engineer or Data Scientist interested in creating scalable ETL solutions and solving analytical challenges! You will be part of a team of dedicated professionals solving our customers' most challenging problems.
In this role you will:
Create scalable ETL and search applications focused on semantic analysis
Identify important and interesting questions surrounding our customer's challenges, then translate those questions into concrete analytical tasks
Assemble/refine, a scalable extract, transform, load (ETL) pipeline for novel applications.
Develop strategies to extract, resolve, and unify information of various types from numerous disparate data sources
Organize and mine massive data sets of both structured and unstructured data
Provide thought-leadership in the area of analytics/data science
Basic Qualifications:​
​3+ years experience in system/software solution development and delivery
Master’s Degree or higher with a quantitative or computational focus
Computer Science, Computational Linguistics, Math, Physics, Statistics, Computer Science, Engineering, Economics, Operations Research, or similar
Prior experience with:
Statistical and topic modeling
Data mining or machine learning
Technologies:
Linux
Python
R, Matlab, Pig or SQL
Java, Scala or C++
Familiarity with the Apache Hadoop ecosystem
Version control systems (GIT)
Desired Skills:
Interest in:
Latent semantic analysis and natural language processing
Predictive and prescriptive modelling
Statistical analysis
Hypothesis testing
Experience:
Delivering big data solutions
Application development, systems administration/engineering or other technical disciplines
With commercial or government cloud solutions (AWS, Openstack, etc)
With DevOps (configuration management, application deployment, etc)
Comfortable with:
Recommending strategies for design implementation during the development process
Setting customer or team expectations in regards to project timelines
Algorithm development
Security Clearance:
Must have an active US Government Secret clearance
Company Description
So what does Novetta do?
We focus on three core areas: Cyber, Entity, and Multi-Int Analytics. Our products are focused on processing and analyzing vast amounts of data in these core areas. Our services are focused on helping our customers move from complexity to clarity. At Novetta, we bridge the gap between what our customers think they can do and what they aspire to achieve.
Our culture is shaped by a commitment to our Core Values:
Integrity: We hold ourselves accountable to the highest standards of integrity and ethics.
Customer Mission Success: Customer mission success drives our daily efforts—we strive always to exceed customer expectations and focus on mission success beyond contractual commitments.
Employee Focus: We value our employees and demonstrate our commitment to them by providing clear communications, outstanding benefits, career development, and opportunities to work on problems and technical challenges of national significance.
Innovation: We believe that innovation is critical to our success – that discovering new and more effective ways to achieve customer mission success is what makes us a great company.
",https://www.clearancejobs.com/jobs/2322584/data-scientistdata-engineer-16721
JOB273747123285,"Senior Data Engineer Jobs in Reston, Virginia - ClearanceJobs","Senior Data Engineer Jobs in Reston, Virginia - ClearanceJobs",,,"
ClearanceJobs.com, the largest security-cleared career network, specializes in defense jobs for professionals with federal security clearances. Search thousands of jobs from pre-screened defense employers and government contractors. Learn More
Latest security clearance news – delivered monthly
",https://www.clearancejobs.com/jobs/2312042/apply
JOB274640172302,Data Engineer,Data Engineer,,,"Description
Data Engineer - Main skills SQL, Cloud architecture
The Data Engineer will part of our clients Data Science & Analytics team.
Strong SQL Database architecture skills, importing data from a variety of sources, optimising data in AGILE environment.
Responsible for the maintenance and development of a real-time, API first tech stack that serves as the foundation for our clients UK and other territories business.
You will be a hands-on and used to working in a fast paced, agile environment with a strong background in Cloud and hybrid infrastructure e.g. SQL/NOSQL, Redshift, BigQuery, Hadoop, Spark. You will collaborate with Software Engineers and Data Scientists to help implement robust and scalable applications across both territories (UK/US)
Skills & experience required:
- MUST be BSc in a highly-numerate/computer science discipline or practical commercial experience
- MUST have proven experience in working with large-volume heterogeneous data including NoSQL, Redshift, preferably with Hadoop/HBase or Apache Spark
- MUST have significant coding experience and the ability to span languages as needed, depending on the data processing framework in use
- MUST have Knowledge of data modeling, data access and data storage techniques
- MUST have excellent written and verbal communication skills. Able to work effectively to tight deadlines and stay calm under pressure. Problem solver attitude
Our client offered excellent working conditions, benefits and on-going training and career development.
You must have excellent communication skills and be able to work in a team and with stakeholders.
Type
Start Date
Contract Length
Telephone
Job Reference
Job ID
",https://www.cv-library.co.uk/job/206489990/Data-Engineer
JOB1754722796,Sr. Software Data Engineer,Sr. Software Data Engineer,,,"
Sr. Software Data Engineer Sr. Software Data Engineer - Skills Required - Python, Go, Machine Learning, Artificial Intelligence, RESTful, JSON
If you are a Sr. Software Data Engineer with experience, please read on!
Located just outside of Washington D.C. we are a fast-paced high technology data science company changing the millenial shopping world! We pride ourselves in our collaborative culture and are looking for a rockstar Sr. Software Data Engineer to join our team.
**What's In It for You**
We offer an amazing compensation package including:
- A competitive salary ranging from $150-$175K (DOE)
- Full Benefits (Medical, Dental, Vision)
- Bonuses/ Stock options/ Equity
- Vacation/PTO/Sick days
- Gym membership!
- Free uber rides!
- Free coffee/snacks, catered lunches, fully stocked kitchen
- Casual dress
- Office activities/ company social events
- Game room
**What You Will Be Doing**
- Improving backend systems
- Writing code and demonstrating accuracy through tests
- Designing, building and maintaining new web services
- Migrating Python projects to Go
- Performing code reviews
- Building development paradigms and release processes
**What You Need for this Position**
At Least 2 Years of software development/data science experience and knowledge of most of the skills below:
- Bachelor's in Computer Science or 5 years relevant experience
- MS Degree in Mathematics, Computer Science, Statistics, Operations Research or other quantitative field
- Writing Python code
- Writing Go code
- Work or educational experience in Machine Learning or Artificial Intelligence
- Experience building RESTful or JSON webservices (Django, Flask, Tornado, Rails, Sinatra, Gorilla, Martini, net/http)
- Writing test cases ( py.test, Unittest, Nose, Rspec, JUnit, go-test, Ginkgo)
- Database integration (MongoDB, PostgreSQL/MySQL, Redis, Elasticsearch)
- Data analytics and data engineering
- Data wrangling (SQL, Python, R or Java)
- Data Visualization (Python, Tableau, R)
- Digital Media Analytics (web scraping, social media APIs)
- Semantic data modeling
Plusses! Experience with:
- NumPy, SciPy, SciKitLearn
- Scala, AWS, Docker
- Artificial Intelligence
- Distributed AI
- Big Data Problems
- Evolutionary algorithms
So, if you are a Sr. Software Data Engineer with experience, please apply today!
Applicants must be authorized to work in the U.S.
**CyberCoders, Inc is proud to be an Equal Opportunity Employer**
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.
**Your Right to Work** ? In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.
*Sr. Software Data Engineer*
*VA-Ashburn*
*RK6-1336737* 6400cfbdbbae49beba253caa44503a14
",http://www.classifiedads.com/technical_jobs/xb25wyv2ydd9
JOB2700364947,Data Engineer,Data Engineer,,,"
Data Engineer more... ▼
Overview:
CallidusCloud is the global leader in cloud-based sales, marketing and learning solutions. CallidusCloud enables organizations to accelerate and maximize their lead to money process with a complete suite of solutions that identify the right leads, ensure proper territory and quota distribution, enable sales forces, automate configure price quote, and streamline sales compensation - driving bigger deals, faster. Over 5,200 organizations, across all industries, rely on CallidusCloud to optimize the lead to money process to close more deals for more money in record time.
You will be working on next generation data infrastructure, supporting new functionalities on existing platform, and mining data for analytics insights and product features. Developing on this infrastructure presents many technical challenges in the areas of efficient query processing, large-scale data processing, machine learning and modeling, as well as satisfying complex business rules. If you are someone who is passionate about data, enjoys working with new technologies, setting up big data infrastructures and implementing new reporting solutions and metrics, we want to hear from you!
Responsibilities:
Develop complex queries, pipelines and software programs to solve analytics and data mining problems.
Interact with data scientists, product managers, and engineers to understand business problems, technical requirements to deliver predictive and smart data solutions.
Prototype new metrics or data systems.
Lead data investigations to troubleshoot data issues that arise along the data pipelines.
Collaborate with different product owners to incorporate data science solutions.
Maintain and improve data science platform.
Qualifications:
BS/MS/PhD in Computer Science, Electrical Engineering or related disciplines.
Strong fundamentals: data structures, algorithms, database.
5+ years of software industry experience with 2+ years in analytics, data mining, and/or data warehouse.
Fluency with Java/Scala & Python.
Proficiency with SQL/Unix/Shell.
Self-driven, challenge-loving, detail oriented, teamwork spirit, excellent communication skills, ability to multi-task and manage expectations.
Preferred
Industry experience in Hadoop technologies (Hive, HBase, Spark, Kafka, Impala, CDH).
Experience with machine learning algorithms and/or R a plus.
Experience with any MPP analytics engines like Vertica.
Experience with data integration tools like Pentaho.
Callidus Software (d.b.a CallidusCloud) is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, religion, color national origin, sex, age status as a protected veteran, or status as a qualified individual with disability.
",http://diversityjobs.com/jobsearch/display/714921054
JOB7526148633,Senior Data Engineer,Senior Data Engineer,Daily catered lunches from LA’s best restaurants and fully stocked kitchen,"Identify and evangelize programming best practices with the Data Engineering and Modeling teams.,Work closely with Analysis to ensure quality & availability of data in the Data Warehouse along with support of our Business Intelligence platform.,Lead and participate in design / architecture reviews, as well as code reviews and walkthroughs.,Design/Implement robust end-2-end ETL pipelines.,Develop solutions with a mind towards quality, scalability and high performance on large data sets.,8+ years experience in a senior developer or data engineer role,Hands-on coding experience in R, Python, Scala or similar,Solid foundation with Data Science workflow, experience with Pandas and Scikit-Learn preferred,Experience with distributed processing frameworks like Amazon EMR and Spark,Experience working with high volume heterogeneous data,Amazon Web Services, e.g. RedShift, EMR, VPC, RDS, S3, and Route53,Docker for provisioning servers and deploying applications/services,Excellent verbal and written communication skills including the ability to explain technical issues to a non-technical audience,B.S. in Computer Science or equivalent experience,People – the best part of Zest,Robust healthcare plans, matching 401K and unlimited vacation time,Dog friendly office with lounge areas, video games and gigantic jigsaw puzzles,On-site gym with yoga, salsa and other employee run fitness classes,Generous family leave policy (6 month maternity leave/3 month paternity leave),Tuition reimbursement, conference allowance and Zest talks,Complimentary massages, manicures, pedicures and more","
Description
In this role you will:
Work with Modeling, Product and Business to define requirements, design and build the next generation of ZestFinance product roadmap features.
Identify and evangelize programming best practices with the Data Engineering and Modeling teams.
Work closely with Analysis to ensure quality & availability of data in the Data Warehouse along with support of our Business Intelligence platform.
Lead and participate in design / architecture reviews, as well as code reviews and walkthroughs.
Design/Implement robust end-2-end ETL pipelines.
Develop solutions with a mind towards quality, scalability and high performance on large data sets.
We are looking for:
8+ years experience in a senior developer or data engineer role
Hands-on coding experience in R, Python, Scala or similar
Solid foundation with Data Science workflow, experience with Pandas and Scikit-Learn preferred
Experience with distributed processing frameworks like Amazon EMR and Spark
Experience working with high volume heterogeneous data
Amazon Web Services, e.g. RedShift, EMR, VPC, RDS, S3, and Route53
Docker for provisioning servers and deploying applications/services
Excellent verbal and written communication skills including the ability to explain technical issues to a non-technical audience
B.S. in Computer Science or equivalent experience
Perks and benefits:
People – the best part of Zest
Robust healthcare plans, matching 401K and unlimited vacation time
Dog friendly office with lounge areas, video games and gigantic jigsaw puzzles
On-site gym with yoga, salsa and other employee run fitness classes
Generous family leave policy (6 month maternity leave/3 month paternity leave)
Tuition reimbursement, conference allowance and Zest talks
Complimentary massages, manicures, pedicures and more
Daily catered lunches from LA’s best restaurants and fully stocked kitchen
About ZestFinance:
ZestFinance, Inc. applies its unique credit-decisioning technology platform — based on data science and machine learning — to help lenders effectively predict credit risk so they can increase revenues, reduce risk and ensure compliance. ZestFinance was founded in 2009 by Douglas Merrill and a team of former Google employees with the mission of making fair and transparent credit available to everyone.
We are committed to diversity in hiring, professional development, and everyday discussion. Zest is determined to hire crazy smart people who are different from each other to create broad thinking, lots of different ideas, and by extension, the best team possible.
",https://www.builtinla.com/job/data/senior-data-engineer/44172
JOB8238732914,"Internship Data Engineer (Paris, FR)","Internship Data Engineer (Paris, FR)",Indemnity according to the profile,"Extract, centralize and collect data from different databases.,Analyze and provide answers as needed by the different operational teams,Set up periodic data flow (data pipeline),maintenance and development of a BI platform,the contribution and deployment of machine learning models,POC of backends for analysis and data processing.,Higher education from Bac +3, with a specialization in data processing, data science or good experience of database systems.,You are familiar with web applications and the e-commerce environment.,You have a good web culture and an analytical mind,You are looking for challenges and want to join an international startup.,You are organized, autonomous and you are force of proposal.,You have good experience with SQL and NoSQL databases (MongoDB, PostgreSQL).,You have development experience in Python,A knowledge of one of the following databases would be a plus: Elasticsearch, Redshift, Kubu, Druid, Hive, etc.,Knowledge of the AWS environment,The opportunity to revolutionize mobility with us,A superb integration with lots of surprises,Career evolution,Atypical premises in the heart of Paris (5min from St Lazare),Latest work tools,Maximum collaboration between the different teams,No room for coffee is old fashioned!,A restaurant card allowing you to have good food delivered,A GymLib gym pass to burn all those good food ..,Foosball duels for lunch,Regular afterworks,Internationally-oriented teams and projects to perfect your languages,Employment type: Internship agreement - Minimum duration of 6 months,Job location: Paris 75 (9th),Immediate availability","
Your mission :
In close connection with the Data Center, you are in charge of:
Extract, centralize and collect data from different databases.
Analyze and provide answers as needed by the different operational teams
Set up periodic data flow (data pipeline)
These missions may have to evolve according to the motivation of the candidate towards:
maintenance and development of a BI platform
the contribution and deployment of machine learning models
POC of backends for analysis and data processing.
Who are you :
Higher education from Bac +3, with a specialization in data processing, data science or good experience of database systems.
You are familiar with web applications and the e-commerce environment.
You have a good web culture and an analytical mind
You are looking for challenges and want to join an international startup.
Required Skills :
You are organized, autonomous and you are force of proposal.
You have good experience with SQL and NoSQL databases (MongoDB, PostgreSQL).
You have development experience in Python
A knowledge of one of the following databases would be a plus: Elasticsearch, Redshift, Kubu, Druid, Hive, etc.
Knowledge of the AWS environment
""You have a real taste for challenge and are attracted by start-up environments so do not wait any longer postulate!""
What we offer:
Working at TravelCar is integrating a tribe in which excellence and performance culture rhyme with good atmosphere
The opportunity to revolutionize mobility with us
A superb integration with lots of surprises
Career evolution
Atypical premises in the heart of Paris (5min from St Lazare)
Latest work tools
Maximum collaboration between the different teams
No room for coffee is old fashioned!
A restaurant card allowing you to have good food delivered
A GymLib gym pass to burn all those good food ..
Foosball duels for lunch
Regular afterworks
Internationally-oriented teams and projects to perfect your languages
Non-exhaustive list!
Employment type: Internship agreement - Minimum duration of 6 months
Job location: Paris 75 (9th)
Immediate availability
Indemnity according to the profile
Please note: the original job description is in French
Apply for this job
",http://www.parking-net.com/parking-jobs/travelcar/internship-data-engineer-paris-fr-1
JOB8452054842,Data Engineer OR Data & Analytics Consultant in Everett,Data Engineer OR Data & Analytics Consultant in Everett,Ability to work successfully with 3rd party vendors to support application enhancements or troubleshoot problems as required to meet business processes and priorities.,"Bachelor’s Degree in Business Administration, Computer Science or related field; AND,Two (2) years progressively more responsible directly related subject matter expertise, quantitative, business intelligence and data management experience.,MSc in Business, Economics, Mathematics, Statistics, or Computer Science,Bachelor’s in Business, Economics, Mathematics, Statistics, or Computer Science (OR the equivalent combination of directly related education and experience in quantitative, business intelligence, and data management analysis), AND,Three (3) years directly related subject matter expertise, quantitative, business intelligence and data management skills.,Data modeling and database design for analytics and business intelligence solutions.,Strong analytical skills and experience with Extract, Transform, and Load (ETL) tools.,Experience in Software Development Cycle (Agile) and has a strong quality ethic.,Work effectively in a collaborative team environment along with the commitment to the overall success of a group.","
Data Engineer OR Data & Analytics Consultant
Job #9822
$64,000 - $110,000 (DOQ)
BASIC RESPONSIBILITIES:
Provide analytic support and services across the organization. Develop new analytical models and business intelligence solutions in order to provide actionable insights. Deliver projects related to predictive analytics, enterprise data management, master data management, and analytic applications using a combination of methodologies.
Candidate demonstrates intellectual curiosity, business acuity and attention to detail. Experience with business intelligence tools, data mining concepts, predictive analytic concepts and data integration tools strongly preferred. Candidate will possess, or quickly gain, an understanding of SAP and Microsoft analytic tools as well as an understanding of data modelling and data integration tools and concepts. Must be able to learn new technologies/concepts and be proactive in applying that knowledge to work. Candidate will demonstrate excellent communication skills and comfort in leading discussions.
MINIMUM QUALIFICATIONS:
Data Engineer (Applications Analyst)
Bachelor’s Degree in Business Administration, Computer Science or related field; AND
Two (2) years progressively more responsible directly related subject matter expertise, quantitative, business intelligence and data management experience.
Data & Analytics Consultant
MSc in Business, Economics, Mathematics, Statistics, or Computer Science
OR
Bachelor’s in Business, Economics, Mathematics, Statistics, or Computer Science (OR the equivalent combination of directly related education and experience in quantitative, business intelligence, and data management analysis), AND
Three (3) years directly related subject matter expertise, quantitative, business intelligence and data management skills.
PREFERRED QUALIFICATIONS:
Data modeling and database design for analytics and business intelligence solutions.
Strong analytical skills and experience with Extract, Transform, and Load (ETL) tools.
Experience in Software Development Cycle (Agile) and has a strong quality ethic.
Work effectively in a collaborative team environment along with the commitment to the overall success of a group.
Ability to work successfully with 3rd party vendors to support application enhancements or troubleshoot problems as required to meet business processes and priorities.
BENEFITS: Complete benefits plan and retirement program.
TO APPLY: Interested individuals should complete the online application and submit cover letter and resume at www.snopud.com under Careers by January 1, 2019. A full job description is available on the website.
Snohomish County P.U.D. #1 is an Equal Opportunity Employer of Minorities, Women, Disabled and Veterans.
Email me jobs like this
",http://jobs.seattletimes.com/jobs/170028/data-engineer-or-data--and--analytics-consultant-in-united-states-snohomish-county-pud/
JOB8513198056,Data Engineer,Data Engineer,,"You have a hands-on mentality to solve complex issues,Learning new tools and software development skills is your second nature,You have at least 2 years’ experience in software development,You think about data as a massive asset to leverage,You are keen on automation using Continuous Integration/Delivery tooling,You have an Agile mindset and SCRUM way of working,You feel personally committed to the goal setting and delivery of the team (local and international),Able to create data pipelines, using at least one of the following; ADF, Kafka, SSIS, Databricks,Bring data science solutions to life using any of Spark, Python and SQL,Familiar with CI, CD, testing and version control (e.g. VSTS/TFC, ARM, GIT or similar),Basic knowledge in Linux,Experience working with configuration management tools,Proficient in spoken and written English, Dutch is beneficial,A central office location with easy access, by either public transport or car,Healthy work-life balance (smart working),The time for you to develop your profession as Data Engineer,Opportunity to work for a clean energy company that aims for creating fossil free energy within one generation","
Data Engineer - Vattenfall Customer Analytics
Do you want to become part of a team that develops and keeps our data together in a data platform? Do you want to be responsible for the creation of data products to accelerate Vattenfall’s digital transformation strategy?
You will design, build and integrate data from various sources. Writing complex queries that, make data easily accessible, work smoothly while optimizing the performance of the company’s Big data ecosystem and many other analytical and data driven solutions.
Your stack will, amongst others, consist of Azure related services (i.e.: SQL Server, ADF, HDInsight). Data Engineers will work closely with our business partners in Sales, Marketing, Finance and Customer Solutions. Will you help them getting better insight in our customers’ demands? Feel energized? Great! Then read on because there is more in it for you.
About you:
You have a hands-on mentality to solve complex issues
Learning new tools and software development skills is your second nature
You have at least 2 years’ experience in software development
You think about data as a massive asset to leverage
You are keen on automation using Continuous Integration/Delivery tooling
You have an Agile mindset and SCRUM way of working
You feel personally committed to the goal setting and delivery of the team (local and international)
Last but not least you are not afraid to drink a cup of coffee with a product owner
Able to create data pipelines, using at least one of the following; ADF, Kafka, SSIS, Databricks
Bring data science solutions to life using any of Spark, Python and SQL
Familiar with CI, CD, testing and version control (e.g. VSTS/TFC, ARM, GIT or similar)
Basic knowledge in Linux
Experience working with configuration management tools
Proficient in spoken and written English, Dutch is beneficial
Preferably Bachelor’s degree in Computer Science or comparable degree
A central office location with easy access, by either public transport or car
Healthy work-life balance (smart working)
The time for you to develop your profession as Data Engineer
Opportunity to work for a clean energy company that aims for creating fossil free energy within one generation
Work with energetic, motivated colleagues that like to have fun as well
At Vattenfall we promote smart working. Meaning you can easily combine work life with your private situation to ensure a healthy work life balance. To attract and retain a talented workforce is successfully implemented within Vattenfall such as the possibility to work from home.
Apply now or contact us for additional information! We welcome your application in English, including CV and cover letter. For more information about the position you can contact Mareike Albrecht (Manager Customer Analytics).
For more information about the recruitment process you are welcome to contact Iris Eveleens (Recruiter) at +31 (0)6 11 03 4109.
",https://www.nuon.com/carriere/vacatures/data-engineer/
JOB11538400185,Lead Data Engineer,Lead Data Engineer,"Excellent experience of Amazon Web Services (AWS),Strong coding skills in Python and Java,Demonstrable experience of messaging queue technology such as Apache Kafka (or similar),Hands-on experience of real-time systems at production stage,5+ years of post-academic experience in a data engineering capacity,Experience of Docker,Apache Spark,ElasticSearch",,"
Senior Data Engineer
This is a unique opportunity to join a truly innovative analytics software firm working in the energy trading subject area.
Description:
The Lead Data Engineer is responsible for building and upgrading the business' data platform and taking ownership of its user-interface, back-end processes and machine learning models. The successful applicant will demonstrate exceptional coding and data modelling skills and tangible experience of building systems capable of real-time processing at production stage.
You will work closely with Data Scientists, Product Owners and Engineers (Front and Back-End) to define and implement data architecture and infrastructure through a highly iterative, evolutionary approach.
Skills/Qualifications:
Excellent experience of Amazon Web Services (AWS)
Strong coding skills in Python and Java
Demonstrable experience of messaging queue technology such as Apache Kafka (or similar)
Hands-on experience of real-time systems at production stage
5+ years of post-academic experience in a data engineering capacity
Strong experience integrating external APIs and a large number of data sources
Bonus points for:
Experience of Docker
Apache Spark
ElasticSearch
Popular NoSQL DBs (Cassandra, HBase, Redshift, MongoDB etc.)
This job was originally posted as www.totaljobs.com/job/74584787
",https://jobs.telegraph.co.uk/job/8671408/lead-data-engineer/
JOB12837628944,"Big Data Engineer - Hadoop, SalesForce.com, SQL Server required","Big Data Engineer - Hadoop, SalesForce.com, SQL Server required",Google Analytics,"Help set up a data lake,Setup Integration points from various back end systems into the data lake,Help with the overall Big data strategy, architectural approach and Hadoop eco system tool selection,Big Data Engineer - Hadoop, SalesForce.com, SQL Server required,SQL Server (2008 & 2012),Web/Call Analytics,Hadoop/HDFS,Oozie,Sqoop,Kafka,Flume,SOAP/ RESTful web services,Java,PIG,Spark,Scala,HBASE,Cloudera,Good to have travel industry experience,Good working knowledge of Spark, Hive and Impala would be very beneficial,A good knowledge of the languages Scala and Java","
Big Data Engineer - Hadoop, SalesForce.com, SQL Server required - Berkshire - £550-£600pd
Spargonet Consulting, an IT Services Consultancy, is looking for a Big Data Engineer to help set-up a data lake for one of our customers in the Leisure Industry. This is a green field development opportunity. The ideal candidate will be able to provide thought leadership and architectural guidance. We are looking for an experienced engineer with a proven track record.
Main activities
Help set up a data lake
Setup Integration points from various back end systems into the data lake
Help with the overall Big data strategy, architectural approach and Hadoop eco system tool selection
Mandatory skills :
Big Data Engineer - Hadoop, SalesForce.com, SQL Server required
SQL Server (2008 & 2012)
Web/Call Analytics
Hadoop/HDFS
Oozie
Sqoop
Kafka
Flume
SOAP/ RESTful web services
Desired skills :
Java
PIG
Spark
Scala
HBASE
Cloudera
Working knowledge :
Good to have travel industry experience
Good working knowledge of Spark, Hive and Impala would be very beneficial
A good knowledge of the languages Scala and Java
Google Analytics
Spargonet Consulting Plc is a leading IT consultancy with over thirty years pedigree and experience of supplying IT services to household name blue chip clients within a range of business sectors. By joining the personable team at Spargonet, you become a valued member of our personnel with good prospects of a rewarding and challenging opportunity. All applications welcome for an informal and confidential discussion.
This job was originally posted as
www.cwjobs.co.uk - August 4
",https://www.careerjet.co.uk/clk/61ed307d7b07968515d0b4f780fff179.html
JOB14960594748,"Data Engineer (BBBH106102) Baku city, Azerbaijan","Data Engineer (BBBH106102) Baku city, Azerbaijan",,,"
My client is one of the leading telecoms companies and they are looking for an experienced Engineer to Join their team on a project in Azerbaijan.
Requirements:
- HP Openview NMS Experience
- Duration 2 - 6 weeks
- 6 day working Sunday day of rest
- All flights and expenses covered
- Laptop and terminal cable
- Previous experience with BP
- Offshore certification
Please send your CV to: robert.mackie@spencer-ogden.com or call on: 0207 268 9263
",http://www.aplitrak.com/?adid=cm9iZXJ0Lm1hY2tpZS45NjE5Ni41MjYxQHNwZW5jZXJvZ2Rlbi5hcGxpdHJhay5jb20
JOB15455988744,Senior ETL Data Engineer | SAS | XML | SQL | Croydon,Senior ETL Data Engineer | SAS | XML | SQL | Croydon,Agile/Scrum working practices,"Use of SAS Data Integration (DI) Studio to populate data warehouse/lakes,Extracting data from data sources (including databases, XML, flat files, Excel etc.),Writing and optimising SQL queries, functions, procedures (Greenplum, Postgres),Documenting ETL designs and implementations, and operations guide,Data Analysis and Modelling (including Entity Relationship Diagrams, Star Schemas, Relational Data Analysis),Experience with POLE models and data matching,ETL Scheduling (concepts/practice and any use of ActiveEon),Experience with Business As Usual ETL operations,Database partitioning design and strategy,Experience interfacing with data sources/systems via APIs e.g. REST,Data Quality monitoring and reporting,SAS Macro programming,SAS Enterprise Guide,Scripting (DOS, Linux, PowerShell, VBScript),Windows and/or Linux networking fundamentals,XML (XML validation, XSDs),Programmatic text file manipulation (Grep, Sed, Awk, Tr, Findstr)","
Senior ETL Data Engineer with SAS Data Integration, XML and SQL experience is required by large Public Sector authority in Croydon
*IR35 status confirmed out of scope.
*SC Clearance- Will consider candidates who are SC cleared and Eligible for SC
ETL Data Engineer Essential experience:
Use of SAS Data Integration (DI) Studio to populate data warehouse/lakes
Extracting data from data sources (including databases, XML, flat files, Excel etc.)
Writing and optimising SQL queries, functions, procedures (Greenplum, Postgres)
Documenting ETL designs and implementations, and operations guide
Data Analysis and Modelling (including Entity Relationship Diagrams, Star Schemas, Relational Data Analysis)
ETL Data Engineer Desirable experience:
Experience with POLE models and data matching
ETL Scheduling (concepts/practice and any use of ActiveEon)
Experience with Business As Usual ETL operations
Database partitioning design and strategy
Experience interfacing with data sources/systems via APIs e.g. REST
Data Quality monitoring and reporting
SAS Macro programming
SAS Enterprise Guide
Scripting (DOS, Linux, PowerShell, VBScript)
Windows and/or Linux networking fundamentals
XML (XML validation, XSDs)
Programmatic text file manipulation (Grep, Sed, Awk, Tr, Findstr)
Agile/Scrum working practices
Immediate interview and flexible start dates available via Square One Resources
This job was originally posted as
www.cwjobs.co.uk - August 3
",https://www.careerjet.co.uk/clk/c4e0a226c7f415b3e99f686a7dc14404.html
JOB16453146049,data engineer,data engineer,,,"
Data Engineer
If you are a Data Engineer with experience, please read on! We are a global investment firm built around world-class talent, sound risk management, and innovative leading-edge technology. For a quarte...
Data Engineer
If you are a Data Engineer with experience, please read on! We are a global investment firm built around world-class talent, sound risk management, and innovative leading-edge technology. For a quarte...
Data Engineer
If you are a Data Engineer with experience, please read on! Top Reasons to Work with Us We are a community of people who believe everyone deserves better and better should not cost more. We are democr...
Data Engineer
If you are a Data Engineer with experience, please read on! We are a global investment firm built around world-class talent, sound risk management, and innovative leading-edge technology. For a quarte...
Data Engineer
If you are a Data Engineer with experience, please read on! Top Reasons to Work with Us Highly Reputable What You Will Be Doing The ideal candidate will see the big picture from the business perspecti...
Data Engineer
If you are a Data Engineer with experience, please read on! Top Reasons to Work with Us We are a community of people who believe everyone deserves better and better should not cost more. We are democr...
Data Engineer
Data Engineer
Data Engineer
Data Engineer
Data Engineer
Data Engineer
Data Engineer
Data Engineer
Data Engineer
Data Engineer
Big Data Engineer
Senior Data Engineer
Senior Data Engineer/Developer
Senior Big Data Engineer
",https://www.cybercoders.com/jobs/data-engineer-jobs/
JOB16853569877,Data Engineer - Start up,Data Engineer - Start up,,,"
Description
Data Engineer - Start up
The Role Work for a Health and Wellness Start up gaining significant traction. They focus on Mens Lifestyle and wellness - catering to a relatively untapped market and very quickly becoming leaders in the service they provide. They are looking for a Data Engineer to work in their Dubai office; ...
Contact:
Organisation : CSG - BW Penman - UAE
Other Similar Jobs
",http://www.godubai.com/jobs/jobdetails.asp?jid=381698
JOB19012633315,Big Data Engineer - Machine Learning (Scala),Big Data Engineer - Machine Learning (Scala),"Bachelors and 2+ years of experience or Masters degree and 1+ years of experience,Experience and proficiency with Scala,Experience and proficiency with Spark,A deep understanding of machine learning and interest in applying it at scale.,Experience with data cleaning, preparation, and feature building and selection techniques.,Experience working with large data sets to solve problems.,Effective communication, interpersonal and teamwork skills.,Ability to handle multiple concurrent projects while working independently and in teams.,Ability to work in a fast-paced and deadline driven environment.,Experience in hierarchical models, random effect models, and online learning","Predict item availability in stores for online orders,Entire lifecycle of product development from research support to production deployment, monitoring, evaluation, and documentation.,Apply machine learning and optimization algorithms to maximize the efficiency of our business and minimize risks.,Build, validate, test and deploy predictive models using machine learning techniques to explain or predict behavior and solve a variety of business and engineering problems.","
The Inventory team @WalmartLabs in Hoboken, NJ is dedicated to the mission of creating the best user experience for millions of customers. This team is responsible for all aspects of inventory in stores, ecommerce, and distribution centers. It touches on aspects of physical movement of merchandise, data recording, archival systems, algorithms for replenishment, and website visibility/availability. There are countless opportunities where machine learning can have an impact in being smarter, simpler, and reactive. The end results being a better user experience, and cost efficiencies.
Team members take end-end responsibility in analyzing large amounts of data, creating complex models, improving their accuracy and deploying these models to serve customers. Data must be pulled from many archival systems and stitched together. No two stores are the same, with variability in supply/demand patterns, and service from distribution centers. We seek solutions to problems consisting of 30+million products, across 5000+ stores. As part of this team, you'll solve some of the most fascinating and impactful problems in machine learning.
Your work will be visible to millions of customers and you will have a direct impact on the goals of the Fortune #1 enterprise. If you speak and think machine learning then we want to talk to you. Come join our team and be part of this exciting journey!
Responsibilities:
Predict item availability in stores for online orders
Entire lifecycle of product development from research support to production deployment, monitoring, evaluation, and documentation.
Apply machine learning and optimization algorithms to maximize the efficiency of our business and minimize risks.
Build, validate, test and deploy predictive models using machine learning techniques to explain or predict behavior and solve a variety of business and engineering problems.
Requirements:
Bachelors and 2+ years of experience or Masters degree and 1+ years of experience
Experience and proficiency with Scala
Experience and proficiency with Spark
A deep understanding of machine learning and interest in applying it at scale.
Experience with data cleaning, preparation, and feature building and selection techniques.
Experience working with large data sets to solve problems.
Effective communication, interpersonal and teamwork skills.
Ability to handle multiple concurrent projects while working independently and in teams.
Ability to work in a fast-paced and deadline driven environment.
Bonus:
Experience in hierarchical models, random effect models, and online learning
Imagine working in an environment where one experiment can catapult an entire industry toward a smarter future. That’s what we do at Walmart Labs. We’re a team of 5,000+ software engineers, data scientists, designers and product managers within Walmart, the world’s largest retailer, delivering innovations that improve how our customers shop and our enterprise operates.
",https://careers.walmart.com/us/jobs/GH1973650-big-data-engineer-machine-learning-scala-hoboken-nj
JOB19691318309,Senior Data Engineer - BODS BO Sybase IQ,Senior Data Engineer - BODS BO Sybase IQ,,,"
Would you like to join a great technical team and have the opportunity to develop within Data Services?
I am looking for a Data Engineering professional with significant experience in ETL processes and integration.
In terms of technology, the desirable skill set will be:
4 to 5 years SAP Data Services/ BODS - Mandatory
Business Objects - highly desirable
Sybase IQ - Desirable
SQL expertise - essential
CMC - desirable
If you also have some experience mentoring colleagues and minimal exposure to Qlikview/Tableau/Power BI, this is the ideal role for you.
Get in touch for further details - Apply ASAP
This job was originally posted as
www.cwjobs.co.uk - July 27
",https://www.careerjet.co.uk/clk/77f93ff349b619d1eea9620f34bbfca1.html
JOB20072108373,Big Data Engineer (TELECOM INDUSTRY IN UAE) - Star Services,Big Data Engineer (TELECOM INDUSTRY IN UAE) - Star Services,,,"
<p><p>STAR SERVICES LLC. IS HIRING FOR MAJOR TELECOM Co. OF UAE</p><br /><p>REQUIRED POSITION:<br />1) Big Data Engineer</p><br /><p>PROFILE DESCRIPTION:</p><br /><p>• Ability to setup, configure and maintain a production grade vanilla Hadoop cluster using Hadoop and wire other open source tools to bring up a working Hadoop cluster.<br />• Implementation including loading from disparate data sets, preprocessing using Hive and Pig.<br />• Scope and deliver various Big Data solutions<br />• Ability to design solutions independently based on high-level architecture.<br />• Maintain the Development and production systems (Kafka, Hadoop, Cassandra, Elasticsearch)<br />• Familiarity with Azure Databricks<br />• Design, construct, install, test and maintain data pipelines to ingest data from different source systems.<br />• Develop set processes for data mining, data modeling, and data production.<br />• Collaborate with members of your team (eg, data architects, the IT team, data scientists) on the project’s goals.<br />• Recommend different ways to constantly improve data reliability and quality.</p><br /><p>INTERESTED CANDIDATES MAY APPLY WITH POSITION NAME FROM THE ABOVE REQUIREMENT<br />#TELECOM# IT# software# Big Data Engineer# Hadoop# data scientists # Cloudera # Hortonworks# data architects# data scientists#</p></p><h2>Job Details</h2> <div class=""chart-box""> <table width=""100%"" class=""chart""> <tbody> <tr class=""a"" valign=""top""> <td class=""th"" width=""25%""><b>Posted Date:</b></td> <td width=""75%"">2020-06-28</td> </tr> <tr class=""b"" valign=""top""> <td class=""th"" width=""25%""><b>Job Location:</b></td> <td width=""75%"">Abu Dhabi, United Arab Emirates</td> </tr> <tr class=""a"" valign=""top""> <td class=""th"" width=""25%""><b>Job Role:</b></td> <td width=""75%"">Information Technology</td> </tr> <tr class=""b"" valign=""top""> <td class=""th"" width=""25%""><b>Company Industry:</b></td> <td width=""75%"">Telecommunications</td> </tr> </tbody> </table> </div><h2>Preferred Candidate</h2> <div class=""chart-box""> <table width=""100%"" class=""chart""> <tbody> <tr class=""a"" valign=""top""> <td class=""th"" width=""25%""><b>Career Level:</b></td> <td width=""75%"">Mid Career</td> </tr> <tr class=""b"" valign=""top""> <td class=""th"" width=""25%""><b>Degree:</b></td> <td width=""75%"">Bachelors degree</td> </tr> </tbody> </table> </div>
",http://www.godubai.com/jobs/jobdetails.asp?jid=397204
JOB21889034767,Data Engineer at Prodege LLC,Data Engineer at Prodege LLC,,"Design, build and maintain data loading routines using a variety of tools including open source ETL tools, stored procedures, scripting and programming languages such as Java, C, Python, etc.,Improve the performance and scale of our data operations to deliver information on a real-time basis.,Design, build and maintain data QA routines to ensure that our systems deliver quality information to our customers.,Contribute to the design and architecture of our Enterprise Data Infrastructure.,Work closely with end-users and technical team members on data ingestion projects, investigating and solving data and reporting problems.,5+ years development experience using MySQL, Oracle or other relational database software experience. Experience writing and optimizing complex SQL queries.,5+ years developing back end data processing routines for data warehouses or any backend data system using open source tools, and/or high level languages.,5+ years experience developing database related software using Java, C, C++, etc.,Excellent verbal and written communication skills.,B.S. Computer Science, Math, Physics or equivalent experience.,Knowledge of BI Analytical tools a plus.,Los Angeles Business Journal – Best Places to Work, August 2018, 2017, 2016, 2014 & 2013,The 2016 & 2017 Career Launching Companies, Wealthfront,Inc 500 – Fastest Growing Private Companies,Deloitte’s Technology Fast 500,Los Angeles Business Journal – Fastest Growing Companies,Los Angeles Business Journal– Best Places to Work,President Josef Gorowitz -- Ernst & Young 2014 Entrepreneur of the Year: Los Angeles, Advertising Category,President Josef Gorowitz -- SoCal Tech Top 50 Executives Award 2013,CEO Chuck Davis – Los Angeles Venture Association (LAVA) Hall of Fame Honoree,CFO Brad Kates -- Los Angeles Business Journal: 2014 CFO of the Year, Winner","
Description
Named as one of LA's Best Places to work in 2018, Prodege, LLC, parent company of rewards community Swagbucks.com & cash-back shopping sites MyPoints.com & ShopAtHome.com has awarded over $500 million to its members. Our business solutions brands, ProdegeMR (market research), ProdegeDR (direct response) & ProdegeVN (video network) allow our partners to reach, influence and acquire consumers online.
Join Prodege and help us ""Create Rewarding Moments"" for consumers around the world!
We are currently looking for a Data Engineer to join our team. As a key member of our Technology and Business Intelligence team, this position will:
Design, build and maintain data loading routines using a variety of tools including open source ETL tools, stored procedures, scripting and programming languages such as Java, C, Python, etc.
Improve the performance and scale of our data operations to deliver information on a real-time basis.
Design, build and maintain data QA routines to ensure that our systems deliver quality information to our customers.
Contribute to the design and architecture of our Enterprise Data Infrastructure.
Work closely with end-users and technical team members on data ingestion projects, investigating and solving data and reporting problems.
Skills and experience required:
5+ years development experience using MySQL, Oracle or other relational database software experience. Experience writing and optimizing complex SQL queries.
5+ years developing back end data processing routines for data warehouses or any backend data system using open source tools, and/or high level languages.
5+ years experience developing database related software using Java, C, C++, etc.
Excellent verbal and written communication skills.
B.S. Computer Science, Math, Physics or equivalent experience.
Knowledge of BI Analytical tools a plus.
Our Accolades:
Los Angeles Business Journal – Best Places to Work, August 2018, 2017, 2016, 2014 & 2013
The 2016 & 2017 Career Launching Companies, Wealthfront
Inc 500 – Fastest Growing Private Companies
Deloitte’s Technology Fast 500
Los Angeles Business Journal – Fastest Growing Companies
Los Angeles Business Journal– Best Places to Work
President Josef Gorowitz -- Ernst & Young 2014 Entrepreneur of the Year: Los Angeles, Advertising Category
President Josef Gorowitz -- SoCal Tech Top 50 Executives Award 2013
CEO Chuck Davis – Los Angeles Venture Association (LAVA) Hall of Fame Honoree
CFO Brad Kates -- Los Angeles Business Journal: 2014 CFO of the Year, Winner
CTO Shane O’Neill -- Los Angeles Business Journal: 2014 CIO of the Year, Finalist
",https://www.builtinla.com/job/data/data-engineer/44152
JOB22028017809,Data Engineer,Data Engineer,Performs other duties as assigned.,"Design, Develop, and unit test new or existing Data Integration solutions to meet business requirements.,Participate in troubleshooting and resolving data integration issues such as data quality.,Conduct exploratory data analysis & model prototyping using Spark/Python/SQL,Perform data sourcing, integrating, mining and modeling to produce insights, predictions, and forecasts, in collaboration with domain experts across a variety of disciplines.,Responsible for selecting and using DevOps tools for continuous integration, builds, and monitoring of solutions.,Deliver increased productivity and effectiveness through rapid delivery of high-quality applications.,Provide work estimates and communicate status of assignments.,Assist in QA efforts on tasks by providing input for test cases and supporting test case execution.,Analyze transaction errors, troubleshoot issues in the software, develop bug-fixes, involved in performance tuning efforts.,Experience in developing Informatica/Mulesoft Mappings and complex Oracle PL/SQL programs for the Data Warehouse.,Makes some independent decisions and recommendations which affect the section, department and/or division.,Manage complex API portfolio.,Participates and provides input to area budget. Works within financial objectives/budget set by management.,Develops alternative solutions for decision-making which support organizational goals/objectives and budget constraints.,Identifies project growth and integration challenges and helps with budgeting and strategic planning.,Makes strategic contributions about designing enterprise integration solutions with Anypoint Platform.,Operates with substantial latitude for independent action in setting objectives and deciding how to proceed.,This is the highest level subject matter/technical expert and may include limited supervisory responsibilities.,Works with minimum supervision, conferring with superior on unusual matters. Incumbents have considerable freedom to decide on work priorities and procedures to be followed.,Provide reporting and analytics functionality to monitor API usage and load (overall hits, completed transactions, number of data objects returned, amount of compute time and other internal resources consumed, volume of data transferred).,Provide leadership for API-based monetization functionality to support charging for access to commercial APIs and/or the services the API enable.","
We are engineers, high line workers, power plant managers, accountants, electricians, project coordinators, risk analysts, customer service operators, community representatives, safety and security specialists, communicators, human resources partners, information technology technicians and much, much more. We are 3,300 people committed to enhancing the lives of the communities we serve. Together, we are powering the growth and success of our community progress every day!
Exciting opportunity to design, develop, and unit test new or existing Data Integration solutions.
GRADE: 16
DEADLINE TO APPLY: Monday, December 17th, 2018
Position Summary
Provide the development and automation of computing processes to detect, predict and respond to opportunities in business operations. Working with a variety of disparate datasets that encompass many disciplines and business units including weather, transmission and distribution grid infrastructure, power generation, gas delivery, commercial market operations, safety and security and customer engagement. Strive to transform and implement true business integration, leveraging top-notch data integration best practices. Merging and securing data in a way that reduces the cost to maintain and increases the utilization of enterprise-wide data as an asset. Developing business intelligence.
Tasks and Responsibilities
Design, Develop, and unit test new or existing Data Integration solutions to meet business requirements.
Participate in troubleshooting and resolving data integration issues such as data quality.
Conduct exploratory data analysis & model prototyping using Spark/Python/SQL
Perform data sourcing, integrating, mining and modeling to produce insights, predictions, and forecasts, in collaboration with domain experts across a variety of disciplines.
Responsible for selecting and using DevOps tools for continuous integration, builds, and monitoring of solutions.
Deliver increased productivity and effectiveness through rapid delivery of high-quality applications.
Provide work estimates and communicate status of assignments.
Assist in QA efforts on tasks by providing input for test cases and supporting test case execution.
Analyze transaction errors, troubleshoot issues in the software, develop bug-fixes, involved in performance tuning efforts.
Experience in developing Informatica/Mulesoft Mappings and complex Oracle PL/SQL programs for the Data Warehouse.
Makes some independent decisions and recommendations which affect the section, department and/or division.
Manage complex API portfolio.
Participates and provides input to area budget. Works within financial objectives/budget set by management.
Develops alternative solutions for decision-making which support organizational goals/objectives and budget constraints.
Identifies project growth and integration challenges and helps with budgeting and strategic planning.
Makes strategic contributions about designing enterprise integration solutions with Anypoint Platform.
Operates with substantial latitude for independent action in setting objectives and deciding how to proceed.
This is the highest level subject matter/technical expert and may include limited supervisory responsibilities.
Works with minimum supervision, conferring with superior on unusual matters. Incumbents have considerable freedom to decide on work priorities and procedures to be followed.
Provide reporting and analytics functionality to monitor API usage and load (overall hits, completed transactions, number of data objects returned, amount of compute time and other internal resources consumed, volume of data transferred).
Provide leadership for API-based monetization functionality to support charging for access to commercial APIs and/or the services the API enable.
Performs other duties as assigned.
CPS Energy
145 Navarro
San Antonio
Texas United States
www.cpsenergy.com
From the same organization
",http://electricenergyonline.com/job/opportunity/energy/183953/cps-energy/engineer/texas/data-engineer.html
JOB22757495086,BI DATA ENGINEER,BI DATA ENGINEER,,,"
Company: NEORIS
Sorry, this position has been filled.
",https://careers.neoris.com/job/MADRID-BI-DATA-ENGINEER-ISBAN/3080919/
JOB23666243087,"Application for Senior Data Engineer, Cloud","Application for Senior Data Engineer, Cloud",,,"
Application for Senior Data Engineer, Cloud
Complete this form to apply for this job and upload your resume. Please note that there is a file upload limit of 1MB.
",https://secure2.sophos.com/pl-pl/about-us/careers/united-states/senior-data-engineer-cloud/apply.aspx
JOB26858184615,Data Engineer at Havenly,Data Engineer at Havenly,,"Develop a highly scalable, reliable, and real-time data processing pipeline.,Partner with the Data Science team to provide data infrastructure for a variety of projects.,Enable data science/analytics team to write new transformations in infrastructure managed by data engineering.,Design, build and launch new ETL processes into production.,Work with data infrastructure to triage issues and drive to resolution.,Work with our entire team to help provide a consistent, fast, and delightful experience to our customers and designers.,BS/MS in Engineering, Computer Science, Math, Physics, or equivalent work experience.,5 or more years in a Data Engineering role.,5+ years experience with Python or Java development.,Experience with modern data platforms (Spark, Hadoop/Map Reduce, Hive, Airflow, Kafka/Kinesis),Experience with Docker and Kubernetes,Experience with machine learning frameworks Tensorflow and Keras,Experience analyzing data to identify deliverables, gaps and inconsistencies.,Experience working cross-functionally to communicate data plans that address business challenges.,Ability to develop and scale ETL pipelines.,Expertise with SQL, databases management, and best practices.,A true team player. You enjoy collaborating, learning from or teaching others so we can all become better developers.,A great communicator - You have excellent communication skills and enjoy working in cross-functional group settings.,Startup Savvy - You want to work hard and build something great, and have the ability to learn and adapt in a rapidly changing environment.,A challenging opportunity, and a great team to work beside,A data driven environment where your insights and expertise will be valued,An environment where you can move fast, work hard, see results, and feel your impact,An opportunity to get in on the ground floor of a successful startup","
Havenly is looking for an experienced Data Engineer to work in our Denver HQ. In this role, you’ll work closely with our Data Scientists, Product Managers, and Engineers to figure out ways to optimize the core user, designer, and e-commerce experience - all using massive amounts of data. In this role, you will see a direct link between your work, company growth, and user satisfaction.You’ll get the opportunity to solve some of our most challenging business problems that will unlock huge areas of opportunity for the business.
We’re making the delight of a beautiful home accessible for everyone, and we would love your help in doing so. If you’re interested in tackling big challenges, working hard, and creating success at a top funded consumer startup in Denver, this might be the job for you.
What You’ll Do:
Develop a highly scalable, reliable, and real-time data processing pipeline.
Partner with the Data Science team to provide data infrastructure for a variety of projects.
Enable data science/analytics team to write new transformations in infrastructure managed by data engineering.
Design, build and launch new ETL processes into production.
Work with data infrastructure to triage issues and drive to resolution.
Work with our entire team to help provide a consistent, fast, and delightful experience to our customers and designers.
What You'll Bring
BS/MS in Engineering, Computer Science, Math, Physics, or equivalent work experience.
5 or more years in a Data Engineering role.
5+ years experience with Python or Java development.
Experience with modern data platforms (Spark, Hadoop/Map Reduce, Hive, Airflow, Kafka/Kinesis)
Experience with Docker and Kubernetes
Experience with machine learning frameworks Tensorflow and Keras
Experience analyzing data to identify deliverables, gaps and inconsistencies.
Experience working cross-functionally to communicate data plans that address business challenges.
Ability to develop and scale ETL pipelines.
Expertise with SQL, databases management, and best practices.
The desire to always leave code better than you found it.
Who you are:
A true team player. You enjoy collaborating, learning from or teaching others so we can all become better developers.
A great communicator - You have excellent communication skills and enjoy working in cross-functional group settings.
Startup Savvy - You want to work hard and build something great, and have the ability to learn and adapt in a rapidly changing environment.
Innately curious - You have a thirst for new knowledge, and are curious to the core. You are excited about digging in, and tackling new things, and are constantly wondering why or how to make things better or different.
What we offer:
A challenging opportunity, and a great team to work beside
A data driven environment where your insights and expertise will be valued
An environment where you can move fast, work hard, see results, and feel your impact
An opportunity to get in on the ground floor of a successful startup
Salary, benefits, and design services - Have a room that needs some love? We got you!
At Havenly we hire people who exhibit gumption, act like owners, outperform, and are always playful. If this sounds like a great fit for you, and a challenge you're ready to run with, we want to hear from you.
",https://www.builtincolorado.com/job/data/data-engineer/48647
JOB27026817944,Data Engineer (MOJ Clearance),Data Engineer (MOJ Clearance),,," MSL Recruitment are proud to be recruiting for one of our major data and IT clients.
We require Data Engineers with current MOJ Clearance to start on a 4 month project in Leeds.
Job Description:
• Installing CAT6 Data Cabling
• Terminating CAT6 Patch Panels
• Terminating CAT6 Floor Boxes and CAT6 GOP Boxes or Wall Outlets
• Testing CAT6 Structured Cabling using a Fluke tester.
• Labelling data cables, patch panels and floor outlets
• Carrying out any tasks as requested by our client on site.
Location: Leeds
Duration: 4 months
Working Hrs: Monday – Friday 08:00 – 17.00
Hourly Rate: GBP16.50
For this role, you'll need the following:
• MOJ Clearance (must be valid and provide details of who holds it)
• CSCS Card
• All hand tools and terminating tools (110 punch down, Krone Tool,
ModTap tester.
• Full 5 Point PPE (safety boots, yellow high vis jacket, hard hat, goggles &
gloves.
If you are available for this role then please call MSL Recruitment on (Apply online only) and ask for Harry.
Please also like our Facebook page and follow us on social media for all our latest job vacancies and construction industry news
",https://jobs.telegraph.co.uk/job/6762950/data-engineer-moj-clearance-/
JOB32013013312,Data Engineer - 6 Month Renewable Contract,Data Engineer - 6 Month Renewable Contract,,,"
Description
Data Engineer - 6 Month Renewable Contract
The Role The role focuses in operations of data and analytics platform, Data Ingestion, ETL Jobs Monitoring, Big Data Server and Application Operation. It requires a demonstrated ability for complex data ingestion, extraction, operational validation and monitoring. Client Details Michael Page D...
Organisation : Michael Page
Other Similar Jobs
",http://www.godubai.com/jobs/jobdetails.asp?jid=377129
JOB33412301384,Sr Developer - Data Engineer,Sr Developer - Data Engineer,"Bachelor Degree and 4 years Information Technology experience OR Technical Certification and/or College Courses and 6 years Information Technology experience OR 8 years Information Technology experience.,Proficiency in domain driven design and domain modeling.,Experience with NoSql solutions, such as Gemfire, Cassandra, HBase,Distributed Caching,Experience with any relational database system, such as (but not limited to) MySQL, SQL Server, Oracle, or PostgreSQL,Communicate in written and verbal form effectively,CI/CD tools, such as Jenkins, Concourse and Ansible,CA",,"Description:
As the health care industry continues to rapidly transform, our IT team conceives, develops and delivers impactful technology solutions to support access to quality, affordable health care for our members. We are driven by our collective company purpose: To do everything in our power to stand with our members in sickness and in health. Our IT team unleashes the power of this purpose through technology. We come to work every day to make a difference, and we deliver the highest quality and best solutions to our members.
Job Purpose:
In this role, you will be part of the Digital XP Team whose vision is to help API product teams adopt a modern data architecture. In addition to exploring new data technologies and practices, responsibilities would include design/model, performance tuning, troubleshooting and lifecycle management of current data solutions
Other functions include:
Required Job Qualifications:
Bachelor Degree and 4 years Information Technology experience OR Technical Certification and/or College Courses and 6 years Information Technology experience OR 8 years Information Technology experience.
Experience with following tech/environments:
Proficiency in domain driven design and domain modeling.
Experience with NoSql solutions, such as Gemfire, Cassandra, HBase
Distributed Caching
Experience with any relational database system, such as (but not limited to) MySQL, SQL Server, Oracle, or PostgreSQL
Communicate in written and verbal form effectively
CI/CD tools, such as Jenkins, Concourse and Ansible
CA
HCSC is committed to diversity in the workplace and to providing equal opportunity and affirmative action to employees and applicants. We are an Equal Opportunity Employment / Affirmative Action employer dedicated to workforce diversity and a drug-free and smoke-free workplace. Drug screening and background investigation are required, as allowed by law. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or protected veteran status.
BCBSTX complies with applicable Federal civil rights laws and does not discriminate on the basis of race, color, national origin, age, disability, or sex.
",https://illinoisjoblink.illinois.gov/ada/r/jobs/6001811
JOB35924808060,Data Engineer - Start up,Data Engineer - Start up,,,"
Careers by Category
- Select a Job Category - Accounting / AuditArchitecture / DesignAuto IndustryAviationBanking / FinanceBeauty / Health / FitnessCatering/Food Services/RestaurantsComputer ProgrammerConstruction / CivilConsulting / Senior LevelCustomer Service / SecretaryEducation / Teaching / TrainersEngineeringEntertainmentFMCGGeneral TradingGovernmentHospitality / Tourism / TravelHuman ResourceInsuranceIT / Graphic DesignersIT SoftwareLegalLogistic / Shipping / TransportationMaintenance / OperationsManufacturing / ProductionMarketing / Public RelationsMedia / AdvertisingMedical/Healthcare/PharmaceuticalNon-ProfitOil / PetroleumOthersProfessional ServicesPublishingReal Estate / Property ServicesRetail / WholesaleSales / Business DevelopmentSecuritySteward/Cabin Crew/PilotTechnical / SkilledTelecommunicationTop ManagementUnSkilled Search for
Job Details
SCALA Engineer
Description
SCALA Engineer
The Role Should have competence in most of the below : • Scala Content Manager Maintenance • Scala Design • Scala Server Installation and configuration • Scala Server Maintenance . • Scala Server Database installation and configuration • Scala Server Database Maintenance Requirements...
Contact:
Organisation : Saudi Networkers Services (SNS Group)
Other Similar Jobs
Job Title
Location
",http://www.godubai.com/jobs/jobdetails.asp?jid=381663
JOB37573543410,Sr. Enterprise Data Engineer,Sr. Enterprise Data Engineer,"All persons employed by the Baltimore County Public Schools, regular and temporary, are required to be fingerprinted and have a criminal background investigation (State of Maryland, Senate Bill 315, effective October 1, 1986) completed. The fee charged for fingerprinting is $81.00. An identification card will be issued which must be shown prior to employment.,Anyone offered employment is required to provide proper identification and documentation of eligibility for employment in the US.,If you have military experience you will be asked to provide a copy of DD214.,Official transcripts for all higher education must be received prior to contract signing.,Some positions will require employees to undergo a physical examination and/or drug testing.,All newly hired personnel must attend a Badges and Benefits session.,Additional job verification will be required for salary credit.","Collaborate with product owners and stakeholders to plan and define requirements. Translate business requirements into business value and assist in supporting leadership and project managers to establish priorities and meeting timelines.,Represent the Data Warehouse team at meetings and events, which may include preparing and delivering presentations in front of a large group.,Supports the Data Governance Committee by attending meetings, acting as a subject matter expert, working with workgroups to solve problems, providing input into BCPS policies and rules, and representing the Data Warehouse team.,Responsible for implementing and following data warehouse best practices and development processes, including conceptual/logical/physical dimensional data modeling, data flow diagrams, design scalability for the future, ETL architecture, source to target mappings, automation through ETL and stored procedures, data validation, quality assurance, and monitoring/alerting.,Lead data model and ETL design review sessions with team members and provide feedback. Approve the release of changes to the production data warehouse. Ensure all data models, dictionaries, and metadata are maintained.,Meets regularly with leadership and the project manager to provide input and feedback on project level of effort, feasibility, timelines, issues, and project status. Advises leadership on issues, including resolution. Participate in and contribute to daily stand-up and project planning meetings.,Collaborate daily with developers to ensure data availability and structure meet the needs of the report or data visualization.,Create SQL scripts to extract data from the data warehouse to support data analysis or fulfill an ad hoc data request.,Ensure the stability of the BCPS Enterprise Data Warehouse through monitoring, performance tuning, disaster recovery planning, new installations, patching, upgrading, storage planning, issue resolution, and collaboration with vendors and the Department of Information Technology. Escalate issues and risks as needed.,Oversee the data security architecture to ensure student and employee data privacy guidelines are met. Work closely with Network Administrators to define and maintain Windows AD groups used to establish access to business intelligence systems.,Evaluate and recommend new and emerging technologies that will enhance the ability of the team to produce quality output to include evaluating vendor products, reviewing publications, interviewing vendors, researching reviews and competitors, negotiating pricing, and providing a summary to leadership. May participate in a request for proposal (RFP) process.,Performs other duties as assigned.,Graduation from an accredited college with a bachelor's degree in Computer Science, Information Systems, Engineering, or related field.,Five years' hands-on experience designing, architecting, and implementing enterprise scale data warehouses, data marts, ETL architecture and code, and SQL code/stored procedures.,Experience in K-12 education preferred.,Thorough knowledge of the infrastructure and architecture required to build and maintain an enterprise data warehouse that integrates multiple disparate data sources on a Microsoft SQL Server platform.,Familiarity with data visualization tools like Tableau, Cognos, and Microsoft BI Suite and how the data warehouse supports their solutions.,Understanding of information systems and data life-cycle management best practices and methodologies, and systems development life cycle (SDLC).,Proficient in ETL using Microsoft SSIS and SQL programming including stored procedures/views/functions. VB/C# scripting for enhanced automation is a plus.,Hands-on experience in Kimball dimensional data modeling and master data management. Strong experience with one or more recognized data modeling tools like ER Studio or ERwin.,Ability to work on multiple projects simultaneously and adhere to deadlines while working in a fast past environment using agile project management methodologies.,Ability to work in a team environment and mentor other team members.,Excellent communication skills?.,Applicants are required to have a completed application on file for employment with the Baltimore County Public Schools, and a separate completed application must be submitted for each position and location in which you are interested.,Professional references must be submitted to complete your application. Examples of professional references include current and former principals, supervisors, managers, mentor teachers and university/college supervisors. Personal references from colleagues, friends, community members, etc. will not be accepted.,Be sure to account for all periods of employment and unemployment, including school psychology practicum and school psychology internship experience, and include names, addresses, and telephone numbers of employers.,Be sure to answer all criminal background questions. If you answer ""yes"" to any of the criminal background questions you must provide a written explanation. A criminal offense does not necessarily exclude an applicant from employment with BCPS. Factors such as passage of time since the offense, the nature of the violation, and the extent of rehabilitation will be taken into consideration."," BALTIMORE COUNTY PUBLIC SCHOOLS
CLASS TITLE : Sr. Enterprise Data Engineer
REPORTS TO : Coordinator of Data Warehouse
DEFINITION : Leads the end-to-end vision and implementation of the BCPS Enterprise Data Warehouse to ensure the delivery of meaningful data analysis, reports, and visualizations to meet BCPS' mission and vision set forth in Blueprint 2.0. Oversees aspects of the BCPS Enterprise Data Warehouse including data acquisition, data modeling, ETL, storage, security, archiving, and recovery. Mentors other team members. Performs other duties as assigned.
EXAMPLES OF DUTIES :
Collaborate with product owners and stakeholders to plan and define requirements. Translate business requirements into business value and assist in supporting leadership and project managers to establish priorities and meeting timelines.
Represent the Data Warehouse team at meetings and events, which may include preparing and delivering presentations in front of a large group.
Supports the Data Governance Committee by attending meetings, acting as a subject matter expert, working with workgroups to solve problems, providing input into BCPS policies and rules, and representing the Data Warehouse team.
Responsible for implementing and following data warehouse best practices and development processes, including conceptual/logical/physical dimensional data modeling, data flow diagrams, design scalability for the future, ETL architecture, source to target mappings, automation through ETL and stored procedures, data validation, quality assurance, and monitoring/alerting.
Lead data model and ETL design review sessions with team members and provide feedback. Approve the release of changes to the production data warehouse. Ensure all data models, dictionaries, and metadata are maintained.
Meets regularly with leadership and the project manager to provide input and feedback on project level of effort, feasibility, timelines, issues, and project status. Advises leadership on issues, including resolution. Participate in and contribute to daily stand-up and project planning meetings.
Collaborate daily with developers to ensure data availability and structure meet the needs of the report or data visualization.
Create SQL scripts to extract data from the data warehouse to support data analysis or fulfill an ad hoc data request.
Ensure the stability of the BCPS Enterprise Data Warehouse through monitoring, performance tuning, disaster recovery planning, new installations, patching, upgrading, storage planning, issue resolution, and collaboration with vendors and the Department of Information Technology. Escalate issues and risks as needed.
Oversee the data security architecture to ensure student and employee data privacy guidelines are met. Work closely with Network Administrators to define and maintain Windows AD groups used to establish access to business intelligence systems.
Evaluate and recommend new and emerging technologies that will enhance the ability of the team to produce quality output to include evaluating vendor products, reviewing publications, interviewing vendors, researching reviews and competitors, negotiating pricing, and providing a summary to leadership. May participate in a request for proposal (RFP) process.
Performs other duties as assigned.
MINIMUM QUALIFICATIONS :
Education, Training, and Experience :
Graduation from an accredited college with a bachelor's degree in Computer Science, Information Systems, Engineering, or related field.
Five years' hands-on experience designing, architecting, and implementing enterprise scale data warehouses, data marts, ETL architecture and code, and SQL code/stored procedures.
Experience in K-12 education preferred.
Note: Other combination of applicable education, training, and experience which provide the knowledge, skills and abilities necessary to perform effectively in the position, may be considered.
Knowledge, Skills, and Abilities :
Thorough knowledge of the infrastructure and architecture required to build and maintain an enterprise data warehouse that integrates multiple disparate data sources on a Microsoft SQL Server platform.
Familiarity with data visualization tools like Tableau, Cognos, and Microsoft BI Suite and how the data warehouse supports their solutions.
Understanding of information systems and data life-cycle management best practices and methodologies, and systems development life cycle (SDLC).
Proficient in ETL using Microsoft SSIS and SQL programming including stored procedures/views/functions. VB/C# scripting for enhanced automation is a plus.
Hands-on experience in Kimball dimensional data modeling and master data management. Strong experience with one or more recognized data modeling tools like ER Studio or ERwin.
Ability to work on multiple projects simultaneously and adhere to deadlines while working in a fast past environment using agile project management methodologies.
Ability to work in a team environment and mentor other team members.
Excellent communication skills?.
PHYSICAL AND ENVIRONMENTAL CONDITIONS :
The work of this position is generally sedentary with occasional walking, standing, and other limited physical activities.
CONDITIONS OF EMPLOYMENT :
Persons appointed to this classification are designated as Essential-As-Needed Personnel and are required to work when schools and/or offices are closed during adverse weather conditions or any other emergency when contacted and directed to do so.
Employees may be required to work beyond their normally scheduled hours with little or no advanced notice.
SALARY: Grade 08 on the OPE 12 Month Pay Scale ($78,942-$122,044)
FLSA : Exempt
This position is eligible for the Baltimore County Employees' Retirement System
This class specification defines the types of duties and level of difficulty of work required of positions in this title. It shall not be held to exclude duties not mentioned nor limit the right of management to assign work to employees.
Citizenship, residency or work VISA in United States required
Application Instructions
Please read and carefully follow the instructions provided below.
Applicants are required to have a completed application on file for employment with the Baltimore County Public Schools, and a separate completed application must be submitted for each position and location in which you are interested.
Professional references must be submitted to complete your application. Examples of professional references include current and former principals, supervisors, managers, mentor teachers and university/college supervisors. Personal references from colleagues, friends, community members, etc. will not be accepted.
Be sure to account for all periods of employment and unemployment, including school psychology practicum and school psychology internship experience, and include names, addresses, and telephone numbers of employers.
Be sure to answer all criminal background questions. If you answer ""yes"" to any of the criminal background questions you must provide a written explanation. A criminal offense does not necessarily exclude an applicant from employment with BCPS. Factors such as passage of time since the offense, the nature of the violation, and the extent of rehabilitation will be taken into consideration.
Pre-Employment Requirements:
All persons employed by the Baltimore County Public Schools, regular and temporary, are required to be fingerprinted and have a criminal background investigation (State of Maryland, Senate Bill 315, effective October 1, 1986) completed. The fee charged for fingerprinting is $81.00. An identification card will be issued which must be shown prior to employment.
Anyone offered employment is required to provide proper identification and documentation of eligibility for employment in the US.
If you have military experience you will be asked to provide a copy of DD214.
Official transcripts for all higher education must be received prior to contract signing.
Some positions will require employees to undergo a physical examination and/or drug testing.
All newly hired personnel must attend a Badges and Benefits session.
Additional job verification will be required for salary credit.
NON-DISCRIMINATION STATEMENT
The Board of Education of Baltimore County does not discriminate on the basis of race, color, religion, sex, national origin, age, marital status, sexual orientation, gender identity, genetic information, disability, or veteran status in matters affecting employment or in providing access to educational programs or activities and provides equal access to the Boy Scouts and other designated youth groups. Inquiries regarding the Board's nondiscrimination policies should be directed to: EEO Officer, Office of Equal Employment Opportunity, Baltimore County Public Schools, 6901 Charles Street, Building B, Towson, Maryland 21204 (443-809-8937). There is a compliance officer responsible for identifying, preventing, and remedying prohibited harassment concerning students. Complaints of harassment should be directed to the executive director, Department of School Safety and Security, 9610 Pulaski Park Drive, Suite 219, Baltimore, Maryland 21220 (443-809-4360).
Contact Information
Michael Hodge
Supervisor, HR Staffing
6901 Charles Street, E Building
Towson, Maryland 21204
Phone: 443-809-7872
Fax: 410-887-7876
Email: mhodge@bcps.org
",https://www.topschooljobs.org/job/883337/sr-enterprise-data-engineer/
JOB37956059774,Data Engineer - RBG,Data Engineer - RBG,,,"Click the Facebook, Google+ or LinkedIn icons to share this job with your friends or contacts. Click the Twitter icon to tweet this job to your followers. Click the link button to view the URL of the job, which then can be copied and pasted into an e-mail or other document.
Description
Position Description:
Position Summary: The Data Engineer is responsible for designing, developing, and supporting data management solutions. The position will develop data models, perform data analysis, construct technical designs, develop data integration solutions, collaborate with team members and business stakeholders, and support existing data solutions. This position will also lead and coordinate the work activities of offshore development and support resources.
People or Process Management Responsibility: Works on multiple, complex projects as technical lead and coordinates the work of other technical BI resources.
Position Responsibilities may include, but not limited to:
+ Responsible for the solution architecture, design, development, and support of data management applications
+ Drive data sourcing and integration solution design and development on hybrid (cloud & on-prem) data solutions
+ Perform data analysis and architect data models for analytics
+ Providing guidance and direction to offshore ETL support/development resources
+ Collaborate with cross functional teams such as Infrastructure, Support, DBA and Business team
+ Assist with task identification and effort estimates for ETL development
+ Assist with risk and issue identification and resolution
+ Provide off-hour/weekend ETL support (on a rotating basis)
+ Other duties as assigned
Position Requirements:
Position Requirements: Minimum Requirements :
+ 4 year degree in Computer Science, Information Systems
+ 5+ years of relevant Business Intelligence/Data Warehousing/Data Integration work experience
+ 4+ years of Hands-on experience developing data management solutions using MSBI (SSIS)
+ 2+ years Data modelling (logical/physical, relational and document/object) and 2+ years of Data Integration solution design experience
+ 1-3 years of developing solutions using Windows Server OS
+ Strong understanding of Dimensional Modeling techniques
+ Experience leading other developers
+ Strong written and verbal communication skills
+ Strong problem solving and analytical skills
+ Strong understanding of SDLC best practices with an emphasis on DW/BI practices
+ This position must pass a post-offer background and drug test
Preferred:
+ Experience with one of the ETL tools – MS SSIS, Informatics on SQL Server DB
+ 1+ year of Public cloud experience (Azure, AWS)
+ Proficiency in scripting languages such as Power Shell
+ 1+ year of experience leveraging Cloud Services (IaaS, PaaS)
+ 1+ year hands-on development experience using open source data integration tool such as Talend, Azure Data Factory
+ Experience leading offshore resources
+ ITIL certification
+ Experience in Agile (SCRUM) and Waterfall methodologies
+ Distribution and Logistics Industry experience
Physical Demands and Work Environment:
The physical demands and work environment characteristics described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
Due to the nature of our business in regard to such things as delivery schedules, order inputs, selection, and Department of Transportation Hours of Service; overtime, attendance and punctuality are essential job functions. Should an individual in this classification not be able to adhere to this requirement due to a disability, they should contact their Human Resource department to see what, if any, reasonable accommodation may be made.
As an Equal Opportunity Employer, Reyes Holdings companies will recruit and select applicants for employment solely on the basis of their qualifications. Our Practices and Procedures, including those relating to wages, benefits, transfers, promotions, terminations and self-development opportunities, will be administered without regard to race, color, religion, sex, sexual orientation and gender identity, age, national origin, disability, or protected veteran status and all other classes protected by the Federal and State Government. Drug Free Employer.
To view full details and how to apply, please login or create a Job Seeker account.
",https://illinoisjoblink.illinois.gov/ada/r/jobs/5980064
JOB40296158656,Data Engineer in Barcelona,Data Engineer in Barcelona,"Fluent in English,3+ years experience working with Java, Scala or any other Object Oriented language,Strong Object-Oriented experience, and a true passion for writing high-quality code,Experience with quick prototyping and ability to work in a dynamic environment,Experience with NoSQL databases (MongoDB, etc…),Experience with API-based architecture,Experience with distributed framework for parallel processing such as Hadoop, Pig, Spark and Hive,Strong experience with Java or Scala is a plus,Experience with large scale data/distributed systems,Ability to work independently while being a strong part of the team,Experience with real-time applications is a plus,Very attractive compensation package including equity,Have a real impact,Awesome work environment at a company with a huge vision,Be right there from the start of a success story,Relaxed, fun work environment and flexible working hours,Extras like catered lunch, gym membership,private health insurance…","Shape a solid data infrastructure that collects, stores, processes and serves massive amounts of information,Work with spatial information and build leverageable solutions that our Data Viz team will use to create powerful visualizations of a city’s deliveries,Dive deep into the core of large scale data processing systems and produce high-quality code that can help answer questions from the business, operations and clients side"," Data Engineer in Barcelona Stuart Category
Data Engineer
Industry
Logistics Industry
Salary
Undisclosed salary
Workplace
Onsite
Hours
Full-Time
Internship
No
Skills
Nodejs Java Spark Scala MongoDB Hive Hadoop
Share offer
Job Description
Stuart is the disruptive on-demand urban logistics platform that will transform our daily lives. Our technology allows businesses big and small in every industry to deliver to their local customers with never-before-seen speed and efficiency. We create thousands of economic opportunities for businesses and courier partners whilst redefining customer expectations when it comes to delivery.
Led by Clément Benoit and Benjamin Chemla, the founders of two successful, international delivery businesses, and supported by 22M€ in funding led by Le Groupe La Poste, Stuart began operating in Paris mid-2015. Earlier this year we launched London and Barcelona, with many more cities across Europe in the pipeline for 2016.
We’re looking for a talented for a Data Engineer who will play a critical role in our expansion in Europe. Your mission will be to build the data architecture that will power our data-driven product as we deliver things. Based in our office in sunny Barcelona , you will be joining a growing team of successful entrepreneurs and alumni from Uber, Yahoo and BCG.
What will you do?
Shape a solid data infrastructure that collects, stores, processes and serves massive amounts of information
Work with spatial information and build leverageable solutions that our Data Viz team will use to create powerful visualizations of a city’s deliveries
Dive deep into the core of large scale data processing systems and produce high-quality code that can help answer questions from the business, operations and clients side
Be part of a team of talented engineers that makes Stuart the best delivery platform for businesses in a highly competitive market
Requirements Who are you?
Fluent in English
3+ years experience working with Java, Scala or any other Object Oriented language
Strong Object-Oriented experience, and a true passion for writing high-quality code
Experience with quick prototyping and ability to work in a dynamic environment
Experience with NoSQL databases (MongoDB, etc…)
Experience with API-based architecture
Experience with distributed framework for parallel processing such as Hadoop, Pig, Spark and Hive
Strong experience with Java or Scala is a plus
Experience with large scale data/distributed systems
Ability to work independently while being a strong part of the team
Experience with real-time applications is a plus
Experience with geospatial data is a plus
Benefits The icing on the cake?
Very attractive compensation package including equity
Have a real impact
Awesome work environment at a company with a huge vision
Be right there from the start of a success story
Relaxed, fun work environment and flexible working hours
Extras like catered lunch, gym membership,private health insurance…
We want you to take on a role you love and we want to offer you a place you’re proud and happy to come to everyday.
If you feel like this role could be a good fit, hit the button and apply. We'd love to hear more about you.
Apply on company website LinkedIn login required
Cancel
I want to get introduced to top companies seeking for profiles like mine.
Offer not available? Let us know!
Otros empleos que te pueden interesar
Purchasing Engineer
binternational - Barcelona, Barcelona
hace 10 días
Data Engineer
CAPITOLE CONSULTING - Barcelona, Barcelona
hace 7 días
Data Engineer
eDreams ODIGEO - Barcelona, Barcelona
edreams - hace 8 días
Data Engineer
OPM Recruitment - Barcelona, Barcelona
hace 18 días
Data Engineer (Barcelona)
Stuart - Barcelona, Barcelona
hace 30+ días
","https://www.indeed.es/empleo/Data-engineer-para-Stuart-en-Barcelona,-Barcelona-8181f8d12e0ce529"
JOB40450048601,Senior Data Engineer,Senior Data Engineer,A good understanding of and adherence to data security standards,"Bachelors degree in IT, or similar experience,Extensive experience in??data integration and a year data orchestration experience with Microsoft Azure,In-depth experience of designing and implementing data flows and pipelines,3+??years’ experience as a Data Engineer is highly desirable,Comfortable being hands on with data, data modelling, query techniques,Background in the Data management Space","Click the Facebook, Google+ or LinkedIn icons to share this job with your friends or contacts. Click the Twitter icon to tweet this job to your followers. Click the link button to view the URL of the job, which then can be copied and pasted into an e-mail or other document.
XX
This Role can be based in Chicago, IL or Mount Olive, NJ
This is an exciting time at Mars. We?re using digital, data and user insights to transform our business by finding answers to problems that we?ve often never asked ourselves before. From joining the dots to improve our Petcare data ecosystem, to streamlining the efficiency and automation of our supply chain and quality operations, we?re already seeing some brilliant results. In fact, we?ve built so much momentum that we?re now looking for industry leaders in Business Translation, Data Science and Data Engineering with different and complementary skills to influence how we operate and grow beyond anything we?ve achieved before. Join us, and discover a company set up to develop your capabilities and ambitions and a group of colleagues ready to support and inspire you. Working together, we???ll create a better world for our planet, our communities and our pets.
What you???ll do
Keeping the data flowing and readily available to solve problems as and when they need solving is core to what you?ll do. You might do that through Agile sprints or self-service analytics – it?s up to you. The day-to-day? You?ll be working within a sprint team building both new data pipelines and establishing or improving new platform capabilities. Without people in this crucial role treating data as an asset, we won?t be able to become the business we want to be.
Working in a small Agile team alongside Global Analytics, Data, Source Systems, Business Translation and Integration colleagues, you?ll partner with Product Owners to establish and maintain the data pipelines (ETL/Batch/Streaming) within and between different technology platforms, such as SAP/SAP BW and Microsoft Azure. You?ll also work closely with users from our segments and markets around the world as part of SCRUM teams. This exposure will also give you the exciting opportunity to influence and contribute true ?firsts?. That?s new and emerging approaches that Mars, and maybe even the industry, hasn?t seen before.??
Data integration, orchestration and automation ? you?ll build data flow components of MVP analytic solutions. And you?ll do it across the entire Mars data landscape. That?s on premises, cloud, internal, external, formal & informal data. You???ll look to the future too. That means thinking about how data assets yet to come can be integrated into the end-to-end Mars data landscape.
In everything you do, you?ll be thinking about the bigger business picture and making sure your solutions address specific business challenges. On top of that, you?ll work closely with the Enterprise Architecture function and other Mars Digital Technologies capabilities to ensure alignment with the Enterprise Architecture initiatives and capacity and infrastructure planning.
What you???ll need
To do all this, you???ll need:
Bachelors degree in IT, or similar experience
Extensive experience in??data integration and a year data orchestration experience with Microsoft Azure
In-depth experience of designing and implementing data flows and pipelines
3+??years’ experience as a Data Engineer is highly desirable
Comfortable being hands on with data, data modelling, query techniques
Background in the Data management Space
A good understanding of and adherence to data security standards
So, if you?ve got the skills we need and you?re looking for the opportunity to really make a mark in a world-renowned and supportive business going through a period of fast and massive digital transformation, this could be the role you???ve been waiting for.
??
Mars is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law. If you need assistance or an accommodation during the application process because of a disability, it is available upon request. The company is pleased to provide such assistance, and no applicant will be penalized as a result of such a request.
??
VEVRAA Federal Contractor
Request Priority Protected Veteran Referrals
EOE -Veteran /Disabled/Minority/AA/F/M/SO
To view full details and how to apply, please login or create a Job Seeker account.
",https://illinoisjoblink.illinois.gov/ada/r/jobs/5990346
JOB51362305479,NEW! Data Engineer,NEW! Data Engineer,,"Large scale treatment of operative data to develop analytics solutions and high quality systems for the product’s service cloud,Develop and evaluate data to make logical recommendations of data usage, treatment and storage,Implement alternatives to the existing system to improve the capacity, performance and robustness of the solution, detect problems with the application and define new methods for processing data,Analyse internal libraries and tools to enable our teams to work at maximum capacity,Experience in Software Engineering and Big Data solutions,Experience in AWS, services in cloud and other technologies used for Big Data: S3, Storm, Alluxio, NoSql, Drill, Redshift, Zookeeper, Docker, Kubernetes, Tableau, etc,Confident use of usual development environments and languages in these kind of solutions: Node.js, Clojure, SQL,Ability to analyse, design and be pro-active,Availability to travel,Good level of both spoken and written English,Experience in TV or media solutions,Experience in deployment of solutions, network dimensioning, AWS CloudFormation, etc,Fixed salary depending on the experience of the successful candidate,Variable incentives,Ticket RestaurantⓇ,Health insurance,Short working hours every Friday and throughout July and August,English classes,Flexibility with taking holidays,Fantastic work environment,Regular outdoor and team-building events,In-office perks such as Fruit Friday"," Do you have experience in Big Data? Do you enjoy working with AWS solutions? Then you may have the opportunity to join Mirada’s Analytics team.
Analytics at Mirada
Analytics is becoming a key feature in Mirada’s solution and it is being requested by most of our clients due to the huge additional value that it offers.
It basically consists of managing and analysing all the information received from clients (across STBs, tablets, mobiles and web), related to purchases, media consumption, audience measurement of live content, quality of service, content browsing and navigation across the different sections in the application.
This information needs to be collected, processed and presented in such a way that it provides very useful information to the TV Operators. It is also used for other services in the platform such as the recommendations engine or the mosaic which shows the most-watched channels in real time.
Click here to see a typical day for data dude, Nacho
What you will do:
Large scale treatment of operative data to develop analytics solutions and high quality systems for the product’s service cloud
Develop and evaluate data to make logical recommendations of data usage, treatment and storage
Implement alternatives to the existing system to improve the capacity, performance and robustness of the solution, detect problems with the application and define new methods for processing data
Analyse internal libraries and tools to enable our teams to work at maximum capacity
Work together with other technical experts within Mirada to define solutions and cross implementations, while keeping up with the evolution of development methodologies and architectural frameworks
What we require:
Experience in Software Engineering and Big Data solutions
Experience in AWS, services in cloud and other technologies used for Big Data: S3, Storm, Alluxio, NoSql, Drill, Redshift, Zookeeper, Docker, Kubernetes, Tableau, etc
Confident use of usual development environments and languages in these kind of solutions: Node.js, Clojure, SQL
Ability to analyse, design and be pro-active
Availability to travel
Good level of both spoken and written English
Friendly with a positive attitude to life
What we would love:
Experience in TV or media solutions
Experience in deployment of solutions, network dimensioning, AWS CloudFormation, etc
Experience in client-server solutions, HTTP, HTTPs, REST
What we offer:
Fixed salary depending on the experience of the successful candidate
Variable incentives
Ticket RestaurantⓇ
Health insurance
Short working hours every Friday and throughout July and August
English classes
Flexibility with taking holidays
Fantastic work environment
Regular outdoor and team-building events
In-office perks such as Fruit Friday
and much more…
Interested?
APPLY NOW
Connect with us for a sneak peek into life at Mirada:
A typical day at Mirada for data dude, Nacho
Before getting to the office, it’s sport time! I arrive at the gym next to the office with people from Mirada – usually HR! It’s great to see that in a tech company we are interested not only in geeky stuff but in sports too!!! 
After burning some calories, I arrive at the office and check my emails: no problems in the platform! I check our daily reports and the state of the processes that collect information from the platform and I can see that everything is running OK… Perfect!
Coffee break! We go to Juan’s bar for our daily dose of caffeine while we talk about new projects, the company, football and any other topic.
Back in the office, we check if there are new requirements for our reports: HBO has asked us if we can add a new field in the reports we generate with their VOD consumption. After a short meeting with the team to analyse if we are able to give them this information with the data we collect from the devices, we proceed to estimate how much time this change is going to take.
“It’s great to see that in a tech company we are interested not only in geeky stuff but in sports too!” Time to develop some SQL queries! We are working on a new report that needs to be integrated in the new system we are deploying in Amazon Web Services to know how people consume the VOD contents by HLS streams. We finish the query and upload it to the system and prepare its automatic execution.
Let’s go for lunch!! We meet in front on the office while we wait until people from several departments join us to go to a nice restaurant. There is a street full of them really close to the office and we have a great variety: Italian, typical Spanish food, Chinese… Today we choose Chinese food, “rollitos de primavera”!
After a good lunch and some more coffee, it’s time to check if the query developed works for a small set of data. All the results makes sense and only some minor fixes need to be done. Then we prepare the query to run automatically that night in a testing environment and tomorrow we’ll analyse the results.
Before leaving the office, I check if all the environment is running correctly and then I check my list of pending tasks to prepare tomorrow’s schedule. Enough for today! I leave the office and I meet some colleagues in the lift. We chat for a bit before we take the bus and say goodbye until a new day at Mirada arrives!
","https://www.indeed.es/empleo/New-data-engineer-para-mirada-en-Madrid,-Madrid-965e92b65059a3cc"
JOB54543077705,"GoDubai Jobs : Data Engineer, IT Software at United Arab Emirates","GoDubai Jobs : Data Engineer, IT Software at United Arab Emirates",,,"
Description
Data Engineer
The Role As the Data Engineer, you will support and sustain the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources and tools. You will showcase expertise and knowledge of AWS Data technologies whilst taking on large data asset...
Organisation : Michael Page
Other Similar Jobs
",http://www.godubai.com/jobs/job_view.asp?jid=397895
JOB54938083239,Senior Data Engineer at LogRhythm,Senior Data Engineer at LogRhythm,"3+ years of experience with at least one of the following: Google Cloud Dataflow/Google PubSub, Elasticsearch, Spark. Any of the following are a plus: Hadoop Kafka/Kinesis, BigQuery, Other distributed SQL/NoSSQL databases,3+ years of experience with at least one of the following: Python, Golang, Clojure and R,3+ year(s) experience with provisioned and on-demand cloud computing platforms such as GCP or AWS/Azure,3+ year(s) experience with standard development tooling (e.g. Git, Jira, etc.),Knowledge of distributed computing fundamentals and the ability to design for scalability on Linux platforms","Leverage modern analytics stacks and cloud platforms to design, implement and maintain scalable infrastructure for ingesting, processing and persisting large volumes of batched and streaming data.,Contribute to multiple production code bases in a continuous delivery (CI/CD) environment.,Write, debug, maintain and constructively review code on a highly collaborative software engineering team.,Develop production quality software for interacting with distributed data pipelines, data stores and data models.","
Overview
LogRhythm is the pioneer in Next Generation SIEM and Threat Lifecycle ManagementTM (TLM) technology, empowering organizations on six continents to rapidly detect, respond to and neutralize damaging cyberthreats. Our TLM platform unifies leading-edge data lake technology, artificial intelligence and security analytics to serve as the foundation for the AI-enabled security operations center. We are consistently recognized as a leader in the security intelligence domain and have been placed in Gartner’s SIEM Magic Quadrant for 6 consecutive years.
The LogRhythm Data Science team is seeking a qualified Senior Data Engineer with the requisite experience and passion for designing, implementing and delivering data-driven analytics products to support our customers need for advanced cyber threat detection and mitigation. The qualified individual is an experienced engineer who has demonstrated expertise with modern, scalable and distributed analytics platforms in a highly collaborative engineering environment. The Senior Data Engineer is expected to be a key contributor on a growing Data Science team.
Responsibilities
Leverage modern analytics stacks and cloud platforms to design, implement and maintain scalable infrastructure for ingesting, processing and persisting large volumes of batched and streaming data.
Contribute to multiple production code bases in a continuous delivery (CI/CD) environment.
Write, debug, maintain and constructively review code on a highly collaborative software engineering team.
Develop production quality software for interacting with distributed data pipelines, data stores and data models.
Provide thought leadership and advocate for best practices regarding big data and scalable processing and storage infrastructure.
Requirements
3+ years of experience with at least one of the following: Google Cloud Dataflow/Google PubSub, Elasticsearch, Spark. Any of the following are a plus: Hadoop Kafka/Kinesis, BigQuery, Other distributed SQL/NoSSQL databases
3+ years of experience with at least one of the following: Python, Golang, Clojure and R
3+ year(s) experience with provisioned and on-demand cloud computing platforms such as GCP or AWS/Azure
3+ year(s) experience with standard development tooling (e.g. Git, Jira, etc.)
Knowledge of distributed computing fundamentals and the ability to design for scalability on Linux platforms
Some experience with machine learning algorithms and libraries (e.g. scikit-learn)
LogRhythm is proud to be an equal opportunity employer. We are committed to equal opportunity regardless of race, color, ancestry, religion, gender, gender identity, genetic information, parental or pregnancy status, national origin, sexual orientation, age, citizenship, marital status, disability, or Veteran status.
",https://www.builtincolorado.com/job/data/senior-data-engineer/49120
JOB55443385357,"Big Data Engineer - Hadoop, SalesForce.com, SQL Server required","Big Data Engineer - Hadoop, SalesForce.com, SQL Server required",Google Analytics,"Help set up a data lake,Setup Integration points from various back end systems into the data lake,Help with the overall Big data strategy, architectural approach and Hadoop eco system tool selection,Big Data Engineer - Hadoop, SalesForce.com, SQL Server required,SQL Server (2008 & 2012),Web/Call Analytics,Hadoop/HDFS,Oozie,Sqoop,Kafka,Flume,SOAP/ RESTful web services,Java,PIG,Spark,Scala,HBASE,Cloudera,Good to have travel industry experience,Good working knowledge of Spark, Hive and Impala would be very beneficial,A good knowledge of the languages Scala and Java","
Big Data Engineer - Hadoop, SalesForce.com, SQL Server required - Berkshire - £550-£600pd
Spargonet Consulting, an IT Services Consultancy, is looking for a Big Data Engineer to help set-up a data lake for one of our customers in the Leisure Industry. This is a green field development opportunity. The ideal candidate will be able to provide thought leadership and architectural guidance. We are looking for an experienced engineer with a proven track record.
Main activities
Help set up a data lake
Setup Integration points from various back end systems into the data lake
Help with the overall Big data strategy, architectural approach and Hadoop eco system tool selection
Mandatory skills :
Big Data Engineer - Hadoop, SalesForce.com, SQL Server required
SQL Server (2008 & 2012)
Web/Call Analytics
Hadoop/HDFS
Oozie
Sqoop
Kafka
Flume
SOAP/ RESTful web services
Desired skills :
Java
PIG
Spark
Scala
HBASE
Cloudera
Working knowledge :
Good to have travel industry experience
Good working knowledge of Spark, Hive and Impala would be very beneficial
A good knowledge of the languages Scala and Java
Google Analytics
Spargonet Consulting Plc is a leading IT consultancy with over thirty years pedigree and experience of supplying IT services to household name blue chip clients within a range of business sectors. By joining the personable team at Spargonet, you become a valued member of our personnel with good prospects of a rewarding and challenging opportunity. All applications welcome for an informal and confidential discussion.
This job was originally posted as
www.cwjobs.co.uk - August 11
",https://www.careerjet.co.uk/clk/1fcf0e7d4a3e8d433ea59e1734f65188.html
JOB56367507978,Senior Data Engineer at PatientPop,Senior Data Engineer at PatientPop,,"5+ years of experience with data engineering and/or machine learning engineering,Strong proficiency in SQL and Python,Proven ability to devise innovative solutions.,Experience gathering complex business requirements and identifying data needs.,Extensive experience with the design and development of relational databases and data warehouses.,Extensive ETL development experience with large-scale DBS or big data systems.,AWS Redshift experience strongly preferred.,Experience supporting Data Scientists, including code optimization and productionalization of ML models.","
At PatientPop, we believe healthcare providers should focus their attention on delivering quality care to patients. That's why we take a holistic approach to improving every digital touchpoint along the patient journey with the leading all-in-one practice growth solution.
We've helped thousands of providers since our founding in 2014. Along the way, we cultivated an incredible work environment — one of the best, according to Great Place to Work.
Our dedicated team brings a blend of experiences that drives innovation and customer success. Our culture of continuous innovation allows employees to thrive personally and professionally. And our bustling (dog-friendly!) offices are in an enviable location: just two blocks from the beach and around the corner from 3rd Street Promenade.
Now, we want you to be a part of it all.
How you will contribute:
You will work with Data Engineers, Data Scientists, and Business Stakeholders from marketing, sales, product, customer success and finance to develop elegant solutions to meet data needs. You will deploy and maintain our portfolio of machine learning models and other data products and manage our in-house data science platform. You will define technical requirements and design the architecture for our pipelines and data warehouse. You will build optimized ETL processes, ensure data quality and consistency and enable access to data users across the company.
Skills you’ll bring:
5+ years of experience with data engineering and/or machine learning engineering
Strong proficiency in SQL and Python
Proven ability to devise innovative solutions.
Experience gathering complex business requirements and identifying data needs.
Extensive experience with the design and development of relational databases and data warehouses.
Extensive ETL development experience with large-scale DBS or big data systems.
AWS Redshift experience strongly preferred.
Experience supporting Data Scientists, including code optimization and productionalization of ML models.
Experience supporting BI reporting tools such as Periscope, Tableau or PowerBI.
Why you're important to us:
This role will significantly impact our organization by architecting and developing data warehouse solutions and productionalizing data products to help provide key market, customer and product insights. With these insights, we can prospect and sell more effectively and create high-value products to help our customers thrive.
In 90 days you will:
Define technical requirements and data architecture for our data warehouse. Build pipelines and databases to extend our industry-leading stores of market and user data. Deploy data products that support business decisions company-wide. You should prepare to have an immediate impact on the organization from day one. You’ll take this far beyond your first 90 days. Expect to constantly be learning, challenging yourself and strategizing with your team on building a world-class data engineering practice.
PatientPop has one simple mission: help healthcare practices thrive. Our solution is the leading all-in-one practice growth platform that's HIPAA-compliant and helps providers promote their practice online, attract patients, and retain them for life. Learn more at patientpop.com
We will consider for employment all qualified Applicants, including those with Criminal Histories, in a manner consistent with the requirements of applicable state and local laws, including the City of Los Angeles’ Fair Chance Initiative for Hiring Ordinance.
",https://www.builtinla.com/job/data/senior-data-engineer-sql-python/46339
JOB59920527839,"Software Architect, Data Engineer","Software Architect, Data Engineer",,,"
Ultimate Software is seeking a hands-on Software Architect, Data Engineer to help lead development of our Data Engineering capabilities. You will work to establish our nextgen data ingestion, transformation, and publishing capabilities and transform our current practices to take advantage of these capabilities.
This position demands strong leadership with the ability to collaborate across the organization as well as the ability and desire to roll up your sleeves and lead by example. You will be working with current and emerging technologies, with an emphasis on delivery. Excellent analytical skills, team orientation, flexibility, innovative thinking, problem solving, conflict management, and self-motivation are required. The opportunity requires you to be able to contribute at a senior level, to design, develop, troubleshoot, and debug complex data issues, at the enterprise level. As an architect, you will collaborate with both product, engineering and operations teams so great communication skills are a necessity.
Ultimate is ranked #1 on FORTUNE's ""Best Places to Work in Technology"" for 2017 and #15 for ""100 Best Places to Work For"" in 2016. Ultimate is also ranked #5 on the inaugural list of ""100 Best Workplaces for Millennials,"" #5 on Fortune's ""50 Best Workplaces for Diversity,"" and #8 on Forbes magazine's 2016 list of ""Most Innovative Growth Companies.""
Primary Duties and Responsibilities:
* Deliver capabilities to ingest, transform and publish data in near-real-time and batch using a variety of technologies
* Establish data engineering operational practices to ensure timeliness, completeness and quality.
* Produce quality code, tests, and documentation.
* Build consensus around approach and help to manage people through change.
* Ensure appropriate levels of service are met in terms of performance, scale, and availability.
* Research, design, test, and evaluate new technologies, platforms and third party products
* Work with technology teams to prototype and prove the viability of solutions
* Facilitate production implementation of solutions
* Ensure alignment of solutions with Enterprise Architecture principles and guidelines
* Provide leadership and expertise in the development of standards, architectural governance, design patterns, and practices
Requirements:
* 5+ years of experience leading development of a modern data architecture
* Experience working in a data engineering operation in a multi-tenant Enterprise SaaS environment.
* Experience operationalizing a data lake in a production environment that spans multiple regions.
* Production Experience with Mongo, Hadoop, and RDBMS's.
* Production Experience with other modern data engineering tools like:
* HBase
* Spark
* Hive
* Impala
* Sqoop
* Kafka
* Flume
* Etc...
* Experience standing up a data lake/warehouse in a private cloud environment is desirable.
* Experience establishing data security practices in a multi-tenant environment.
* Experience designing backup and recovery strategies for critical infrastructure and data.
Travel Requirement:
* If located in South Florida, limited upon request
* If working out of one of our other offices (Atlanta, Toronto, San Fran) travel to South Florida (HQ) up to twice per month for several days
This job description has been written to include the general nature of work performed. It is not designed to contain a comprehensive detailed inventory of all duties, responsibilities and qualifications required of employees assigned to this job.jsw3fd1034e:NTRkODIxZGFjYjJkNTRiMDk3YjY1NmQ3NGVmMzc3MjZfMjI4X2k=
",https://www.classifiedads.com/technical_jobs/81wwywq5ndf8
JOB60024063453,Data Engineer,Data Engineer,"BS in Computer Science, Data Science, or equivalent,2+ years of professional software development or data engineering experience,Strong CS and data engineering fundamentals,Proven fluency in SQL and a development language such as Python,Understanding of ETL/ELT pipelines and Data Warehousing design, tooling, and support,Understanding of different data formatting (JSON, CSV, XML) and data storage techniques (3NF, EAV Model, Star Schema, Data Lake),Experience with tools we use every day:,Storage: Snowflake, AWS Storage Services (S3, RDS, Glacier, DynamoDB),ETL/BI: Matillion, Looker,Experience with tools we don't use,Proven passion and talent for teaching fellow engineers and non-engineers,Proven passion for building and learning: open source contributions, pet projects, self-education, Stack Overflow","respecting privacy and ensuring security while offering useful insights by making smart choices in tech stack, database design, and encryption,helping school principals understand how teachers are teaching and how students are learning by architecting data warehouse schemas and SQL transforms with just the right CTEs, window functions, and pivots,immersing oneself in agile rituals and leveraging our infrastructure,leading collaboration, pull request-ing, and mentoring on a cross-functional team,participating in cross-team share-outs, brownbags, and workshop series","
A pioneer in K-12 education since 2000, Amplify is leading the way in next-generation curriculum and assessment. Our captivating core and supplemental programs in ELA, math, and science engage all students in rigorous learning and inspire them to think deeply, creatively, and for themselves. Our formative assessment products turn data into practical instructional support to help students at every skill level build a strong foundation in early reading and math. Our programs provide teachers with powerful tools that help them understand and respond to the needs of all their students. Today, Amplify serves five million students in all 50 states.
Amplify is a leader in creating immersive, rigorous digital learning experiences that look great, play great, and help students expect great things of themselves. Amplify has been described as the best tech company in education, and the best education company in tech.
As an engineer at Amplify, you will join a talented team tackling the toughest problems in education with the best ideas in technology - including user experience, APIs and services, data analysis, and deployment pipelines. You'll play an active role in imagining and improving product design and the classroom experience.
What You'll Do
Our data team builds, augments, and maintains the infrastructure that empowers teams across Amplify and our customers to make sense of and tell stories with their data. We believe strongly in teaching our teammates to serve themselves, within a safe, reliable, and agile environment. You'll be building data systems, but also the sharing-and-learning culture so that every team uses these tools to improve their own lives, and those of our students and teachers.
Impress the toughest customers around - students - by:
helping teams create fun, compelling apps by leveraging millions of data points
Make life better for passionate teachers by:
helping teachers understand their students by building reusable data pipelines
Make life better for passionate, Marketing and Sales teams by:
using REST APIs for sourcing/sending data to SaaS like Salesforce and HubSpot
Help school administrators build great schools by:
respecting privacy and ensuring security while offering useful insights by making smart choices in tech stack, database design, and encryption
helping school principals understand how teachers are teaching and how students are learning by architecting data warehouse schemas and SQL transforms with just the right CTEs, window functions, and pivots
analyzing performance and squashing tricky bugs using tools like Snowflake, Matillion, SQL, Python, Looker, and Datadog
Learn every day by:
immersing oneself in agile rituals and leveraging our infrastructure
leading collaboration, pull request-ing, and mentoring on a cross-functional team
participating in cross-team share-outs, brownbags, and workshop series
becoming an expert in the data models and standards within Amplify and the educational industry in order to deliver quality and consistent solutions
Example Projects You Might Work On
Building well-tested and optimized ETL data pipelines for both full and delta extraction
Collaborating with data scientists to store, aggregate, and calculate captured students' work
Contributing to leading industry data standards, such as Caliper Analytics or xAPI
Improving our deployment and testing automation data pipelines
Basic Requirements
BS in Computer Science, Data Science, or equivalent
2+ years of professional software development or data engineering experience
Strong CS and data engineering fundamentals
Proven fluency in SQL and a development language such as Python
Understanding of ETL/ELT pipelines and Data Warehousing design, tooling, and support
Understanding of different data formatting (JSON, CSV, XML) and data storage techniques (3NF, EAV Model, Star Schema, Data Lake)
Strong communication skills in writing, conversation, and maybe silly gifs
Extra Credit For
Experience with tools we use every day:
Storage: Snowflake, AWS Storage Services (S3, RDS, Glacier, DynamoDB)
ETL/BI: Matillion, Looker
Cloud Infrastructure: AWS Kinesis, Lambda, API Gateway, Terraform
Experience with tools we don't use
Proven passion and talent for teaching fellow engineers and non-engineers
Proven passion for building and learning: open source contributions, pet projects, self-education, Stack Overflow
Experience in education or ed-tech
We celebrate diversity and are committed to creating an inclusive environment for all employees. To that end, we seek to recruit, develop and retain the most talented people from a diverse candidate pool.
Amplify is an Equal Opportunity Employer of Minorities, Females, Protected Veterans and Individuals with Disabilities.
This position may be funded, in whole or in part, through American Recovery & Reinvestment Act funds.
Amplify Education, Inc. is an E-Verify participant.
",https://www.topschooljobs.org/job/1186290/data-engineer
JOB63678321008,Data Engineer - Data Lakes,Data Engineer - Data Lakes,,,"
Description
Data Engineer - Data Lakes
The Role Chance to build data frameworks for a leading FTSE 250 company. Focus on building and maintaining highly optimized and available data pipelines from large scale data sets (data lakes). Client Details Key global player in 29 countries worldwide, delivering integrated services across the...
Contact:
Organisation : Michael Page
Other Similar Jobs
",http://www.godubai.com/jobs/jobdetails.asp?jid=378758
JOB64174650903,"Application for Senior Data Engineer, Cloud","Application for Senior Data Engineer, Cloud",,,"
Application for Senior Data Engineer, Cloud
Complete this form to apply for this job and upload your resume. Please note that there is a file upload limit of 1MB.
",https://secure2.sophos.com/hu-hu/about-us/careers/united-states/senior-data-engineer-cloud/apply.aspx
JOB65011889719,"Application for Senior Data Engineer, Cloud","Application for Senior Data Engineer, Cloud",,,"
Application for Senior Data Engineer, Cloud
Complete this form to apply for this job and upload your resume. Please note that there is a file upload limit of 1MB.
* Mandatory fields
Step 1: Contact details
Step 2: Supporting Information
",https://secure2.sophos.com/zh-cn/about-us/careers/united-states/senior-data-engineer-cloud/apply.aspx
JOB65564340674,Big Data Engineer,Big Data Engineer,,,"
Global video game publisher/developer headquartered in Rockville, MD, seeks a Big Data Engineer. This position works within the Enterprise BI Team and is responsible for the development of the Big Data Platform for Enterprise wide reporting. The Big Data Engineer will be supporting a broad range of data pipelining needs from all facets of the business, including e-commerce, financial, and game event data.
The incumbent will have at least 2+ years of previous experience partnering with both technical and business teams to facilitate implementation across the enterprise. The Big Data Engineer will facilitate the creation of data pipeline processes to move data from enterprise data sources such as relational databases and log files.
Responsibilities:
* Work within the Enterprise BI team, supporting the creation of data pipeline processes for ingesting data at large scales
* Work directly with Data Modelers, Enterprise Architect, and Analysts, ensuring that business requirements are being met
* Directly work with the Data Engineers and Data Modelers to understand the source and target structures
* Coordinate with the analysts and report developers to ensure data can be easily digested by Business Intelligence tools
* Be able to straddle differing subject areas such as in game vs business data sources
Requirements:
* 2+ Years of Experience with the Hadoop ecosystem (Hive, Parquet, Avro)
* A clear understanding of both row and columnar storage databases
* Strong SQL skills ? able to query data sources and generate results from complex structures
* Experience with a major programming language (Scala, Python, C, Java, etc)
* Comfortable working with structured, semi-structured, and unstructured source data
* A strong communicator, is comfortable interfacing directly with differing customers across the organization in addition to the BI team
* Working experience with the SCRUM development framework
Preferred Skills:
* Apache Spark experience a major plus (Spark RDDs, Spark DataFrames, Spark SQL)
* Understanding of Amazon Web Services, especially data related components
* Experience working within the VideoGame/MMO industry is desired, though candidates from outside of the industry are also welcomed
* A personal interest in video gaming is a plus
* Understanding of the Free to Play/Micro transaction Business Model is a plus
",http://www.classifiedads.com/technical_jobs/25bwrsh3rdbf
JOB65610010967,Data Engineer - AWS Kinesis,Data Engineer - AWS Kinesis,,,"
Job Details
Data Engineer - AWS Kinesis
Description
Data Engineer - AWS Kinesis
The Role Data Engineer (AWS Kinesis is a MUST) We are working with an exciting company that are growing massively in the Energy/Trading sector. Over the years they have grown organically. Considering their further ambitions, they would like to welcome a Data Engineer into their team. They will ...
Organisation : GroupL
Please Like Us on facebook to see job apply and more details.
Other Similar Jobs
",http://www.godubai.com/jobs/jobdetails.asp?jid=411197
JOB69346806219,Lead Data Engineer,Lead Data Engineer,"Their current tech stack includes: Python, Go, AWS, Spark, GraphDB, Docker, Kubernetes, Jenkins, JSON and Git.,Extensive experience with developing data solutions on AWS.,Experience in building a data vision and/or strategy together with upper management.,Previous experience within FinTech or a related area is a plus.","Chance to work in a high priority business role with tangible impact.,Ability to lead and ultimately grow a data team to maximise data potential.,Innovative scaleup atmosphere with flat hierarchy and short lines of communication.,Chance to work with and implement new and innovative technologies.","
As the Lead Data Engineer you will be leading from the technical perspective on data development, architecture and strategy. Building out an AWS data lake (think S3, Glue, Athena, Codebuild, Redshift Spectrum etc) with complex data sources, and a DevOps mindset, will be the challenge. This will suit a Senior or Lead Data Engineer who is looking for high business impact and the opportunity to shape things their way to ensure scalability, reliability and availability. This is still a majority hands-on role.
Perks:
Chance to work in a high priority business role with tangible impact.
Ability to lead and ultimately grow a data team to maximise data potential.
Innovative scaleup atmosphere with flat hierarchy and short lines of communication.
Chance to work with and implement new and innovative technologies.
Requirements:
Their current tech stack includes: Python, Go, AWS, Spark, GraphDB, Docker, Kubernetes, Jenkins, JSON and Git.
Extensive experience with developing data solutions on AWS.
Experience in building a data vision and/or strategy together with upper management.
Previous experience within FinTech or a related area is a plus.
6-10 Years
40 hours per week
This major Amsterdam scaleup are building a next-gen FinTech platform supporting small and medium businesses in scaling their organisations. With a C level built from Europe’s most successful digital banks, they are on a mission to drive innovation in the industry and deliver fully automated systems.
",https://www.iamexpat.nl/career/jobs-netherlands/it-technology/lead-data-engineer/353055
JOB74290472246,Internship Data Engineer - Paddy Power Betfair,Internship Data Engineer - Paddy Power Betfair,,Internship,"
This job is no longer active!
Vacancy Name Internship Data Engineer
Employment Type Internship
Work Location Cluj - Napoca
About Us Paddy Power Betfair plc is an international sports betting and gaming operator, with a market-leading presence in the UK, Ireland, Australia and the USA, as well as a range of operations across Europe including Romania, Portugal and Malta.
We operate five sports betting and gaming brands; Paddy Power, Betfair, Sportsbet, FanDuel and TVG. We are online-led, mobile-led and sports-led: and our proprietary technology, unique products and innovative marketing all combine to offer a superb experience to our five million customers worldwide.
Our spirit, talent and ambition has taken us into the FTSE 100 index of the London Stock Exchange and we now employ over 7,000 people in sixteen locations across the globe; from Dublin to Los Angeles, and London to Melbourne. Our culture rewards innovation, teamwork and we like to stay fast-moving in a dynamic industry.
Description The Role
We are looking for an enthusiastic, self-motivated, Data Engineer intern to join our great team of engineers in building high-end, high quality applications.
Working within an agile environment you will team up with Data Warehouse, ML, data services and QA engineers and system integrators to work on projects prioritized by various areas of the business;
Key Responsibilities / Duties:
* Work as an effective member of a scrum team - understanding and contributing to the agile delivery process, and taking ownership for your team’s software quality from concept to production
* To ensure risks and issues are identified in a timely manner and effectively communicated with proposed resolution and mitigation strategies to the Data Delivery Manager.
* Write and maintain functional and technical specifications
* Analyse code for problem resolution
Key Skills & Attributes
* Strong desire to learn along with professional drive
* Ability to work in a fast paced, team oriented environment
* Strong written and verbal communication skills
* Strong analytical skills.
* Enthusiasm for the software development process.
* Proactive work ethic with the ability to deliver results and meet challenging deadlines
* Good English language skills
Experience & Qualifications Desirable
* Educated to degree level in a science or technology related field
* Competent with object oriented or functional programming
* Experience using relational databases such as Oracle
* Experience in writing SQL
* Experience in ETL/ELT/BI Tools
* Unit testing knowledge
* Knowledge of ML or analytics
* Knowledge of the online gaming/gambling industry
* Demonstrates exceptional communication, interpersonal skills and consistent high energy levels
Our Values Our values are important to us. In fact they shape and guide everything we do – from improving our performance and working as a team, to hiring the right people and developing our talent.
There are five key values that we live by:
Relentless Will To Win: We strive to stay ahead of the game and achieve more for our customers and each other.
Collaboration: We win by having the best people, working well together and building strong relationships.
Integrity: We take pride in doing what’s right. No exceptions.
Agility: We adapt at pace and with purpose, and thrive amid change.
Low Ego: We take our work seriously but not ourselves, and never believe our own hype.
Applying to this job ad you give your consent for your information to be processed by Jobs from top companies in Romania.
Please read the Personal Data Processing Policy, Jobs from top companies in Romania >>
",https://www.hipo.ro/locuri-de-munca/locuri_de_munca/120047/Jobs-from-top-companies-in-Romania/Internship-Data-Engineer---Paddy-Power-Betfair
JOB79611953880,Senior Data Engineer,Senior Data Engineer,,"Collaborate with Product Owners and Team Leads to identify, design, and implement new features to support the growing real time data needs of Intelligent Retail Lab,Assist and mentor Junior Engineers in troubleshooting and tuning of high volume, distributed applications.,Identify and suggest or implement remediation of cases where we diverge from industry best practices,Evangelize and practice an extremely high standard of code quality, system reliability, and performance to ensure SLAs are metfor uptime, data freshness, data correctness, and quality,Display sense of ownership over assigned work, requiring minimal direction and driving to completion in a sometimes fuzzy and uncharted environment,Focus on enabling developers and analysts through self-service and automated tooling, rather than manual requests and acting as a gatekeeper,Participate in on-call rotation, including continuously seeking to reduce noise, improve monitoring coverage, and improve quality-of-life for on-call engineers,3-5 years experience in running, using and troubleshooting industry standard data technologies such as Spark, HDFS, Cassandra, Kafka,Deep development experience, ideally in a typed language but we are open to other experience if you’re willing to learn the languages we use,Experience processing large amounts of structured and unstructured data in streaming and batch.,Experience with integrating with Business Insights tooling, ideally Power BI from Microsoft,Experience with cloud infrastructure. We use Azure, specifically, but any will do,A focus on automation and providing leverage-based solutions to enable sustainable and scalable growth in an ever-changing ecosystem.,Experience building and maintaining a centralized platform or services, to be consumed by other teams, is ideal, but not necessary,A passion for Operational Excellence and SRE/DevOps mindset, including an eye for monitoring, alerting, self-healing, and automation","
Walmart’s Store No 8 is an innovation hub formed by the world’s largest retailer focuses on identifying and investing in trends and technologies reshaping the shopping experience. It's mission is to create step change in-store experiences, leveraging emerging technology to help define and deliver on evolving customer expectations. Its success requires a cross-functional, mission-based team that is highly entrepreneurial, collaborative and passionate about solving the unsolved problems.
We are looking for an exceptional Senior Software Engineer to help design, build and run the business data platform that powers streaming data generated by a fast-moving landscape. This team places an emphasis on producing robust, scalable, self-service solutions that enable Engineers and Analysts to perform complex streaming transformations across a wide array of use cases to power insights, decisions, and machine learning within the Intelligent Retail Lab ecosystem.
About the Role
This role will be responsible for utilizing industry best technologies and practices to enable analysis, intelligence, and processing of some of the largest datasets at Intelligent Retail Lab in near-real-time. As a Senior Software Engineer, this role will be counted on to have a deep understanding of technology internals in order to tune and troubleshoot individual jobs, as well as a high-level understanding of the landscape to drive value adding features to the platform. This role would take on the following responsibilities:
Collaborate with Product Owners and Team Leads to identify, design, and implement new features to support the growing real time data needs of Intelligent Retail Lab
Assist and mentor Junior Engineers in troubleshooting and tuning of high volume, distributed applications.
Identify and suggest or implement remediation of cases where we diverge from industry best practices
Evangelize and practice an extremely high standard of code quality, system reliability, and performance to ensure SLAs are metfor uptime, data freshness, data correctness, and quality
Display sense of ownership over assigned work, requiring minimal direction and driving to completion in a sometimes fuzzy and uncharted environment
Focus on enabling developers and analysts through self-service and automated tooling, rather than manual requests and acting as a gatekeeper
Participate in on-call rotation, including continuously seeking to reduce noise, improve monitoring coverage, and improve quality-of-life for on-call engineers
About You
3-5 years experience in running, using and troubleshooting industry standard data technologies such as Spark, HDFS, Cassandra, Kafka
Deep development experience, ideally in a typed language but we are open to other experience if you’re willing to learn the languages we use
Experience processing large amounts of structured and unstructured data in streaming and batch.
Experience with integrating with Business Insights tooling, ideally Power BI from Microsoft
Experience with cloud infrastructure. We use Azure, specifically, but any will do
A focus on automation and providing leverage-based solutions to enable sustainable and scalable growth in an ever-changing ecosystem.
Experience building and maintaining a centralized platform or services, to be consumed by other teams, is ideal, but not necessary
A passion for Operational Excellence and SRE/DevOps mindset, including an eye for monitoring, alerting, self-healing, and automation
Experience in an Agile environment, able to manage scope and iterate quickly to consistently deliver value to the customer
",https://careers.walmart.com/us/jobs/GH2084377-senior-data-engineer-hoboken-nj
JOB79847078947,Data Engineer (Data warehouse developer / BI developer / ETL developer),Data Engineer (Data warehouse developer / BI developer / ETL developer),"Fluent English language skills is essential, Dutch language skills is considered a plus","design, build and maintain Allseas companywide global Data Warehouse (could be cloud based!),manage data coming from multiple domains (sources) and modelling such it can be used by the end-users/ Allseas organisation,develop/ maintain ETL processes,regarding projects, review proposals for development and advice,maintaining and improving general security of the applications and control access of end-users,HBO degree in IT or equivalent,Minimum of 3 years’ experience with ETL processes/ tooling","
We are looking for a Data Engineer with specialist knowledge of Business Intelligence (BI), ETL processes, SQL, Data Vault and relational/dimensional modelling to join our data and analytics team in Delft, the Netherlands.
Your role
As a Data Engineer you are primarily responsible for designing, building and maintaining a new central, global data warehouse, collecting and managing vast amounts of data from multiple sources all over the world (including our vessels) and modelling it for end-users organisation-wide.
Together with key users, you will work on new analytics solutions or improve existing solutions to provide better insights, develop and maintain ETL processes, and enhance the data retrieval and reporting procedures critical for company reporting tool(s), Oracle BI / Microsoft Power BI.
Our ideal candidate will have at least three years’ experience: knowledge of SQL, ETL processes and relevant experience setting up and maintain a central Data Warehouse using Data Vault, relational and dimensional modelling technics. Experience with Data Vault is a key aspect for this role.
You must be able to demonstrate a high level of interpersonal and communications skills, teamwork orientation, leadership and assertiveness, excellent organisational skills and the ability to prioritise your workload. Flexibility and a strong desire to learn is key to success in this position.
Your key responsibilities will be to
design, build and maintain Allseas companywide global Data Warehouse (could be cloud based!)
manage data coming from multiple domains (sources) and modelling such it can be used by the end-users/ Allseas organisation
develop/ maintain ETL processes
regarding projects, review proposals for development and advice
maintaining and improving general security of the applications and control access of end-users
What we expect from you
For this role we are looking for candidates who are able to work well in a high pressure environment while maintaining a pragmatic approach with proven experience with setting up and maintaining Data Warehouse using Data Vault, relational -and dimensional modelling. You are a pro-active, stress tolerant and self-starter with strong communication, analytical and problem solving skills and able to organise and plan own work together with team-members
Besides this you will have:
HBO degree in IT or equivalent
Minimum of 3 years’ experience with ETL processes/ tooling
Fluent English language skills is essential, Dutch language skills is considered a plus
What we offer you
In our dynamic, rapidly changing company no two days are the same. You will be working in a positive, collaborative and creative culture with team spirit at its core. Working at Allseas means choosing for personal growth and development. We facilitate you with many opportunities, including study budgets, training and coaching.
Besides this we offer you: Flexible working hours and 30 vacation days (FTE), A good salary, travel allowance and option to join our collective health insurance and pension arrangements
Interested?
You can apply for this exiting role by clicking ‘Apply’.
Acquisition is not appreciated
In our application procedure, you can read what to expect when you apply for a job at Allseas.
Apply with resume
Or call us at +31 15 2681800
",https://allseas.com/vacancy/642/functional-system-administrator-oracle-business-intelligence-bi-specialist/
JOB81714106745,Senior Data Engineer – Big Data Monetization,Senior Data Engineer – Big Data Monetization,,,"
Description
Senior Data Engineer – Big Data Monetization
The Role The purpose of this position is to design and implement data products that can produce actionable insights which third parties will be willing to pay for. The job holder will ensure clear project and resource planning for ‘Big Data’ monetization products. The nature of the job requires...
Organisation : Du Telecoms
Other Similar Jobs
",http://www.godubai.com/jobs/jobdetails.asp?jid=374014
JOB83317100874,Data Engineer - Start up,Data Engineer - Start up,,,"
Description
Digital Analytics Manager
The Role I am currently working with a high growth fintech company that is seeking to improve its digital capability by hiring a Digital Analytics Manager. In this role, you will lead the digital analytics strategy, working alongside key stakeholders to enhance their full digital suite to drive...
Contact:
Organisation : CSG - BW Penman - UAE
Other Similar Jobs
Job Title
Location
",http://www.godubai.com/jobs/jobdetails.asp?jid=381695
JOB83330029019,Data Engineer - Developer,Data Engineer - Developer,,," Professional opportunity for a Data Engineer/Developer, working for a Digital Marketing agency and Editorial Group, to join the data team in charge of databases and large scale processing systems in Amazon AWS, with Spark (Scala) programming skills and NoSQL Databases knowledges (f.i. MongoDB and Redshift).
The company, focused on digital marketing, counts with DBs ot its ownership and affiliate databases, delivering 178 Million Optin emails across Europe.
Based on its experience, the company counts with a platform to create and deliver dynamic personalized ads & content based on user behavioral information.
The company counts with a multidisciplinary & multicultural team with a lot of experience in digital marketing, communication, programming, design and especially email marketing.
Looking for a versatile, passionate, pro-active and team-player Data Engineer / Developer to join the current development team & work closely with the Data Analyst /BI.
The main responsibilities will be:
Develops, constructs, tests and maintain company databases and large scale processing systems.
Programming using Spark (Scala) and MongoDb / Redshift
Knowledge in AWS Services (S3, Kinesis, Lambda, APIGateway)
Microservices oriented.
Agile (Scrum and Kanban). We use Jira/Confluence from Atlassian.
Construct and refine reports in Tableau
Requirements:
Counting with Bachelor Degree studies in Physics, Mathematics, Statistics or Computer Science, you must count with experience in a programming with Spark and Scala and storing data with MongoDB & Amazon Redshift.
It will also be necessary counting with knowledge and skills with Database systems SQL & NoSQL, Data Modeling & ETL Tools, Data warehousing. Business understanding is valued and helpful. We expect the candidate to be fluent working with Data Visualization and if possible with BI tools integration.
In addition to the previous mentioned requirements, it will be valued to count with good communication skills. You will be working every day with marketing and commercial teams.
Knowledge and passion of Data Science, Data Management Platforms, Machine Learning, Deep Learning, Graph Databases (Neo4j), Advanced or Predictive Statistics - > are big pluses!
Spanish or English is required, not necessary both.
The company offers you the opportunity to be involved on the Data exploitation team, working daily around business data in most innovative technologies in the market.
If you consider yourself the perfect professional to address this challenge, do no hesitate to apply for this position.
","http://www.indeed.es/empleo/Data-engineer-para-Robert-Walters-en-Barcelona,-Barcelona-829aa887cb8a37dd"
JOB83860140534,Data Engineer,Data Engineer,,,"
Kelly Services is currently seeking a Data Engineer for a 12+ month long contract in Schenectady, NY. Ideal candidates will have 3+ years of experience with SQL Server and ETL Processes. Below are additional details.
For immediate consideration: Send an updated resume to [Click Here to Email Your Resum?]. Please include the job title, location of the position and desired hourly rate on a W2 basis.
In this role, you will perform a variety of in-depth data analysis, data modeling, and data design tasks on complicated datasets with potentially complex data integration scenarios. Provide Operational support for the data warehousing applications, including quarantine maintenance, troubleshooting, monitoring and resolving bugs and production issues in a timely manner. Proficient in SQL and ETL processes, ETL and DB performance tuning, table partitioning, shell scripting. Works with Product Owners, and Business SME to identify requirements and drive ingestions standards consistent with business processes. This role will work with cross functional teams from Engineering, Services, and Digital to develop, test, and validate software tools in an Agile development environment. Your focus will be to rapidly prototype solutions that delivers valuable and actionable insights based on Wind turbine operational performance data.
Essential Responsibilities:
In this role, you will:
? Develop scripting / programming in Java, Python, Matlab, and / or R
? Develop and compute critical wind turbine performance metrics that drive action across all organizations in the business
? Work closely with IT teams to ensure high quality data is available in the Global Repository (central data warehouse).
? Build software and create data structures to rapidly make important information available to both internal and external customers.
? Develop SQL queries against a Greenplum (Postgresql) data warehouse.
? Rapidly deliver customized datasets and analysis to support teams in resolving high visibility issues.
? Build tools and utilities to automate workflows, reporting tasks, and batch process data.
? Administer local database and application server instances that host team utility apps.
? Guide infrastructure and database improvement development as a representative of FRO.
Basic Qualifications:
? Bachelor's Degree in Computer Engineering, Information Technology, Electrical Engineering, Computer Science from an accredited college or university or equivalent experience
? Minimum of 5 years of experience working in data visualization and analysis.
? Minimum of 2 years of experience with relational database (Oracle, Greenplum, or MS SQL Server) design and development, proficient with Transact SQL.
? 3+ years? experience creating the specification and detailed design of software development projects.
? Database design and configuration
Desired Characteristics:
? Previous experience with wind turbine software and firmware packages including: WindSCADA, VisuPro, ControlST (ToolboxST, WorkstationST), Bachmann PLC software and tools, Mark VIecontrol systems
? Strong focus on data integrity and traceability working in big data environments.
? Previous experience working with large data sets using big data technologies including Greenplum or other MPP database systems
? Cloud based application development and deployment (such as experience with developing on AWS, Heroku, Cloud Foundry or Predix)
? Server side Java development (or server side Python or Node.js)
? UI/UX designer ? using technologies like Angular JS and Polymer
? Database/data modeling (RDBMS and/or NoSQL)
? Capable of implementing RESTful API
? Unit testing and documentation
? Capable of implementing security on https based application (OAuth2 experience)
? Previous experience with advanced SQL programming including DML and DDL
? Familiarity with scripting / programming in Java, Python, Matlab, and/or R
? Strong knowledge of SQL and retrieving data from relational database systems
? Ability to work effectively in a matrix environment
? Superior analytical skills, with strong desire to improve processes and performance
? Ability to work effectively within all levels of the organization and customers
? Strong presentation skills
? Distinctive ability to analyze technical processes
? Strong communication and project leadership skills with ability to clearly communicate issues and resolution to both a technical and non-technical audience
? Strong customer service focus and desire for continual improvement
? Ability to take decisions and to adopt responsibility
? Strong quality awareness and ability to identify future failures, defects and problems
? Experience to working with multicultural teams
? Strong team player with structured work methods and analytical skills
? High flexibility and motivation to succeed
? Previous experience leading cross functional projects
? Experience with direct customer contact
? Distinctive ability to execute technical processes
? Strong communication and leadership skills with ability to clearly communicate issues and resolution to both a technical and non-technical audience
? Strong customer service focus and desire for continual improvement
? Ability to take decisions and to adopt responsibility
? Strong quality awareness and ability to identify future failures, defects and problems
? Experience to working with multicultural teams
? Strong team player with structured work methods and analytical skills
? High flexibility and motivation to succeed
? Six Sigma Green Belt / Black Belt Certification or equivalent quality certification
With Kelly, you?ll have direct connections to leading IT organizations in the best companies around the globe?offering you the chance to work on some of today?s most intriguing, innovative and high-visibility projects. In a field where change is the only constant, our connections and opportunities will help you take your career exactly where you want to go. We work with 95 of the Fortune 100? companies, and more than 9,000 IT hiring managers turn to us each year to access the best talent: people like you.
Last year we found 10,000 opportunities for IT professionals. Let us help advance your career today.
As a workforce advocate for over 70 years, we are proud to have a role in managing employment opportunities for more than one million workers around the globe. We employ 550,000 of these individuals directly with the remaining workers engaged through our talent supply chain network of supplier partners. Revenue in 2015 was $5.5 billion. Visit kellyservices.com and connect with us on Facebook, LinkedIn and Twitter.
Kelly Services is an equal opportunity employer including, but not limited to, Minorities, Females, Individuals with Disabilities, Protected Veterans, Sexual Orientation, Gender Identity and is committed to employing a diverse workforce. Equal Employment Opportunity is The Law.
jsw3fd1034e:NF9KM0szRFE2WUJRUlNIVjk5RDc1XzIyM19i
",http://www.classifiedads.com/technical_jobs/cc47dkyx1x18
JOB84220367181,Cyber Security Data Engineer (Dubai),Cyber Security Data Engineer (Dubai),,,"
Job Details
Cyber Security Data Engineer (Dubai)
Description
Cyber Security Data Engineer (Dubai)
O Experience with agile or other rapid application development methods. You will work closely with other team members to continually evolve data solutions as...
Organisation : Spinwell
Other Similar Jobs
",http://www.godubai.com/jobs/jobdetails.asp?jid=245636
JOB90018385671,"Supervising Data Engineer (150950QSA) Croydon, England","Supervising Data Engineer (150950QSA) Croydon, England",,,"
Morson International are looking for a supervising data centre engineer for one of the UK’s leading independent engineering, IT and facilities services business.
Long term contract based in Croydon with an immediate start.
On offer:
• Temporary contract - paid weekly to LTD, Umbrella & PAYE.
• Immediate start
• Competitive hourly rate
Duties include, not limited to:
• Dealing with the customer on a daily basis to coordinate and manage escalations for data issues.
• Planning of upcoming works via change requests
• On-site service support of networks
• Planning of patching requests
• Racking and stacking of hardware (Switches and Servers)
• Patching of Cat6A, MM LC-LC/MTP, SM MTP
• Low level Break fix (patching, drives, PSU’s etc)
If you have the experience required and available for an immediate start, please call Quade on 0207 633 2050 or apply online TODAY!
",http://www.aplitrak.com/?adid=UXVhZGUuU21pdGhBbGxlbi42OTM0MS41MjYxQG1vcnNvbi5hcGxpdHJhay5jb20
JOB92089980530,"Senior Data Engineer (Chicago, US)","Senior Data Engineer (Chicago, US)","A workplace recognized as the Best Consumer Web Company by Built in Chicago, Top Company Culture by Entrepreneur, a Top Workplace by Chicago Tribune, and one of Chicago’s Best Places to Work for Women Under 35 by Crain’s Chicago Business.","Work with our analytics and data science teams to understand our data processing needs,Be a key hands-on contributor to the design and implementation of our data platform from the infrastructure layer up to the API,Model and architect our data in a way that will scale with the increasingly complex ways we’re analyzing it,Build robust pipelines that make sure data is where it needs to be, when it needs to be there,Build frameworks and tools to help our software engineers, data analysts and scientists design and build their own data pipelines in a self-service manner,Performance testing and engineering to ensure that our systems always scale to meet our needs,Incorporate our data science models back into our customer-facing products,Key member of the team focused on pure hands-on contribution to the implementation and operation of our data platform,We value humility, a strong work ethic, flexibility, collaboration, technical curiosity, and constant learning,At least one project that demonstrate prowess in designing, implementing, and operating large scale, high throughput, low latency distributed systems,You can go up and down the stack from deep in the infrastructure layer all the way up to the client libraries,Experience with small teams that move fast -- all members are expected to be able to achieve maximum results with minimal direction,You have at least 7 years of hands on experience as an Engineer across multiple environments on complex distributed polyglot systems. While we primarily work in Python and Java, we welcome others with relevant experience in languages like Scala, Clojure, Go, or C++,Kubernetes and/or Docker experience,Message driven or streaming architectures, such as those with Kafka, Spark, Flink, RabbitMQ, etc.,Postgres, MySql, or other RDBMS experience,AWS, GCP and/or Azure experience,Redshift, Presto, or other MPP database experience,Airflow, Luigi, or other ETL scheduling tool experience,Open source contributions to a few major projects,Career game changer – A truly unique experience to work for a fast-growing startup in a role with unlimited potential for growth.,Excellent benefits – We cover 90% of Medical Premiums, 50% of Dental & Vision Premiums, and offer company sponsored Life Insurance.,Flexible PTO policy, generous parental leave, and great work/life balance – We value and support each individual team member.,Fun perks like snacks, catered lunches, happy hours, wellness programs, and SpotHero swag.,Annual parking stipend (duh – we help people park!).,The opportunity to collaborate with fun, innovative, and passionate people in a casual, yet highly productive atmosphere.","
SpotHero
SpotHero is seeking a Senior Engineer be part of the team building our data platform. The team owns the solution to help us scale out to build a future where the SpotHero platform surfaces real time parking inventory across the United States for millions of customers.
SpotHero is a fast-growing market leader disrupting the mobility space. Drivers across the nation use the SpotHero mobile app, website, and connected car integrations to reserve convenient, affordable parking. Parking companies rely on us to help them reach new customers while optimizing their business. We connect the dots with cutting-edge technology, delivering value to both sides of this exciting, evolving marketplace.
What will you do:
Work with our analytics and data science teams to understand our data processing needs
Be a key hands-on contributor to the design and implementation of our data platform from the infrastructure layer up to the API
Model and architect our data in a way that will scale with the increasingly complex ways we’re analyzing it
Build robust pipelines that make sure data is where it needs to be, when it needs to be there
Build frameworks and tools to help our software engineers, data analysts and scientists design and build their own data pipelines in a self-service manner
Performance testing and engineering to ensure that our systems always scale to meet our needs
Incorporate our data science models back into our customer-facing products
Key member of the team focused on pure hands-on contribution to the implementation and operation of our data platform
Your experience:
We value humility, a strong work ethic, flexibility, collaboration, technical curiosity, and constant learning
At least one project that demonstrate prowess in designing, implementing, and operating large scale, high throughput, low latency distributed systems
You can go up and down the stack from deep in the infrastructure layer all the way up to the client libraries
Experience with small teams that move fast -- all members are expected to be able to achieve maximum results with minimal direction
You have at least 7 years of hands on experience as an Engineer across multiple environments on complex distributed polyglot systems. While we primarily work in Python and Java, we welcome others with relevant experience in languages like Scala, Clojure, Go, or C++
Nice to Haves:
Kubernetes and/or Docker experience
Message driven or streaming architectures, such as those with Kafka, Spark, Flink, RabbitMQ, etc.
Postgres, MySql, or other RDBMS experience
AWS, GCP and/or Azure experience
Redshift, Presto, or other MPP database experience
Airflow, Luigi, or other ETL scheduling tool experience
Open source contributions to a few major projects
What we are offering:
Career game changer – A truly unique experience to work for a fast-growing startup in a role with unlimited potential for growth.
Excellent benefits – We cover 90% of Medical Premiums, 50% of Dental & Vision Premiums, and offer company sponsored Life Insurance.
Flexible PTO policy, generous parental leave, and great work/life balance – We value and support each individual team member.
Fun perks like snacks, catered lunches, happy hours, wellness programs, and SpotHero swag.
Annual parking stipend (duh – we help people park!).
The opportunity to collaborate with fun, innovative, and passionate people in a casual, yet highly productive atmosphere.
A workplace recognized as the Best Consumer Web Company by Built in Chicago, Top Company Culture by Entrepreneur, a Top Workplace by Chicago Tribune, and one of Chicago’s Best Places to Work for Women Under 35 by Crain’s Chicago Business.
Apply for this job ",http://www.parking-net.com/parking-jobs/spothero/senior-data-engineer-chicago-us